{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_snp_all = pd.read_csv(\"./csv/all_train_snp_all_selected.csv\")\n",
    "validation_snp_all = pd.read_csv(\"./csv/validation_snp_all_selected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all_ = all_train_snp_all.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "X_val_all_ = validation_snp_all.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "y_all_train = all_train_snp_all[\"target\"] - 1\n",
    "y_val = validation_snp_all[\"target\"] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регрессия на всех SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC bigset: 0.5172\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "model_gb = LogisticRegression()\n",
    "model_gb.fit(X_train_all, y_all_train)\n",
    "\n",
    "y_pred_proba = model_gb.predict_proba(X_val_all)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4939\n",
      "ROC-AUC: 0.5709\n",
      "ROC-AUC: 0.5789\n",
      "ROC-AUC: 0.5632\n",
      "ROC-AUC: 0.5555\n",
      "среднее 0.5524895001890676\n"
     ]
    }
   ],
   "source": [
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    model_gb = LogisticRegression()\n",
    "    model_gb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг на всех SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC bigset: 0.5576\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "model_gb = GradientBoostingClassifier()\n",
    "model_gb.fit(X_train_all, y_all_train)\n",
    "\n",
    "y_pred_proba = model_gb.predict_proba(X_val_all)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5606\n",
      "ROC-AUC: 0.5723\n",
      "ROC-AUC: 0.6328\n",
      "ROC-AUC: 0.5440\n",
      "ROC-AUC: 0.5105\n",
      "среднее 0.5640355884352959\n"
     ]
    }
   ],
   "source": [
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    model_gb = GradientBoostingClassifier()\n",
    "    model_gb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC на всех SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC bigset: 0.5343\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "model_gb = SVC(probability=True)\n",
    "model_gb.fit(X_train_all, y_all_train)\n",
    "\n",
    "y_pred_proba = model_gb.predict_proba(X_val_all)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.4972\n",
      "ROC-AUC: 0.5809\n",
      "ROC-AUC: 0.5716\n",
      "ROC-AUC: 0.5800\n",
      "ROC-AUC: 0.5833\n",
      "среднее 0.562620690906191\n"
     ]
    }
   ],
   "source": [
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    model_gb = SVC(probability=True)\n",
    "    model_gb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полносвязная сеть на всех snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5232\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train_all)\n",
    "y_train_tensor = torch.FloatTensor(y_all_train.values).reshape(-1, 1)\n",
    "\n",
    "model = Net(X_train_all.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_val_tensor = torch.FloatTensor(X_val_all)\n",
    "    y_pred_proba = model(X_val_tensor).numpy().flatten()\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5048\n",
      "ROC-AUC autoencoded: 0.5675\n",
      "ROC-AUC autoencoded: 0.5745\n",
      "ROC-AUC autoencoded: 0.5635\n",
      "ROC-AUC autoencoded: 0.5653\n",
      "среднее 0.5551211531085267\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "    \n",
    "    model = Net(X_train.shape[1])\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val_tensor = torch.FloatTensor(X_val)\n",
    "        y_pred_proba = model(X_val_tensor).numpy().flatten()\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок обучения с использованием классического автоэнкодера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С использованием логистической регрессии для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-08 04:42:58,175] A new study created in memory with name: no-name-41b12e27-a9ba-4268-a8c8-fb1dde4db152\n",
      "[I 2025-05-08 04:43:07,904] Trial 0 finished with value: 0.5766045548654244 and parameters: {'latent_dim': 54, 'hidden_dim': 237, 'lr': 0.0025511136935467485, 'epochs': 16, 'C': 2.141368457228479, 'dropout_rate': 0.366999015821723}. Best is trial 0 with value: 0.5766045548654244.\n",
      "[I 2025-05-08 04:43:12,060] Trial 1 finished with value: 0.5285829307568438 and parameters: {'latent_dim': 27, 'hidden_dim': 152, 'lr': 0.009888738790397821, 'epochs': 10, 'C': 0.020503955690532562, 'dropout_rate': 0.30343056771971766}. Best is trial 0 with value: 0.5766045548654244.\n",
      "[I 2025-05-08 04:43:29,139] Trial 2 finished with value: 0.5189786059351277 and parameters: {'latent_dim': 25, 'hidden_dim': 182, 'lr': 0.0010571741817764957, 'epochs': 36, 'C': 4.023865276655204, 'dropout_rate': 0.3256700412358906}. Best is trial 0 with value: 0.5766045548654244.\n",
      "[I 2025-05-08 04:43:43,883] Trial 3 finished with value: 0.5648148148148149 and parameters: {'latent_dim': 57, 'hidden_dim': 124, 'lr': 0.0024322403535420997, 'epochs': 41, 'C': 0.0015311341567762406, 'dropout_rate': 0.3696086531149899}. Best is trial 0 with value: 0.5766045548654244.\n",
      "[I 2025-05-08 04:43:57,301] Trial 4 finished with value: 0.5548654244306419 and parameters: {'latent_dim': 41, 'hidden_dim': 130, 'lr': 0.00046783890431955385, 'epochs': 48, 'C': 0.002649086131788379, 'dropout_rate': 0.44942796974567567}. Best is trial 0 with value: 0.5766045548654244.\n",
      "[I 2025-05-08 04:44:05,801] Trial 5 finished with value: 0.5448585231193926 and parameters: {'latent_dim': 62, 'hidden_dim': 70, 'lr': 0.005096578049192473, 'epochs': 39, 'C': 0.13904279776471765, 'dropout_rate': 0.3207077868726341}. Best is trial 0 with value: 0.5766045548654244.\n",
      "[I 2025-05-08 04:44:16,742] Trial 6 finished with value: 0.599091327352197 and parameters: {'latent_dim': 14, 'hidden_dim': 112, 'lr': 0.0010659709752120076, 'epochs': 41, 'C': 4.963733647738834, 'dropout_rate': 0.21143336484002423}. Best is trial 6 with value: 0.599091327352197.\n",
      "[I 2025-05-08 04:44:30,000] Trial 7 finished with value: 0.5599263860133424 and parameters: {'latent_dim': 33, 'hidden_dim': 130, 'lr': 0.00016520028348729611, 'epochs': 46, 'C': 0.0012084614998992527, 'dropout_rate': 0.43096651529738217}. Best is trial 6 with value: 0.599091327352197.\n",
      "[I 2025-05-08 04:44:43,649] Trial 8 finished with value: 0.5304807913503565 and parameters: {'latent_dim': 88, 'hidden_dim': 183, 'lr': 0.0001474691650339054, 'epochs': 41, 'C': 0.22055500051157997, 'dropout_rate': 0.22078285008940035}. Best is trial 6 with value: 0.599091327352197.\n",
      "[I 2025-05-08 04:44:58,823] Trial 9 finished with value: 0.5135725787899701 and parameters: {'latent_dim': 69, 'hidden_dim': 172, 'lr': 0.0014361224446929792, 'epochs': 47, 'C': 0.8118922811944205, 'dropout_rate': 0.33757701551675323}. Best is trial 6 with value: 0.599091327352197.\n",
      "[I 2025-05-08 04:45:04,454] Trial 10 finished with value: 0.48636991028295373 and parameters: {'latent_dim': 10, 'hidden_dim': 68, 'lr': 0.0004279331419582236, 'epochs': 26, 'C': 8.06134047965177, 'dropout_rate': 0.11033975792860967}. Best is trial 6 with value: 0.599091327352197.\n",
      "[I 2025-05-08 04:45:13,986] Trial 11 finished with value: 0.5127099148838279 and parameters: {'latent_dim': 91, 'hidden_dim': 251, 'lr': 0.003094659806808293, 'epochs': 23, 'C': 1.3442679664097201, 'dropout_rate': 0.21592548332638845}. Best is trial 6 with value: 0.599091327352197.\n",
      "[I 2025-05-08 04:45:20,340] Trial 12 finished with value: 0.5881067402806532 and parameters: {'latent_dim': 13, 'hidden_dim': 256, 'lr': 0.0005051135204137235, 'epochs': 15, 'C': 1.2538538919177715, 'dropout_rate': 0.21657712567747056}. Best is trial 6 with value: 0.599091327352197.\n",
      "[I 2025-05-08 04:45:27,915] Trial 13 finished with value: 0.5072463768115942 and parameters: {'latent_dim': 12, 'hidden_dim': 96, 'lr': 0.00047101155499631715, 'epochs': 29, 'C': 0.4595898123046934, 'dropout_rate': 0.20952609022926572}. Best is trial 6 with value: 0.599091327352197.\n",
      "[I 2025-05-08 04:45:34,980] Trial 14 finished with value: 0.5186335403726707 and parameters: {'latent_dim': 19, 'hidden_dim': 215, 'lr': 0.0002643502184977702, 'epochs': 18, 'C': 0.035249515038618666, 'dropout_rate': 0.13508671425826363}. Best is trial 6 with value: 0.599091327352197.\n",
      "[I 2025-05-08 04:45:46,902] Trial 15 finished with value: 0.5329537612146308 and parameters: {'latent_dim': 44, 'hidden_dim': 211, 'lr': 0.00082777459084411, 'epochs': 32, 'C': 8.519313781181438, 'dropout_rate': 0.16743581760549933}. Best is trial 6 with value: 0.599091327352197.\n",
      "[I 2025-05-08 04:45:49,990] Trial 16 finished with value: 0.5287554635380722 and parameters: {'latent_dim': 39, 'hidden_dim': 100, 'lr': 0.0008207947681607748, 'epochs': 12, 'C': 0.4492887900091872, 'dropout_rate': 0.25369813858011536}. Best is trial 6 with value: 0.599091327352197.\n",
      "[I 2025-05-08 04:45:56,384] Trial 17 finished with value: 0.4468599033816425 and parameters: {'latent_dim': 20, 'hidden_dim': 156, 'lr': 0.00028865985622862823, 'epochs': 21, 'C': 3.27115202160763, 'dropout_rate': 0.26958707994325626}. Best is trial 6 with value: 0.599091327352197.\n",
      "[I 2025-05-08 04:46:07,860] Trial 18 finished with value: 0.6435472739820566 and parameters: {'latent_dim': 74, 'hidden_dim': 206, 'lr': 0.001505265381972118, 'epochs': 32, 'C': 0.04867827396369008, 'dropout_rate': 0.16689373989928946}. Best is trial 18 with value: 0.6435472739820566.\n",
      "[I 2025-05-08 04:46:20,449] Trial 19 finished with value: 0.5876466528640442 and parameters: {'latent_dim': 81, 'hidden_dim': 203, 'lr': 0.0014089792809419356, 'epochs': 35, 'C': 0.0372097344143868, 'dropout_rate': 0.16249308962501893}. Best is trial 18 with value: 0.6435472739820566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6157\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "    \n",
    "def train_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, _ in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _ = model(batch_x)\n",
    "            loss = criterion(reconstructed, batch_x)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    C = trial.suggest_float('C', 1e-3, 10.0, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "    autoencoder = train_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "    \n",
    "    X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "    X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "    \n",
    "    logreg = LogisticRegression(C=C, max_iter=1000)\n",
    "    logreg.fit(X_train_latent, y_train)\n",
    "    \n",
    "    y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(C=best_params['C'], max_iter=1000)\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latent_dim': 74,\n",
       " 'hidden_dim': 206,\n",
       " 'lr': 0.001505265381972118,\n",
       " 'epochs': 32,\n",
       " 'C': 0.04867827396369008,\n",
       " 'dropout_rate': 0.16689373989928946}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5159\n",
      "ROC-AUC autoencoded: 0.5719\n",
      "ROC-AUC autoencoded: 0.5489\n",
      "ROC-AUC autoencoded: 0.5599\n",
      "ROC-AUC autoencoded: 0.5310\n",
      "среднее 0.5455174757040305\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "    autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "    \n",
    "    X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "    X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "    \n",
    "    logreg = LogisticRegression(C=best_params['C'], max_iter=1000)\n",
    "    logreg.fit(X_train_latent, y_train)\n",
    "    \n",
    "    y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "с градиентным бустингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-08 23:04:50,306] A new study created in memory with name: no-name-17a2299a-ef26-4f79-b6d4-e58f73f111b2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-08 23:05:17,956] Trial 0 finished with value: 0.47931523656161334 and parameters: {'latent_dim': 17, 'hidden_dim': 198, 'lr': 0.000923383177938935, 'epochs': 20, 'dropout_rate': 0.38035274488888104, 'n_estimators': 126, 'max_depth': 6, 'learning_rate': 0.09035750454097984, 'subsample': 0.8773464981083348, 'min_samples_split': 13, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.47931523656161334.\n",
      "[I 2025-05-08 23:06:10,754] Trial 1 finished with value: 0.5177517061575033 and parameters: {'latent_dim': 49, 'hidden_dim': 254, 'lr': 0.0034915105131338164, 'epochs': 12, 'dropout_rate': 0.17540495394830036, 'n_estimators': 333, 'max_depth': 8, 'learning_rate': 0.057276239767164866, 'subsample': 0.8478020497246556, 'min_samples_split': 12, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.5177517061575033.\n",
      "[I 2025-05-08 23:07:50,324] Trial 2 finished with value: 0.5517406640595046 and parameters: {'latent_dim': 48, 'hidden_dim': 209, 'lr': 0.006180466468000477, 'epochs': 36, 'dropout_rate': 0.37931555359235525, 'n_estimators': 421, 'max_depth': 10, 'learning_rate': 0.03235625480554429, 'subsample': 0.9793336987590452, 'min_samples_split': 16, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.5517406640595046.\n",
      "[I 2025-05-08 23:08:28,966] Trial 3 finished with value: 0.5334905298673415 and parameters: {'latent_dim': 33, 'hidden_dim': 142, 'lr': 0.0021143205217284793, 'epochs': 37, 'dropout_rate': 0.2711439526401386, 'n_estimators': 76, 'max_depth': 9, 'learning_rate': 0.17334349291040912, 'subsample': 0.8303762277754381, 'min_samples_split': 14, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.5517406640595046.\n",
      "[I 2025-05-08 23:09:12,610] Trial 4 finished with value: 0.46190859596656697 and parameters: {'latent_dim': 34, 'hidden_dim': 208, 'lr': 0.00017775120970667694, 'epochs': 18, 'dropout_rate': 0.453365619303687, 'n_estimators': 392, 'max_depth': 5, 'learning_rate': 0.12892318848333256, 'subsample': 0.9533464818478558, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.5517406640595046.\n",
      "[I 2025-05-08 23:10:29,398] Trial 5 finished with value: 0.46668200291388695 and parameters: {'latent_dim': 72, 'hidden_dim': 93, 'lr': 0.0024333044030643925, 'epochs': 21, 'dropout_rate': 0.40209082252173356, 'n_estimators': 447, 'max_depth': 8, 'learning_rate': 0.01352231336829078, 'subsample': 0.7226262386205436, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.5517406640595046.\n",
      "[I 2025-05-08 23:10:58,479] Trial 6 finished with value: 0.5464496587684994 and parameters: {'latent_dim': 33, 'hidden_dim': 222, 'lr': 0.0015218146538827054, 'epochs': 22, 'dropout_rate': 0.1585384817641231, 'n_estimators': 51, 'max_depth': 8, 'learning_rate': 0.03762889369478147, 'subsample': 0.7199299826181359, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.5517406640595046.\n",
      "[I 2025-05-08 23:11:32,182] Trial 7 finished with value: 0.5028563760447818 and parameters: {'latent_dim': 55, 'hidden_dim': 160, 'lr': 0.00028249601597536456, 'epochs': 23, 'dropout_rate': 0.34871819001151527, 'n_estimators': 126, 'max_depth': 8, 'learning_rate': 0.022840620444562382, 'subsample': 0.6310924158012325, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.5517406640595046.\n",
      "[I 2025-05-08 23:12:40,320] Trial 8 finished with value: 0.5144160723870869 and parameters: {'latent_dim': 31, 'hidden_dim': 235, 'lr': 0.00114093709968053, 'epochs': 42, 'dropout_rate': 0.4436176558841788, 'n_estimators': 293, 'max_depth': 9, 'learning_rate': 0.02479931337548114, 'subsample': 0.6636962594981087, 'min_samples_split': 17, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.5517406640595046.\n",
      "[I 2025-05-08 23:13:49,580] Trial 9 finished with value: 0.5494785675945096 and parameters: {'latent_dim': 69, 'hidden_dim': 171, 'lr': 0.0007772566095404097, 'epochs': 39, 'dropout_rate': 0.19248559801322784, 'n_estimators': 279, 'max_depth': 7, 'learning_rate': 0.2509679927280646, 'subsample': 0.7121971891670421, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.5517406640595046.\n",
      "[I 2025-05-08 23:15:01,964] Trial 10 finished with value: 0.5305958132045089 and parameters: {'latent_dim': 98, 'hidden_dim': 64, 'lr': 0.005266947625661465, 'epochs': 31, 'dropout_rate': 0.2743714244397888, 'n_estimators': 489, 'max_depth': 3, 'learning_rate': 0.011709260394432786, 'subsample': 0.9771545480626113, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.5517406640595046.\n",
      "[I 2025-05-08 23:16:26,928] Trial 11 finished with value: 0.5730772180047542 and parameters: {'latent_dim': 79, 'hidden_dim': 173, 'lr': 0.00995002154953084, 'epochs': 49, 'dropout_rate': 0.10318535870194714, 'n_estimators': 230, 'max_depth': 10, 'learning_rate': 0.26208697188068986, 'subsample': 0.7572760710827973, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.5730772180047542.\n",
      "[I 2025-05-08 23:17:44,766] Trial 12 finished with value: 0.5334521892492907 and parameters: {'latent_dim': 87, 'hidden_dim': 127, 'lr': 0.008816823861121648, 'epochs': 46, 'dropout_rate': 0.11760675441277171, 'n_estimators': 195, 'max_depth': 10, 'learning_rate': 0.06168847761780879, 'subsample': 0.7729868513967079, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.5730772180047542.\n",
      "[I 2025-05-08 23:19:10,347] Trial 13 finished with value: 0.5406985660608848 and parameters: {'latent_dim': 76, 'hidden_dim': 175, 'lr': 0.008472447578673391, 'epochs': 50, 'dropout_rate': 0.33533466639697146, 'n_estimators': 202, 'max_depth': 10, 'learning_rate': 0.2704399111173468, 'subsample': 0.9103506135947379, 'min_samples_split': 16, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.5730772180047542.\n",
      "[I 2025-05-08 23:20:38,186] Trial 14 finished with value: 0.5024346292462235 and parameters: {'latent_dim': 57, 'hidden_dim': 193, 'lr': 0.004577467359505759, 'epochs': 33, 'dropout_rate': 0.23912733058968252, 'n_estimators': 372, 'max_depth': 10, 'learning_rate': 0.036104327174394164, 'subsample': 0.779622569032842, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.5730772180047542.\n",
      "[I 2025-05-08 23:21:51,820] Trial 15 finished with value: 0.5575300973851698 and parameters: {'latent_dim': 86, 'hidden_dim': 126, 'lr': 0.00048354347688329616, 'epochs': 46, 'dropout_rate': 0.114321832534603, 'n_estimators': 225, 'max_depth': 4, 'learning_rate': 0.08125598515072681, 'subsample': 0.9169327758574215, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.5730772180047542.\n",
      "[I 2025-05-08 23:22:59,096] Trial 16 finished with value: 0.5369220151828847 and parameters: {'latent_dim': 90, 'hidden_dim': 117, 'lr': 0.00042953408842237866, 'epochs': 50, 'dropout_rate': 0.11289641974481247, 'n_estimators': 199, 'max_depth': 3, 'learning_rate': 0.0971666807038176, 'subsample': 0.9122933821713701, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.5730772180047542.\n",
      "[I 2025-05-08 23:23:59,831] Trial 17 finished with value: 0.524825550187869 and parameters: {'latent_dim': 84, 'hidden_dim': 97, 'lr': 0.0005515420741288031, 'epochs': 44, 'dropout_rate': 0.10069941800690267, 'n_estimators': 224, 'max_depth': 5, 'learning_rate': 0.17414455295359407, 'subsample': 0.8157702854576209, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.5730772180047542.\n",
      "[I 2025-05-08 23:25:02,834] Trial 18 finished with value: 0.5156621424737367 and parameters: {'latent_dim': 99, 'hidden_dim': 143, 'lr': 0.00011283773900302546, 'epochs': 46, 'dropout_rate': 0.21691394715376355, 'n_estimators': 251, 'max_depth': 4, 'learning_rate': 0.08825956690208278, 'subsample': 0.6027757512736899, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.5730772180047542.\n",
      "[I 2025-05-08 23:25:50,399] Trial 19 finished with value: 0.446380645656008 and parameters: {'latent_dim': 66, 'hidden_dim': 104, 'lr': 0.00030811308402802406, 'epochs': 41, 'dropout_rate': 0.49922962560831585, 'n_estimators': 142, 'max_depth': 6, 'learning_rate': 0.18270745715756587, 'subsample': 0.7666965206731053, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.5730772180047542.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5223\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры градиентного бустинга\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4575\n",
      "ROC-AUC autoencoded: 0.4897\n",
      "ROC-AUC autoencoded: 0.5310\n",
      "ROC-AUC autoencoded: 0.5081\n",
      "ROC-AUC autoencoded: 0.4477\n",
      "ROC-AUC autoencoded: 0.5002\n",
      "ROC-AUC autoencoded: 0.4953\n",
      "ROC-AUC autoencoded: 0.4784\n",
      "ROC-AUC autoencoded: 0.4727\n",
      "ROC-AUC autoencoded: 0.4472\n",
      "ROC-AUC autoencoded: 0.4614\n",
      "ROC-AUC autoencoded: 0.5999\n",
      "ROC-AUC autoencoded: 0.5068\n",
      "ROC-AUC autoencoded: 0.5179\n",
      "ROC-AUC autoencoded: 0.4544\n",
      "ROC-AUC autoencoded: 0.5413\n",
      "ROC-AUC autoencoded: 0.5150\n",
      "ROC-AUC autoencoded: 0.5473\n",
      "ROC-AUC autoencoded: 0.5541\n",
      "ROC-AUC autoencoded: 0.4690\n",
      "ROC-AUC autoencoded: 0.4569\n",
      "ROC-AUC autoencoded: 0.5400\n",
      "ROC-AUC autoencoded: 0.5353\n",
      "ROC-AUC autoencoded: 0.5254\n",
      "ROC-AUC autoencoded: 0.4623\n",
      "среднее 0.5006017860922738\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь с SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 00:32:30,423] A new study created in memory with name: no-name-d86e2645-a260-4fb1-871d-3aa2c97f83c4\n",
      "[I 2025-05-09 00:33:10,603] Trial 0 finished with value: 0.4939996932750556 and parameters: {'latent_dim': 35, 'hidden_dim': 98, 'lr': 0.00016201851725554023, 'epochs': 49, 'dropout_rate': 0.48666662801555327, 'C': 76.4741329365315, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.4939996932750556.\n",
      "[I 2025-05-09 00:39:57,106] Trial 1 finished with value: 0.5324745034889963 and parameters: {'latent_dim': 24, 'hidden_dim': 162, 'lr': 0.0012736333624688075, 'epochs': 47, 'dropout_rate': 0.3680777793791248, 'C': 64.42096559230161, 'kernel': 'linear'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:40:39,981] Trial 2 finished with value: 0.508243232880914 and parameters: {'latent_dim': 77, 'hidden_dim': 132, 'lr': 0.0001500658531724266, 'epochs': 49, 'dropout_rate': 0.16318135424248725, 'C': 21.380086684030612, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:40:50,054] Trial 3 finished with value: 0.5054060271451576 and parameters: {'latent_dim': 44, 'hidden_dim': 91, 'lr': 0.0001832093789937649, 'epochs': 12, 'dropout_rate': 0.3266816961739959, 'C': 2.7187651146060916, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:41:27,989] Trial 4 finished with value: 0.5140518365156046 and parameters: {'latent_dim': 19, 'hidden_dim': 205, 'lr': 0.0022675687254109715, 'epochs': 34, 'dropout_rate': 0.18358594307284715, 'C': 4.764590803951359, 'kernel': 'linear'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:42:25,286] Trial 5 finished with value: 0.49223602484472057 and parameters: {'latent_dim': 89, 'hidden_dim': 244, 'lr': 0.00036696171681436287, 'epochs': 46, 'dropout_rate': 0.458810338576248, 'C': 95.95677897179145, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:42:49,172] Trial 6 finished with value: 0.5032397822252894 and parameters: {'latent_dim': 17, 'hidden_dim': 187, 'lr': 0.000292284844814618, 'epochs': 15, 'dropout_rate': 0.37844106334824323, 'C': 17.10161646672469, 'kernel': 'linear'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:43:24,388] Trial 7 finished with value: 0.4905490376504869 and parameters: {'latent_dim': 17, 'hidden_dim': 161, 'lr': 0.0005733247986441821, 'epochs': 37, 'dropout_rate': 0.34081107442369374, 'C': 13.66061086677376, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:43:40,692] Trial 8 finished with value: 0.4874626178974005 and parameters: {'latent_dim': 86, 'hidden_dim': 86, 'lr': 0.000164527431369173, 'epochs': 21, 'dropout_rate': 0.4972126587933364, 'C': 0.20500226036043148, 'kernel': 'linear'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:43:52,640] Trial 9 finished with value: 0.5091250670960816 and parameters: {'latent_dim': 14, 'hidden_dim': 82, 'lr': 0.0003246706116355162, 'epochs': 16, 'dropout_rate': 0.3450725530905752, 'C': 66.49466652066074, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:44:17,015] Trial 10 finished with value: 0.5062686910512997 and parameters: {'latent_dim': 68, 'hidden_dim': 136, 'lr': 0.008839343434905863, 'epochs': 26, 'dropout_rate': 0.23190914576020463, 'C': 0.3991754724068921, 'kernel': 'linear'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:45:01,893] Trial 11 finished with value: 0.48481711525189786 and parameters: {'latent_dim': 36, 'hidden_dim': 216, 'lr': 0.0024898344374428404, 'epochs': 39, 'dropout_rate': 0.11259374270994923, 'C': 1.7387021513499596, 'kernel': 'linear'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:45:39,697] Trial 12 finished with value: 0.5300973851698488 and parameters: {'latent_dim': 52, 'hidden_dim': 195, 'lr': 0.0019907033672113047, 'epochs': 33, 'dropout_rate': 0.254832076790595, 'C': 6.428142746184583, 'kernel': 'linear'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:46:23,607] Trial 13 finished with value: 0.5105436699639597 and parameters: {'latent_dim': 59, 'hidden_dim': 173, 'lr': 0.0013548297422630768, 'epochs': 42, 'dropout_rate': 0.4011017568610607, 'C': 0.8507616467143276, 'kernel': 'linear'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:46:51,370] Trial 14 finished with value: 0.48082969097461853 and parameters: {'latent_dim': 52, 'hidden_dim': 137, 'lr': 0.0057570740673855095, 'epochs': 29, 'dropout_rate': 0.26010232928915006, 'C': 7.435975367547301, 'kernel': 'linear'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:49:04,594] Trial 15 finished with value: 0.5010351966873706 and parameters: {'latent_dim': 30, 'hidden_dim': 245, 'lr': 0.000993854365929633, 'epochs': 33, 'dropout_rate': 0.279309697343018, 'C': 34.446603853176015, 'kernel': 'linear'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:49:52,463] Trial 16 finished with value: 0.4780499961659382 and parameters: {'latent_dim': 59, 'hidden_dim': 206, 'lr': 0.00324788322690688, 'epochs': 43, 'dropout_rate': 0.4313476038721896, 'C': 0.9922588351994909, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:50:19,521] Trial 17 finished with value: 0.5055018786902845 and parameters: {'latent_dim': 47, 'hidden_dim': 186, 'lr': 0.0010093998485442516, 'epochs': 25, 'dropout_rate': 0.23251481613567287, 'C': 8.109564338607404, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:50:54,332] Trial 18 finished with value: 0.5297714899164174 and parameters: {'latent_dim': 98, 'hidden_dim': 119, 'lr': 0.004518121558601457, 'epochs': 39, 'dropout_rate': 0.3093117120340969, 'C': 39.468712606282445, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.5324745034889963.\n",
      "[I 2025-05-09 00:51:08,134] Trial 19 finished with value: 0.4762288168085269 and parameters: {'latent_dim': 28, 'hidden_dim': 64, 'lr': 0.001594263186968208, 'epochs': 21, 'dropout_rate': 0.21435203254738255, 'C': 0.11395966571783114, 'kernel': 'linear'}. Best is trial 1 with value: 0.5324745034889963.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5548\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры SVC\n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if best_params['kernel'] in ['rbf', 'poly', 'sigmoid'] else 'scale',\n",
    "    degree=best_params['degree'] if best_params['kernel'] == 'poly' else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4957\n",
      "ROC-AUC autoencoded: 0.4594\n",
      "ROC-AUC autoencoded: 0.4712\n",
      "ROC-AUC autoencoded: 0.5462\n",
      "ROC-AUC autoencoded: 0.5098\n",
      "ROC-AUC autoencoded: 0.5819\n",
      "ROC-AUC autoencoded: 0.4171\n",
      "ROC-AUC autoencoded: 0.4643\n",
      "ROC-AUC autoencoded: 0.4979\n",
      "ROC-AUC autoencoded: 0.5051\n",
      "ROC-AUC autoencoded: 0.4994\n",
      "ROC-AUC autoencoded: 0.5547\n",
      "ROC-AUC autoencoded: 0.4211\n",
      "ROC-AUC autoencoded: 0.4968\n",
      "ROC-AUC autoencoded: 0.5156\n",
      "ROC-AUC autoencoded: 0.4829\n",
      "ROC-AUC autoencoded: 0.4912\n",
      "ROC-AUC autoencoded: 0.5116\n",
      "ROC-AUC autoencoded: 0.5166\n",
      "ROC-AUC autoencoded: 0.5110\n",
      "ROC-AUC autoencoded: 0.4326\n",
      "ROC-AUC autoencoded: 0.4302\n",
      "ROC-AUC autoencoded: 0.5064\n",
      "ROC-AUC autoencoded: 0.4519\n",
      "ROC-AUC autoencoded: 0.5203\n",
      "среднее 0.4916355039238232\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if best_params['kernel'] in ['rbf', 'poly', 'sigmoid'] else 'scale',\n",
    "            degree=best_params['degree'] if best_params['kernel'] == 'poly' else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 01:22:22,569] A new study created in memory with name: no-name-dba65f84-00a2-4457-8d51-4b4b5de479d3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 01:23:11,495] Trial 0 finished with value: 0.5338355954297983 and parameters: {'latent_dim': 71, 'hidden_dim_ae': 221, 'lr_ae': 0.00019091002026921025, 'epochs_ae': 33, 'dropout_rate_ae': 0.21788175263520695, 'hidden_dim_mlp': 35, 'lr_mlp': 0.00010000247747672047, 'batch_size_mlp': 16, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.18631960717844231}. Best is trial 0 with value: 0.5338355954297983.\n",
      "[I 2025-05-09 01:23:25,629] Trial 1 finished with value: 0.48635073997392836 and parameters: {'latent_dim': 46, 'hidden_dim_ae': 219, 'lr_ae': 0.0009606694545264923, 'epochs_ae': 10, 'dropout_rate_ae': 0.2041602126253914, 'hidden_dim_mlp': 105, 'lr_mlp': 0.00013415011285256544, 'batch_size_mlp': 64, 'epochs_mlp': 29, 'dropout_rate_mlp': 0.3951772043645948}. Best is trial 0 with value: 0.5338355954297983.\n",
      "[I 2025-05-09 01:23:50,246] Trial 2 finished with value: 0.4914883827927306 and parameters: {'latent_dim': 99, 'hidden_dim_ae': 120, 'lr_ae': 0.0003421262807911017, 'epochs_ae': 23, 'dropout_rate_ae': 0.38701177424454436, 'hidden_dim_mlp': 127, 'lr_mlp': 0.0036363249473185767, 'batch_size_mlp': 32, 'epochs_mlp': 36, 'dropout_rate_mlp': 0.4422768051555592}. Best is trial 0 with value: 0.5338355954297983.\n",
      "[I 2025-05-09 01:24:20,420] Trial 3 finished with value: 0.5566674334790277 and parameters: {'latent_dim': 39, 'hidden_dim_ae': 163, 'lr_ae': 0.008020417621313366, 'epochs_ae': 28, 'dropout_rate_ae': 0.4375215724342104, 'hidden_dim_mlp': 104, 'lr_mlp': 0.0024997781378129024, 'batch_size_mlp': 64, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.32623356839976103}. Best is trial 3 with value: 0.5566674334790277.\n",
      "[I 2025-05-09 01:25:09,082] Trial 4 finished with value: 0.5699332873245916 and parameters: {'latent_dim': 82, 'hidden_dim_ae': 253, 'lr_ae': 0.0003704113362653433, 'epochs_ae': 36, 'dropout_rate_ae': 0.2770346619018736, 'hidden_dim_mlp': 98, 'lr_mlp': 0.0014542062079040171, 'batch_size_mlp': 32, 'epochs_mlp': 14, 'dropout_rate_mlp': 0.4667502734033625}. Best is trial 4 with value: 0.5699332873245916.\n",
      "[I 2025-05-09 01:25:22,926] Trial 5 finished with value: 0.517636684303351 and parameters: {'latent_dim': 68, 'hidden_dim_ae': 236, 'lr_ae': 0.0001535175862196569, 'epochs_ae': 10, 'dropout_rate_ae': 0.4874166856530153, 'hidden_dim_mlp': 86, 'lr_mlp': 0.0037374188978950887, 'batch_size_mlp': 32, 'epochs_mlp': 12, 'dropout_rate_mlp': 0.4530078275227223}. Best is trial 4 with value: 0.5699332873245916.\n",
      "[I 2025-05-09 01:25:49,575] Trial 6 finished with value: 0.4926386013342534 and parameters: {'latent_dim': 97, 'hidden_dim_ae': 123, 'lr_ae': 0.00421366197565933, 'epochs_ae': 16, 'dropout_rate_ae': 0.2583783839215925, 'hidden_dim_mlp': 117, 'lr_mlp': 0.00014768977678439774, 'batch_size_mlp': 16, 'epochs_mlp': 44, 'dropout_rate_mlp': 0.3121295142582359}. Best is trial 4 with value: 0.5699332873245916.\n",
      "[I 2025-05-09 01:26:08,801] Trial 7 finished with value: 0.5363469059121233 and parameters: {'latent_dim': 78, 'hidden_dim_ae': 129, 'lr_ae': 0.006992420605297321, 'epochs_ae': 17, 'dropout_rate_ae': 0.19122544648033976, 'hidden_dim_mlp': 99, 'lr_mlp': 0.00018911541523972274, 'batch_size_mlp': 32, 'epochs_mlp': 26, 'dropout_rate_mlp': 0.14735388102739316}. Best is trial 4 with value: 0.5699332873245916.\n",
      "[I 2025-05-09 01:26:25,558] Trial 8 finished with value: 0.5518173452956061 and parameters: {'latent_dim': 64, 'hidden_dim_ae': 155, 'lr_ae': 0.0032367730077270747, 'epochs_ae': 14, 'dropout_rate_ae': 0.1759020566987229, 'hidden_dim_mlp': 64, 'lr_mlp': 0.0005963705047396133, 'batch_size_mlp': 64, 'epochs_mlp': 44, 'dropout_rate_mlp': 0.4952902530946711}. Best is trial 4 with value: 0.5699332873245916.\n",
      "[I 2025-05-09 01:27:26,889] Trial 9 finished with value: 0.551108043861667 and parameters: {'latent_dim': 51, 'hidden_dim_ae': 172, 'lr_ae': 0.0038830122889349015, 'epochs_ae': 47, 'dropout_rate_ae': 0.3317869517009726, 'hidden_dim_mlp': 124, 'lr_mlp': 0.001839520197610219, 'batch_size_mlp': 16, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.37977816327933966}. Best is trial 4 with value: 0.5699332873245916.\n",
      "[I 2025-05-09 01:27:57,427] Trial 10 finished with value: 0.5785790966950387 and parameters: {'latent_dim': 19, 'hidden_dim_ae': 67, 'lr_ae': 0.0006389845548887724, 'epochs_ae': 42, 'dropout_rate_ae': 0.12767743757255284, 'hidden_dim_mlp': 64, 'lr_mlp': 0.00882335838369266, 'batch_size_mlp': 32, 'epochs_mlp': 23, 'dropout_rate_mlp': 0.23529793877544072}. Best is trial 10 with value: 0.5785790966950387.\n",
      "[I 2025-05-09 01:28:26,595] Trial 11 finished with value: 0.5168507016333104 and parameters: {'latent_dim': 10, 'hidden_dim_ae': 65, 'lr_ae': 0.0006290730612029351, 'epochs_ae': 41, 'dropout_rate_ae': 0.11128828354160948, 'hidden_dim_mlp': 64, 'lr_mlp': 0.009692885441655152, 'batch_size_mlp': 32, 'epochs_mlp': 21, 'dropout_rate_mlp': 0.24627776139513424}. Best is trial 10 with value: 0.5785790966950387.\n",
      "[I 2025-05-09 01:28:54,927] Trial 12 finished with value: 0.5130933210643356 and parameters: {'latent_dim': 22, 'hidden_dim_ae': 82, 'lr_ae': 0.0004838854200963522, 'epochs_ae': 38, 'dropout_rate_ae': 0.10859817349976712, 'hidden_dim_mlp': 68, 'lr_mlp': 0.0006268781500356707, 'batch_size_mlp': 32, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.24011267607513848}. Best is trial 10 with value: 0.5785790966950387.\n",
      "[I 2025-05-09 01:30:03,320] Trial 13 finished with value: 0.5403343301894027 and parameters: {'latent_dim': 30, 'hidden_dim_ae': 255, 'lr_ae': 0.001537847201578677, 'epochs_ae': 50, 'dropout_rate_ae': 0.3189222192660367, 'hidden_dim_mlp': 44, 'lr_mlp': 0.009979661973779174, 'batch_size_mlp': 32, 'epochs_mlp': 20, 'dropout_rate_mlp': 0.24345059720844991}. Best is trial 10 with value: 0.5785790966950387.\n",
      "[I 2025-05-09 01:30:51,631] Trial 14 finished with value: 0.4930795184418373 and parameters: {'latent_dim': 86, 'hidden_dim_ae': 181, 'lr_ae': 0.00028287804465997084, 'epochs_ae': 42, 'dropout_rate_ae': 0.25362611199304663, 'hidden_dim_mlp': 81, 'lr_mlp': 0.0011456161810044778, 'batch_size_mlp': 32, 'epochs_mlp': 25, 'dropout_rate_mlp': 0.10434743213665623}. Best is trial 10 with value: 0.5785790966950387.\n",
      "[I 2025-05-09 01:31:21,100] Trial 15 finished with value: 0.5378997009431792 and parameters: {'latent_dim': 11, 'hidden_dim_ae': 90, 'lr_ae': 0.0011518142331791215, 'epochs_ae': 34, 'dropout_rate_ae': 0.3703210676668295, 'hidden_dim_mlp': 50, 'lr_mlp': 0.0003440741823763975, 'batch_size_mlp': 32, 'epochs_mlp': 33, 'dropout_rate_mlp': 0.3750272263305546}. Best is trial 10 with value: 0.5785790966950387.\n",
      "[I 2025-05-09 01:31:52,864] Trial 16 finished with value: 0.5197645886051683 and parameters: {'latent_dim': 58, 'hidden_dim_ae': 192, 'lr_ae': 0.00010309258344581761, 'epochs_ae': 28, 'dropout_rate_ae': 0.14642306179680578, 'hidden_dim_mlp': 90, 'lr_mlp': 0.004247596318743963, 'batch_size_mlp': 32, 'epochs_mlp': 15, 'dropout_rate_mlp': 0.27233707038677957}. Best is trial 10 with value: 0.5785790966950387.\n",
      "[I 2025-05-09 01:32:43,094] Trial 17 finished with value: 0.5466413618587531 and parameters: {'latent_dim': 84, 'hidden_dim_ae': 199, 'lr_ae': 0.0005704952657111977, 'epochs_ae': 43, 'dropout_rate_ae': 0.2599460540712948, 'hidden_dim_mlp': 73, 'lr_mlp': 0.0014864031399423588, 'batch_size_mlp': 32, 'epochs_mlp': 23, 'dropout_rate_mlp': 0.19142961743524042}. Best is trial 10 with value: 0.5785790966950387.\n",
      "[I 2025-05-09 01:33:18,611] Trial 18 finished with value: 0.5164672954528027 and parameters: {'latent_dim': 35, 'hidden_dim_ae': 143, 'lr_ae': 0.001972681486661524, 'epochs_ae': 36, 'dropout_rate_ae': 0.2882424995585312, 'hidden_dim_mlp': 54, 'lr_mlp': 0.006267907890519877, 'batch_size_mlp': 64, 'epochs_mlp': 31, 'dropout_rate_mlp': 0.33442049741396124}. Best is trial 10 with value: 0.5785790966950387.\n",
      "[I 2025-05-09 01:33:56,975] Trial 19 finished with value: 0.4996357641285178 and parameters: {'latent_dim': 19, 'hidden_dim_ae': 100, 'lr_ae': 0.0003078708990696478, 'epochs_ae': 45, 'dropout_rate_ae': 0.15196372197172772, 'hidden_dim_mlp': 94, 'lr_mlp': 0.0006585627497534735, 'batch_size_mlp': 16, 'epochs_mlp': 14, 'dropout_rate_mlp': 0.2076234083310164}. Best is trial 10 with value: 0.5785790966950387.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5303\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры MLP\n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    batch_size_mlp = trial.suggest_categorical('batch_size_mlp', [16, 32, 64])\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(latent_dim, hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size_mlp, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "mlp = MLP(best_params['latent_dim'], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], best_params['batch_size_mlp'], best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5054\n",
      "ROC-AUC autoencoded: 0.5460\n",
      "ROC-AUC autoencoded: 0.4973\n",
      "ROC-AUC autoencoded: 0.4413\n",
      "ROC-AUC autoencoded: 0.4953\n",
      "ROC-AUC autoencoded: 0.4100\n",
      "ROC-AUC autoencoded: 0.5668\n",
      "ROC-AUC autoencoded: 0.5078\n",
      "ROC-AUC autoencoded: 0.4578\n",
      "ROC-AUC autoencoded: 0.5182\n",
      "ROC-AUC autoencoded: 0.5059\n",
      "ROC-AUC autoencoded: 0.5531\n",
      "ROC-AUC autoencoded: 0.5311\n",
      "ROC-AUC autoencoded: 0.5148\n",
      "ROC-AUC autoencoded: 0.4746\n",
      "ROC-AUC autoencoded: 0.4717\n",
      "ROC-AUC autoencoded: 0.4351\n",
      "ROC-AUC autoencoded: 0.4503\n",
      "ROC-AUC autoencoded: 0.5084\n",
      "ROC-AUC autoencoded: 0.5387\n",
      "ROC-AUC autoencoded: 0.5106\n",
      "ROC-AUC autoencoded: 0.5382\n",
      "ROC-AUC autoencoded: 0.4973\n",
      "ROC-AUC autoencoded: 0.5125\n",
      "ROC-AUC autoencoded: 0.5026\n",
      "среднее 0.4996270616162519\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(best_params['latent_dim'], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], best_params['batch_size_mlp'], best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок с классическим автоэнкодером с второй классифицирующей головой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "логситическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 01:58:28,538] A new study created in memory with name: no-name-45fe1810-76ad-4515-b865-ea2b199ce443\n",
      "[I 2025-05-09 01:59:02,667] Trial 0 finished with value: 0.5177133655394525 and parameters: {'latent_dim': 21, 'hidden_dim': 180, 'lr': 0.0038317082317066635, 'epochs': 33, 'dropout_rate': 0.11762403853817155, 'recon_weight': 0.7550238634584083, 'C': 21.174112875555252}. Best is trial 0 with value: 0.5177133655394525.\n",
      "[I 2025-05-09 01:59:27,985] Trial 1 finished with value: 0.5253048079135035 and parameters: {'latent_dim': 51, 'hidden_dim': 133, 'lr': 0.00016179998222630112, 'epochs': 22, 'dropout_rate': 0.2510476421564185, 'recon_weight': 0.8493708317656521, 'C': 1.282820541242031}. Best is trial 1 with value: 0.5253048079135035.\n",
      "[I 2025-05-09 01:59:48,113] Trial 2 finished with value: 0.5167931907062342 and parameters: {'latent_dim': 76, 'hidden_dim': 151, 'lr': 0.0002128011140829034, 'epochs': 22, 'dropout_rate': 0.40480031280111406, 'recon_weight': 0.15800174312875148, 'C': 7.1582514983943355}. Best is trial 1 with value: 0.5253048079135035.\n",
      "[I 2025-05-09 02:00:44,497] Trial 3 finished with value: 0.5162180814354728 and parameters: {'latent_dim': 88, 'hidden_dim': 221, 'lr': 0.002491551471373289, 'epochs': 46, 'dropout_rate': 0.4457511836959168, 'recon_weight': 0.7952575551463182, 'C': 0.8860615639031328}. Best is trial 1 with value: 0.5253048079135035.\n",
      "[I 2025-05-09 02:01:22,950] Trial 4 finished with value: 0.5101219231654014 and parameters: {'latent_dim': 36, 'hidden_dim': 208, 'lr': 0.0007970978340040754, 'epochs': 29, 'dropout_rate': 0.2595129746693483, 'recon_weight': 0.7171283911855814, 'C': 1.7510208954237936}. Best is trial 1 with value: 0.5253048079135035.\n",
      "[I 2025-05-09 02:01:47,574] Trial 5 finished with value: 0.5164481251437774 and parameters: {'latent_dim': 55, 'hidden_dim': 84, 'lr': 0.0035580680659908137, 'epochs': 30, 'dropout_rate': 0.27230541601020175, 'recon_weight': 0.21774231262559163, 'C': 2.57368877863397}. Best is trial 1 with value: 0.5253048079135035.\n",
      "[I 2025-05-09 02:02:38,175] Trial 6 finished with value: 0.5018020090483858 and parameters: {'latent_dim': 59, 'hidden_dim': 181, 'lr': 0.008266916943679701, 'epochs': 48, 'dropout_rate': 0.32583689847786157, 'recon_weight': 0.38738481619718146, 'C': 1.2356634761867082}. Best is trial 1 with value: 0.5253048079135035.\n",
      "[I 2025-05-09 02:02:49,961] Trial 7 finished with value: 0.5136300897170462 and parameters: {'latent_dim': 35, 'hidden_dim': 196, 'lr': 0.0007116904151778109, 'epochs': 11, 'dropout_rate': 0.3525883632178629, 'recon_weight': 0.2795654826839192, 'C': 0.01796733721115094}. Best is trial 1 with value: 0.5253048079135035.\n",
      "[I 2025-05-09 02:03:11,040] Trial 8 finished with value: 0.5428839812897784 and parameters: {'latent_dim': 99, 'hidden_dim': 94, 'lr': 0.007888174387543813, 'epochs': 28, 'dropout_rate': 0.1898448111713177, 'recon_weight': 0.8158435848412336, 'C': 71.99142143812271}. Best is trial 8 with value: 0.5428839812897784.\n",
      "[I 2025-05-09 02:03:48,617] Trial 9 finished with value: 0.5131700023004371 and parameters: {'latent_dim': 50, 'hidden_dim': 136, 'lr': 0.0001807560478969158, 'epochs': 43, 'dropout_rate': 0.46239858446360416, 'recon_weight': 0.5393400486679404, 'C': 9.840802005098706}. Best is trial 8 with value: 0.5428839812897784.\n",
      "[I 2025-05-09 02:03:55,639] Trial 10 finished with value: 0.5204738900391074 and parameters: {'latent_dim': 99, 'hidden_dim': 66, 'lr': 0.008440143393336425, 'epochs': 10, 'dropout_rate': 0.11631021666699459, 'recon_weight': 0.5836742515735248, 'C': 79.59862994681471}. Best is trial 8 with value: 0.5428839812897784.\n",
      "[I 2025-05-09 02:04:12,180] Trial 11 finished with value: 0.522065025688214 and parameters: {'latent_dim': 70, 'hidden_dim': 111, 'lr': 0.00040443086174171374, 'epochs': 20, 'dropout_rate': 0.1972811460918382, 'recon_weight': 0.8860797349534402, 'C': 0.13514726340390623}. Best is trial 8 with value: 0.5428839812897784.\n",
      "[I 2025-05-09 02:04:30,534] Trial 12 finished with value: 0.5037573805689748 and parameters: {'latent_dim': 76, 'hidden_dim': 117, 'lr': 0.00011266620114932732, 'epochs': 22, 'dropout_rate': 0.21281138597995808, 'recon_weight': 0.8974477432182242, 'C': 0.19367054300052744}. Best is trial 8 with value: 0.5428839812897784.\n",
      "[I 2025-05-09 02:04:58,978] Trial 13 finished with value: 0.5139943255885284 and parameters: {'latent_dim': 12, 'hidden_dim': 103, 'lr': 0.001642432905852775, 'epochs': 37, 'dropout_rate': 0.1902451361087661, 'recon_weight': 0.630851916364991, 'C': 43.02748324466592}. Best is trial 8 with value: 0.5428839812897784.\n",
      "[I 2025-05-09 02:05:21,018] Trial 14 finished with value: 0.5157196534008128 and parameters: {'latent_dim': 39, 'hidden_dim': 252, 'lr': 0.0005070591025113899, 'epochs': 17, 'dropout_rate': 0.16343163142538397, 'recon_weight': 0.4278865348614496, 'C': 0.1261111439976892}. Best is trial 8 with value: 0.5428839812897784.\n",
      "[I 2025-05-09 02:05:44,389] Trial 15 finished with value: 0.5158730158730158 and parameters: {'latent_dim': 100, 'hidden_dim': 141, 'lr': 0.0013682980055202498, 'epochs': 26, 'dropout_rate': 0.24748801776092477, 'recon_weight': 0.6643209653100728, 'C': 0.35399152958181623}. Best is trial 8 with value: 0.5428839812897784.\n",
      "[I 2025-05-09 02:06:11,818] Trial 16 finished with value: 0.507533931446975 and parameters: {'latent_dim': 68, 'hidden_dim': 89, 'lr': 0.00030829666556161765, 'epochs': 38, 'dropout_rate': 0.31292722378789534, 'recon_weight': 0.8199919645443381, 'C': 0.036126912272228084}. Best is trial 8 with value: 0.5428839812897784.\n",
      "[I 2025-05-09 02:06:25,956] Trial 17 finished with value: 0.50904838585998 and parameters: {'latent_dim': 86, 'hidden_dim': 132, 'lr': 0.00010270192326333974, 'epochs': 16, 'dropout_rate': 0.16158328449214887, 'recon_weight': 0.7182053837075473, 'C': 5.980480368992704}. Best is trial 8 with value: 0.5428839812897784.\n",
      "[I 2025-05-09 02:06:51,215] Trial 18 finished with value: 0.5064028832144775 and parameters: {'latent_dim': 45, 'hidden_dim': 159, 'lr': 0.005818730419973025, 'epochs': 26, 'dropout_rate': 0.3688952332306602, 'recon_weight': 0.8184900393418659, 'C': 98.15040199635779}. Best is trial 8 with value: 0.5428839812897784.\n",
      "[I 2025-05-09 02:07:15,733] Trial 19 finished with value: 0.5165631469979296 and parameters: {'latent_dim': 25, 'hidden_dim': 65, 'lr': 0.0013014542072331433, 'epochs': 37, 'dropout_rate': 0.2383775767896783, 'recon_weight': 0.37280026035222036, 'C': 17.3407346039101}. Best is trial 8 with value: 0.5428839812897784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5479\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(ClassifyingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "\n",
    "def train_classifying_autoencoder(model, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    class_criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _, classification = model(batch_x)\n",
    "            \n",
    "            recon_loss = recon_criterion(reconstructed, batch_x)\n",
    "            class_loss = class_criterion(classification, batch_y)\n",
    "            \n",
    "            loss = recon_weight * recon_loss + class_weight * class_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent, _ = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Веса для объединенной функции потерь\n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    # Параметры логистической регрессии\n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(C=C, max_iter=1000, random_state=42)\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(C=best_params['C'], max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4813\n",
      "ROC-AUC autoencoded: 0.5071\n",
      "ROC-AUC autoencoded: 0.4822\n",
      "ROC-AUC autoencoded: 0.4952\n",
      "ROC-AUC autoencoded: 0.5034\n",
      "ROC-AUC autoencoded: 0.5561\n",
      "ROC-AUC autoencoded: 0.5666\n",
      "ROC-AUC autoencoded: 0.5386\n",
      "ROC-AUC autoencoded: 0.5450\n",
      "ROC-AUC autoencoded: 0.5632\n",
      "ROC-AUC autoencoded: 0.5752\n",
      "ROC-AUC autoencoded: 0.5638\n",
      "ROC-AUC autoencoded: 0.5846\n",
      "ROC-AUC autoencoded: 0.5753\n",
      "ROC-AUC autoencoded: 0.5652\n",
      "ROC-AUC autoencoded: 0.5762\n",
      "ROC-AUC autoencoded: 0.5657\n",
      "ROC-AUC autoencoded: 0.5572\n",
      "ROC-AUC autoencoded: 0.5451\n",
      "ROC-AUC autoencoded: 0.5308\n",
      "ROC-AUC autoencoded: 0.5305\n",
      "ROC-AUC autoencoded: 0.5763\n",
      "ROC-AUC autoencoded: 0.5575\n",
      "ROC-AUC autoencoded: 0.5614\n",
      "ROC-AUC autoencoded: 0.5856\n",
      "среднее 0.5475645124795029\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(C=best_params['C'], max_iter=1000, random_state=42)\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 03:09:55,250] A new study created in memory with name: no-name-48366539-891b-494d-b878-2c66947f9369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 03:11:13,868] Trial 0 finished with value: 0.47609462464534924 and parameters: {'latent_dim': 83, 'hidden_dim': 193, 'lr': 0.008456360810943349, 'epochs': 29, 'dropout_rate': 0.3642618312360736, 'recon_weight': 0.8533836496998368, 'n_estimators': 333, 'max_depth': 8, 'learning_rate': 0.0103216604153239, 'subsample': 0.6758712784055878, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.47609462464534924.\n",
      "[I 2025-05-09 03:11:36,443] Trial 1 finished with value: 0.5206368376658231 and parameters: {'latent_dim': 29, 'hidden_dim': 248, 'lr': 0.003961172203580615, 'epochs': 16, 'dropout_rate': 0.26149241965279724, 'recon_weight': 0.6632520120421269, 'n_estimators': 337, 'max_depth': 5, 'learning_rate': 0.22560471920772465, 'subsample': 0.6225428431210622, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.5206368376658231.\n",
      "[I 2025-05-09 03:11:58,874] Trial 2 finished with value: 0.48434744268077595 and parameters: {'latent_dim': 23, 'hidden_dim': 219, 'lr': 0.0008276762620740576, 'epochs': 16, 'dropout_rate': 0.17595255368239793, 'recon_weight': 0.6702251532566471, 'n_estimators': 106, 'max_depth': 8, 'learning_rate': 0.07961691226083432, 'subsample': 0.7126999574749493, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.5206368376658231.\n",
      "[I 2025-05-09 03:12:26,149] Trial 3 finished with value: 0.5313722107200368 and parameters: {'latent_dim': 51, 'hidden_dim': 165, 'lr': 0.00012415378898760564, 'epochs': 27, 'dropout_rate': 0.1137323980067456, 'recon_weight': 0.36780894574487766, 'n_estimators': 187, 'max_depth': 3, 'learning_rate': 0.2645816098606225, 'subsample': 0.6115783039655239, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:12:39,753] Trial 4 finished with value: 0.47739820565907526 and parameters: {'latent_dim': 13, 'hidden_dim': 95, 'lr': 0.0055087575562440625, 'epochs': 13, 'dropout_rate': 0.3815869958338447, 'recon_weight': 0.46672837384523913, 'n_estimators': 313, 'max_depth': 4, 'learning_rate': 0.04665323226103053, 'subsample': 0.6718320139844093, 'min_samples_split': 13, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:13:03,758] Trial 5 finished with value: 0.4860344298750096 and parameters: {'latent_dim': 47, 'hidden_dim': 115, 'lr': 0.004713972209980087, 'epochs': 22, 'dropout_rate': 0.10982267609352805, 'recon_weight': 0.6604793034160481, 'n_estimators': 347, 'max_depth': 9, 'learning_rate': 0.17976192668135899, 'subsample': 0.8392994531614328, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:13:35,559] Trial 6 finished with value: 0.5028467908902692 and parameters: {'latent_dim': 60, 'hidden_dim': 233, 'lr': 0.0036450812264642554, 'epochs': 17, 'dropout_rate': 0.40514281829046606, 'recon_weight': 0.3787174039169747, 'n_estimators': 390, 'max_depth': 10, 'learning_rate': 0.16234128973791512, 'subsample': 0.8325591098738743, 'min_samples_split': 16, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:14:18,467] Trial 7 finished with value: 0.4840886435089334 and parameters: {'latent_dim': 69, 'hidden_dim': 109, 'lr': 0.009469190415245549, 'epochs': 47, 'dropout_rate': 0.17484328657680392, 'recon_weight': 0.45486441135161526, 'n_estimators': 53, 'max_depth': 7, 'learning_rate': 0.09323458586906576, 'subsample': 0.9317354330303909, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:14:39,923] Trial 8 finished with value: 0.5201863354037266 and parameters: {'latent_dim': 31, 'hidden_dim': 175, 'lr': 0.0016994595639015385, 'epochs': 10, 'dropout_rate': 0.33883381309942556, 'recon_weight': 0.5439453651993394, 'n_estimators': 134, 'max_depth': 4, 'learning_rate': 0.10472971888686214, 'subsample': 0.814283708919046, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:15:30,303] Trial 9 finished with value: 0.5005367686527107 and parameters: {'latent_dim': 86, 'hidden_dim': 169, 'lr': 0.00020431254397078118, 'epochs': 18, 'dropout_rate': 0.34119650750967706, 'recon_weight': 0.21361044675389432, 'n_estimators': 104, 'max_depth': 10, 'learning_rate': 0.07009776673353528, 'subsample': 0.8400131049897763, 'min_samples_split': 12, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:16:16,665] Trial 10 finished with value: 0.47931523656161334 and parameters: {'latent_dim': 48, 'hidden_dim': 66, 'lr': 0.00012936560325786575, 'epochs': 44, 'dropout_rate': 0.25455787855489004, 'recon_weight': 0.1203203503730493, 'n_estimators': 481, 'max_depth': 3, 'learning_rate': 0.03086680080302729, 'subsample': 0.9850927762590479, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:16:43,950] Trial 11 finished with value: 0.48069549881144086 and parameters: {'latent_dim': 30, 'hidden_dim': 141, 'lr': 0.00045799718980629636, 'epochs': 29, 'dropout_rate': 0.24555175944150034, 'recon_weight': 0.28664347195241346, 'n_estimators': 207, 'max_depth': 5, 'learning_rate': 0.282722712925994, 'subsample': 0.609617246612338, 'min_samples_split': 20, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:17:32,392] Trial 12 finished with value: 0.48939881910896404 and parameters: {'latent_dim': 41, 'hidden_dim': 256, 'lr': 0.001752000146007948, 'epochs': 37, 'dropout_rate': 0.4677714218553885, 'recon_weight': 0.8605746630976647, 'n_estimators': 238, 'max_depth': 5, 'learning_rate': 0.248391992333363, 'subsample': 0.6232934885220377, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:18:04,873] Trial 13 finished with value: 0.48818150448585235 and parameters: {'latent_dim': 65, 'hidden_dim': 195, 'lr': 0.0003307387010264484, 'epochs': 24, 'dropout_rate': 0.10734446977688034, 'recon_weight': 0.6458565714556832, 'n_estimators': 201, 'max_depth': 3, 'learning_rate': 0.1403410840731927, 'subsample': 0.7446954150632251, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:18:37,334] Trial 14 finished with value: 0.4924756537075378 and parameters: {'latent_dim': 10, 'hidden_dim': 142, 'lr': 0.0023949196464224435, 'epochs': 36, 'dropout_rate': 0.26729502990104, 'recon_weight': 0.7566655120954128, 'n_estimators': 406, 'max_depth': 5, 'learning_rate': 0.2824029150525051, 'subsample': 0.650747398861437, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:19:31,072] Trial 15 finished with value: 0.46761176290161793 and parameters: {'latent_dim': 37, 'hidden_dim': 256, 'lr': 0.0008486997015416126, 'epochs': 24, 'dropout_rate': 0.18970272456044515, 'recon_weight': 0.34320953878243365, 'n_estimators': 278, 'max_depth': 6, 'learning_rate': 0.023305270216249535, 'subsample': 0.7475287996598465, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:20:17,154] Trial 16 finished with value: 0.48252626332336473 and parameters: {'latent_dim': 100, 'hidden_dim': 215, 'lr': 0.0004114091972008255, 'epochs': 35, 'dropout_rate': 0.21764124540767227, 'recon_weight': 0.5415716883041553, 'n_estimators': 180, 'max_depth': 4, 'learning_rate': 0.17310494571542528, 'subsample': 0.6091958379720712, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:20:54,289] Trial 17 finished with value: 0.5085882984433708 and parameters: {'latent_dim': 51, 'hidden_dim': 144, 'lr': 0.0001543488687870089, 'epochs': 22, 'dropout_rate': 0.13943920149727773, 'recon_weight': 0.746611974940599, 'n_estimators': 264, 'max_depth': 6, 'learning_rate': 0.042992945152590716, 'subsample': 0.7252298920940645, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:21:30,677] Trial 18 finished with value: 0.49231270608082206 and parameters: {'latent_dim': 24, 'hidden_dim': 197, 'lr': 0.001279672392225705, 'epochs': 32, 'dropout_rate': 0.2999315051228964, 'recon_weight': 0.5788200982764383, 'n_estimators': 446, 'max_depth': 3, 'learning_rate': 0.11167845432806299, 'subsample': 0.7803294369961006, 'min_samples_split': 18, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.5313722107200368.\n",
      "[I 2025-05-09 03:22:24,757] Trial 19 finished with value: 0.4718100605781765 and parameters: {'latent_dim': 73, 'hidden_dim': 231, 'lr': 0.003084498676408753, 'epochs': 43, 'dropout_rate': 0.3023504329961466, 'recon_weight': 0.438948104287314, 'n_estimators': 153, 'max_depth': 4, 'learning_rate': 0.20400873342109183, 'subsample': 0.6838641927952038, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.5313722107200368.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5095\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Веса для объединенной функции потерь\n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    # Параметры градиентного бустинга\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4608\n",
      "ROC-AUC autoencoded: 0.4609\n",
      "ROC-AUC autoencoded: 0.4780\n",
      "ROC-AUC autoencoded: 0.4918\n",
      "ROC-AUC autoencoded: 0.4251\n",
      "ROC-AUC autoencoded: 0.5126\n",
      "ROC-AUC autoencoded: 0.5887\n",
      "ROC-AUC autoencoded: 0.5282\n",
      "ROC-AUC autoencoded: 0.5880\n",
      "ROC-AUC autoencoded: 0.5573\n",
      "ROC-AUC autoencoded: 0.5598\n",
      "ROC-AUC autoencoded: 0.5102\n",
      "ROC-AUC autoencoded: 0.5457\n",
      "ROC-AUC autoencoded: 0.5860\n",
      "ROC-AUC autoencoded: 0.5820\n",
      "ROC-AUC autoencoded: 0.5353\n",
      "ROC-AUC autoencoded: 0.5434\n",
      "ROC-AUC autoencoded: 0.5561\n",
      "ROC-AUC autoencoded: 0.5296\n",
      "ROC-AUC autoencoded: 0.5562\n",
      "ROC-AUC autoencoded: 0.5462\n",
      "ROC-AUC autoencoded: 0.5432\n",
      "ROC-AUC autoencoded: 0.5587\n",
      "ROC-AUC autoencoded: 0.5105\n",
      "ROC-AUC autoencoded: 0.5131\n",
      "среднее 0.5306983376722503\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 03:31:30,950] A new study created in memory with name: no-name-cd5dc03d-3011-4dde-b8c9-472997ed75de\n",
      "[I 2025-05-09 03:32:04,731] Trial 0 finished with value: 0.5125373821025995 and parameters: {'latent_dim': 44, 'hidden_dim': 224, 'lr': 0.0007686786252716893, 'epochs': 29, 'dropout_rate': 0.38024990605827513, 'recon_weight': 0.5638739825960716, 'C': 0.5909876558306919, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.5125373821025995.\n",
      "[I 2025-05-09 03:32:54,560] Trial 1 finished with value: 0.5246626025611533 and parameters: {'latent_dim': 58, 'hidden_dim': 245, 'lr': 0.007813532453994434, 'epochs': 41, 'dropout_rate': 0.4338736160653268, 'recon_weight': 0.7810241555334292, 'C': 78.54317318488002, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 1 with value: 0.5246626025611533.\n",
      "[I 2025-05-09 03:33:07,108] Trial 2 finished with value: 0.5057510927076144 and parameters: {'latent_dim': 100, 'hidden_dim': 90, 'lr': 0.0027252600763545635, 'epochs': 18, 'dropout_rate': 0.4441667805772713, 'recon_weight': 0.31574543509150066, 'C': 0.6066631791268988, 'kernel': 'linear'}. Best is trial 1 with value: 0.5246626025611533.\n",
      "[I 2025-05-09 03:33:40,818] Trial 3 finished with value: 0.5151062035120005 and parameters: {'latent_dim': 73, 'hidden_dim': 209, 'lr': 0.004886008447149302, 'epochs': 31, 'dropout_rate': 0.2698540666869179, 'recon_weight': 0.7666985287316671, 'C': 3.0119784338321143, 'kernel': 'linear'}. Best is trial 1 with value: 0.5246626025611533.\n",
      "[I 2025-05-09 03:34:14,205] Trial 4 finished with value: 0.5131508319914116 and parameters: {'latent_dim': 38, 'hidden_dim': 245, 'lr': 0.0004352308699149398, 'epochs': 28, 'dropout_rate': 0.48335128969053676, 'recon_weight': 0.6319471242684321, 'C': 98.7117278061451, 'kernel': 'linear'}. Best is trial 1 with value: 0.5246626025611533.\n",
      "[I 2025-05-09 03:34:56,302] Trial 5 finished with value: 0.5155471206195844 and parameters: {'latent_dim': 29, 'hidden_dim': 148, 'lr': 0.005301771163283994, 'epochs': 48, 'dropout_rate': 0.14921476410355636, 'recon_weight': 0.5735452724971545, 'C': 87.29447622473816, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.5246626025611533.\n",
      "[I 2025-05-09 03:35:47,647] Trial 6 finished with value: 0.5011693888505483 and parameters: {'latent_dim': 48, 'hidden_dim': 232, 'lr': 0.0012726671824599218, 'epochs': 45, 'dropout_rate': 0.4111272419747004, 'recon_weight': 0.16318532743262726, 'C': 4.740616233563647, 'kernel': 'linear'}. Best is trial 1 with value: 0.5246626025611533.\n",
      "[I 2025-05-09 03:35:56,661] Trial 7 finished with value: 0.5244421440073613 and parameters: {'latent_dim': 42, 'hidden_dim': 80, 'lr': 0.0014619508672851847, 'epochs': 13, 'dropout_rate': 0.3037797121632211, 'recon_weight': 0.4925587894997604, 'C': 0.5689490335667051, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 1 with value: 0.5246626025611533.\n",
      "[I 2025-05-09 03:36:42,451] Trial 8 finished with value: 0.535580093551108 and parameters: {'latent_dim': 93, 'hidden_dim': 175, 'lr': 0.0026966558244195075, 'epochs': 46, 'dropout_rate': 0.4136595884826917, 'recon_weight': 0.4804007520958681, 'C': 1.951528790084813, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 8 with value: 0.535580093551108.\n",
      "[I 2025-05-09 03:36:53,213] Trial 9 finished with value: 0.5256115328579097 and parameters: {'latent_dim': 51, 'hidden_dim': 70, 'lr': 0.000332531645799431, 'epochs': 17, 'dropout_rate': 0.12815193559288424, 'recon_weight': 0.21838629314510316, 'C': 0.1790769100470169, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 8 with value: 0.535580093551108.\n",
      "[I 2025-05-09 03:37:29,536] Trial 10 finished with value: 0.5187869028448738 and parameters: {'latent_dim': 12, 'hidden_dim': 173, 'lr': 0.00011816262673060476, 'epochs': 38, 'dropout_rate': 0.30665278071118507, 'recon_weight': 0.3827310841358643, 'C': 9.943501963286488, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 8 with value: 0.535580093551108.\n",
      "[I 2025-05-09 03:37:47,003] Trial 11 finished with value: 0.5105340848094471 and parameters: {'latent_dim': 79, 'hidden_dim': 125, 'lr': 0.0002492016023763738, 'epochs': 21, 'dropout_rate': 0.103276126649133, 'recon_weight': 0.13815707368159036, 'C': 0.11645141020753665, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 8 with value: 0.535580093551108.\n",
      "[I 2025-05-09 03:37:58,190] Trial 12 finished with value: 0.5131891726094625 and parameters: {'latent_dim': 95, 'hidden_dim': 184, 'lr': 0.0003094012239336374, 'epochs': 10, 'dropout_rate': 0.20530922989911277, 'recon_weight': 0.3158802262718803, 'C': 0.13251854912286007, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 8 with value: 0.535580093551108.\n",
      "[I 2025-05-09 03:38:27,640] Trial 13 finished with value: 0.5246721877156659 and parameters: {'latent_dim': 66, 'hidden_dim': 121, 'lr': 0.0024659822820997913, 'epochs': 36, 'dropout_rate': 0.36598143090832863, 'recon_weight': 0.42786027042324704, 'C': 1.638014809348623, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 8 with value: 0.535580093551108.\n",
      "[I 2025-05-09 03:38:45,162] Trial 14 finished with value: 0.5176079288398129 and parameters: {'latent_dim': 84, 'hidden_dim': 145, 'lr': 0.0006620446244907412, 'epochs': 20, 'dropout_rate': 0.22719884345838104, 'recon_weight': 0.2591294786342637, 'C': 18.66989222668023, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 8 with value: 0.535580093551108.\n",
      "[I 2025-05-09 03:39:15,751] Trial 15 finished with value: 0.4971436239552181 and parameters: {'latent_dim': 59, 'hidden_dim': 67, 'lr': 0.00010086174388836774, 'epochs': 50, 'dropout_rate': 0.3541390597451702, 'recon_weight': 0.8944811263017924, 'C': 0.35912142953612486, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 8 with value: 0.535580093551108.\n",
      "[I 2025-05-09 03:39:43,373] Trial 16 finished with value: 0.4990989954758071 and parameters: {'latent_dim': 24, 'hidden_dim': 192, 'lr': 0.002054534564368452, 'epochs': 25, 'dropout_rate': 0.49805564317238626, 'recon_weight': 0.21986995776654056, 'C': 0.25524390565044586, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 8 with value: 0.535580093551108.\n",
      "[I 2025-05-09 03:40:09,241] Trial 17 finished with value: 0.5258415765662142 and parameters: {'latent_dim': 90, 'hidden_dim': 111, 'lr': 0.00023503790400700698, 'epochs': 34, 'dropout_rate': 0.18084988705575536, 'recon_weight': 0.6720432437119037, 'C': 1.283556390918831, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 8 with value: 0.535580093551108.\n",
      "[I 2025-05-09 03:40:32,446] Trial 18 finished with value: 0.5159401119546048 and parameters: {'latent_dim': 88, 'hidden_dim': 105, 'lr': 0.00018094346541077825, 'epochs': 35, 'dropout_rate': 0.20434659035044833, 'recon_weight': 0.6918725065668101, 'C': 1.2481901692516495, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 8 with value: 0.535580093551108.\n",
      "[I 2025-05-09 03:41:09,167] Trial 19 finished with value: 0.5230810520665593 and parameters: {'latent_dim': 71, 'hidden_dim': 162, 'lr': 0.0005664234747299994, 'epochs': 43, 'dropout_rate': 0.17473620216958563, 'recon_weight': 0.4766108612972627, 'C': 1.6153797636952547, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 8 with value: 0.535580093551108.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5220\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5172\n",
      "ROC-AUC autoencoded: 0.4859\n",
      "ROC-AUC autoencoded: 0.5219\n",
      "ROC-AUC autoencoded: 0.5010\n",
      "ROC-AUC autoencoded: 0.5089\n",
      "ROC-AUC autoencoded: 0.5562\n",
      "ROC-AUC autoencoded: 0.5674\n",
      "ROC-AUC autoencoded: 0.5769\n",
      "ROC-AUC autoencoded: 0.5362\n",
      "ROC-AUC autoencoded: 0.5594\n",
      "ROC-AUC autoencoded: 0.5679\n",
      "ROC-AUC autoencoded: 0.5433\n",
      "ROC-AUC autoencoded: 0.5879\n",
      "ROC-AUC autoencoded: 0.5590\n",
      "ROC-AUC autoencoded: 0.5677\n",
      "ROC-AUC autoencoded: 0.5852\n",
      "ROC-AUC autoencoded: 0.5524\n",
      "ROC-AUC autoencoded: 0.5505\n",
      "ROC-AUC autoencoded: 0.5508\n",
      "ROC-AUC autoencoded: 0.5655\n",
      "ROC-AUC autoencoded: 0.5545\n",
      "ROC-AUC autoencoded: 0.5664\n",
      "ROC-AUC autoencoded: 0.5273\n",
      "ROC-AUC autoencoded: 0.5436\n",
      "ROC-AUC autoencoded: 0.5549\n",
      "среднее 0.548307018571218\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 03:49:45,870] A new study created in memory with name: no-name-0e15e7b4-8d7c-4705-86cc-7db008d42e8b\n",
      "[I 2025-05-09 03:50:15,857] Trial 0 finished with value: 0.5025688214094011 and parameters: {'latent_dim': 66, 'hidden_dim': 163, 'lr': 0.00011361118347877057, 'epochs': 29, 'dropout_rate': 0.3111726000709911, 'recon_weight': 0.6004017079153309}. Best is trial 0 with value: 0.5025688214094011.\n",
      "[I 2025-05-09 03:51:01,755] Trial 1 finished with value: 0.5224580170232344 and parameters: {'latent_dim': 61, 'hidden_dim': 170, 'lr': 0.003252101133058358, 'epochs': 47, 'dropout_rate': 0.20079010925030039, 'recon_weight': 0.24820479287447236}. Best is trial 1 with value: 0.5224580170232344.\n",
      "[I 2025-05-09 03:51:35,362] Trial 2 finished with value: 0.5318418832911586 and parameters: {'latent_dim': 48, 'hidden_dim': 163, 'lr': 0.006831640053542927, 'epochs': 34, 'dropout_rate': 0.334596342408254, 'recon_weight': 0.7349827415457008}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:51:47,210] Trial 3 finished with value: 0.5214324054903766 and parameters: {'latent_dim': 74, 'hidden_dim': 193, 'lr': 0.000283189010282026, 'epochs': 11, 'dropout_rate': 0.18183254115771685, 'recon_weight': 0.8132900002033837}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:52:03,671] Trial 4 finished with value: 0.5123840196303965 and parameters: {'latent_dim': 15, 'hidden_dim': 81, 'lr': 0.0003700945895821041, 'epochs': 24, 'dropout_rate': 0.46832989291389027, 'recon_weight': 0.6529953772935472}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:52:19,965] Trial 5 finished with value: 0.5072463768115941 and parameters: {'latent_dim': 26, 'hidden_dim': 180, 'lr': 0.00010155100662446522, 'epochs': 16, 'dropout_rate': 0.35328881877174956, 'recon_weight': 0.14359549480501743}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:52:57,992] Trial 6 finished with value: 0.4831588835212024 and parameters: {'latent_dim': 36, 'hidden_dim': 169, 'lr': 0.000992081931150536, 'epochs': 39, 'dropout_rate': 0.2285825726948293, 'recon_weight': 0.2576811129003129}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:53:41,379] Trial 7 finished with value: 0.5154800245379955 and parameters: {'latent_dim': 17, 'hidden_dim': 169, 'lr': 0.0014539459472030722, 'epochs': 45, 'dropout_rate': 0.48102276002792943, 'recon_weight': 0.1771766358960413}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:54:09,236] Trial 8 finished with value: 0.5264166858369757 and parameters: {'latent_dim': 64, 'hidden_dim': 214, 'lr': 0.0002654545187577, 'epochs': 25, 'dropout_rate': 0.21563439436882523, 'recon_weight': 0.18782634933911568}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:54:52,843] Trial 9 finished with value: 0.5105915957365232 and parameters: {'latent_dim': 18, 'hidden_dim': 209, 'lr': 0.0008568352567932039, 'epochs': 40, 'dropout_rate': 0.1733711027152895, 'recon_weight': 0.47301060194437994}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:55:36,402] Trial 10 finished with value: 0.504370830457787 and parameters: {'latent_dim': 89, 'hidden_dim': 250, 'lr': 0.008564227754944418, 'epochs': 35, 'dropout_rate': 0.10045647450553738, 'recon_weight': 0.8858585195301554}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:55:58,124] Trial 11 finished with value: 0.49738325281803536 and parameters: {'latent_dim': 46, 'hidden_dim': 115, 'lr': 0.007886735014448164, 'epochs': 27, 'dropout_rate': 0.34564194825122757, 'recon_weight': 0.4196954128495279}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:56:22,759] Trial 12 finished with value: 0.49191012959128894 and parameters: {'latent_dim': 51, 'hidden_dim': 232, 'lr': 0.0027368509318951755, 'epochs': 21, 'dropout_rate': 0.4020449537658476, 'recon_weight': 0.72170149670149}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:56:51,237] Trial 13 finished with value: 0.5061824246606855 and parameters: {'latent_dim': 81, 'hidden_dim': 133, 'lr': 0.0003704869076031138, 'epochs': 33, 'dropout_rate': 0.26726965843081074, 'recon_weight': 0.4298099667501441}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:57:14,222] Trial 14 finished with value: 0.4986964189862741 and parameters: {'latent_dim': 43, 'hidden_dim': 215, 'lr': 0.00021834725771943192, 'epochs': 19, 'dropout_rate': 0.2641035561306143, 'recon_weight': 0.331577864718723}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:57:42,691] Trial 15 finished with value: 0.5106299363545741 and parameters: {'latent_dim': 97, 'hidden_dim': 123, 'lr': 0.0006372786042891606, 'epochs': 33, 'dropout_rate': 0.4001145570799487, 'recon_weight': 0.5760410048163627}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:58:07,705] Trial 16 finished with value: 0.512863277356031 and parameters: {'latent_dim': 60, 'hidden_dim': 139, 'lr': 0.0037641613499771213, 'epochs': 26, 'dropout_rate': 0.11993860417688805, 'recon_weight': 0.7790698026303651}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:58:34,553] Trial 17 finished with value: 0.5020608082202285 and parameters: {'latent_dim': 72, 'hidden_dim': 84, 'lr': 0.0018208883675687078, 'epochs': 39, 'dropout_rate': 0.2841820237204581, 'recon_weight': 0.10452795066676557}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:59:27,884] Trial 18 finished with value: 0.5071025994939039 and parameters: {'latent_dim': 33, 'hidden_dim': 201, 'lr': 0.005353039822632453, 'epochs': 50, 'dropout_rate': 0.22755162284838776, 'recon_weight': 0.5462226105399315}. Best is trial 2 with value: 0.5318418832911586.\n",
      "[I 2025-05-09 03:59:46,828] Trial 19 finished with value: 0.5126715742657771 and parameters: {'latent_dim': 54, 'hidden_dim': 255, 'lr': 0.0001661655617438543, 'epochs': 15, 'dropout_rate': 0.1438127416812995, 'recon_weight': 0.34391633943587463}. Best is trial 2 with value: 0.5318418832911586.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5459\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Веса для объединенной функции потерь\n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        # Используем голову классификатора для получения предсказаний\n",
    "        y_pred_proba = predict_with_classifier_head(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "def predict_with_classifier_head(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, _, classification = model(X_tensor)\n",
    "    return classification.cpu().numpy().flatten()\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "# Используем голову классификатора для получения предсказаний\n",
    "y_pred_proba = predict_with_classifier_head(autoencoder, X_val_all)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4901\n",
      "ROC-AUC autoencoded: 0.4887\n",
      "ROC-AUC autoencoded: 0.4727\n",
      "ROC-AUC autoencoded: 0.5108\n",
      "ROC-AUC autoencoded: 0.5015\n",
      "ROC-AUC autoencoded: 0.5758\n",
      "ROC-AUC autoencoded: 0.5290\n",
      "ROC-AUC autoencoded: 0.5775\n",
      "ROC-AUC autoencoded: 0.5897\n",
      "ROC-AUC autoencoded: 0.5539\n",
      "ROC-AUC autoencoded: 0.5786\n",
      "ROC-AUC autoencoded: 0.5957\n",
      "ROC-AUC autoencoded: 0.5372\n",
      "ROC-AUC autoencoded: 0.5767\n",
      "ROC-AUC autoencoded: 0.5826\n",
      "ROC-AUC autoencoded: 0.5772\n",
      "ROC-AUC autoencoded: 0.5613\n",
      "ROC-AUC autoencoded: 0.5727\n",
      "ROC-AUC autoencoded: 0.5321\n",
      "ROC-AUC autoencoded: 0.5593\n",
      "ROC-AUC autoencoded: 0.5614\n",
      "ROC-AUC autoencoded: 0.5504\n",
      "ROC-AUC autoencoded: 0.5743\n",
      "ROC-AUC autoencoded: 0.5745\n",
      "ROC-AUC autoencoded: 0.5491\n",
      "среднее 0.5509233711345222\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        # Используем голову классификатора для получения предсказаний\n",
    "        y_pred_proba = predict_with_classifier_head(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше идет блок со sparse автоэнкодером без классифицирующей головы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 04:16:10,010] A new study created in memory with name: no-name-1960f810-4b9b-4dc3-b966-6e18bfd0e92b\n",
      "[I 2025-05-09 04:17:27,278] Trial 0 finished with value: 0.5218158116708841 and parameters: {'latent_dim': 14, 'hidden_dim': 243, 'lr': 0.00022132527381144788, 'epochs': 47, 'dropout_rate': 0.36030479558019757, 'sparsity_weight': 0.0006452355993560507, 'C': 0.17966089436724958, 'solver': 'liblinear'}. Best is trial 0 with value: 0.5218158116708841.\n",
      "[I 2025-05-09 04:18:17,972] Trial 1 finished with value: 0.5063837129054519 and parameters: {'latent_dim': 34, 'hidden_dim': 234, 'lr': 0.0005305287872667082, 'epochs': 40, 'dropout_rate': 0.4759067551011207, 'sparsity_weight': 0.004984515378644766, 'C': 44.631270366152556, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5218158116708841.\n",
      "[I 2025-05-09 04:18:45,379] Trial 2 finished with value: 0.5175600030672495 and parameters: {'latent_dim': 57, 'hidden_dim': 84, 'lr': 0.0024706700515002068, 'epochs': 38, 'dropout_rate': 0.4964204773226226, 'sparsity_weight': 0.009111492900595607, 'C': 0.04265422063349392, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5218158116708841.\n",
      "[I 2025-05-09 04:18:56,930] Trial 3 finished with value: 0.48978222528947163 and parameters: {'latent_dim': 55, 'hidden_dim': 184, 'lr': 0.0004393076877514784, 'epochs': 11, 'dropout_rate': 0.17370740362646975, 'sparsity_weight': 0.0005185171832799169, 'C': 0.10699377251850856, 'solver': 'liblinear'}. Best is trial 0 with value: 0.5218158116708841.\n",
      "[I 2025-05-09 04:19:43,002] Trial 4 finished with value: 0.50929759987731 and parameters: {'latent_dim': 21, 'hidden_dim': 183, 'lr': 0.00011993067978565284, 'epochs': 44, 'dropout_rate': 0.10547153415917046, 'sparsity_weight': 0.00010739074040807533, 'C': 0.4348807954982695, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5218158116708841.\n",
      "[I 2025-05-09 04:20:16,124] Trial 5 finished with value: 0.49697109117398974 and parameters: {'latent_dim': 93, 'hidden_dim': 120, 'lr': 0.003702474890846456, 'epochs': 40, 'dropout_rate': 0.48970146062934217, 'sparsity_weight': 0.000134136966983683, 'C': 65.22659097919484, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5218158116708841.\n",
      "[I 2025-05-09 04:20:39,811] Trial 6 finished with value: 0.5536385246530174 and parameters: {'latent_dim': 43, 'hidden_dim': 199, 'lr': 0.00401404026016819, 'epochs': 22, 'dropout_rate': 0.28856338215341426, 'sparsity_weight': 0.026666266640480413, 'C': 1.5886347182321314, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.5536385246530174.\n",
      "[I 2025-05-09 04:21:26,693] Trial 7 finished with value: 0.49635764128517756 and parameters: {'latent_dim': 29, 'hidden_dim': 202, 'lr': 0.0002455391274630143, 'epochs': 37, 'dropout_rate': 0.14828855492101933, 'sparsity_weight': 0.00010081134841479995, 'C': 3.6789119688376455, 'solver': 'saga'}. Best is trial 6 with value: 0.5536385246530174.\n",
      "[I 2025-05-09 04:22:18,768] Trial 8 finished with value: 0.5873974388467142 and parameters: {'latent_dim': 74, 'hidden_dim': 244, 'lr': 0.003637625592515867, 'epochs': 40, 'dropout_rate': 0.27130835199420417, 'sparsity_weight': 0.0039598342992045, 'C': 0.013142035573521262, 'solver': 'saga'}. Best is trial 8 with value: 0.5873974388467142.\n",
      "[I 2025-05-09 04:22:36,593] Trial 9 finished with value: 0.5407273215244229 and parameters: {'latent_dim': 84, 'hidden_dim': 75, 'lr': 0.0010145070424157924, 'epochs': 25, 'dropout_rate': 0.13387605057549115, 'sparsity_weight': 0.009325228949251491, 'C': 0.023548467576000133, 'solver': 'saga'}. Best is trial 8 with value: 0.5873974388467142.\n",
      "[I 2025-05-09 04:23:23,184] Trial 10 finished with value: 0.5726171305881451 and parameters: {'latent_dim': 74, 'hidden_dim': 145, 'lr': 0.008558044015127119, 'epochs': 50, 'dropout_rate': 0.24872797620539608, 'sparsity_weight': 0.08294436569365685, 'C': 0.01126792807050321, 'solver': 'saga'}. Best is trial 8 with value: 0.5873974388467142.\n",
      "[I 2025-05-09 04:24:06,002] Trial 11 finished with value: 0.5731155586228049 and parameters: {'latent_dim': 74, 'hidden_dim': 145, 'lr': 0.009807952402427803, 'epochs': 48, 'dropout_rate': 0.26162283059566865, 'sparsity_weight': 0.09577570309380667, 'C': 0.011177361197045144, 'solver': 'saga'}. Best is trial 8 with value: 0.5873974388467142.\n",
      "[I 2025-05-09 04:24:33,061] Trial 12 finished with value: 0.5560731538992408 and parameters: {'latent_dim': 72, 'hidden_dim': 138, 'lr': 0.009986401149375417, 'epochs': 31, 'dropout_rate': 0.35852872417370274, 'sparsity_weight': 0.09681909577761949, 'C': 0.04668759545573439, 'solver': 'saga'}. Best is trial 8 with value: 0.5873974388467142.\n",
      "[I 2025-05-09 04:25:00,269] Trial 13 finished with value: 0.5456061651713825 and parameters: {'latent_dim': 100, 'hidden_dim': 107, 'lr': 0.0017701450205840816, 'epochs': 32, 'dropout_rate': 0.24946627500138233, 'sparsity_weight': 0.0014690532912195618, 'C': 0.010599797772899999, 'solver': 'saga'}. Best is trial 8 with value: 0.5873974388467142.\n",
      "[I 2025-05-09 04:26:14,641] Trial 14 finished with value: 0.5950847327658921 and parameters: {'latent_dim': 66, 'hidden_dim': 256, 'lr': 0.005459830698237786, 'epochs': 45, 'dropout_rate': 0.21467895477175386, 'sparsity_weight': 0.02887371152569355, 'C': 11.569589157487256, 'solver': 'saga'}. Best is trial 14 with value: 0.5950847327658921.\n",
      "[I 2025-05-09 04:27:05,340] Trial 15 finished with value: 0.5870907139023082 and parameters: {'latent_dim': 59, 'hidden_dim': 254, 'lr': 0.0038419279903275034, 'epochs': 44, 'dropout_rate': 0.21099135326498583, 'sparsity_weight': 0.024753601445954215, 'C': 11.875647795470755, 'solver': 'saga'}. Best is trial 14 with value: 0.5950847327658921.\n",
      "[I 2025-05-09 04:27:48,528] Trial 16 finished with value: 0.5324936737980216 and parameters: {'latent_dim': 65, 'hidden_dim': 223, 'lr': 0.0012893549590966308, 'epochs': 34, 'dropout_rate': 0.32459530875784925, 'sparsity_weight': 0.002779359826712417, 'C': 11.582638565799336, 'solver': 'saga'}. Best is trial 14 with value: 0.5950847327658921.\n",
      "[I 2025-05-09 04:28:17,702] Trial 17 finished with value: 0.5586803159266926 and parameters: {'latent_dim': 47, 'hidden_dim': 222, 'lr': 0.005401021290739206, 'epochs': 25, 'dropout_rate': 0.4064696005384798, 'sparsity_weight': 0.02686877427801088, 'C': 0.899651572599336, 'solver': 'liblinear'}. Best is trial 14 with value: 0.5950847327658921.\n",
      "[I 2025-05-09 04:29:11,776] Trial 18 finished with value: 0.557185031822713 and parameters: {'latent_dim': 84, 'hidden_dim': 254, 'lr': 0.0021114585966855626, 'epochs': 42, 'dropout_rate': 0.20541224856149806, 'sparsity_weight': 0.011500128405625079, 'C': 7.441011902913076, 'solver': 'saga'}. Best is trial 14 with value: 0.5950847327658921.\n",
      "[I 2025-05-09 04:29:29,075] Trial 19 finished with value: 0.5561114945172916 and parameters: {'latent_dim': 87, 'hidden_dim': 207, 'lr': 0.006051673890271763, 'epochs': 14, 'dropout_rate': 0.21001863226937972, 'sparsity_weight': 0.001853451986199918, 'C': 3.816857930094143, 'solver': 'saga'}. Best is trial 14 with value: 0.5950847327658921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5403\n"
     ]
    }
   ],
   "source": [
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "    \n",
    "def train_sparse_autoencoder(model, X_train, epochs, batch_size, lr, sparsity_weight):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, _ in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, latent = model(batch_x)\n",
    "            \n",
    "            recon_loss = criterion(reconstructed, batch_x)\n",
    "            \n",
    "            sparsity_loss = torch.mean(torch.abs(latent))\n",
    "            \n",
    "            loss = recon_loss + sparsity_weight * sparsity_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs, batch_size, lr, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4613\n",
      "ROC-AUC autoencoded: 0.5223\n",
      "ROC-AUC autoencoded: 0.5117\n",
      "ROC-AUC autoencoded: 0.4786\n",
      "ROC-AUC autoencoded: 0.4946\n",
      "ROC-AUC autoencoded: 0.4515\n",
      "ROC-AUC autoencoded: 0.5485\n",
      "ROC-AUC autoencoded: 0.5423\n",
      "ROC-AUC autoencoded: 0.4906\n",
      "ROC-AUC autoencoded: 0.5302\n",
      "ROC-AUC autoencoded: 0.5772\n",
      "ROC-AUC autoencoded: 0.5942\n",
      "ROC-AUC autoencoded: 0.5396\n",
      "ROC-AUC autoencoded: 0.6124\n",
      "ROC-AUC autoencoded: 0.5479\n",
      "ROC-AUC autoencoded: 0.4796\n",
      "ROC-AUC autoencoded: 0.5289\n",
      "ROC-AUC autoencoded: 0.5219\n",
      "ROC-AUC autoencoded: 0.5196\n",
      "ROC-AUC autoencoded: 0.5365\n",
      "ROC-AUC autoencoded: 0.5263\n",
      "ROC-AUC autoencoded: 0.5127\n",
      "ROC-AUC autoencoded: 0.5100\n",
      "ROC-AUC autoencoded: 0.5641\n",
      "ROC-AUC autoencoded: 0.5354\n",
      "среднее 0.525519170124399\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 04:44:53,253] A new study created in memory with name: no-name-1e50409e-1ece-4938-8131-53029ba2215c\n",
      "[I 2025-05-09 04:45:55,651] Trial 0 finished with value: 0.5366152902384786 and parameters: {'latent_dim': 73, 'hidden_dim': 122, 'lr': 0.00048442005608490186, 'epochs': 24, 'dropout_rate': 0.4757362729309921, 'sparsity_weight': 0.07124437799086655, 'n_estimators': 417, 'max_depth': 5, 'learning_rate': 0.24814306542492226, 'subsample': 0.6758489157831679, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.5366152902384786.\n",
      "[I 2025-05-09 04:46:26,997] Trial 1 finished with value: 0.5014377731769036 and parameters: {'latent_dim': 35, 'hidden_dim': 94, 'lr': 0.0005322437514525651, 'epochs': 13, 'dropout_rate': 0.11344427579261747, 'sparsity_weight': 0.0005796078032044157, 'n_estimators': 308, 'max_depth': 9, 'learning_rate': 0.28581195072975096, 'subsample': 0.6413342414203862, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.5366152902384786.\n",
      "[I 2025-05-09 04:47:00,773] Trial 2 finished with value: 0.5049842803465991 and parameters: {'latent_dim': 18, 'hidden_dim': 241, 'lr': 0.00011016767769807159, 'epochs': 17, 'dropout_rate': 0.31742245297851246, 'sparsity_weight': 0.004991806142432818, 'n_estimators': 298, 'max_depth': 9, 'learning_rate': 0.06645796805823215, 'subsample': 0.7487455535165476, 'min_samples_split': 17, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.5366152902384786.\n",
      "[I 2025-05-09 04:47:43,106] Trial 3 finished with value: 0.4857756307031669 and parameters: {'latent_dim': 40, 'hidden_dim': 195, 'lr': 0.0001699487474897926, 'epochs': 13, 'dropout_rate': 0.178296105022844, 'sparsity_weight': 0.0002911080396277764, 'n_estimators': 258, 'max_depth': 10, 'learning_rate': 0.026371017889683913, 'subsample': 0.8220793091266437, 'min_samples_split': 20, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.5366152902384786.\n",
      "[I 2025-05-09 04:49:00,809] Trial 4 finished with value: 0.48111724560999924 and parameters: {'latent_dim': 98, 'hidden_dim': 76, 'lr': 0.0002779665075947411, 'epochs': 29, 'dropout_rate': 0.11605454850040622, 'sparsity_weight': 0.0003121944469215052, 'n_estimators': 360, 'max_depth': 5, 'learning_rate': 0.03905049665665571, 'subsample': 0.8772926881606131, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.5366152902384786.\n",
      "[I 2025-05-09 04:50:19,171] Trial 5 finished with value: 0.5288704853922246 and parameters: {'latent_dim': 47, 'hidden_dim': 182, 'lr': 0.0001325773323614563, 'epochs': 35, 'dropout_rate': 0.20622045374290204, 'sparsity_weight': 0.00016803326469469107, 'n_estimators': 459, 'max_depth': 6, 'learning_rate': 0.0380697978013584, 'subsample': 0.6412708124964296, 'min_samples_split': 19, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.5366152902384786.\n",
      "[I 2025-05-09 04:51:30,299] Trial 6 finished with value: 0.5081282110267618 and parameters: {'latent_dim': 55, 'hidden_dim': 155, 'lr': 0.0021433279915114047, 'epochs': 34, 'dropout_rate': 0.3772180646449863, 'sparsity_weight': 0.008921202139475896, 'n_estimators': 393, 'max_depth': 6, 'learning_rate': 0.017885607901182668, 'subsample': 0.7685449024605404, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.5366152902384786.\n",
      "[I 2025-05-09 04:52:22,407] Trial 7 finished with value: 0.4825166781688521 and parameters: {'latent_dim': 42, 'hidden_dim': 86, 'lr': 0.00028971482210789565, 'epochs': 27, 'dropout_rate': 0.48370979264118197, 'sparsity_weight': 0.016498749186204715, 'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.1068201993448168, 'subsample': 0.6870139589200431, 'min_samples_split': 19, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.5366152902384786.\n",
      "[I 2025-05-09 04:53:04,556] Trial 8 finished with value: 0.5087224906065485 and parameters: {'latent_dim': 35, 'hidden_dim': 215, 'lr': 0.004140624701215102, 'epochs': 30, 'dropout_rate': 0.40915215027306295, 'sparsity_weight': 0.029355078842366503, 'n_estimators': 289, 'max_depth': 3, 'learning_rate': 0.011510120534177598, 'subsample': 0.7371575240806206, 'min_samples_split': 18, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.5366152902384786.\n",
      "[I 2025-05-09 04:53:19,452] Trial 9 finished with value: 0.5134383866267924 and parameters: {'latent_dim': 35, 'hidden_dim': 146, 'lr': 0.0004876609898425091, 'epochs': 12, 'dropout_rate': 0.48711680667604174, 'sparsity_weight': 0.011351755017654569, 'n_estimators': 64, 'max_depth': 7, 'learning_rate': 0.07977866823551, 'subsample': 0.7331165503809539, 'min_samples_split': 19, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.5366152902384786.\n",
      "[I 2025-05-09 04:54:16,685] Trial 10 finished with value: 0.5383406180507629 and parameters: {'latent_dim': 80, 'hidden_dim': 124, 'lr': 0.0014953987742659268, 'epochs': 50, 'dropout_rate': 0.2955855335743437, 'sparsity_weight': 0.05440115903443133, 'n_estimators': 171, 'max_depth': 3, 'learning_rate': 0.29088179197618264, 'subsample': 0.991487758596205, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.5383406180507629.\n",
      "[I 2025-05-09 04:55:11,488] Trial 11 finished with value: 0.5508588298443371 and parameters: {'latent_dim': 80, 'hidden_dim': 121, 'lr': 0.001350103291078089, 'epochs': 48, 'dropout_rate': 0.27844353196071003, 'sparsity_weight': 0.08960428249712016, 'n_estimators': 160, 'max_depth': 3, 'learning_rate': 0.2788964976631332, 'subsample': 0.999768822989092, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.5508588298443371.\n",
      "[I 2025-05-09 04:56:07,191] Trial 12 finished with value: 0.5227934974311785 and parameters: {'latent_dim': 80, 'hidden_dim': 119, 'lr': 0.0015560909284388666, 'epochs': 50, 'dropout_rate': 0.2704659880289785, 'sparsity_weight': 0.08735696807133557, 'n_estimators': 161, 'max_depth': 3, 'learning_rate': 0.15367736083346434, 'subsample': 0.9971218563348748, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.5508588298443371.\n",
      "[I 2025-05-09 04:57:09,365] Trial 13 finished with value: 0.5210298290008435 and parameters: {'latent_dim': 78, 'hidden_dim': 122, 'lr': 0.007935509802922873, 'epochs': 50, 'dropout_rate': 0.28267013610019437, 'sparsity_weight': 0.001607304167530093, 'n_estimators': 172, 'max_depth': 4, 'learning_rate': 0.14903087000634227, 'subsample': 0.986158660321423, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.5508588298443371.\n",
      "[I 2025-05-09 04:58:01,057] Trial 14 finished with value: 0.5553830227743272 and parameters: {'latent_dim': 97, 'hidden_dim': 138, 'lr': 0.0011167556068006899, 'epochs': 42, 'dropout_rate': 0.33583062513016276, 'sparsity_weight': 0.03520905272864794, 'n_estimators': 154, 'max_depth': 3, 'learning_rate': 0.18638141988307386, 'subsample': 0.9251404104148443, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.5553830227743272.\n",
      "[I 2025-05-09 04:58:52,150] Trial 15 finished with value: 0.5100644122383252 and parameters: {'latent_dim': 95, 'hidden_dim': 175, 'lr': 0.0009030917216328368, 'epochs': 41, 'dropout_rate': 0.36905240081061685, 'sparsity_weight': 0.029672186558835058, 'n_estimators': 84, 'max_depth': 4, 'learning_rate': 0.1616440309314606, 'subsample': 0.9125325208056612, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.5553830227743272.\n",
      "[I 2025-05-09 04:59:50,553] Trial 16 finished with value: 0.5324361628709454 and parameters: {'latent_dim': 67, 'hidden_dim': 145, 'lr': 0.0029208458779133623, 'epochs': 43, 'dropout_rate': 0.2257507958900084, 'sparsity_weight': 0.0025435346171295277, 'n_estimators': 222, 'max_depth': 4, 'learning_rate': 0.1934719186322251, 'subsample': 0.9191662927124783, 'min_samples_split': 14, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.5553830227743272.\n",
      "[I 2025-05-09 05:00:36,829] Trial 17 finished with value: 0.49807338394294914 and parameters: {'latent_dim': 90, 'hidden_dim': 65, 'lr': 0.0009091279447417969, 'epochs': 43, 'dropout_rate': 0.343783841319501, 'sparsity_weight': 0.031276566232278494, 'n_estimators': 119, 'max_depth': 5, 'learning_rate': 0.10754537813446986, 'subsample': 0.9457644238941793, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.5553830227743272.\n",
      "[I 2025-05-09 05:01:19,128] Trial 18 finished with value: 0.5210106586918181 and parameters: {'latent_dim': 63, 'hidden_dim': 102, 'lr': 0.0047112606742843715, 'epochs': 38, 'dropout_rate': 0.41847623259917033, 'sparsity_weight': 0.0053458569731084545, 'n_estimators': 226, 'max_depth': 3, 'learning_rate': 0.10425843843930221, 'subsample': 0.8369514751810266, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.5553830227743272.\n",
      "[I 2025-05-09 05:02:26,809] Trial 19 finished with value: 0.5067862893949849 and parameters: {'latent_dim': 87, 'hidden_dim': 167, 'lr': 0.0010235886210724497, 'epochs': 46, 'dropout_rate': 0.24664066505426444, 'sparsity_weight': 0.09332198651562013, 'n_estimators': 111, 'max_depth': 8, 'learning_rate': 0.2048971335079593, 'subsample': 0.8787833066585531, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.5553830227743272.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5094\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs, batch_size, lr, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4945\n",
      "ROC-AUC autoencoded: 0.4674\n",
      "ROC-AUC autoencoded: 0.5198\n",
      "ROC-AUC autoencoded: 0.4775\n",
      "ROC-AUC autoencoded: 0.4477\n",
      "ROC-AUC autoencoded: 0.5307\n",
      "ROC-AUC autoencoded: 0.4551\n",
      "ROC-AUC autoencoded: 0.4914\n",
      "ROC-AUC autoencoded: 0.4399\n",
      "ROC-AUC autoencoded: 0.4217\n",
      "ROC-AUC autoencoded: 0.4501\n",
      "ROC-AUC autoencoded: 0.4880\n",
      "ROC-AUC autoencoded: 0.5494\n",
      "ROC-AUC autoencoded: 0.5490\n",
      "ROC-AUC autoencoded: 0.5471\n",
      "ROC-AUC autoencoded: 0.4699\n",
      "ROC-AUC autoencoded: 0.4915\n",
      "ROC-AUC autoencoded: 0.5468\n",
      "ROC-AUC autoencoded: 0.5026\n",
      "ROC-AUC autoencoded: 0.5236\n",
      "ROC-AUC autoencoded: 0.4875\n",
      "ROC-AUC autoencoded: 0.5108\n",
      "ROC-AUC autoencoded: 0.4256\n",
      "ROC-AUC autoencoded: 0.4372\n",
      "ROC-AUC autoencoded: 0.4364\n",
      "среднее 0.48644165410824924\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 05:14:07,413] A new study created in memory with name: no-name-23279a58-e1e6-40d3-a2a0-7cefc43d5d1a\n",
      "[I 2025-05-09 05:14:39,393] Trial 0 finished with value: 0.5013227513227513 and parameters: {'latent_dim': 23, 'hidden_dim': 85, 'lr': 0.00382058773317508, 'epochs': 43, 'dropout_rate': 0.27329099907700183, 'sparsity_weight': 0.0014558557422345083, 'C': 1.4681521521146017, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.5013227513227513.\n",
      "[I 2025-05-09 05:15:14,540] Trial 1 finished with value: 0.495782532014416 and parameters: {'latent_dim': 32, 'hidden_dim': 151, 'lr': 0.00018205991423434766, 'epochs': 39, 'dropout_rate': 0.21770096667215966, 'sparsity_weight': 0.039792569244957665, 'C': 2.604215600653708, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 0 with value: 0.5013227513227513.\n",
      "[I 2025-05-09 05:15:28,760] Trial 2 finished with value: 0.48500881834215165 and parameters: {'latent_dim': 64, 'hidden_dim': 121, 'lr': 0.0005436809209044868, 'epochs': 16, 'dropout_rate': 0.16622950309648044, 'sparsity_weight': 0.0015807718835084803, 'C': 1.4492066214350132, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.5013227513227513.\n",
      "[I 2025-05-09 05:16:18,424] Trial 3 finished with value: 0.4529368913426884 and parameters: {'latent_dim': 49, 'hidden_dim': 171, 'lr': 0.000981983312151216, 'epochs': 50, 'dropout_rate': 0.19078364081519628, 'sparsity_weight': 0.004210870586714991, 'C': 1.0987119177419005, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 0 with value: 0.5013227513227513.\n",
      "[I 2025-05-09 05:17:01,941] Trial 4 finished with value: 0.5138793037343762 and parameters: {'latent_dim': 79, 'hidden_dim': 216, 'lr': 0.0005381421693145164, 'epochs': 36, 'dropout_rate': 0.24265741263405238, 'sparsity_weight': 0.03948728540370304, 'C': 48.02267238352772, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 4 with value: 0.5138793037343762.\n",
      "[I 2025-05-09 05:17:12,726] Trial 5 finished with value: 0.5005751092707614 and parameters: {'latent_dim': 43, 'hidden_dim': 91, 'lr': 0.000270333535221188, 'epochs': 14, 'dropout_rate': 0.4873377819159853, 'sparsity_weight': 0.034981933482557855, 'C': 13.12004611379984, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.5138793037343762.\n",
      "[I 2025-05-09 05:17:31,305] Trial 6 finished with value: 0.5083774250440917 and parameters: {'latent_dim': 25, 'hidden_dim': 131, 'lr': 0.0006857500133693111, 'epochs': 21, 'dropout_rate': 0.3592460308449156, 'sparsity_weight': 0.006983555535914319, 'C': 0.12121848990532226, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 4 with value: 0.5138793037343762.\n",
      "[I 2025-05-09 05:17:57,112] Trial 7 finished with value: 0.512058124376965 and parameters: {'latent_dim': 48, 'hidden_dim': 231, 'lr': 0.0004975367255675743, 'epochs': 21, 'dropout_rate': 0.3505757546082109, 'sparsity_weight': 0.001897600892298633, 'C': 3.5893291472338595, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 4 with value: 0.5138793037343762.\n",
      "[I 2025-05-09 05:18:32,396] Trial 8 finished with value: 0.47973698336017173 and parameters: {'latent_dim': 69, 'hidden_dim': 239, 'lr': 0.003738966274812079, 'epochs': 29, 'dropout_rate': 0.23116125111191518, 'sparsity_weight': 0.00020124413724041172, 'C': 40.25381699155965, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 4 with value: 0.5138793037343762.\n",
      "[I 2025-05-09 05:42:35,725] Trial 9 finished with value: 0.5048117475653707 and parameters: {'latent_dim': 63, 'hidden_dim': 123, 'lr': 0.0003416447024824799, 'epochs': 34, 'dropout_rate': 0.20192446055272995, 'sparsity_weight': 0.0003093995419338524, 'C': 68.89816002484339, 'kernel': 'linear'}. Best is trial 4 with value: 0.5138793037343762.\n",
      "[I 2025-05-09 05:43:09,064] Trial 10 finished with value: 0.5044666820029139 and parameters: {'latent_dim': 97, 'hidden_dim': 199, 'lr': 0.001981907054834195, 'epochs': 28, 'dropout_rate': 0.1283122718297801, 'sparsity_weight': 0.09902845278897851, 'C': 14.545704217615217, 'kernel': 'linear'}. Best is trial 4 with value: 0.5138793037343762.\n",
      "[I 2025-05-09 05:43:40,825] Trial 11 finished with value: 0.5284870792117169 and parameters: {'latent_dim': 82, 'hidden_dim': 255, 'lr': 0.00013196017182521007, 'epochs': 24, 'dropout_rate': 0.3547573269257833, 'sparsity_weight': 0.011695973870529905, 'C': 7.941960674202553, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 11 with value: 0.5284870792117169.\n",
      "[I 2025-05-09 05:44:22,849] Trial 12 finished with value: 0.49823633156966496 and parameters: {'latent_dim': 87, 'hidden_dim': 254, 'lr': 0.00012726369552720757, 'epochs': 33, 'dropout_rate': 0.41647743655792924, 'sparsity_weight': 0.014817591546672912, 'C': 17.22455488242217, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 11 with value: 0.5284870792117169.\n",
      "[I 2025-05-09 05:44:49,752] Trial 13 finished with value: 0.4866382946093091 and parameters: {'latent_dim': 81, 'hidden_dim': 202, 'lr': 0.00010439742173974477, 'epochs': 23, 'dropout_rate': 0.3073994569280724, 'sparsity_weight': 0.015101096033434284, 'C': 98.7352841841481, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 11 with value: 0.5284870792117169.\n",
      "[I 2025-05-09 05:45:02,210] Trial 14 finished with value: 0.4757399739283798 and parameters: {'latent_dim': 78, 'hidden_dim': 210, 'lr': 0.007765509494489938, 'epochs': 10, 'dropout_rate': 0.4120121999842588, 'sparsity_weight': 0.08118558314963614, 'C': 7.747443844195847, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 11 with value: 0.5284870792117169.\n",
      "[I 2025-05-09 05:45:54,919] Trial 15 finished with value: 0.5231002223755846 and parameters: {'latent_dim': 96, 'hidden_dim': 255, 'lr': 0.001577159046574893, 'epochs': 39, 'dropout_rate': 0.28044271381002606, 'sparsity_weight': 0.014417632417805455, 'C': 31.097037937267345, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 11 with value: 0.5284870792117169.\n",
      "[I 2025-05-09 05:46:53,182] Trial 16 finished with value: 0.5275477340694731 and parameters: {'latent_dim': 99, 'hidden_dim': 254, 'lr': 0.001730960418497747, 'epochs': 45, 'dropout_rate': 0.3051236991578292, 'sparsity_weight': 0.010086683079965141, 'C': 0.504641901543669, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.5284870792117169.\n",
      "[I 2025-05-09 05:47:41,662] Trial 17 finished with value: 0.522314239705544 and parameters: {'latent_dim': 90, 'hidden_dim': 183, 'lr': 0.0018768156931057362, 'epochs': 46, 'dropout_rate': 0.34055045971467013, 'sparsity_weight': 0.0005813588011520995, 'C': 0.30845822149486885, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.5284870792117169.\n",
      "[I 2025-05-09 05:48:13,500] Trial 18 finished with value: 0.5223334100145695 and parameters: {'latent_dim': 100, 'hidden_dim': 232, 'lr': 0.00984384169139749, 'epochs': 26, 'dropout_rate': 0.40939569693463296, 'sparsity_weight': 0.006630042694009442, 'C': 0.43935837068348527, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.5284870792117169.\n",
      "[I 2025-05-09 05:49:04,479] Trial 19 finished with value: 0.5070738440303657 and parameters: {'latent_dim': 72, 'hidden_dim': 181, 'lr': 0.003931105257334869, 'epochs': 49, 'dropout_rate': 0.48066540650730155, 'sparsity_weight': 0.007889046844557424, 'C': 0.5411030828099908, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.5284870792117169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5403\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs, batch_size, lr, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5235\n",
      "ROC-AUC autoencoded: 0.4642\n",
      "ROC-AUC autoencoded: 0.5776\n",
      "ROC-AUC autoencoded: 0.5288\n",
      "ROC-AUC autoencoded: 0.4605\n",
      "ROC-AUC autoencoded: 0.4720\n",
      "ROC-AUC autoencoded: 0.4417\n",
      "ROC-AUC autoencoded: 0.5439\n",
      "ROC-AUC autoencoded: 0.4845\n",
      "ROC-AUC autoencoded: 0.5278\n",
      "ROC-AUC autoencoded: 0.4257\n",
      "ROC-AUC autoencoded: 0.4995\n",
      "ROC-AUC autoencoded: 0.5167\n",
      "ROC-AUC autoencoded: 0.4693\n",
      "ROC-AUC autoencoded: 0.5127\n",
      "ROC-AUC autoencoded: 0.5113\n",
      "ROC-AUC autoencoded: 0.5261\n",
      "ROC-AUC autoencoded: 0.4724\n",
      "ROC-AUC autoencoded: 0.5448\n",
      "ROC-AUC autoencoded: 0.4865\n",
      "ROC-AUC autoencoded: 0.5067\n",
      "ROC-AUC autoencoded: 0.4555\n",
      "ROC-AUC autoencoded: 0.5739\n",
      "ROC-AUC autoencoded: 0.5866\n",
      "ROC-AUC autoencoded: 0.5049\n",
      "среднее 0.5046809746067684\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 05:52:46,322] A new study created in memory with name: no-name-ad708487-b095-48ab-b3bb-2e17d839d055\n",
      "[I 2025-05-09 05:53:23,587] Trial 0 finished with value: 0.5931485315543287 and parameters: {'latent_dim': 26, 'hidden_dim_ae': 111, 'lr_ae': 0.002481475768484453, 'epochs_ae': 40, 'dropout_rate_ae': 0.2617312490468205, 'sparsity_weight': 0.03158834783614738, 'hidden_dim_mlp': 62, 'lr_mlp': 0.00018344754705476972, 'epochs_mlp': 44, 'dropout_rate_mlp': 0.4427247327533441}. Best is trial 0 with value: 0.5931485315543287.\n",
      "[I 2025-05-09 05:54:19,992] Trial 1 finished with value: 0.5171190859596656 and parameters: {'latent_dim': 71, 'hidden_dim_ae': 176, 'lr_ae': 0.004545432382869, 'epochs_ae': 42, 'dropout_rate_ae': 0.36696598845170014, 'sparsity_weight': 0.03609500708522312, 'hidden_dim_mlp': 88, 'lr_mlp': 0.007478370046971429, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.16634025329966887}. Best is trial 0 with value: 0.5931485315543287.\n",
      "[I 2025-05-09 05:55:03,523] Trial 2 finished with value: 0.4883827927306188 and parameters: {'latent_dim': 60, 'hidden_dim_ae': 79, 'lr_ae': 0.00011389732873480096, 'epochs_ae': 45, 'dropout_rate_ae': 0.13960743622144292, 'sparsity_weight': 0.032958526610753026, 'hidden_dim_mlp': 118, 'lr_mlp': 0.0019445360571495854, 'epochs_mlp': 43, 'dropout_rate_mlp': 0.25260357024252533}. Best is trial 0 with value: 0.5931485315543287.\n",
      "[I 2025-05-09 05:55:39,776] Trial 3 finished with value: 0.5094126217314624 and parameters: {'latent_dim': 59, 'hidden_dim_ae': 72, 'lr_ae': 0.00031186779580247504, 'epochs_ae': 41, 'dropout_rate_ae': 0.3263788411391238, 'sparsity_weight': 0.0018652826035092211, 'hidden_dim_mlp': 38, 'lr_mlp': 0.004420385635399093, 'epochs_mlp': 35, 'dropout_rate_mlp': 0.42755320269942454}. Best is trial 0 with value: 0.5931485315543287.\n",
      "[I 2025-05-09 05:56:07,867] Trial 4 finished with value: 0.5480216241085806 and parameters: {'latent_dim': 81, 'hidden_dim_ae': 138, 'lr_ae': 0.007525046969061472, 'epochs_ae': 20, 'dropout_rate_ae': 0.14461795081031326, 'sparsity_weight': 0.08947357544174045, 'hidden_dim_mlp': 106, 'lr_mlp': 0.00010712854079954086, 'epochs_mlp': 40, 'dropout_rate_mlp': 0.3552905957204373}. Best is trial 0 with value: 0.5931485315543287.\n",
      "[I 2025-05-09 05:56:33,997] Trial 5 finished with value: 0.5363085652940726 and parameters: {'latent_dim': 73, 'hidden_dim_ae': 126, 'lr_ae': 0.0003734671151869883, 'epochs_ae': 23, 'dropout_rate_ae': 0.38051436397546057, 'sparsity_weight': 0.03265040248459911, 'hidden_dim_mlp': 123, 'lr_mlp': 0.001694541966880799, 'epochs_mlp': 23, 'dropout_rate_mlp': 0.14486298812988913}. Best is trial 0 with value: 0.5931485315543287.\n",
      "[I 2025-05-09 05:56:53,612] Trial 6 finished with value: 0.5530634153822559 and parameters: {'latent_dim': 95, 'hidden_dim_ae': 234, 'lr_ae': 0.0030392773294150768, 'epochs_ae': 10, 'dropout_rate_ae': 0.18110012422845911, 'sparsity_weight': 0.04290672076746246, 'hidden_dim_mlp': 32, 'lr_mlp': 0.00027470181114444986, 'epochs_mlp': 35, 'dropout_rate_mlp': 0.3438697414087346}. Best is trial 0 with value: 0.5931485315543287.\n",
      "[I 2025-05-09 05:57:38,444] Trial 7 finished with value: 0.5400276052449966 and parameters: {'latent_dim': 20, 'hidden_dim_ae': 104, 'lr_ae': 0.007787539736233656, 'epochs_ae': 44, 'dropout_rate_ae': 0.455014765808304, 'sparsity_weight': 0.03564325073029885, 'hidden_dim_mlp': 128, 'lr_mlp': 0.000910208165741544, 'epochs_mlp': 34, 'dropout_rate_mlp': 0.14386633787637884}. Best is trial 0 with value: 0.5931485315543287.\n",
      "[I 2025-05-09 05:58:10,549] Trial 8 finished with value: 0.5042941492216855 and parameters: {'latent_dim': 76, 'hidden_dim_ae': 139, 'lr_ae': 0.00015571393154026247, 'epochs_ae': 29, 'dropout_rate_ae': 0.36627094899908863, 'sparsity_weight': 0.0625454523559973, 'hidden_dim_mlp': 58, 'lr_mlp': 0.00014662495356569948, 'epochs_mlp': 13, 'dropout_rate_mlp': 0.2411129118428033}. Best is trial 0 with value: 0.5931485315543287.\n",
      "[I 2025-05-09 05:58:56,238] Trial 9 finished with value: 0.5542711448508552 and parameters: {'latent_dim': 29, 'hidden_dim_ae': 256, 'lr_ae': 0.006857846915999278, 'epochs_ae': 26, 'dropout_rate_ae': 0.3256297146700845, 'sparsity_weight': 0.0019205651136305114, 'hidden_dim_mlp': 116, 'lr_mlp': 0.0006728973383971937, 'epochs_mlp': 31, 'dropout_rate_mlp': 0.24603830221858158}. Best is trial 0 with value: 0.5931485315543287.\n",
      "[I 2025-05-09 05:59:44,975] Trial 10 finished with value: 0.5651982209953225 and parameters: {'latent_dim': 36, 'hidden_dim_ae': 180, 'lr_ae': 0.001552848384043417, 'epochs_ae': 38, 'dropout_rate_ae': 0.22577321281871093, 'sparsity_weight': 0.0001282284801801591, 'hidden_dim_mlp': 70, 'lr_mlp': 0.0003285069837870581, 'epochs_mlp': 22, 'dropout_rate_mlp': 0.48999394417825226}. Best is trial 0 with value: 0.5931485315543287.\n",
      "[I 2025-05-09 06:00:30,904] Trial 11 finished with value: 0.5962541216164405 and parameters: {'latent_dim': 38, 'hidden_dim_ae': 189, 'lr_ae': 0.0014297000457914539, 'epochs_ae': 35, 'dropout_rate_ae': 0.22845062225163323, 'sparsity_weight': 0.00010498166505407064, 'hidden_dim_mlp': 66, 'lr_mlp': 0.0003357884582429322, 'epochs_mlp': 21, 'dropout_rate_mlp': 0.4773014016605631}. Best is trial 11 with value: 0.5962541216164405.\n",
      "[I 2025-05-09 06:01:20,036] Trial 12 finished with value: 0.5946438156583084 and parameters: {'latent_dim': 40, 'hidden_dim_ae': 211, 'lr_ae': 0.0014489303654549401, 'epochs_ae': 36, 'dropout_rate_ae': 0.25361980597511363, 'sparsity_weight': 0.00020218533588720394, 'hidden_dim_mlp': 52, 'lr_mlp': 0.00034773517212566686, 'epochs_mlp': 20, 'dropout_rate_mlp': 0.49247405928635524}. Best is trial 11 with value: 0.5962541216164405.\n",
      "[I 2025-05-09 06:02:04,943] Trial 13 finished with value: 0.5638946399815965 and parameters: {'latent_dim': 42, 'hidden_dim_ae': 210, 'lr_ae': 0.0007966666367852448, 'epochs_ae': 33, 'dropout_rate_ae': 0.24276545446556042, 'sparsity_weight': 0.0001137347205038942, 'hidden_dim_mlp': 47, 'lr_mlp': 0.0004732570828768676, 'epochs_mlp': 13, 'dropout_rate_mlp': 0.49327848322065376}. Best is trial 11 with value: 0.5962541216164405.\n",
      "[I 2025-05-09 06:03:11,159] Trial 14 finished with value: 0.5632236791657083 and parameters: {'latent_dim': 12, 'hidden_dim_ae': 204, 'lr_ae': 0.000867317631125742, 'epochs_ae': 50, 'dropout_rate_ae': 0.1874429813981986, 'sparsity_weight': 0.00044273604145967277, 'hidden_dim_mlp': 83, 'lr_mlp': 0.0004108849167521873, 'epochs_mlp': 22, 'dropout_rate_mlp': 0.40944866616251596}. Best is trial 11 with value: 0.5962541216164405.\n",
      "[I 2025-05-09 06:03:58,488] Trial 15 finished with value: 0.5531976075454337 and parameters: {'latent_dim': 46, 'hidden_dim_ae': 205, 'lr_ae': 0.0014544874908753351, 'epochs_ae': 34, 'dropout_rate_ae': 0.10119849615359694, 'sparsity_weight': 0.0004040359788986214, 'hidden_dim_mlp': 49, 'lr_mlp': 0.0016661414307171515, 'epochs_mlp': 18, 'dropout_rate_mlp': 0.3812176778292598}. Best is trial 11 with value: 0.5962541216164405.\n",
      "[I 2025-05-09 06:04:43,675] Trial 16 finished with value: 0.5321294379265393 and parameters: {'latent_dim': 51, 'hidden_dim_ae': 174, 'lr_ae': 0.0005403908817183193, 'epochs_ae': 35, 'dropout_rate_ae': 0.2845364808573362, 'sparsity_weight': 0.00039062026969329005, 'hidden_dim_mlp': 95, 'lr_mlp': 0.00019778811386820638, 'epochs_mlp': 27, 'dropout_rate_mlp': 0.4601916741738991}. Best is trial 11 with value: 0.5962541216164405.\n",
      "[I 2025-05-09 06:05:12,334] Trial 17 finished with value: 0.6016409784525727 and parameters: {'latent_dim': 37, 'hidden_dim_ae': 223, 'lr_ae': 0.0017109364207916339, 'epochs_ae': 17, 'dropout_rate_ae': 0.19679075424099657, 'sparsity_weight': 0.008274895768294354, 'hidden_dim_mlp': 73, 'lr_mlp': 0.0006234710568674253, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.3053011561804302}. Best is trial 17 with value: 0.6016409784525727.\n",
      "[I 2025-05-09 06:05:40,901] Trial 18 finished with value: 0.539701709991565 and parameters: {'latent_dim': 32, 'hidden_dim_ae': 237, 'lr_ae': 0.0026106115695924037, 'epochs_ae': 17, 'dropout_rate_ae': 0.1933231172318738, 'sparsity_weight': 0.008844113018888818, 'hidden_dim_mlp': 74, 'lr_mlp': 0.0010425562756927172, 'epochs_mlp': 16, 'dropout_rate_mlp': 0.28804448978282626}. Best is trial 17 with value: 0.6016409784525727.\n",
      "[I 2025-05-09 06:05:55,975] Trial 19 finished with value: 0.5429223219078291 and parameters: {'latent_dim': 11, 'hidden_dim_ae': 159, 'lr_ae': 0.003912438515200837, 'epochs_ae': 12, 'dropout_rate_ae': 0.4802115241177433, 'sparsity_weight': 0.007449515363092207, 'hidden_dim_mlp': 72, 'lr_mlp': 0.0005986015244010594, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.2003513577601309}. Best is trial 17 with value: 0.6016409784525727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5326\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(latent_dim, hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "mlp = MLP(best_params['latent_dim'], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4986\n",
      "ROC-AUC autoencoded: 0.4677\n",
      "ROC-AUC autoencoded: 0.4702\n",
      "ROC-AUC autoencoded: 0.4347\n",
      "ROC-AUC autoencoded: 0.5452\n",
      "ROC-AUC autoencoded: 0.4940\n",
      "ROC-AUC autoencoded: 0.5026\n",
      "ROC-AUC autoencoded: 0.4766\n",
      "ROC-AUC autoencoded: 0.5209\n",
      "ROC-AUC autoencoded: 0.5367\n",
      "ROC-AUC autoencoded: 0.5423\n",
      "ROC-AUC autoencoded: 0.5806\n",
      "ROC-AUC autoencoded: 0.4830\n",
      "ROC-AUC autoencoded: 0.5070\n",
      "ROC-AUC autoencoded: 0.5638\n",
      "ROC-AUC autoencoded: 0.5279\n",
      "ROC-AUC autoencoded: 0.5177\n",
      "ROC-AUC autoencoded: 0.5660\n",
      "ROC-AUC autoencoded: 0.5197\n",
      "ROC-AUC autoencoded: 0.5333\n",
      "ROC-AUC autoencoded: 0.5186\n",
      "ROC-AUC autoencoded: 0.5459\n",
      "ROC-AUC autoencoded: 0.4703\n",
      "ROC-AUC autoencoded: 0.5746\n",
      "ROC-AUC autoencoded: 0.4977\n",
      "среднее 0.515818500025604\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(best_params['latent_dim'], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь блок с sparse автоэнкодером с классифицирующей головой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 06:09:01,525] A new study created in memory with name: no-name-8250c72d-9531-4c6c-b816-133c1db72e4c\n",
      "[I 2025-05-09 06:09:41,877] Trial 0 finished with value: 0.5184226669733917 and parameters: {'latent_dim': 39, 'hidden_dim': 150, 'lr': 0.0006565879320086474, 'epochs': 38, 'dropout_rate': 0.45518348703734823, 'sparsity_weight': 0.0007248104891809296, 'classification_weight': 0.3344581545837956, 'C': 0.11007001393507052, 'solver': 'saga'}. Best is trial 0 with value: 0.5184226669733917.\n",
      "[I 2025-05-09 06:09:58,223] Trial 1 finished with value: 0.5214324054903764 and parameters: {'latent_dim': 56, 'hidden_dim': 215, 'lr': 0.007661888925451286, 'epochs': 12, 'dropout_rate': 0.18812290238988189, 'sparsity_weight': 0.021780434787194426, 'classification_weight': 0.25048198606500294, 'C': 0.5740651216043625, 'solver': 'liblinear'}. Best is trial 1 with value: 0.5214324054903764.\n",
      "[I 2025-05-09 06:10:21,975] Trial 2 finished with value: 0.5108503949083659 and parameters: {'latent_dim': 70, 'hidden_dim': 156, 'lr': 0.00021964535298238462, 'epochs': 20, 'dropout_rate': 0.36294950585632846, 'sparsity_weight': 0.00010805334502168061, 'classification_weight': 0.6343213415909306, 'C': 74.06437861011719, 'solver': 'saga'}. Best is trial 1 with value: 0.5214324054903764.\n",
      "[I 2025-05-09 06:10:56,966] Trial 3 finished with value: 0.5083390844260409 and parameters: {'latent_dim': 95, 'hidden_dim': 110, 'lr': 0.002095202004473664, 'epochs': 38, 'dropout_rate': 0.33384764636556497, 'sparsity_weight': 0.0040610963483659925, 'classification_weight': 0.4501223377706278, 'C': 0.014821866157383606, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.5214324054903764.\n",
      "[I 2025-05-09 06:11:14,904] Trial 4 finished with value: 0.5044091710758377 and parameters: {'latent_dim': 13, 'hidden_dim': 238, 'lr': 0.003913987523903712, 'epochs': 12, 'dropout_rate': 0.29540927471371253, 'sparsity_weight': 0.0036011964018969186, 'classification_weight': 0.5533491207084481, 'C': 7.8990845305284, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.5214324054903764.\n",
      "[I 2025-05-09 06:11:29,503] Trial 5 finished with value: 0.5140901771336553 and parameters: {'latent_dim': 51, 'hidden_dim': 209, 'lr': 0.00011232986431723892, 'epochs': 11, 'dropout_rate': 0.4008922464658021, 'sparsity_weight': 0.00013723470503925402, 'classification_weight': 0.3174547994221818, 'C': 0.05433671854317862, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.5214324054903764.\n",
      "[I 2025-05-09 06:12:09,161] Trial 6 finished with value: 0.533567211103443 and parameters: {'latent_dim': 54, 'hidden_dim': 210, 'lr': 0.00203730155801813, 'epochs': 30, 'dropout_rate': 0.43054142128967976, 'sparsity_weight': 0.08730440476218564, 'classification_weight': 0.38112165995166125, 'C': 0.025520962974491305, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.533567211103443.\n",
      "[I 2025-05-09 06:12:48,698] Trial 7 finished with value: 0.512364849321371 and parameters: {'latent_dim': 62, 'hidden_dim': 247, 'lr': 0.0060629080385041865, 'epochs': 26, 'dropout_rate': 0.20354940898023288, 'sparsity_weight': 0.004912965109490355, 'classification_weight': 0.5604809281821032, 'C': 0.03488463776321856, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.533567211103443.\n",
      "[I 2025-05-09 06:13:45,178] Trial 8 finished with value: 0.5085882984433708 and parameters: {'latent_dim': 15, 'hidden_dim': 247, 'lr': 0.0005009576546094525, 'epochs': 38, 'dropout_rate': 0.2044630325670248, 'sparsity_weight': 0.055327473979384874, 'classification_weight': 0.2122713218280258, 'C': 1.2884162457129444, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.533567211103443.\n",
      "[I 2025-05-09 06:14:05,682] Trial 9 finished with value: 0.5005942795797867 and parameters: {'latent_dim': 92, 'hidden_dim': 224, 'lr': 0.005027562159486664, 'epochs': 15, 'dropout_rate': 0.12912472468685832, 'sparsity_weight': 0.00023350657963324263, 'classification_weight': 0.7455260460532772, 'C': 6.522757970934807, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.533567211103443.\n",
      "[I 2025-05-09 06:14:41,595] Trial 10 finished with value: 0.5175791733762748 and parameters: {'latent_dim': 35, 'hidden_dim': 77, 'lr': 0.001476556580504024, 'epochs': 48, 'dropout_rate': 0.4864445309855448, 'sparsity_weight': 0.08963906292614006, 'classification_weight': 0.87856144026658, 'C': 0.29381966013701993, 'solver': 'liblinear'}. Best is trial 6 with value: 0.533567211103443.\n",
      "[I 2025-05-09 06:15:13,871] Trial 11 finished with value: 0.5193620121156353 and parameters: {'latent_dim': 75, 'hidden_dim': 195, 'lr': 0.008667585886065967, 'epochs': 26, 'dropout_rate': 0.25472659232354283, 'sparsity_weight': 0.019393127259517154, 'classification_weight': 0.15888945066646426, 'C': 0.6718051716358105, 'solver': 'liblinear'}. Best is trial 6 with value: 0.533567211103443.\n",
      "[I 2025-05-09 06:15:38,658] Trial 12 finished with value: 0.4985238862050456 and parameters: {'latent_dim': 48, 'hidden_dim': 191, 'lr': 0.0025239217712464622, 'epochs': 20, 'dropout_rate': 0.1124315051859458, 'sparsity_weight': 0.020625823814233932, 'classification_weight': 0.38321078814951265, 'C': 0.010844165160731015, 'solver': 'liblinear'}. Best is trial 6 with value: 0.533567211103443.\n",
      "[I 2025-05-09 06:16:37,906] Trial 13 finished with value: 0.5244421440073613 and parameters: {'latent_dim': 29, 'hidden_dim': 175, 'lr': 0.009721717710925667, 'epochs': 50, 'dropout_rate': 0.4099616614494162, 'sparsity_weight': 0.024708308727492356, 'classification_weight': 0.24571048650024643, 'C': 3.0936868428718967, 'solver': 'liblinear'}. Best is trial 6 with value: 0.533567211103443.\n",
      "[I 2025-05-09 06:17:34,536] Trial 14 finished with value: 0.5228701786672801 and parameters: {'latent_dim': 27, 'hidden_dim': 174, 'lr': 0.0010901685379262837, 'epochs': 49, 'dropout_rate': 0.4130080251389045, 'sparsity_weight': 0.0488483698542012, 'classification_weight': 0.11572863880526135, 'C': 5.934220543974564, 'solver': 'liblinear'}. Best is trial 6 with value: 0.533567211103443.\n",
      "[I 2025-05-09 06:18:05,536] Trial 15 finished with value: 0.5174258109040717 and parameters: {'latent_dim': 31, 'hidden_dim': 131, 'lr': 0.002852102947002871, 'epochs': 31, 'dropout_rate': 0.42984426854507735, 'sparsity_weight': 0.010069480444450822, 'classification_weight': 0.4383348421137888, 'C': 2.272363501539037, 'solver': 'saga'}. Best is trial 6 with value: 0.533567211103443.\n",
      "[I 2025-05-09 06:18:54,192] Trial 16 finished with value: 0.5143585614600107 and parameters: {'latent_dim': 22, 'hidden_dim': 178, 'lr': 0.0004685564303383601, 'epochs': 42, 'dropout_rate': 0.4862993902978046, 'sparsity_weight': 0.09775726222712637, 'classification_weight': 0.2318788367726557, 'C': 47.33003158535185, 'solver': 'liblinear'}. Best is trial 6 with value: 0.533567211103443.\n",
      "[I 2025-05-09 06:19:26,943] Trial 17 finished with value: 0.5220266850701633 and parameters: {'latent_dim': 84, 'hidden_dim': 140, 'lr': 0.0015762666331779493, 'epochs': 32, 'dropout_rate': 0.3694056939102736, 'sparsity_weight': 0.0015899966373960038, 'classification_weight': 0.35629083629543595, 'C': 0.18935622739258431, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.533567211103443.\n",
      "[I 2025-05-09 06:20:04,376] Trial 18 finished with value: 0.5068054597040105 and parameters: {'latent_dim': 41, 'hidden_dim': 112, 'lr': 0.003870229191320678, 'epochs': 42, 'dropout_rate': 0.30403893274240934, 'sparsity_weight': 0.009890482735872523, 'classification_weight': 0.2729244049191226, 'C': 16.98978138893319, 'solver': 'liblinear'}. Best is trial 6 with value: 0.533567211103443.\n",
      "[I 2025-05-09 06:20:36,063] Trial 19 finished with value: 0.5177708764665286 and parameters: {'latent_dim': 65, 'hidden_dim': 176, 'lr': 0.009804742184013024, 'epochs': 27, 'dropout_rate': 0.44485960894263715, 'sparsity_weight': 0.039526972830374936, 'classification_weight': 0.49568467710152697, 'C': 2.1007090284029886, 'solver': 'saga'}. Best is trial 6 with value: 0.533567211103443.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5165\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingSparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(ClassifyingSparseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "    \n",
    "def train_classifying_sparse_autoencoder(model, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    class_criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, latent, classification = model(batch_x)\n",
    "            \n",
    "            recon_loss = recon_criterion(reconstructed, batch_x)\n",
    "            sparsity_loss = torch.mean(torch.abs(latent))\n",
    "            class_loss = class_criterion(classification, batch_y)\n",
    "            \n",
    "            loss = (1 - classification_weight) * (recon_loss + sparsity_weight * sparsity_loss) + classification_weight * class_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent, _ = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5203\n",
      "ROC-AUC autoencoded: 0.4966\n",
      "ROC-AUC autoencoded: 0.4867\n",
      "ROC-AUC autoencoded: 0.5081\n",
      "ROC-AUC autoencoded: 0.5099\n",
      "ROC-AUC autoencoded: 0.5523\n",
      "ROC-AUC autoencoded: 0.5541\n",
      "ROC-AUC autoencoded: 0.5765\n",
      "ROC-AUC autoencoded: 0.5683\n",
      "ROC-AUC autoencoded: 0.5804\n",
      "ROC-AUC autoencoded: 0.5772\n",
      "ROC-AUC autoencoded: 0.5430\n",
      "ROC-AUC autoencoded: 0.5657\n",
      "ROC-AUC autoencoded: 0.5311\n",
      "ROC-AUC autoencoded: 0.5674\n",
      "ROC-AUC autoencoded: 0.5518\n",
      "ROC-AUC autoencoded: 0.5716\n",
      "ROC-AUC autoencoded: 0.5635\n",
      "ROC-AUC autoencoded: 0.5496\n",
      "ROC-AUC autoencoded: 0.5506\n",
      "ROC-AUC autoencoded: 0.5791\n",
      "ROC-AUC autoencoded: 0.5397\n",
      "ROC-AUC autoencoded: 0.5445\n",
      "ROC-AUC autoencoded: 0.5634\n",
      "ROC-AUC autoencoded: 0.5361\n",
      "среднее 0.5474985722269333\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 15:12:51,202] A new study created in memory with name: no-name-e7de6083-16a2-4594-8b94-16d6aba2defa\n",
      "[I 2025-05-09 15:14:00,713] Trial 0 finished with value: 0.4846829230887202 and parameters: {'latent_dim': 13, 'hidden_dim': 160, 'lr': 0.004097432109618048, 'epochs': 45, 'dropout_rate': 0.24678845602755733, 'sparsity_weight': 0.00012465455382326015, 'classification_weight': 0.25197729128131396, 'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.01898694051996589, 'subsample': 0.7667086290119485, 'min_samples_split': 15, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.4846829230887202.\n",
      "[I 2025-05-09 15:14:40,838] Trial 1 finished with value: 0.4667395138409631 and parameters: {'latent_dim': 30, 'hidden_dim': 143, 'lr': 0.002772009448392026, 'epochs': 18, 'dropout_rate': 0.26079296970383636, 'sparsity_weight': 0.012637579849262523, 'classification_weight': 0.20622294068081512, 'n_estimators': 298, 'max_depth': 7, 'learning_rate': 0.016982307861081198, 'subsample': 0.6920116342511213, 'min_samples_split': 14, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.4846829230887202.\n",
      "[I 2025-05-09 15:15:18,071] Trial 2 finished with value: 0.4856126830764513 and parameters: {'latent_dim': 89, 'hidden_dim': 111, 'lr': 0.0029642399187875825, 'epochs': 18, 'dropout_rate': 0.21827688540702794, 'sparsity_weight': 0.00717007298216028, 'classification_weight': 0.8424717089789662, 'n_estimators': 238, 'max_depth': 5, 'learning_rate': 0.06026824698243791, 'subsample': 0.6916828539606107, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.4856126830764513.\n",
      "[I 2025-05-09 15:15:44,871] Trial 3 finished with value: 0.5040161797408174 and parameters: {'latent_dim': 42, 'hidden_dim': 100, 'lr': 0.0004481344228302047, 'epochs': 26, 'dropout_rate': 0.4898402780437888, 'sparsity_weight': 0.0026726136583800596, 'classification_weight': 0.8539647844013607, 'n_estimators': 220, 'max_depth': 5, 'learning_rate': 0.01108723734513192, 'subsample': 0.6155390656239547, 'min_samples_split': 18, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.5040161797408174.\n",
      "[I 2025-05-09 15:16:59,822] Trial 4 finished with value: 0.4795932060424814 and parameters: {'latent_dim': 99, 'hidden_dim': 157, 'lr': 0.0038401249813773317, 'epochs': 50, 'dropout_rate': 0.13667733450909153, 'sparsity_weight': 0.000550642350046181, 'classification_weight': 0.8802775087986296, 'n_estimators': 207, 'max_depth': 6, 'learning_rate': 0.0954954229005628, 'subsample': 0.7088592840089846, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.5040161797408174.\n",
      "[I 2025-05-09 15:17:54,879] Trial 5 finished with value: 0.4731328119009279 and parameters: {'latent_dim': 62, 'hidden_dim': 180, 'lr': 0.0005161687153471702, 'epochs': 27, 'dropout_rate': 0.4357027666719796, 'sparsity_weight': 0.0004906748552466047, 'classification_weight': 0.8137147747823078, 'n_estimators': 429, 'max_depth': 3, 'learning_rate': 0.03689565584370381, 'subsample': 0.6450792676456439, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.5040161797408174.\n",
      "[I 2025-05-09 15:18:46,569] Trial 6 finished with value: 0.5203205275669044 and parameters: {'latent_dim': 54, 'hidden_dim': 148, 'lr': 0.009504555674215293, 'epochs': 30, 'dropout_rate': 0.25820434549851046, 'sparsity_weight': 0.0012534008089735897, 'classification_weight': 0.1431639934453573, 'n_estimators': 239, 'max_depth': 9, 'learning_rate': 0.05975814473186289, 'subsample': 0.8076446598054601, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.5203205275669044.\n",
      "[I 2025-05-09 15:19:09,852] Trial 7 finished with value: 0.466279426424354 and parameters: {'latent_dim': 57, 'hidden_dim': 183, 'lr': 0.0022051492961533896, 'epochs': 19, 'dropout_rate': 0.1710594823120356, 'sparsity_weight': 0.0002804883860308612, 'classification_weight': 0.5278990775919425, 'n_estimators': 67, 'max_depth': 3, 'learning_rate': 0.017541680785838048, 'subsample': 0.783517075018769, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 6 with value: 0.5203205275669044.\n",
      "[I 2025-05-09 15:19:38,742] Trial 8 finished with value: 0.46211946936584614 and parameters: {'latent_dim': 12, 'hidden_dim': 245, 'lr': 0.0017254739061875878, 'epochs': 20, 'dropout_rate': 0.40035490060990464, 'sparsity_weight': 0.005249256975407136, 'classification_weight': 0.6811758121611865, 'n_estimators': 299, 'max_depth': 3, 'learning_rate': 0.014538576804837654, 'subsample': 0.718763286674239, 'min_samples_split': 11, 'min_samples_leaf': 10}. Best is trial 6 with value: 0.5203205275669044.\n",
      "[I 2025-05-09 15:20:27,048] Trial 9 finished with value: 0.4790180967717199 and parameters: {'latent_dim': 25, 'hidden_dim': 237, 'lr': 0.003169867672381253, 'epochs': 37, 'dropout_rate': 0.34583845941181723, 'sparsity_weight': 0.011026123296277751, 'classification_weight': 0.3368255440489898, 'n_estimators': 165, 'max_depth': 3, 'learning_rate': 0.016048751212252774, 'subsample': 0.6938083038391696, 'min_samples_split': 19, 'min_samples_leaf': 6}. Best is trial 6 with value: 0.5203205275669044.\n",
      "[I 2025-05-09 15:20:53,062] Trial 10 finished with value: 0.4715704317153593 and parameters: {'latent_dim': 74, 'hidden_dim': 67, 'lr': 0.00965385301484637, 'epochs': 34, 'dropout_rate': 0.3278378850785507, 'sparsity_weight': 0.09024884644650834, 'classification_weight': 0.11270844035795508, 'n_estimators': 407, 'max_depth': 10, 'learning_rate': 0.2438396622335944, 'subsample': 0.9155611332946385, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.5203205275669044.\n",
      "[I 2025-05-09 15:21:22,145] Trial 11 finished with value: 0.4789510006901312 and parameters: {'latent_dim': 41, 'hidden_dim': 106, 'lr': 0.00015435253982401908, 'epochs': 27, 'dropout_rate': 0.49165673770654056, 'sparsity_weight': 0.001579328975388588, 'classification_weight': 0.5304958092029126, 'n_estimators': 89, 'max_depth': 9, 'learning_rate': 0.09152582430306284, 'subsample': 0.8881593851559866, 'min_samples_split': 20, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.5203205275669044.\n",
      "[I 2025-05-09 15:21:57,477] Trial 12 finished with value: 0.49408595966566976 and parameters: {'latent_dim': 45, 'hidden_dim': 107, 'lr': 0.00038856584479325917, 'epochs': 31, 'dropout_rate': 0.3853431407463392, 'sparsity_weight': 0.0015394048993151777, 'classification_weight': 0.3821076817914818, 'n_estimators': 334, 'max_depth': 8, 'learning_rate': 0.031189764582167736, 'subsample': 0.9933321387818613, 'min_samples_split': 18, 'min_samples_leaf': 8}. Best is trial 6 with value: 0.5203205275669044.\n",
      "[I 2025-05-09 15:22:31,816] Trial 13 finished with value: 0.4836573115558622 and parameters: {'latent_dim': 70, 'hidden_dim': 83, 'lr': 0.0005839794658615807, 'epochs': 38, 'dropout_rate': 0.29526498406343465, 'sparsity_weight': 0.0016322015826494875, 'classification_weight': 0.6791018313712475, 'n_estimators': 131, 'max_depth': 10, 'learning_rate': 0.22641751300282692, 'subsample': 0.6105718055319878, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.5203205275669044.\n",
      "[I 2025-05-09 15:23:05,516] Trial 14 finished with value: 0.538465225059428 and parameters: {'latent_dim': 45, 'hidden_dim': 122, 'lr': 0.00013161499042424588, 'epochs': 10, 'dropout_rate': 0.4927305223155439, 'sparsity_weight': 0.03546313749310379, 'classification_weight': 0.6597606926011725, 'n_estimators': 354, 'max_depth': 5, 'learning_rate': 0.010040673382869595, 'subsample': 0.8433517673872994, 'min_samples_split': 14, 'min_samples_leaf': 8}. Best is trial 14 with value: 0.538465225059428.\n",
      "[I 2025-05-09 15:23:30,091] Trial 15 finished with value: 0.5140039107430412 and parameters: {'latent_dim': 50, 'hidden_dim': 132, 'lr': 0.00013361451991304501, 'epochs': 11, 'dropout_rate': 0.1974324407602609, 'sparsity_weight': 0.038614037505966876, 'classification_weight': 0.6556288700777257, 'n_estimators': 491, 'max_depth': 7, 'learning_rate': 0.13914062269413668, 'subsample': 0.8542863596536102, 'min_samples_split': 13, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.538465225059428.\n",
      "[I 2025-05-09 15:24:08,007] Trial 16 finished with value: 0.5006038647342995 and parameters: {'latent_dim': 29, 'hidden_dim': 206, 'lr': 0.009212012982087363, 'epochs': 11, 'dropout_rate': 0.10349278804250453, 'sparsity_weight': 0.027102560972955183, 'classification_weight': 0.4041510352744835, 'n_estimators': 376, 'max_depth': 8, 'learning_rate': 0.033460409265203016, 'subsample': 0.8274019054932191, 'min_samples_split': 12, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.538465225059428.\n",
      "[I 2025-05-09 15:25:09,945] Trial 17 finished with value: 0.5117705697415842 and parameters: {'latent_dim': 70, 'hidden_dim': 132, 'lr': 0.00022671536520520925, 'epochs': 43, 'dropout_rate': 0.289271874841571, 'sparsity_weight': 0.09696674537718275, 'classification_weight': 0.5946194897543075, 'n_estimators': 257, 'max_depth': 6, 'learning_rate': 0.05101178695283572, 'subsample': 0.9446125713391188, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.538465225059428.\n",
      "[I 2025-05-09 15:25:53,102] Trial 18 finished with value: 0.5179338240932444 and parameters: {'latent_dim': 79, 'hidden_dim': 190, 'lr': 0.0015112918338723448, 'epochs': 23, 'dropout_rate': 0.44394217727357, 'sparsity_weight': 0.027617728014984435, 'classification_weight': 0.7654161903638035, 'n_estimators': 354, 'max_depth': 4, 'learning_rate': 0.06981921648338031, 'subsample': 0.8334350423516061, 'min_samples_split': 15, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.538465225059428.\n",
      "[I 2025-05-09 15:26:22,269] Trial 19 finished with value: 0.4950444751169389 and parameters: {'latent_dim': 56, 'hidden_dim': 215, 'lr': 0.0009541386587494044, 'epochs': 13, 'dropout_rate': 0.35340534830643294, 'sparsity_weight': 0.0006263631722417905, 'classification_weight': 0.1060634169481118, 'n_estimators': 462, 'max_depth': 9, 'learning_rate': 0.13284857295517435, 'subsample': 0.759270973042285, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.538465225059428.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.4339\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4821\n",
      "ROC-AUC autoencoded: 0.5069\n",
      "ROC-AUC autoencoded: 0.5004\n",
      "ROC-AUC autoencoded: 0.4412\n",
      "ROC-AUC autoencoded: 0.5217\n",
      "ROC-AUC autoencoded: 0.5119\n",
      "ROC-AUC autoencoded: 0.5734\n",
      "ROC-AUC autoencoded: 0.5938\n",
      "ROC-AUC autoencoded: 0.5640\n",
      "ROC-AUC autoencoded: 0.5960\n",
      "ROC-AUC autoencoded: 0.5388\n",
      "ROC-AUC autoencoded: 0.5616\n",
      "ROC-AUC autoencoded: 0.5583\n",
      "ROC-AUC autoencoded: 0.5196\n",
      "ROC-AUC autoencoded: 0.5149\n",
      "ROC-AUC autoencoded: 0.5323\n",
      "ROC-AUC autoencoded: 0.5604\n",
      "ROC-AUC autoencoded: 0.5129\n",
      "ROC-AUC autoencoded: 0.5500\n",
      "ROC-AUC autoencoded: 0.5572\n",
      "ROC-AUC autoencoded: 0.5286\n",
      "ROC-AUC autoencoded: 0.5398\n",
      "ROC-AUC autoencoded: 0.4977\n",
      "ROC-AUC autoencoded: 0.5527\n",
      "ROC-AUC autoencoded: 0.4651\n",
      "среднее 0.5312536895922529\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 15:30:12,637] A new study created in memory with name: no-name-7fa41503-c1a5-49bb-b8f8-a686e01022e7\n",
      "[I 2025-05-09 15:30:42,458] Trial 0 finished with value: 0.5185185185185185 and parameters: {'latent_dim': 73, 'hidden_dim': 110, 'lr': 0.007515831680941104, 'epochs': 38, 'dropout_rate': 0.3236528552450849, 'sparsity_weight': 0.023195681185510603, 'classification_weight': 0.3827035346966099, 'C': 0.1803920130099687, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.5185185185185185.\n",
      "[I 2025-05-09 15:30:59,764] Trial 1 finished with value: 0.5222183881604172 and parameters: {'latent_dim': 21, 'hidden_dim': 152, 'lr': 0.006742682032405692, 'epochs': 19, 'dropout_rate': 0.24658098250447993, 'sparsity_weight': 0.0023384375111655475, 'classification_weight': 0.4529044533598561, 'C': 0.14755916585748036, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 1 with value: 0.5222183881604172.\n",
      "[I 2025-05-09 15:31:22,751] Trial 2 finished with value: 0.5288704853922245 and parameters: {'latent_dim': 47, 'hidden_dim': 133, 'lr': 0.0028523613274582427, 'epochs': 27, 'dropout_rate': 0.47242081167909666, 'sparsity_weight': 0.005956901651385247, 'classification_weight': 0.5675997157873788, 'C': 1.0711907655820843, 'kernel': 'linear'}. Best is trial 2 with value: 0.5288704853922245.\n",
      "[I 2025-05-09 15:31:55,119] Trial 3 finished with value: 0.5101890192469902 and parameters: {'latent_dim': 90, 'hidden_dim': 178, 'lr': 0.0028118567323544455, 'epochs': 33, 'dropout_rate': 0.3584044016444853, 'sparsity_weight': 0.014287199947355217, 'classification_weight': 0.5441777617452719, 'C': 0.1479005026582698, 'kernel': 'linear'}. Best is trial 2 with value: 0.5288704853922245.\n",
      "[I 2025-05-09 15:32:03,554] Trial 4 finished with value: 0.5119239322137873 and parameters: {'latent_dim': 57, 'hidden_dim': 107, 'lr': 0.0006050207560699642, 'epochs': 11, 'dropout_rate': 0.45578946094025197, 'sparsity_weight': 0.02304106056661853, 'classification_weight': 0.33464077643737455, 'C': 0.782886157088433, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 2 with value: 0.5288704853922245.\n",
      "[I 2025-05-09 15:32:14,175] Trial 5 finished with value: 0.5168123610152594 and parameters: {'latent_dim': 63, 'hidden_dim': 138, 'lr': 0.00039838396077430347, 'epochs': 12, 'dropout_rate': 0.3834938057916577, 'sparsity_weight': 0.00015655053342170534, 'classification_weight': 0.47891426865331865, 'C': 0.11341907395965098, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 2 with value: 0.5288704853922245.\n",
      "[I 2025-05-09 15:32:27,349] Trial 6 finished with value: 0.5273464458247067 and parameters: {'latent_dim': 52, 'hidden_dim': 188, 'lr': 0.0020745194778368854, 'epochs': 13, 'dropout_rate': 0.2581241214278833, 'sparsity_weight': 0.007484090215778448, 'classification_weight': 0.44014770536596604, 'C': 7.605954782013895, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 2 with value: 0.5288704853922245.\n",
      "[I 2025-05-09 15:32:41,471] Trial 7 finished with value: 0.5339026915113871 and parameters: {'latent_dim': 55, 'hidden_dim': 86, 'lr': 0.007265227277512711, 'epochs': 21, 'dropout_rate': 0.30159884095562484, 'sparsity_weight': 0.00018430045025559275, 'classification_weight': 0.8025774485727549, 'C': 11.045740778971389, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 7 with value: 0.5339026915113871.\n",
      "[I 2025-05-09 15:33:13,686] Trial 8 finished with value: 0.5187964879993864 and parameters: {'latent_dim': 25, 'hidden_dim': 194, 'lr': 0.0010036184977421589, 'epochs': 31, 'dropout_rate': 0.25208438329099897, 'sparsity_weight': 0.0004346197329404805, 'classification_weight': 0.5435174885245166, 'C': 2.909585976873256, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 7 with value: 0.5339026915113871.\n",
      "[I 2025-05-09 15:34:06,526] Trial 9 finished with value: 0.5079365079365079 and parameters: {'latent_dim': 89, 'hidden_dim': 238, 'lr': 0.00032363037166379635, 'epochs': 37, 'dropout_rate': 0.4494156148916123, 'sparsity_weight': 0.06392263541226575, 'classification_weight': 0.31073690897828843, 'C': 99.84435033136629, 'kernel': 'linear'}. Best is trial 7 with value: 0.5339026915113871.\n",
      "[I 2025-05-09 15:34:49,097] Trial 10 finished with value: 0.5175983436853002 and parameters: {'latent_dim': 38, 'hidden_dim': 76, 'lr': 0.00017482299116628868, 'epochs': 50, 'dropout_rate': 0.11612575439322834, 'sparsity_weight': 0.0008273565673773796, 'classification_weight': 0.8634206971788521, 'C': 20.45346987606317, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 7 with value: 0.5339026915113871.\n",
      "[I 2025-05-09 15:35:06,499] Trial 11 finished with value: 0.4954374664519592 and parameters: {'latent_dim': 40, 'hidden_dim': 66, 'lr': 0.0031735288667892763, 'epochs': 22, 'dropout_rate': 0.17881989486513356, 'sparsity_weight': 0.0020009585942605407, 'classification_weight': 0.7698930059503664, 'C': 1.2669603417955382, 'kernel': 'linear'}. Best is trial 7 with value: 0.5339026915113871.\n",
      "[I 2025-05-09 15:35:25,035] Trial 12 finished with value: 0.5059427957978683 and parameters: {'latent_dim': 42, 'hidden_dim': 108, 'lr': 0.009997118426962442, 'epochs': 24, 'dropout_rate': 0.4890200035996326, 'sparsity_weight': 0.00011561995607174112, 'classification_weight': 0.12167938290426578, 'C': 21.06936322860173, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 7 with value: 0.5339026915113871.\n",
      "[I 2025-05-09 15:35:47,723] Trial 13 finished with value: 0.5144352426961122 and parameters: {'latent_dim': 71, 'hidden_dim': 132, 'lr': 0.0014298277440680021, 'epochs': 26, 'dropout_rate': 0.3842429489829685, 'sparsity_weight': 0.0055386071266686375, 'classification_weight': 0.6839814617835909, 'C': 0.5861961191558728, 'kernel': 'linear'}. Best is trial 7 with value: 0.5339026915113871.\n",
      "[I 2025-05-09 15:36:00,397] Trial 14 finished with value: 0.5180871865654475 and parameters: {'latent_dim': 50, 'hidden_dim': 88, 'lr': 0.0040355100922461334, 'epochs': 18, 'dropout_rate': 0.18385546057437419, 'sparsity_weight': 0.0006890457983477951, 'classification_weight': 0.6580212174817832, 'C': 5.147104979652412, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 7 with value: 0.5339026915113871.\n",
      "[I 2025-05-09 15:36:32,408] Trial 15 finished with value: 0.5194578636607622 and parameters: {'latent_dim': 31, 'hidden_dim': 222, 'lr': 0.004527247681106694, 'epochs': 28, 'dropout_rate': 0.41830579418588837, 'sparsity_weight': 0.0013690601607502552, 'classification_weight': 0.8530959708368155, 'C': 19.924616994807852, 'kernel': 'linear'}. Best is trial 7 with value: 0.5339026915113871.\n",
      "[I 2025-05-09 15:37:09,379] Trial 16 finished with value: 0.5097576872939192 and parameters: {'latent_dim': 10, 'hidden_dim': 124, 'lr': 0.0017989661788066567, 'epochs': 44, 'dropout_rate': 0.2930741115191696, 'sparsity_weight': 0.00023856183224710685, 'classification_weight': 0.7724845656009296, 'C': 1.969454246911504, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 7 with value: 0.5339026915113871.\n",
      "[I 2025-05-09 15:37:23,070] Trial 17 finished with value: 0.5296372977532399 and parameters: {'latent_dim': 74, 'hidden_dim': 90, 'lr': 0.004901103467354839, 'epochs': 19, 'dropout_rate': 0.3305094768882255, 'sparsity_weight': 0.09791753405811456, 'classification_weight': 0.6437224183210251, 'C': 0.4478186646309014, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 7 with value: 0.5339026915113871.\n",
      "[I 2025-05-09 15:37:35,153] Trial 18 finished with value: 0.5277010965416763 and parameters: {'latent_dim': 78, 'hidden_dim': 86, 'lr': 0.005726131910926683, 'epochs': 17, 'dropout_rate': 0.3198174799652636, 'sparsity_weight': 0.031769488106186704, 'classification_weight': 0.6639500017887472, 'C': 74.74821949786036, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 7 with value: 0.5339026915113871.\n",
      "[I 2025-05-09 15:37:50,327] Trial 19 finished with value: 0.5086841499884979 and parameters: {'latent_dim': 64, 'hidden_dim': 98, 'lr': 0.00011337599672701787, 'epochs': 20, 'dropout_rate': 0.20536163221426873, 'sparsity_weight': 0.08688413093790741, 'classification_weight': 0.7622644826766741, 'C': 0.4162075070644255, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 7 with value: 0.5339026915113871.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5009\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5018\n",
      "ROC-AUC autoencoded: 0.4914\n",
      "ROC-AUC autoencoded: 0.4750\n",
      "ROC-AUC autoencoded: 0.5224\n",
      "ROC-AUC autoencoded: 0.5216\n",
      "ROC-AUC autoencoded: 0.5548\n",
      "ROC-AUC autoencoded: 0.5783\n",
      "ROC-AUC autoencoded: 0.5953\n",
      "ROC-AUC autoencoded: 0.5406\n",
      "ROC-AUC autoencoded: 0.5592\n",
      "ROC-AUC autoencoded: 0.5477\n",
      "ROC-AUC autoencoded: 0.5717\n",
      "ROC-AUC autoencoded: 0.5870\n",
      "ROC-AUC autoencoded: 0.5652\n",
      "ROC-AUC autoencoded: 0.5417\n",
      "ROC-AUC autoencoded: 0.5604\n",
      "ROC-AUC autoencoded: 0.5502\n",
      "ROC-AUC autoencoded: 0.5150\n",
      "ROC-AUC autoencoded: 0.5356\n",
      "ROC-AUC autoencoded: 0.5788\n",
      "ROC-AUC autoencoded: 0.5913\n",
      "ROC-AUC autoencoded: 0.6025\n",
      "ROC-AUC autoencoded: 0.5102\n",
      "ROC-AUC autoencoded: 0.5343\n",
      "ROC-AUC autoencoded: 0.5861\n",
      "среднее 0.5487213564051417\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 15:39:36,463] A new study created in memory with name: no-name-77aaac77-6572-49a7-854e-5c8f91f8ca4d\n",
      "[I 2025-05-09 15:40:19,500] Trial 0 finished with value: 0.5249597423510467 and parameters: {'latent_dim': 49, 'hidden_dim': 184, 'lr': 0.00013826227184156635, 'epochs': 43, 'dropout_rate': 0.27036458897944754, 'sparsity_weight': 0.014924858397746307, 'classification_weight': 0.3032495975201448}. Best is trial 0 with value: 0.5249597423510467.\n",
      "[I 2025-05-09 15:40:50,670] Trial 1 finished with value: 0.5169657234874626 and parameters: {'latent_dim': 74, 'hidden_dim': 176, 'lr': 0.005983324858898052, 'epochs': 30, 'dropout_rate': 0.30592959054689206, 'sparsity_weight': 0.00012351477116307244, 'classification_weight': 0.6607796515216171}. Best is trial 0 with value: 0.5249597423510467.\n",
      "[I 2025-05-09 15:41:14,224] Trial 2 finished with value: 0.5140518365156046 and parameters: {'latent_dim': 29, 'hidden_dim': 136, 'lr': 0.007874331940920281, 'epochs': 27, 'dropout_rate': 0.4037820155300319, 'sparsity_weight': 0.0001214998423873014, 'classification_weight': 0.2954352039303536}. Best is trial 0 with value: 0.5249597423510467.\n",
      "[I 2025-05-09 15:41:58,229] Trial 3 finished with value: 0.5135917490989954 and parameters: {'latent_dim': 12, 'hidden_dim': 186, 'lr': 0.0037196358841764276, 'epochs': 43, 'dropout_rate': 0.10623862393559302, 'sparsity_weight': 0.08123598570924177, 'classification_weight': 0.5926819966616729}. Best is trial 0 with value: 0.5249597423510467.\n",
      "[I 2025-05-09 15:42:46,069] Trial 4 finished with value: 0.5134479717813051 and parameters: {'latent_dim': 29, 'hidden_dim': 197, 'lr': 0.002212348779448579, 'epochs': 45, 'dropout_rate': 0.3408643919966149, 'sparsity_weight': 0.005591637228534346, 'classification_weight': 0.6087050805769794}. Best is trial 0 with value: 0.5249597423510467.\n",
      "[I 2025-05-09 15:43:11,888] Trial 5 finished with value: 0.5163522735986504 and parameters: {'latent_dim': 69, 'hidden_dim': 172, 'lr': 0.0038491062323401932, 'epochs': 26, 'dropout_rate': 0.487581887829562, 'sparsity_weight': 0.012714786675403923, 'classification_weight': 0.5289359673337731}. Best is trial 0 with value: 0.5249597423510467.\n",
      "[I 2025-05-09 15:43:40,663] Trial 6 finished with value: 0.5160167931907063 and parameters: {'latent_dim': 72, 'hidden_dim': 76, 'lr': 0.0006971314154825604, 'epochs': 43, 'dropout_rate': 0.3777510074824446, 'sparsity_weight': 0.008300035117410218, 'classification_weight': 0.7574821461584431}. Best is trial 0 with value: 0.5249597423510467.\n",
      "[I 2025-05-09 15:44:09,657] Trial 7 finished with value: 0.510783298826777 and parameters: {'latent_dim': 57, 'hidden_dim': 85, 'lr': 0.009763226186840862, 'epochs': 41, 'dropout_rate': 0.14154317141042713, 'sparsity_weight': 0.0029073470130736227, 'classification_weight': 0.49466171659067837}. Best is trial 0 with value: 0.5249597423510467.\n",
      "[I 2025-05-09 15:44:21,998] Trial 8 finished with value: 0.5282474503488995 and parameters: {'latent_dim': 19, 'hidden_dim': 169, 'lr': 0.004940156971888503, 'epochs': 13, 'dropout_rate': 0.3872291463900489, 'sparsity_weight': 0.0002932659644826331, 'classification_weight': 0.5653054433229113}. Best is trial 8 with value: 0.5282474503488995.\n",
      "[I 2025-05-09 15:45:00,085] Trial 9 finished with value: 0.5007284717429644 and parameters: {'latent_dim': 85, 'hidden_dim': 120, 'lr': 0.0001801457986872693, 'epochs': 46, 'dropout_rate': 0.4308365177328288, 'sparsity_weight': 0.006922715618333634, 'classification_weight': 0.19795843285247489}. Best is trial 8 with value: 0.5282474503488995.\n",
      "[I 2025-05-09 15:45:13,399] Trial 10 finished with value: 0.5175983436853001 and parameters: {'latent_dim': 99, 'hidden_dim': 248, 'lr': 0.0009718475058324521, 'epochs': 10, 'dropout_rate': 0.21936140567984022, 'sparsity_weight': 0.0006632980109597265, 'classification_weight': 0.8934341405778682}. Best is trial 8 with value: 0.5282474503488995.\n",
      "[I 2025-05-09 15:45:25,690] Trial 11 finished with value: 0.521854152288935 and parameters: {'latent_dim': 40, 'hidden_dim': 216, 'lr': 0.00011937277045660259, 'epochs': 10, 'dropout_rate': 0.24591421864899446, 'sparsity_weight': 0.04252427542036239, 'classification_weight': 0.35352471805686536}. Best is trial 8 with value: 0.5282474503488995.\n",
      "[I 2025-05-09 15:45:43,669] Trial 12 finished with value: 0.4977379035350049 and parameters: {'latent_dim': 11, 'hidden_dim': 138, 'lr': 0.0003366483949054808, 'epochs': 20, 'dropout_rate': 0.2449958808087155, 'sparsity_weight': 0.0012212680336937442, 'classification_weight': 0.3777925549138052}. Best is trial 8 with value: 0.5282474503488995.\n",
      "[I 2025-05-09 15:46:22,576] Trial 13 finished with value: 0.5285637604478185 and parameters: {'latent_dim': 44, 'hidden_dim': 219, 'lr': 0.00041984853710159395, 'epochs': 35, 'dropout_rate': 0.30648795308681615, 'sparsity_weight': 0.00047752736803593484, 'classification_weight': 0.11174467999757987}. Best is trial 13 with value: 0.5285637604478185.\n",
      "[I 2025-05-09 15:47:05,222] Trial 14 finished with value: 0.5163618587531631 and parameters: {'latent_dim': 28, 'hidden_dim': 234, 'lr': 0.00046347341575674506, 'epochs': 36, 'dropout_rate': 0.3460453117563036, 'sparsity_weight': 0.00042531858158283836, 'classification_weight': 0.10649394135909682}. Best is trial 13 with value: 0.5285637604478185.\n",
      "[I 2025-05-09 15:47:28,406] Trial 15 finished with value: 0.5121348056130665 and parameters: {'latent_dim': 44, 'hidden_dim': 215, 'lr': 0.0017401080981697993, 'epochs': 21, 'dropout_rate': 0.4540475835480896, 'sparsity_weight': 0.0003340403084969083, 'classification_weight': 0.47364063926106}. Best is trial 13 with value: 0.5285637604478185.\n",
      "[I 2025-05-09 15:48:00,497] Trial 16 finished with value: 0.5109462464534927 and parameters: {'latent_dim': 20, 'hidden_dim': 144, 'lr': 0.001621947659969261, 'epochs': 36, 'dropout_rate': 0.1984645639402092, 'sparsity_weight': 0.0015047198591331857, 'classification_weight': 0.13046791032290997}. Best is trial 13 with value: 0.5285637604478185.\n",
      "[I 2025-05-09 15:48:20,102] Trial 17 finished with value: 0.5152020550571276 and parameters: {'latent_dim': 37, 'hidden_dim': 212, 'lr': 0.00024340599307484954, 'epochs': 18, 'dropout_rate': 0.32314806420656905, 'sparsity_weight': 0.00023254734010487625, 'classification_weight': 0.7632955926263219}. Best is trial 13 with value: 0.5285637604478185.\n",
      "[I 2025-05-09 15:48:47,740] Trial 18 finished with value: 0.5279982363315697 and parameters: {'latent_dim': 60, 'hidden_dim': 109, 'lr': 0.0005702445938564366, 'epochs': 35, 'dropout_rate': 0.38169347542254095, 'sparsity_weight': 0.0008347899658976732, 'classification_weight': 0.4361457599668222}. Best is trial 13 with value: 0.5285637604478185.\n",
      "[I 2025-05-09 15:49:02,866] Trial 19 finished with value: 0.5039107430411779 and parameters: {'latent_dim': 33, 'hidden_dim': 158, 'lr': 0.0010483433622937442, 'epochs': 16, 'dropout_rate': 0.27875542493651334, 'sparsity_weight': 0.0022039827841137906, 'classification_weight': 0.22380625632328646}. Best is trial 13 with value: 0.5285637604478185.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5078\n"
     ]
    }
   ],
   "source": [
    "def predict_classifier_head(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, _, classification = model(X_tensor)\n",
    "    return classification.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        y_pred_proba = predict_classifier_head(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "y_pred_proba = predict_classifier_head(autoencoder, X_val_all)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4652\n",
      "ROC-AUC autoencoded: 0.4898\n",
      "ROC-AUC autoencoded: 0.4730\n",
      "ROC-AUC autoencoded: 0.5076\n",
      "ROC-AUC autoencoded: 0.5041\n",
      "ROC-AUC autoencoded: 0.5782\n",
      "ROC-AUC autoencoded: 0.5473\n",
      "ROC-AUC autoencoded: 0.5680\n",
      "ROC-AUC autoencoded: 0.5743\n",
      "ROC-AUC autoencoded: 0.5438\n",
      "ROC-AUC autoencoded: 0.5829\n",
      "ROC-AUC autoencoded: 0.5174\n",
      "ROC-AUC autoencoded: 0.5628\n",
      "ROC-AUC autoencoded: 0.5728\n",
      "ROC-AUC autoencoded: 0.5704\n",
      "ROC-AUC autoencoded: 0.5589\n",
      "ROC-AUC autoencoded: 0.5583\n",
      "ROC-AUC autoencoded: 0.5714\n",
      "ROC-AUC autoencoded: 0.5468\n",
      "ROC-AUC autoencoded: 0.5548\n",
      "ROC-AUC autoencoded: 0.5418\n",
      "ROC-AUC autoencoded: 0.5222\n",
      "ROC-AUC autoencoded: 0.5568\n",
      "ROC-AUC autoencoded: 0.5224\n",
      "ROC-AUC autoencoded: 0.5494\n",
      "среднее 0.5416157234797359\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = predict_classifier_head(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше идет блок со stacked автоэнкодером"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:02:35,315] A new study created in memory with name: no-name-3afcce0a-44b1-4cf4-ace6-5c4149a57070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:03:53,164] Trial 0 finished with value: 0.5410628019323672 and parameters: {'num_layers': 2, 'latent_dim_0': 914, 'latent_dim_1': 787, 'lr': 0.00042383632922039403, 'epochs': 15, 'dropout_rate': 0.11953260859932452, 'C': 45.839470680981854, 'solver': 'liblinear'}. Best is trial 0 with value: 0.5410628019323672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:05:58,675] Trial 1 finished with value: 0.5261962272831838 and parameters: {'num_layers': 2, 'latent_dim_0': 1007, 'latent_dim_1': 574, 'lr': 0.0007123078703955394, 'epochs': 21, 'dropout_rate': 0.2340936809591106, 'C': 3.990065793919274, 'solver': 'saga'}. Best is trial 0 with value: 0.5410628019323672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:09:43,574] Trial 2 finished with value: 0.5378805306341539 and parameters: {'num_layers': 2, 'latent_dim_0': 886, 'latent_dim_1': 510, 'lr': 0.0009049668859938895, 'epochs': 50, 'dropout_rate': 0.3131019950925894, 'C': 0.034133761529179296, 'solver': 'liblinear'}. Best is trial 0 with value: 0.5410628019323672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:11:41,228] Trial 3 finished with value: 0.5174449812130972 and parameters: {'num_layers': 2, 'latent_dim_0': 940, 'latent_dim_1': 600, 'lr': 0.0016647235595161872, 'epochs': 24, 'dropout_rate': 0.30117880298496136, 'C': 0.33421925469448605, 'solver': 'liblinear'}. Best is trial 0 with value: 0.5410628019323672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:13:43,733] Trial 4 finished with value: 0.5341423203742045 and parameters: {'num_layers': 2, 'latent_dim_0': 1479, 'latent_dim_1': 542, 'lr': 0.007504230391678993, 'epochs': 16, 'dropout_rate': 0.4908029491671999, 'C': 1.061876553370415, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5410628019323672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:17:51,540] Trial 5 finished with value: 0.5101794340924776 and parameters: {'num_layers': 2, 'latent_dim_0': 1374, 'latent_dim_1': 541, 'lr': 0.00010185996894284712, 'epochs': 34, 'dropout_rate': 0.2229211206688287, 'C': 0.30717856264151133, 'solver': 'saga'}. Best is trial 0 with value: 0.5410628019323672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:21:39,620] Trial 6 finished with value: 0.5035273368606702 and parameters: {'num_layers': 2, 'latent_dim_0': 1092, 'latent_dim_1': 471, 'lr': 0.000135470931502559, 'epochs': 38, 'dropout_rate': 0.12710236395828556, 'C': 0.05373330853698333, 'solver': 'liblinear'}. Best is trial 0 with value: 0.5410628019323672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:26:15,303] Trial 7 finished with value: 0.49975078598267003 and parameters: {'num_layers': 2, 'latent_dim_0': 1152, 'latent_dim_1': 531, 'lr': 0.00021974333639045022, 'epochs': 48, 'dropout_rate': 0.4339212610459384, 'C': 0.27405838630033547, 'solver': 'liblinear'}. Best is trial 0 with value: 0.5410628019323672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:33:14,801] Trial 8 finished with value: 0.5426539375814737 and parameters: {'num_layers': 2, 'latent_dim_0': 1570, 'latent_dim_1': 723, 'lr': 0.00268256133314762, 'epochs': 50, 'dropout_rate': 0.4575121115156976, 'C': 0.03667116560944597, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.5426539375814737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:36:07,635] Trial 9 finished with value: 0.5102752856376045 and parameters: {'num_layers': 2, 'latent_dim_0': 935, 'latent_dim_1': 664, 'lr': 0.00014119646420496942, 'epochs': 37, 'dropout_rate': 0.4155645415242618, 'C': 0.014488200410305596, 'solver': 'saga'}. Best is trial 8 with value: 0.5426539375814737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:41:40,834] Trial 10 finished with value: 0.5317652020550572 and parameters: {'num_layers': 2, 'latent_dim_0': 1606, 'latent_dim_1': 704, 'lr': 0.0035652950184418123, 'epochs': 44, 'dropout_rate': 0.38059914103622194, 'C': 17.52837321906827, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.5426539375814737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:42:58,620] Trial 11 finished with value: 0.5293880837359097 and parameters: {'num_layers': 2, 'latent_dim_0': 1309, 'latent_dim_1': 797, 'lr': 0.0004067166688266562, 'epochs': 12, 'dropout_rate': 0.16062737124762874, 'C': 87.5381751547598, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.5426539375814737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:46:53,559] Trial 12 finished with value: 0.5057510927076144 and parameters: {'num_layers': 2, 'latent_dim_0': 1254, 'latent_dim_1': 801, 'lr': 0.0020644945729867722, 'epochs': 27, 'dropout_rate': 0.2199188929374809, 'C': 8.314787235855034, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.5426539375814737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:50:05,511] Trial 13 finished with value: 0.48713672264396907 and parameters: {'num_layers': 2, 'latent_dim_0': 1594, 'latent_dim_1': 721, 'lr': 0.0004407109397912215, 'epochs': 18, 'dropout_rate': 0.105556351808272, 'C': 86.2895033761316, 'solver': 'liblinear'}. Best is trial 8 with value: 0.5426539375814737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:52:54,740] Trial 14 finished with value: 0.5425005751092707 and parameters: {'num_layers': 2, 'latent_dim_0': 821, 'latent_dim_1': 743, 'lr': 0.004344492718514689, 'epochs': 30, 'dropout_rate': 0.3525944787358829, 'C': 1.2145241018111184, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.5426539375814737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 19:57:43,051] Trial 15 finished with value: 0.5141093474426807 and parameters: {'num_layers': 2, 'latent_dim_0': 1461, 'latent_dim_1': 655, 'lr': 0.008850766891153753, 'epochs': 30, 'dropout_rate': 0.3584027875479331, 'C': 1.548679377370249, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.5426539375814737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 20:00:48,053] Trial 16 finished with value: 0.4803887738670347 and parameters: {'num_layers': 2, 'latent_dim_0': 819, 'latent_dim_1': 405, 'lr': 0.003824128534878545, 'epochs': 42, 'dropout_rate': 0.4777696342369608, 'C': 0.06837106533068597, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.5426539375814737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 20:03:40,453] Trial 17 finished with value: 0.5608465608465608 and parameters: {'num_layers': 2, 'latent_dim_0': 1061, 'latent_dim_1': 729, 'lr': 0.004234382891231851, 'epochs': 31, 'dropout_rate': 0.34699308850310645, 'C': 0.14209357213235993, 'solver': 'lbfgs'}. Best is trial 17 with value: 0.5608465608465608.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 20:07:29,227] Trial 18 finished with value: 0.5230810520665593 and parameters: {'num_layers': 2, 'latent_dim_0': 1046, 'latent_dim_1': 653, 'lr': 0.0018285049428349116, 'epochs': 43, 'dropout_rate': 0.4484278994017968, 'C': 0.01088919656886573, 'solver': 'lbfgs'}. Best is trial 17 with value: 0.5608465608465608.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 20:10:59,994] Trial 19 finished with value: 0.5229660302124071 and parameters: {'num_layers': 2, 'latent_dim_0': 1146, 'latent_dim_1': 750, 'lr': 0.002782156673394911, 'epochs': 34, 'dropout_rate': 0.40331739590781124, 'C': 0.15738035934309808, 'solver': 'lbfgs'}. Best is trial 17 with value: 0.5608465608465608.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.5336\n"
     ]
    }
   ],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(SimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "        \n",
    "        return reconstructions, latents\n",
    "    \n",
    "def train_stacked_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    \n",
    "    # Обучаем каждый автоэнкодер последовательно\n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, latent)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, _ in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent = ae(batch_x)\n",
    "                loss = criterion(reconstructed, batch_x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры логистической регрессии\n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4936\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4741\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4211\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4643\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5302\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5021\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5701\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5475\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5725\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6192\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5564\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5303\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5750\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5722\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5411\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5145\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5529\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5258\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5912\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5553\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5440\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5202\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5432\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5262\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5607\n",
      "среднее 0.5361558673506339\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 20:31:09,814] A new study created in memory with name: no-name-76b3bee6-de32-44b6-b49b-a61ae016ea59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 20:36:27,039] Trial 0 finished with value: 0.5051184725097769 and parameters: {'num_layers': 2, 'latent_dim_0': 1196, 'latent_dim_1': 696, 'lr': 0.0060433524042482045, 'epochs': 30, 'dropout_rate': 0.4106081401437709, 'n_estimators': 106, 'max_depth': 6, 'learning_rate': 0.15843477513164672, 'subsample': 0.7576009713396139, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.5051184725097769.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 20:44:34,831] Trial 1 finished with value: 0.514626945786366 and parameters: {'num_layers': 2, 'latent_dim_0': 1227, 'latent_dim_1': 770, 'lr': 0.0026822695299389453, 'epochs': 13, 'dropout_rate': 0.36182040658506276, 'n_estimators': 279, 'max_depth': 6, 'learning_rate': 0.021939676496495444, 'subsample': 0.9088137649384597, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.514626945786366.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 20:48:36,899] Trial 2 finished with value: 0.5159305268000921 and parameters: {'num_layers': 2, 'latent_dim_0': 847, 'latent_dim_1': 522, 'lr': 0.003433924647261894, 'epochs': 37, 'dropout_rate': 0.1570524902231224, 'n_estimators': 104, 'max_depth': 6, 'learning_rate': 0.010626454737430912, 'subsample': 0.7318414459485225, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.5159305268000921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 20:59:19,719] Trial 3 finished with value: 0.47684226669733915 and parameters: {'num_layers': 2, 'latent_dim_0': 1157, 'latent_dim_1': 636, 'lr': 0.004195885981127074, 'epochs': 45, 'dropout_rate': 0.17933152060167382, 'n_estimators': 233, 'max_depth': 10, 'learning_rate': 0.16631591163800735, 'subsample': 0.9148597418075017, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.5159305268000921.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 21:07:47,694] Trial 4 finished with value: 0.5350241545893719 and parameters: {'num_layers': 2, 'latent_dim_0': 1503, 'latent_dim_1': 424, 'lr': 0.00017810023240514853, 'epochs': 47, 'dropout_rate': 0.18209725288294024, 'n_estimators': 145, 'max_depth': 9, 'learning_rate': 0.022760606421136857, 'subsample': 0.6164814589919418, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 21:19:36,934] Trial 5 finished with value: 0.4601449275362319 and parameters: {'num_layers': 2, 'latent_dim_0': 1508, 'latent_dim_1': 685, 'lr': 0.003951470148321309, 'epochs': 49, 'dropout_rate': 0.16084827598332516, 'n_estimators': 406, 'max_depth': 3, 'learning_rate': 0.21034405923543123, 'subsample': 0.922229092367274, 'min_samples_split': 18, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 21:27:46,738] Trial 6 finished with value: 0.5121923165401426 and parameters: {'num_layers': 2, 'latent_dim_0': 961, 'latent_dim_1': 422, 'lr': 0.00016703633961924358, 'epochs': 21, 'dropout_rate': 0.23394893957292806, 'n_estimators': 495, 'max_depth': 6, 'learning_rate': 0.07779353170207921, 'subsample': 0.9126682914156923, 'min_samples_split': 17, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 21:36:58,687] Trial 7 finished with value: 0.48696418986274054 and parameters: {'num_layers': 2, 'latent_dim_0': 1524, 'latent_dim_1': 635, 'lr': 0.000302932572390833, 'epochs': 49, 'dropout_rate': 0.2566861070890676, 'n_estimators': 152, 'max_depth': 6, 'learning_rate': 0.11129428468865225, 'subsample': 0.8776475207100478, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 21:41:19,317] Trial 8 finished with value: 0.511003757380569 and parameters: {'num_layers': 2, 'latent_dim_0': 1183, 'latent_dim_1': 794, 'lr': 0.005167678506628451, 'epochs': 32, 'dropout_rate': 0.3722138759258832, 'n_estimators': 52, 'max_depth': 7, 'learning_rate': 0.11940570106582987, 'subsample': 0.6007870261037254, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 21:48:06,027] Trial 9 finished with value: 0.5143585614600107 and parameters: {'num_layers': 2, 'latent_dim_0': 1564, 'latent_dim_1': 533, 'lr': 0.0005597076462228226, 'epochs': 11, 'dropout_rate': 0.2643131418953804, 'n_estimators': 381, 'max_depth': 5, 'learning_rate': 0.11377577957364383, 'subsample': 0.8905514956569631, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 21:55:36,027] Trial 10 finished with value: 0.49279196380645657 and parameters: {'num_layers': 2, 'latent_dim_0': 1376, 'latent_dim_1': 414, 'lr': 0.00011252422196651741, 'epochs': 40, 'dropout_rate': 0.47564758303939747, 'n_estimators': 217, 'max_depth': 10, 'learning_rate': 0.03478906082577984, 'subsample': 0.6523575441186359, 'min_samples_split': 12, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 22:00:17,061] Trial 11 finished with value: 0.5091250670960816 and parameters: {'num_layers': 2, 'latent_dim_0': 812, 'latent_dim_1': 498, 'lr': 0.0015262657535700542, 'epochs': 36, 'dropout_rate': 0.11399144354248228, 'n_estimators': 151, 'max_depth': 8, 'learning_rate': 0.010253802528740405, 'subsample': 0.7357543791459676, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 22:04:31,294] Trial 12 finished with value: 0.5118089103596349 and parameters: {'num_layers': 2, 'latent_dim_0': 990, 'latent_dim_1': 506, 'lr': 0.009943342298661891, 'epochs': 42, 'dropout_rate': 0.10069835085350635, 'n_estimators': 52, 'max_depth': 8, 'learning_rate': 0.010085027583778513, 'subsample': 0.6937324204870758, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 22:10:44,984] Trial 13 finished with value: 0.503316463461391 and parameters: {'num_layers': 2, 'latent_dim_0': 1346, 'latent_dim_1': 553, 'lr': 0.0008218940986350005, 'epochs': 28, 'dropout_rate': 0.18874823145675573, 'n_estimators': 149, 'max_depth': 9, 'learning_rate': 0.019651380066044066, 'subsample': 0.8085739603844789, 'min_samples_split': 14, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 22:15:39,147] Trial 14 finished with value: 0.4957058507783145 and parameters: {'num_layers': 2, 'latent_dim_0': 1001, 'latent_dim_1': 460, 'lr': 0.0017623954439735948, 'epochs': 37, 'dropout_rate': 0.30877945321765643, 'n_estimators': 296, 'max_depth': 4, 'learning_rate': 0.018256644242208565, 'subsample': 0.6006644303789831, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 22:24:53,498] Trial 15 finished with value: 0.5011502185415229 and parameters: {'num_layers': 2, 'latent_dim_0': 1387, 'latent_dim_1': 579, 'lr': 0.0004048724993910795, 'epochs': 44, 'dropout_rate': 0.15232103236235456, 'n_estimators': 216, 'max_depth': 8, 'learning_rate': 0.039992712574168456, 'subsample': 0.8024925240356893, 'min_samples_split': 14, 'min_samples_leaf': 6}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 22:28:45,765] Trial 16 finished with value: 0.5198412698412699 and parameters: {'num_layers': 2, 'latent_dim_0': 890, 'latent_dim_1': 473, 'lr': 0.00021432227448896639, 'epochs': 24, 'dropout_rate': 0.2269538043335459, 'n_estimators': 118, 'max_depth': 7, 'learning_rate': 0.014657755480595839, 'subsample': 0.9846388867879212, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 22:37:38,153] Trial 17 finished with value: 0.5268576029445594 and parameters: {'num_layers': 2, 'latent_dim_0': 1086, 'latent_dim_1': 454, 'lr': 0.00021595561160479482, 'epochs': 23, 'dropout_rate': 0.21810361045065899, 'n_estimators': 337, 'max_depth': 9, 'learning_rate': 0.030028008313648005, 'subsample': 0.9919245727478713, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 22:44:23,583] Trial 18 finished with value: 0.5214132351813511 and parameters: {'num_layers': 2, 'latent_dim_0': 1085, 'latent_dim_1': 403, 'lr': 0.00011024454761763518, 'epochs': 16, 'dropout_rate': 0.3059087812588996, 'n_estimators': 356, 'max_depth': 9, 'learning_rate': 0.03311753942915599, 'subsample': 0.8481130262974046, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 22:52:44,373] Trial 19 finished with value: 0.5238862050456253 and parameters: {'num_layers': 2, 'latent_dim_0': 1281, 'latent_dim_1': 456, 'lr': 0.0001985821902261042, 'epochs': 19, 'dropout_rate': 0.20077113862715773, 'n_estimators': 317, 'max_depth': 9, 'learning_rate': 0.050236587133897684, 'subsample': 0.9673616525813509, 'min_samples_split': 20, 'min_samples_leaf': 8}. Best is trial 4 with value: 0.5350241545893719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.4825\n"
     ]
    }
   ],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(SimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "        \n",
    "        return reconstructions, latents\n",
    "    \n",
    "def train_stacked_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    \n",
    "    # Обучаем каждый автоэнкодер последовательно\n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, latent)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, _ in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent = ae(batch_x)\n",
    "                loss = criterion(reconstructed, batch_x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры градиентного бустинга\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5125\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5349\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5450\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4766\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5196\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5583\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4773\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4929\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5108\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4669\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5006\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5188\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5159\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5290\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6158\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4834\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4741\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5240\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5653\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5534\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5053\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5584\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4830\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4959\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5114\n",
      "среднее 0.5171618682621437\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 23:45:27,565] A new study created in memory with name: no-name-19af1969-f4b3-475f-8c28-cccb049a93f7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 23:53:16,059] Trial 0 finished with value: 0.5155087800015337 and parameters: {'num_layers': 2, 'latent_dim_0': 1133, 'latent_dim_1': 423, 'lr': 0.0029453925851400365, 'epochs': 31, 'dropout_rate': 0.20994568576690942, 'C': 20.7885102888376, 'kernel': 'linear'}. Best is trial 0 with value: 0.5155087800015337.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 23:54:58,514] Trial 1 finished with value: 0.5196879073690668 and parameters: {'num_layers': 2, 'latent_dim_0': 940, 'latent_dim_1': 768, 'lr': 0.001218010674722385, 'epochs': 20, 'dropout_rate': 0.40290116141356425, 'C': 0.6009116294270503, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 1 with value: 0.5196879073690668.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 23:56:54,186] Trial 2 finished with value: 0.538091404033433 and parameters: {'num_layers': 2, 'latent_dim_0': 992, 'latent_dim_1': 653, 'lr': 0.0001136969921887093, 'epochs': 22, 'dropout_rate': 0.3134745322410647, 'C': 0.5612421390410959, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 2 with value: 0.538091404033433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:01:14,699] Trial 3 finished with value: 0.511348822943026 and parameters: {'num_layers': 2, 'latent_dim_0': 1451, 'latent_dim_1': 496, 'lr': 0.00010093124436731321, 'epochs': 35, 'dropout_rate': 0.2406518792770784, 'C': 0.2995315771224319, 'kernel': 'linear'}. Best is trial 2 with value: 0.538091404033433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:03:04,525] Trial 4 finished with value: 0.5203205275669044 and parameters: {'num_layers': 2, 'latent_dim_0': 906, 'latent_dim_1': 768, 'lr': 0.0028090147228184187, 'epochs': 21, 'dropout_rate': 0.30362682955438475, 'C': 15.751550181146298, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 2 with value: 0.538091404033433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:06:26,674] Trial 5 finished with value: 0.5066904378498581 and parameters: {'num_layers': 2, 'latent_dim_0': 906, 'latent_dim_1': 470, 'lr': 0.0038220148269792133, 'epochs': 39, 'dropout_rate': 0.4495973358545412, 'C': 0.18808522739817554, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 2 with value: 0.538091404033433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:07:15,101] Trial 6 finished with value: 0.47883597883597884 and parameters: {'num_layers': 2, 'latent_dim_0': 961, 'latent_dim_1': 421, 'lr': 0.001528112255705696, 'epochs': 10, 'dropout_rate': 0.3910338029078603, 'C': 3.2953261264154743, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 2 with value: 0.538091404033433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:10:09,805] Trial 7 finished with value: 0.5162755923625488 and parameters: {'num_layers': 2, 'latent_dim_0': 1139, 'latent_dim_1': 702, 'lr': 0.0007659628745602168, 'epochs': 27, 'dropout_rate': 0.4995324556697742, 'C': 1.0337120155718775, 'kernel': 'linear'}. Best is trial 2 with value: 0.538091404033433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:13:34,469] Trial 8 finished with value: 0.537094547964113 and parameters: {'num_layers': 2, 'latent_dim_0': 1354, 'latent_dim_1': 686, 'lr': 0.0006259113327110145, 'epochs': 28, 'dropout_rate': 0.4459531280930972, 'C': 1.3476584008001988, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 2 with value: 0.538091404033433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:15:44,453] Trial 9 finished with value: 0.554922935357718 and parameters: {'num_layers': 2, 'latent_dim_0': 1173, 'latent_dim_1': 681, 'lr': 0.00870839839322876, 'epochs': 20, 'dropout_rate': 0.3408513432914227, 'C': 8.202445474788554, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.554922935357718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:22:45,190] Trial 10 finished with value: 0.5135342381719193 and parameters: {'num_layers': 2, 'latent_dim_0': 1575, 'latent_dim_1': 577, 'lr': 0.009618564040325185, 'epochs': 48, 'dropout_rate': 0.10218630211536855, 'C': 90.28660642085379, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.554922935357718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:24:55,405] Trial 11 finished with value: 0.4799670270684763 and parameters: {'num_layers': 2, 'latent_dim_0': 1240, 'latent_dim_1': 621, 'lr': 0.00010733433612465713, 'epochs': 15, 'dropout_rate': 0.3109738537849481, 'C': 6.590848007944369, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.554922935357718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:27:21,130] Trial 12 finished with value: 0.5007859826700406 and parameters: {'num_layers': 2, 'latent_dim_0': 1043, 'latent_dim_1': 619, 'lr': 0.0002695842469700098, 'epochs': 21, 'dropout_rate': 0.35035597501191046, 'C': 0.10464321492703699, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.554922935357718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:28:44,810] Trial 13 finished with value: 0.4724906065485775 and parameters: {'num_layers': 2, 'latent_dim_0': 807, 'latent_dim_1': 685, 'lr': 0.0003059706452336062, 'epochs': 15, 'dropout_rate': 0.23224123699400917, 'C': 2.8679493867433106, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 9 with value: 0.554922935357718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:32:02,394] Trial 14 finished with value: 0.5147036270224676 and parameters: {'num_layers': 2, 'latent_dim_0': 1237, 'latent_dim_1': 564, 'lr': 0.0071508396234024356, 'epochs': 24, 'dropout_rate': 0.1636369591980355, 'C': 15.21376902301694, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.554922935357718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:33:13,014] Trial 15 finished with value: 0.513764281880224 and parameters: {'num_layers': 2, 'latent_dim_0': 1059, 'latent_dim_1': 724, 'lr': 0.0003052108903498553, 'epochs': 10, 'dropout_rate': 0.3474332216697185, 'C': 0.5636119283971301, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.554922935357718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:35:00,356] Trial 16 finished with value: 0.5057894333256652 and parameters: {'num_layers': 2, 'latent_dim_0': 1326, 'latent_dim_1': 657, 'lr': 0.00016956056510558, 'epochs': 15, 'dropout_rate': 0.2824303220419232, 'C': 36.287971803116264, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 9 with value: 0.554922935357718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:37:57,430] Trial 17 finished with value: 0.530710835058661 and parameters: {'num_layers': 2, 'latent_dim_0': 1062, 'latent_dim_1': 544, 'lr': 0.0017877664293416925, 'epochs': 33, 'dropout_rate': 0.37399633792839754, 'C': 5.825213581402014, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 9 with value: 0.554922935357718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:42:05,836] Trial 18 finished with value: 0.5093551108043862 and parameters: {'num_layers': 2, 'latent_dim_0': 1186, 'latent_dim_1': 639, 'lr': 0.0004968814069577028, 'epochs': 40, 'dropout_rate': 0.27968860879283386, 'C': 1.7167100362903047, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 9 with value: 0.554922935357718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 00:45:06,660] Trial 19 finished with value: 0.5134383866267925 and parameters: {'num_layers': 2, 'latent_dim_0': 1326, 'latent_dim_1': 731, 'lr': 0.004925732347097705, 'epochs': 25, 'dropout_rate': 0.17848713934797517, 'C': 6.62389751972544, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 9 with value: 0.554922935357718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.4899\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры SVC\n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5029\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5212\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4923\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4842\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5161\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4873\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6055\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4603\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5483\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5502\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5470\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4566\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5159\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.3942\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5962\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5857\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5969\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5378\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5678\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5913\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5172\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4550\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5305\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4550\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5270\n",
      "среднее 0.5216938221386928\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:03:23,083] A new study created in memory with name: no-name-c4f4c7d5-c86c-4977-9057-eafa87f3858e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:07:47,255] Trial 0 finished with value: 0.5411969940955448 and parameters: {'num_layers': 2, 'latent_dim_0': 992, 'latent_dim_1': 446, 'lr_ae': 0.001499361490045845, 'epochs_ae': 41, 'dropout_rate_ae': 0.17666191123545769, 'hidden_dim_mlp': 38, 'lr_mlp': 0.00013497946203102105, 'epochs_mlp': 31, 'dropout_rate_mlp': 0.3047921232310911}. Best is trial 0 with value: 0.5411969940955448.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:09:11,362] Trial 1 finished with value: 0.5505712752089563 and parameters: {'num_layers': 2, 'latent_dim_0': 1129, 'latent_dim_1': 607, 'lr_ae': 0.0009244342449536901, 'epochs_ae': 11, 'dropout_rate_ae': 0.4804265694188051, 'hidden_dim_mlp': 37, 'lr_mlp': 0.005078159049363646, 'epochs_mlp': 14, 'dropout_rate_mlp': 0.24289720512995042}. Best is trial 1 with value: 0.5505712752089563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:12:02,954] Trial 2 finished with value: 0.5423280423280423 and parameters: {'num_layers': 2, 'latent_dim_0': 1507, 'latent_dim_1': 513, 'lr_ae': 0.0016843301366439639, 'epochs_ae': 23, 'dropout_rate_ae': 0.328225083675443, 'hidden_dim_mlp': 32, 'lr_mlp': 0.00012702826998768038, 'epochs_mlp': 24, 'dropout_rate_mlp': 0.3516382351781473}. Best is trial 1 with value: 0.5505712752089563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:13:23,458] Trial 3 finished with value: 0.5146077754773407 and parameters: {'num_layers': 2, 'latent_dim_0': 938, 'latent_dim_1': 439, 'lr_ae': 0.0010611820523193593, 'epochs_ae': 16, 'dropout_rate_ae': 0.18505070759251138, 'hidden_dim_mlp': 80, 'lr_mlp': 0.0005035562595033122, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.32514086986593327}. Best is trial 1 with value: 0.5505712752089563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:16:28,946] Trial 4 finished with value: 0.5237328425734223 and parameters: {'num_layers': 2, 'latent_dim_0': 973, 'latent_dim_1': 454, 'lr_ae': 0.00014522995129237723, 'epochs_ae': 38, 'dropout_rate_ae': 0.3545562633672992, 'hidden_dim_mlp': 55, 'lr_mlp': 0.0011473747150785119, 'epochs_mlp': 16, 'dropout_rate_mlp': 0.16820656175338683}. Best is trial 1 with value: 0.5505712752089563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:20:15,846] Trial 5 finished with value: 0.500901004524193 and parameters: {'num_layers': 2, 'latent_dim_0': 1252, 'latent_dim_1': 718, 'lr_ae': 0.005222274211879952, 'epochs_ae': 33, 'dropout_rate_ae': 0.19916940962373186, 'hidden_dim_mlp': 66, 'lr_mlp': 0.00031921866229031994, 'epochs_mlp': 32, 'dropout_rate_mlp': 0.3863502059895596}. Best is trial 1 with value: 0.5505712752089563.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:22:22,398] Trial 6 finished with value: 0.5554980446284793 and parameters: {'num_layers': 2, 'latent_dim_0': 825, 'latent_dim_1': 566, 'lr_ae': 0.0009161217123062364, 'epochs_ae': 24, 'dropout_rate_ae': 0.3901979034513061, 'hidden_dim_mlp': 115, 'lr_mlp': 0.003328744510612717, 'epochs_mlp': 16, 'dropout_rate_mlp': 0.4369485188121832}. Best is trial 6 with value: 0.5554980446284793.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:27:39,943] Trial 7 finished with value: 0.5150486925849245 and parameters: {'num_layers': 2, 'latent_dim_0': 1415, 'latent_dim_1': 457, 'lr_ae': 0.0017675901985484365, 'epochs_ae': 31, 'dropout_rate_ae': 0.14994850709238663, 'hidden_dim_mlp': 57, 'lr_mlp': 0.0012302387725722822, 'epochs_mlp': 22, 'dropout_rate_mlp': 0.4825884719576624}. Best is trial 6 with value: 0.5554980446284793.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:29:27,466] Trial 8 finished with value: 0.5146844567134422 and parameters: {'num_layers': 2, 'latent_dim_0': 1422, 'latent_dim_1': 623, 'lr_ae': 0.0018971738688327198, 'epochs_ae': 15, 'dropout_rate_ae': 0.2420184984790168, 'hidden_dim_mlp': 107, 'lr_mlp': 0.0003944840457891749, 'epochs_mlp': 45, 'dropout_rate_mlp': 0.46757789487121215}. Best is trial 6 with value: 0.5554980446284793.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:32:10,060] Trial 9 finished with value: 0.5075147611379496 and parameters: {'num_layers': 2, 'latent_dim_0': 1132, 'latent_dim_1': 709, 'lr_ae': 0.00042022665487064756, 'epochs_ae': 29, 'dropout_rate_ae': 0.44332987808435587, 'hidden_dim_mlp': 77, 'lr_mlp': 0.007954418151880274, 'epochs_mlp': 34, 'dropout_rate_mlp': 0.22803958979241826}. Best is trial 6 with value: 0.5554980446284793.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:34:01,982] Trial 10 finished with value: 0.5718311479181043 and parameters: {'num_layers': 2, 'latent_dim_0': 836, 'latent_dim_1': 795, 'lr_ae': 0.007336511470532532, 'epochs_ae': 23, 'dropout_rate_ae': 0.3901666806434842, 'hidden_dim_mlp': 125, 'lr_mlp': 0.002960288710782165, 'epochs_mlp': 43, 'dropout_rate_mlp': 0.4117435428660553}. Best is trial 10 with value: 0.5718311479181043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:37:36,895] Trial 11 finished with value: 0.552910052910053 and parameters: {'num_layers': 2, 'latent_dim_0': 813, 'latent_dim_1': 792, 'lr_ae': 0.005678541912359571, 'epochs_ae': 50, 'dropout_rate_ae': 0.3949147263237404, 'hidden_dim_mlp': 127, 'lr_mlp': 0.0028547962445481757, 'epochs_mlp': 48, 'dropout_rate_mlp': 0.4168760488704119}. Best is trial 10 with value: 0.5718311479181043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:39:17,149] Trial 12 finished with value: 0.48115558622805005 and parameters: {'num_layers': 2, 'latent_dim_0': 830, 'latent_dim_1': 533, 'lr_ae': 0.00044277676582598263, 'epochs_ae': 23, 'dropout_rate_ae': 0.408636312643835, 'hidden_dim_mlp': 108, 'lr_mlp': 0.0026852299609852887, 'epochs_mlp': 39, 'dropout_rate_mlp': 0.424681757222366}. Best is trial 10 with value: 0.5718311479181043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:41:04,934] Trial 13 finished with value: 0.5319185645272602 and parameters: {'num_layers': 2, 'latent_dim_0': 913, 'latent_dim_1': 665, 'lr_ae': 0.007640590675563033, 'epochs_ae': 22, 'dropout_rate_ae': 0.2720940222969141, 'hidden_dim_mlp': 128, 'lr_mlp': 0.0025336368419925444, 'epochs_mlp': 42, 'dropout_rate_mlp': 0.4991376628011812}. Best is trial 10 with value: 0.5718311479181043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:43:46,606] Trial 14 finished with value: 0.5222567287784678 and parameters: {'num_layers': 2, 'latent_dim_0': 1070, 'latent_dim_1': 553, 'lr_ae': 0.00365863924774026, 'epochs_ae': 27, 'dropout_rate_ae': 0.36653744781246295, 'hidden_dim_mlp': 106, 'lr_mlp': 0.005629180009150717, 'epochs_mlp': 24, 'dropout_rate_mlp': 0.3690645310203517}. Best is trial 10 with value: 0.5718311479181043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:46:05,303] Trial 15 finished with value: 0.5299248523886204 and parameters: {'num_layers': 2, 'latent_dim_0': 1281, 'latent_dim_1': 785, 'lr_ae': 0.0004703294715200978, 'epochs_ae': 18, 'dropout_rate_ae': 0.481711062861542, 'hidden_dim_mlp': 96, 'lr_mlp': 0.002257924304803249, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.4293501974413128}. Best is trial 10 with value: 0.5718311479181043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:48:36,136] Trial 16 finished with value: 0.5452610996089257 and parameters: {'num_layers': 2, 'latent_dim_0': 861, 'latent_dim_1': 668, 'lr_ae': 0.00017106043290726947, 'epochs_ae': 36, 'dropout_rate_ae': 0.30828482798838974, 'hidden_dim_mlp': 118, 'lr_mlp': 0.004421578944468295, 'epochs_mlp': 39, 'dropout_rate_mlp': 0.131358605034326}. Best is trial 10 with value: 0.5718311479181043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:50:44,883] Trial 17 finished with value: 0.5186527106816962 and parameters: {'num_layers': 2, 'latent_dim_0': 1054, 'latent_dim_1': 570, 'lr_ae': 0.0034541373696113584, 'epochs_ae': 26, 'dropout_rate_ae': 0.4229837229231662, 'hidden_dim_mlp': 94, 'lr_mlp': 0.009050063010386805, 'epochs_mlp': 28, 'dropout_rate_mlp': 0.2682401274710957}. Best is trial 10 with value: 0.5718311479181043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:51:39,902] Trial 18 finished with value: 0.4998945633003604 and parameters: {'num_layers': 2, 'latent_dim_0': 891, 'latent_dim_1': 747, 'lr_ae': 0.00025970463598278757, 'epochs_ae': 11, 'dropout_rate_ae': 0.36702922354948153, 'hidden_dim_mlp': 117, 'lr_mlp': 0.001567699859321909, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.44672230040824407}. Best is trial 10 with value: 0.5718311479181043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 01:53:12,861] Trial 19 finished with value: 0.5508204892262863 and parameters: {'num_layers': 2, 'latent_dim_0': 1015, 'latent_dim_1': 493, 'lr_ae': 0.009544342475897671, 'epochs_ae': 19, 'dropout_rate_ae': 0.25493620758776503, 'hidden_dim_mlp': 99, 'lr_mlp': 0.0038896729676565172, 'epochs_mlp': 36, 'dropout_rate_mlp': 0.38482280902658794}. Best is trial 10 with value: 0.5718311479181043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.5127\n"
     ]
    }
   ],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(SimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "        \n",
    "        return reconstructions, latents\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "def train_stacked_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    \n",
    "    # Обучаем каждый автоэнкодер последовательно\n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, latent)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, _ in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent = ae(batch_x)\n",
    "                loss = criterion(reconstructed, batch_x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры MLP\n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate_ae)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(latent_dims[-1], hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate_ae'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "mlp = MLP(latent_dims[-1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4752\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4647\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5471\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5304\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4775\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5590\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6170\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5519\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5099\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5404\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5958\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5583\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5112\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5772\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5290\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5259\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5221\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5260\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5494\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5456\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5078\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5251\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4918\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5513\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5026\n",
      "среднее 0.5316871345696963\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(latent_dims[-1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь блок с stacked автоэнкодером. Но у каждого из автоэнкодеров была дополнительная классифицирующая голова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "логистическая рергрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:06:13,378] A new study created in memory with name: no-name-b4ef5c6e-67cd-4f9d-8921-afedc341c290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:09:58,830] Trial 0 finished with value: 0.4976037113718273 and parameters: {'num_layers': 2, 'latent_dim_0': 857, 'latent_dim_1': 663, 'lr': 0.0009656770157769237, 'epochs': 50, 'dropout_rate': 0.19298674178676528, 'class_weight_0': 0.8050434836278758, 'class_weight_1': 0.43750010217057667, 'C': 0.018793692910880882, 'solver': 'saga'}. Best is trial 0 with value: 0.4976037113718273.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:12:22,116] Trial 1 finished with value: 0.5169848937964879 and parameters: {'num_layers': 2, 'latent_dim_0': 1447, 'latent_dim_1': 485, 'lr': 0.00028362131249732117, 'epochs': 19, 'dropout_rate': 0.4295899040309634, 'class_weight_0': 0.4074144001682858, 'class_weight_1': 0.290343769481767, 'C': 0.1380123284821472, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.5169848937964879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:18:46,673] Trial 2 finished with value: 0.5111762901617974 and parameters: {'num_layers': 2, 'latent_dim_0': 1591, 'latent_dim_1': 714, 'lr': 0.00018639981636713203, 'epochs': 43, 'dropout_rate': 0.19674594247812732, 'class_weight_0': 0.4702819627359185, 'class_weight_1': 0.850303546711065, 'C': 1.0984941860029067, 'solver': 'saga'}. Best is trial 1 with value: 0.5169848937964879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:21:25,167] Trial 3 finished with value: 0.5162564220535235 and parameters: {'num_layers': 2, 'latent_dim_0': 1529, 'latent_dim_1': 482, 'lr': 0.00010685262213057167, 'epochs': 20, 'dropout_rate': 0.3964047440511226, 'class_weight_0': 0.6322246532656747, 'class_weight_1': 0.3015334724942534, 'C': 0.25677314229047427, 'solver': 'liblinear'}. Best is trial 1 with value: 0.5169848937964879.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:24:54,708] Trial 4 finished with value: 0.5190169465531784 and parameters: {'num_layers': 2, 'latent_dim_0': 1232, 'latent_dim_1': 790, 'lr': 0.0016218416952139122, 'epochs': 29, 'dropout_rate': 0.41654781556872444, 'class_weight_0': 0.6902631947781759, 'class_weight_1': 0.15926149344151216, 'C': 11.907990302508912, 'solver': 'saga'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:27:46,557] Trial 5 finished with value: 0.5010064412238325 and parameters: {'num_layers': 2, 'latent_dim_0': 1520, 'latent_dim_1': 527, 'lr': 0.0016451974737394918, 'epochs': 21, 'dropout_rate': 0.287574614296231, 'class_weight_0': 0.8393653600308871, 'class_weight_1': 0.2919589837309774, 'C': 16.015101834244234, 'solver': 'saga'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:30:27,663] Trial 6 finished with value: 0.4979391917797715 and parameters: {'num_layers': 2, 'latent_dim_0': 967, 'latent_dim_1': 618, 'lr': 0.009850089944185562, 'epochs': 30, 'dropout_rate': 0.28619409436368654, 'class_weight_0': 0.2212304781045954, 'class_weight_1': 0.5819424776885103, 'C': 1.6834694270340789, 'solver': 'saga'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:34:17,134] Trial 7 finished with value: 0.503623188405797 and parameters: {'num_layers': 2, 'latent_dim_0': 996, 'latent_dim_1': 423, 'lr': 0.004562966902793924, 'epochs': 46, 'dropout_rate': 0.4391761775691454, 'class_weight_0': 0.38791539325450763, 'class_weight_1': 0.39434783651775596, 'C': 4.365703870746684, 'solver': 'saga'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:36:55,973] Trial 8 finished with value: 0.5110996089256958 and parameters: {'num_layers': 2, 'latent_dim_0': 833, 'latent_dim_1': 725, 'lr': 0.002151288479439577, 'epochs': 36, 'dropout_rate': 0.4973623077393188, 'class_weight_0': 0.2550538876770124, 'class_weight_1': 0.2879001083694236, 'C': 82.77150751954596, 'solver': 'liblinear'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:38:41,161] Trial 9 finished with value: 0.5102752856376044 and parameters: {'num_layers': 2, 'latent_dim_0': 871, 'latent_dim_1': 561, 'lr': 0.00018712489044302947, 'epochs': 21, 'dropout_rate': 0.43680287878247115, 'class_weight_0': 0.15244261614758603, 'class_weight_1': 0.3615491280292631, 'C': 0.04565766336818743, 'solver': 'saga'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:39:50,449] Trial 10 finished with value: 0.5161605705083966 and parameters: {'num_layers': 2, 'latent_dim_0': 1284, 'latent_dim_1': 798, 'lr': 0.0005650073577910653, 'epochs': 10, 'dropout_rate': 0.35859896657408147, 'class_weight_0': 0.6505567011903406, 'class_weight_1': 0.10608445787627419, 'C': 81.83647646694334, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:42:48,079] Trial 11 finished with value: 0.5184034966643662 and parameters: {'num_layers': 2, 'latent_dim_0': 1302, 'latent_dim_1': 406, 'lr': 0.000497609000737307, 'epochs': 28, 'dropout_rate': 0.34493548077318775, 'class_weight_0': 0.6030261160495917, 'class_weight_1': 0.10180120023737613, 'C': 0.16872082174115696, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:45:50,118] Trial 12 finished with value: 0.5109079058354421 and parameters: {'num_layers': 2, 'latent_dim_0': 1234, 'latent_dim_1': 402, 'lr': 0.000570670271432442, 'epochs': 31, 'dropout_rate': 0.347738967984767, 'class_weight_0': 0.6597425027166682, 'class_weight_1': 0.1418721839679414, 'C': 8.956413160658425, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:49:22,531] Trial 13 finished with value: 0.5106970324361629 and parameters: {'num_layers': 2, 'latent_dim_0': 1365, 'latent_dim_1': 802, 'lr': 0.0026470984355374014, 'epochs': 29, 'dropout_rate': 0.12327640602628681, 'class_weight_0': 0.5722476166075816, 'class_weight_1': 0.5905768869731762, 'C': 0.17269372047246603, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:52:49,260] Trial 14 finished with value: 0.5075531017560003 and parameters: {'num_layers': 2, 'latent_dim_0': 1125, 'latent_dim_1': 634, 'lr': 0.0008318009752157219, 'epochs': 35, 'dropout_rate': 0.327646390804128, 'class_weight_0': 0.7358335781749249, 'class_weight_1': 0.16892833700344834, 'C': 0.4638321501424325, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 02:55:28,109] Trial 15 finished with value: 0.5109462464534927 and parameters: {'num_layers': 2, 'latent_dim_0': 1120, 'latent_dim_1': 720, 'lr': 0.0003923139559214506, 'epochs': 26, 'dropout_rate': 0.24201479127097691, 'class_weight_0': 0.5324369381340187, 'class_weight_1': 0.1928621328948788, 'C': 24.93921790511196, 'solver': 'liblinear'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 03:00:01,264] Trial 16 finished with value: 0.517636684303351 and parameters: {'num_layers': 2, 'latent_dim_0': 1346, 'latent_dim_1': 557, 'lr': 0.001448466191186474, 'epochs': 36, 'dropout_rate': 0.38963577587329584, 'class_weight_0': 0.8820255673633427, 'class_weight_1': 0.8131238884180263, 'C': 1.849935601362343, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 03:01:33,387] Trial 17 finished with value: 0.5109462464534928 and parameters: {'num_layers': 2, 'latent_dim_0': 1123, 'latent_dim_1': 461, 'lr': 0.003480779218943916, 'epochs': 13, 'dropout_rate': 0.4893421244484848, 'class_weight_0': 0.74892112296779, 'class_weight_1': 0.6979654531272161, 'C': 0.06985481635819468, 'solver': 'saga'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 03:04:16,316] Trial 18 finished with value: 0.5152595659842036 and parameters: {'num_layers': 2, 'latent_dim_0': 1204, 'latent_dim_1': 671, 'lr': 0.006596216166448856, 'epochs': 25, 'dropout_rate': 0.38801091835015167, 'class_weight_0': 0.7336275407362363, 'class_weight_1': 0.21245497321426524, 'C': 0.011933175401320346, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 03:06:08,438] Trial 19 finished with value: 0.5134000460087417 and parameters: {'num_layers': 2, 'latent_dim_0': 1406, 'latent_dim_1': 767, 'lr': 0.0011684510898864273, 'epochs': 15, 'dropout_rate': 0.3113838934402969, 'class_weight_0': 0.46688567099164713, 'class_weight_1': 0.47516876209332903, 'C': 3.806879699698929, 'solver': 'liblinear'}. Best is trial 4 with value: 0.5190169465531784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.5037\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingSimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(ClassifyingSimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(output_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "\n",
    "class ClassifyingStackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(ClassifyingStackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(ClassifyingSimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        classifications = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent, classification = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "            classifications.append(classification)\n",
    "        \n",
    "        return reconstructions, latents, classifications\n",
    "    \n",
    "def train_classifying_stacked_autoencoder(model, X_train, y_train, epochs, batch_size, lr, classification_weights):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        recon_criterion = nn.MSELoss()\n",
    "        class_criterion = nn.BCELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent, classification = ae(batch_x)\n",
    "                \n",
    "                recon_loss = recon_criterion(reconstructed, batch_x)\n",
    "                class_loss = class_criterion(classification, batch_y)\n",
    "                \n",
    "                recon_weight = 1.0 - classification_weights[i]\n",
    "                class_weight = classification_weights[i]\n",
    "                loss = recon_weight * recon_loss + class_weight * class_loss\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent, _ = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent, _ = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "# Восстанавливаем список весов классификации\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4930\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5116\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4963\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5144\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4959\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5870\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5707\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5493\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5596\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5624\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5848\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5587\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5695\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5508\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5834\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5375\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5604\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5523\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5648\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5651\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5476\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5586\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5450\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5505\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5668\n",
      "среднее 0.5494435507846078\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        # Восстанавливаем список весов классификации\n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 03:30:55,292] A new study created in memory with name: no-name-83a5b021-6663-4389-80de-15164c7c521c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 03:36:40,504] Trial 0 finished with value: 0.5141093474426808 and parameters: {'num_layers': 2, 'latent_dim_0': 1282, 'latent_dim_1': 543, 'lr': 0.004350688113361402, 'epochs': 17, 'dropout_rate': 0.23336621930516033, 'class_weight_0': 0.7637432629689394, 'class_weight_1': 0.49674819089577926, 'n_estimators': 285, 'max_depth': 5, 'learning_rate': 0.030683542545027996, 'subsample': 0.895494883212011, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.5141093474426808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 03:42:29,380] Trial 1 finished with value: 0.5083199141170156 and parameters: {'num_layers': 2, 'latent_dim_0': 1422, 'latent_dim_1': 621, 'lr': 0.0020349194198720525, 'epochs': 14, 'dropout_rate': 0.40991819832439813, 'class_weight_0': 0.17309990309613993, 'class_weight_1': 0.40977050217223954, 'n_estimators': 269, 'max_depth': 7, 'learning_rate': 0.09070603001710908, 'subsample': 0.7042703938635402, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.5141093474426808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 03:47:30,755] Trial 2 finished with value: 0.5088566827697263 and parameters: {'num_layers': 2, 'latent_dim_0': 835, 'latent_dim_1': 509, 'lr': 0.001016079830937301, 'epochs': 44, 'dropout_rate': 0.1063000681813353, 'class_weight_0': 0.6826276039410011, 'class_weight_1': 0.8974038107969159, 'n_estimators': 352, 'max_depth': 8, 'learning_rate': 0.22598264438281765, 'subsample': 0.8982567269751609, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.5141093474426808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 03:57:14,757] Trial 3 finished with value: 0.5194386933517369 and parameters: {'num_layers': 2, 'latent_dim_0': 1170, 'latent_dim_1': 449, 'lr': 0.001231437415162433, 'epochs': 44, 'dropout_rate': 0.20928633249262585, 'class_weight_0': 0.44585211495686017, 'class_weight_1': 0.40487706005621205, 'n_estimators': 325, 'max_depth': 7, 'learning_rate': 0.06799353632221689, 'subsample': 0.890495021366128, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.5194386933517369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 04:00:59,915] Trial 4 finished with value: 0.47710106586918183 and parameters: {'num_layers': 2, 'latent_dim_0': 1482, 'latent_dim_1': 640, 'lr': 0.007136155352312498, 'epochs': 21, 'dropout_rate': 0.4019803764170675, 'class_weight_0': 0.29065244294470005, 'class_weight_1': 0.7799453249834069, 'n_estimators': 173, 'max_depth': 4, 'learning_rate': 0.16549598700661575, 'subsample': 0.9717297933946774, 'min_samples_split': 19, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.5194386933517369.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 04:06:38,096] Trial 5 finished with value: 0.522314239705544 and parameters: {'num_layers': 2, 'latent_dim_0': 1316, 'latent_dim_1': 596, 'lr': 0.00041788178555806065, 'epochs': 33, 'dropout_rate': 0.18080549866509218, 'class_weight_0': 0.11493904306863066, 'class_weight_1': 0.29219181610070055, 'n_estimators': 143, 'max_depth': 6, 'learning_rate': 0.07920429838810238, 'subsample': 0.8683287695629174, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 04:13:39,578] Trial 6 finished with value: 0.4960988421133348 and parameters: {'num_layers': 2, 'latent_dim_0': 1592, 'latent_dim_1': 679, 'lr': 0.009513643733994756, 'epochs': 22, 'dropout_rate': 0.27332832281532965, 'class_weight_0': 0.12887426588956546, 'class_weight_1': 0.29634026474993314, 'n_estimators': 257, 'max_depth': 4, 'learning_rate': 0.039272822142513666, 'subsample': 0.847213895785791, 'min_samples_split': 19, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 04:25:41,012] Trial 7 finished with value: 0.5090100452419293 and parameters: {'num_layers': 2, 'latent_dim_0': 1421, 'latent_dim_1': 791, 'lr': 0.0003910696221377192, 'epochs': 24, 'dropout_rate': 0.40774102352088626, 'class_weight_0': 0.8193639105999687, 'class_weight_1': 0.41658664473943785, 'n_estimators': 486, 'max_depth': 5, 'learning_rate': 0.021402078514227228, 'subsample': 0.6668690514162836, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 04:29:51,376] Trial 8 finished with value: 0.4858331416302431 and parameters: {'num_layers': 2, 'latent_dim_0': 1186, 'latent_dim_1': 585, 'lr': 0.006646010540750613, 'epochs': 26, 'dropout_rate': 0.1447826356719921, 'class_weight_0': 0.7412948820782672, 'class_weight_1': 0.4307179605646033, 'n_estimators': 334, 'max_depth': 3, 'learning_rate': 0.10414118185739915, 'subsample': 0.6277533780713225, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 04:37:04,953] Trial 9 finished with value: 0.4993577946476497 and parameters: {'num_layers': 2, 'latent_dim_0': 1218, 'latent_dim_1': 776, 'lr': 0.0026590942801695636, 'epochs': 44, 'dropout_rate': 0.23133158340716764, 'class_weight_0': 0.58869394495585, 'class_weight_1': 0.5076453112237059, 'n_estimators': 256, 'max_depth': 9, 'learning_rate': 0.16173985851340075, 'subsample': 0.8128541229050036, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 04:41:32,051] Trial 10 finished with value: 0.5073422283567212 and parameters: {'num_layers': 2, 'latent_dim_0': 977, 'latent_dim_1': 438, 'lr': 0.00010103146611111837, 'epochs': 35, 'dropout_rate': 0.32940715167811785, 'class_weight_0': 0.3839964161114178, 'class_weight_1': 0.10332889866842265, 'n_estimators': 84, 'max_depth': 10, 'learning_rate': 0.046516430596195965, 'subsample': 0.763956579231308, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 04:46:08,482] Trial 11 finished with value: 0.5003354804079442 and parameters: {'num_layers': 2, 'latent_dim_0': 1105, 'latent_dim_1': 421, 'lr': 0.0004127628353441299, 'epochs': 35, 'dropout_rate': 0.1799754870478807, 'class_weight_0': 0.466905083497816, 'class_weight_1': 0.22921814302113191, 'n_estimators': 87, 'max_depth': 7, 'learning_rate': 0.01278471531477355, 'subsample': 0.9765494220882772, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 04:52:44,728] Trial 12 finished with value: 0.5037765508780002 and parameters: {'num_layers': 2, 'latent_dim_0': 1051, 'latent_dim_1': 481, 'lr': 0.00045905532938812245, 'epochs': 37, 'dropout_rate': 0.18806965162009034, 'class_weight_0': 0.27089599832401884, 'class_weight_1': 0.6551748794272705, 'n_estimators': 415, 'max_depth': 6, 'learning_rate': 0.08172099822124612, 'subsample': 0.9012939580083774, 'min_samples_split': 12, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:02:03,758] Trial 13 finished with value: 0.5146940418679549 and parameters: {'num_layers': 2, 'latent_dim_0': 1310, 'latent_dim_1': 712, 'lr': 0.0009221911015358337, 'epochs': 46, 'dropout_rate': 0.3307950543482383, 'class_weight_0': 0.5165673080327073, 'class_weight_1': 0.2726748967077157, 'n_estimators': 170, 'max_depth': 8, 'learning_rate': 0.06962909867848319, 'subsample': 0.7523550630151873, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:10:12,476] Trial 14 finished with value: 0.5016007208036193 and parameters: {'num_layers': 2, 'latent_dim_0': 1316, 'latent_dim_1': 561, 'lr': 0.00016855612218643772, 'epochs': 50, 'dropout_rate': 0.49589763320423763, 'class_weight_0': 0.3285498148205501, 'class_weight_1': 0.11157107781851322, 'n_estimators': 170, 'max_depth': 6, 'learning_rate': 0.12742016304071718, 'subsample': 0.8421541923888118, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:20:50,709] Trial 15 finished with value: 0.5220554405337013 and parameters: {'num_layers': 2, 'latent_dim_0': 940, 'latent_dim_1': 489, 'lr': 0.0009370662057253947, 'epochs': 31, 'dropout_rate': 0.10502057639363593, 'class_weight_0': 0.1902869173861904, 'class_weight_1': 0.6243386900268907, 'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.058737806745452516, 'subsample': 0.9419916025410308, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:34:02,839] Trial 16 finished with value: 0.5075051759834368 and parameters: {'num_layers': 2, 'latent_dim_0': 815, 'latent_dim_1': 512, 'lr': 0.0002498890509482724, 'epochs': 29, 'dropout_rate': 0.10092578018051654, 'class_weight_0': 0.20065735447948102, 'class_weight_1': 0.6253916379466362, 'n_estimators': 422, 'max_depth': 9, 'learning_rate': 0.023883346167910574, 'subsample': 0.9482867562028402, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:38:54,936] Trial 17 finished with value: 0.4998562226823096 and parameters: {'num_layers': 2, 'latent_dim_0': 944, 'latent_dim_1': 664, 'lr': 0.0006554288326910491, 'epochs': 31, 'dropout_rate': 0.14406917349183723, 'class_weight_0': 0.10199016577391037, 'class_weight_1': 0.6297266034850095, 'n_estimators': 481, 'max_depth': 8, 'learning_rate': 0.2988598790705034, 'subsample': 0.9235932703559655, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:46:40,478] Trial 18 finished with value: 0.47146499501571965 and parameters: {'num_layers': 2, 'latent_dim_0': 958, 'latent_dim_1': 592, 'lr': 0.0018630264842454014, 'epochs': 39, 'dropout_rate': 0.14507649027552777, 'class_weight_0': 0.22552679323392238, 'class_weight_1': 0.7273279642840222, 'n_estimators': 203, 'max_depth': 10, 'learning_rate': 0.050904622477654496, 'subsample': 0.9912475912335846, 'min_samples_split': 16, 'min_samples_leaf': 10}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:53:13,643] Trial 19 finished with value: 0.5134671420903304 and parameters: {'num_layers': 2, 'latent_dim_0': 1053, 'latent_dim_1': 484, 'lr': 0.00022253287034020963, 'epochs': 10, 'dropout_rate': 0.28465155168979867, 'class_weight_0': 0.3680156340787516, 'class_weight_1': 0.5699238210209501, 'n_estimators': 401, 'max_depth': 5, 'learning_rate': 0.01037056400513583, 'subsample': 0.8481149964827942, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.522314239705544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.5163\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4759\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4931\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4713\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4931\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4921\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5783\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5638\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5434\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5635\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5963\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5439\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6019\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5580\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5642\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5467\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5482\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5593\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5476\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5486\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5647\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5535\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5260\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5438\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5414\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5697\n",
      "среднее 0.5435356299538638\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 06:44:43,918] A new study created in memory with name: no-name-0a13459e-1229-4b8e-8adf-5473f9db52f7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 06:48:15,377] Trial 0 finished with value: 0.5102944559466299 and parameters: {'num_layers': 2, 'latent_dim_0': 832, 'latent_dim_1': 634, 'lr': 0.0036549769414722217, 'epochs': 39, 'dropout_rate': 0.24413231752374803, 'class_weight_0': 0.5719864759474848, 'class_weight_1': 0.8447396899695203, 'C': 4.934696182327823, 'kernel': 'linear'}. Best is trial 0 with value: 0.5102944559466299.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 06:50:38,294] Trial 1 finished with value: 0.4817498658078368 and parameters: {'num_layers': 2, 'latent_dim_0': 1191, 'latent_dim_1': 506, 'lr': 0.005136076491682201, 'epochs': 18, 'dropout_rate': 0.45175978047509946, 'class_weight_0': 0.40361718537377766, 'class_weight_1': 0.6747329555565331, 'C': 0.6466470846649719, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 0 with value: 0.5102944559466299.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 06:54:47,108] Trial 2 finished with value: 0.5112433862433862 and parameters: {'num_layers': 2, 'latent_dim_0': 919, 'latent_dim_1': 582, 'lr': 0.00154891744192145, 'epochs': 42, 'dropout_rate': 0.43328608844631133, 'class_weight_0': 0.7376434892832681, 'class_weight_1': 0.7459342183188832, 'C': 47.69322786097306, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.5112433862433862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 06:56:41,225] Trial 3 finished with value: 0.5250172532781229 and parameters: {'num_layers': 2, 'latent_dim_0': 1207, 'latent_dim_1': 419, 'lr': 0.0012524334980179692, 'epochs': 15, 'dropout_rate': 0.2746154600198396, 'class_weight_0': 0.44196246881128676, 'class_weight_1': 0.21129112208841117, 'C': 3.4076341645722863, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:00:18,150] Trial 4 finished with value: 0.5206560079748485 and parameters: {'num_layers': 2, 'latent_dim_0': 1282, 'latent_dim_1': 412, 'lr': 0.0036638541565813163, 'epochs': 27, 'dropout_rate': 0.21835023754686392, 'class_weight_0': 0.11773030056978318, 'class_weight_1': 0.8620184947133834, 'C': 9.959266634627877, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:03:34,805] Trial 5 finished with value: 0.5139368146614524 and parameters: {'num_layers': 2, 'latent_dim_0': 856, 'latent_dim_1': 734, 'lr': 0.0004595353356211473, 'epochs': 34, 'dropout_rate': 0.24544892792222883, 'class_weight_0': 0.8290340243165147, 'class_weight_1': 0.7431780635215247, 'C': 0.4371111380816844, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:07:00,761] Trial 6 finished with value: 0.49468982439996934 and parameters: {'num_layers': 2, 'latent_dim_0': 1451, 'latent_dim_1': 582, 'lr': 0.004571104346574381, 'epochs': 22, 'dropout_rate': 0.13955139452174214, 'class_weight_0': 0.4301222810892764, 'class_weight_1': 0.5869022883736594, 'C': 14.418055913338545, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:08:22,178] Trial 7 finished with value: 0.4999520742274364 and parameters: {'num_layers': 2, 'latent_dim_0': 1237, 'latent_dim_1': 432, 'lr': 0.0009361871656516093, 'epochs': 10, 'dropout_rate': 0.2865898280505364, 'class_weight_0': 0.3223385760436267, 'class_weight_1': 0.7374431716735917, 'C': 0.24084254783870784, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:09:58,124] Trial 8 finished with value: 0.5244133885438234 and parameters: {'num_layers': 2, 'latent_dim_0': 935, 'latent_dim_1': 642, 'lr': 0.0006623443479454818, 'epochs': 15, 'dropout_rate': 0.2271785768371927, 'class_weight_0': 0.6263386545426084, 'class_weight_1': 0.39202703118492355, 'C': 9.067724008595857, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:12:01,769] Trial 9 finished with value: 0.5203972088030059 and parameters: {'num_layers': 2, 'latent_dim_0': 840, 'latent_dim_1': 724, 'lr': 0.0007856297365001741, 'epochs': 22, 'dropout_rate': 0.2551209575636927, 'class_weight_0': 0.23807816030878026, 'class_weight_1': 0.3817519401193039, 'C': 1.9662733529404721, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:19:55,950] Trial 10 finished with value: 0.5053293459090561 and parameters: {'num_layers': 2, 'latent_dim_0': 1574, 'latent_dim_1': 517, 'lr': 0.00018256069808478105, 'epochs': 47, 'dropout_rate': 0.3794865330195935, 'class_weight_0': 0.5524153301493729, 'class_weight_1': 0.11194741319590136, 'C': 96.41435140990684, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:21:16,577] Trial 11 finished with value: 0.517540832758224 and parameters: {'num_layers': 2, 'latent_dim_0': 1064, 'latent_dim_1': 672, 'lr': 0.00027953948980782, 'epochs': 11, 'dropout_rate': 0.1500969797614693, 'class_weight_0': 0.6394328025131729, 'class_weight_1': 0.29587824512965455, 'C': 1.9750000065359974, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:23:19,940] Trial 12 finished with value: 0.5203013572578791 and parameters: {'num_layers': 2, 'latent_dim_0': 1083, 'latent_dim_1': 799, 'lr': 0.0018008416122965297, 'epochs': 16, 'dropout_rate': 0.34767310200975177, 'class_weight_0': 0.6935551432918927, 'class_weight_1': 0.23515672555875688, 'C': 15.526815088402948, 'kernel': 'linear'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:26:30,480] Trial 13 finished with value: 0.5212407024001227 and parameters: {'num_layers': 2, 'latent_dim_0': 1023, 'latent_dim_1': 498, 'lr': 0.0004962092035389119, 'epochs': 29, 'dropout_rate': 0.19170146521921602, 'class_weight_0': 0.8816325457724532, 'class_weight_1': 0.452882553123785, 'C': 4.018513831726155, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:28:58,131] Trial 14 finished with value: 0.51884441377195 and parameters: {'num_layers': 2, 'latent_dim_0': 1357, 'latent_dim_1': 631, 'lr': 0.00012229295311097925, 'epochs': 16, 'dropout_rate': 0.3267738043594478, 'class_weight_0': 0.476048460413499, 'class_weight_1': 0.15343572620498108, 'C': 1.2059035262179654, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:31:56,919] Trial 15 finished with value: 0.5034889962426194 and parameters: {'num_layers': 2, 'latent_dim_0': 1147, 'latent_dim_1': 544, 'lr': 0.0020147675674625203, 'epochs': 24, 'dropout_rate': 0.2937185191653995, 'class_weight_0': 0.2746825881102543, 'class_weight_1': 0.3290933804851312, 'C': 28.39393099491107, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:33:24,199] Trial 16 finished with value: 0.5150678628939498 and parameters: {'num_layers': 2, 'latent_dim_0': 983, 'latent_dim_1': 469, 'lr': 0.00884725641931308, 'epochs': 14, 'dropout_rate': 0.17767251311107746, 'class_weight_0': 0.6025348079469252, 'class_weight_1': 0.471334039091912, 'C': 0.1202339035103758, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:38:21,461] Trial 17 finished with value: 0.5129016179740817 and parameters: {'num_layers': 2, 'latent_dim_0': 1335, 'latent_dim_1': 695, 'lr': 0.0005439594822001793, 'epochs': 34, 'dropout_rate': 0.3912814317150689, 'class_weight_0': 0.7351461127347481, 'class_weight_1': 0.2177522360387268, 'C': 4.469631875448458, 'kernel': 'linear'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:40:50,791] Trial 18 finished with value: 0.5148282340311325 and parameters: {'num_layers': 2, 'latent_dim_0': 1134, 'latent_dim_1': 616, 'lr': 0.0002859924031172113, 'epochs': 19, 'dropout_rate': 0.10555428982597864, 'class_weight_0': 0.38135691208608347, 'class_weight_1': 0.5651521169052747, 'C': 7.5605902810801195, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:42:11,752] Trial 19 finished with value: 0.5098151982209953 and parameters: {'num_layers': 2, 'latent_dim_0': 949, 'latent_dim_1': 773, 'lr': 0.001231384393780008, 'epochs': 13, 'dropout_rate': 0.4864811860050712, 'class_weight_0': 0.4856015330926263, 'class_weight_1': 0.3661132887917369, 'C': 23.083082991840946, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 3 with value: 0.5250172532781229.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.4913\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4883\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4922\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4925\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4970\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5068\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5489\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5756\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5414\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5580\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5462\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5654\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5821\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5984\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5719\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5648\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5655\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5293\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5784\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5371\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5471\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5696\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5423\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5754\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5619\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5576\n",
      "среднее 0.5477535675812156\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:55:40,335] A new study created in memory with name: no-name-337ef968-c0e6-4853-a11f-9e258cffaca3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:59:32,670] Trial 0 finished with value: 0.500277969480868 and parameters: {'num_layers': 2, 'latent_dim_0': 1582, 'latent_dim_1': 434, 'lr': 0.008221528842394849, 'epochs': 24, 'dropout_rate': 0.46253774390512614, 'class_weight_0': 0.14085922063067502, 'class_weight_1': 0.24267831712970234}. Best is trial 0 with value: 0.500277969480868.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:03:40,556] Trial 1 finished with value: 0.510601180891036 and parameters: {'num_layers': 2, 'latent_dim_0': 1251, 'latent_dim_1': 629, 'lr': 0.00015499199142327938, 'epochs': 30, 'dropout_rate': 0.30824419263230163, 'class_weight_0': 0.6895874985598992, 'class_weight_1': 0.46188030271443203}. Best is trial 1 with value: 0.510601180891036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:09:09,205] Trial 2 finished with value: 0.5128441070470057 and parameters: {'num_layers': 2, 'latent_dim_0': 1507, 'latent_dim_1': 623, 'lr': 0.00025887250917271104, 'epochs': 33, 'dropout_rate': 0.4570265652807425, 'class_weight_0': 0.7477444938230577, 'class_weight_1': 0.14382935060264135}. Best is trial 2 with value: 0.5128441070470057.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:12:00,400] Trial 3 finished with value: 0.5089525343148531 and parameters: {'num_layers': 2, 'latent_dim_0': 817, 'latent_dim_1': 752, 'lr': 0.0005397911944836805, 'epochs': 31, 'dropout_rate': 0.2029887591655377, 'class_weight_0': 0.4840747459882433, 'class_weight_1': 0.6449778276155632}. Best is trial 2 with value: 0.5128441070470057.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:15:55,947] Trial 4 finished with value: 0.5099110497661222 and parameters: {'num_layers': 2, 'latent_dim_0': 985, 'latent_dim_1': 580, 'lr': 0.0021687779840987575, 'epochs': 37, 'dropout_rate': 0.16926780760660837, 'class_weight_0': 0.10333531595585575, 'class_weight_1': 0.884445711526354}. Best is trial 2 with value: 0.5128441070470057.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:17:28,159] Trial 5 finished with value: 0.5139847404340158 and parameters: {'num_layers': 2, 'latent_dim_0': 1483, 'latent_dim_1': 435, 'lr': 0.000461837146960408, 'epochs': 10, 'dropout_rate': 0.38456199056716045, 'class_weight_0': 0.7473968982529292, 'class_weight_1': 0.883749566988194}. Best is trial 5 with value: 0.5139847404340158.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:20:50,823] Trial 6 finished with value: 0.5177421210029906 and parameters: {'num_layers': 2, 'latent_dim_0': 1529, 'latent_dim_1': 667, 'lr': 0.0020938442277341506, 'epochs': 20, 'dropout_rate': 0.2836857945979573, 'class_weight_0': 0.18221843485673858, 'class_weight_1': 0.7501168030388421}. Best is trial 6 with value: 0.5177421210029906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:22:34,943] Trial 7 finished with value: 0.5159496971091174 and parameters: {'num_layers': 2, 'latent_dim_0': 1263, 'latent_dim_1': 671, 'lr': 0.0001485856805496259, 'epochs': 12, 'dropout_rate': 0.2848583746215293, 'class_weight_0': 0.21872176788039896, 'class_weight_1': 0.29964192402016887}. Best is trial 6 with value: 0.5177421210029906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:24:50,622] Trial 8 finished with value: 0.5105628402729852 and parameters: {'num_layers': 2, 'latent_dim_0': 1330, 'latent_dim_1': 760, 'lr': 0.0019924703984701966, 'epochs': 15, 'dropout_rate': 0.2853941981899619, 'class_weight_0': 0.8976962884645426, 'class_weight_1': 0.44500800387436423}. Best is trial 6 with value: 0.5177421210029906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:28:20,766] Trial 9 finished with value: 0.5085882984433708 and parameters: {'num_layers': 2, 'latent_dim_0': 1095, 'latent_dim_1': 583, 'lr': 0.0002695795697084062, 'epochs': 29, 'dropout_rate': 0.13782849414304865, 'class_weight_0': 0.5140550136132086, 'class_weight_1': 0.24353402298888105}. Best is trial 6 with value: 0.5177421210029906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:35:34,625] Trial 10 finished with value: 0.5076777087646652 and parameters: {'num_layers': 2, 'latent_dim_0': 1396, 'latent_dim_1': 511, 'lr': 0.005532851430577447, 'epochs': 50, 'dropout_rate': 0.36765795494462683, 'class_weight_0': 0.33235233561878963, 'class_weight_1': 0.6914025735507179}. Best is trial 6 with value: 0.5177421210029906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:38:00,637] Trial 11 finished with value: 0.5118568361321985 and parameters: {'num_layers': 2, 'latent_dim_0': 1148, 'latent_dim_1': 711, 'lr': 0.0014150411519796712, 'epochs': 19, 'dropout_rate': 0.2470278707112099, 'class_weight_0': 0.293870137203015, 'class_weight_1': 0.6209878819992211}. Best is trial 6 with value: 0.5177421210029906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:39:29,568] Trial 12 finished with value: 0.5014761137949544 and parameters: {'num_layers': 2, 'latent_dim_0': 1354, 'latent_dim_1': 694, 'lr': 0.00010025330609285457, 'epochs': 10, 'dropout_rate': 0.34055255425847186, 'class_weight_0': 0.2578099394695519, 'class_weight_1': 0.3479767296101605}. Best is trial 6 with value: 0.5177421210029906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:41:37,250] Trial 13 finished with value: 0.5152020550571276 and parameters: {'num_layers': 2, 'latent_dim_0': 1032, 'latent_dim_1': 670, 'lr': 0.0008922868435524754, 'epochs': 19, 'dropout_rate': 0.24749708833211842, 'class_weight_0': 0.4126516125184723, 'class_weight_1': 0.7413641664637516}. Best is trial 6 with value: 0.5177421210029906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:43:58,357] Trial 14 finished with value: 0.5101410934744268 and parameters: {'num_layers': 2, 'latent_dim_0': 1215, 'latent_dim_1': 793, 'lr': 0.004489961278349996, 'epochs': 17, 'dropout_rate': 0.24708009537686054, 'class_weight_0': 0.2040819062260043, 'class_weight_1': 0.5408428094042572}. Best is trial 6 with value: 0.5177421210029906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:48:04,269] Trial 15 finished with value: 0.5069396518671881 and parameters: {'num_layers': 2, 'latent_dim_0': 1605, 'latent_dim_1': 544, 'lr': 0.0029361315026601004, 'epochs': 24, 'dropout_rate': 0.4059055801916994, 'class_weight_0': 0.41965120805805217, 'class_weight_1': 0.30549610994187915}. Best is trial 6 with value: 0.5177421210029906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:50:13,791] Trial 16 finished with value: 0.514224369296833 and parameters: {'num_layers': 2, 'latent_dim_0': 1426, 'latent_dim_1': 664, 'lr': 0.0007288969169789927, 'epochs': 14, 'dropout_rate': 0.30725856039748634, 'class_weight_0': 0.1864536498134507, 'class_weight_1': 0.7598021237710723}. Best is trial 6 with value: 0.5177421210029906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:53:31,760] Trial 17 finished with value: 0.49705735756460384 and parameters: {'num_layers': 2, 'latent_dim_0': 1292, 'latent_dim_1': 731, 'lr': 0.0013520700237263418, 'epochs': 23, 'dropout_rate': 0.19086086626264565, 'class_weight_0': 0.34972514630034923, 'class_weight_1': 0.5641499532704176}. Best is trial 6 with value: 0.5177421210029906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:58:05,017] Trial 18 finished with value: 0.5195728855149145 and parameters: {'num_layers': 2, 'latent_dim_0': 865, 'latent_dim_1': 512, 'lr': 0.000308528357241638, 'epochs': 50, 'dropout_rate': 0.1058925396159757, 'class_weight_0': 0.5631353940720945, 'class_weight_1': 0.100839221510094}. Best is trial 18 with value: 0.5195728855149145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:02:11,559] Trial 19 finished with value: 0.5060578176520205 and parameters: {'num_layers': 2, 'latent_dim_0': 825, 'latent_dim_1': 512, 'lr': 0.0003923055696072688, 'epochs': 48, 'dropout_rate': 0.13172729133914218, 'class_weight_0': 0.5872479750562078, 'class_weight_1': 0.7933035453474432}. Best is trial 18 with value: 0.5195728855149145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.5187\n"
     ]
    }
   ],
   "source": [
    "def get_classifier_predictions(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    latent = X_tensor\n",
    "    with torch.no_grad():\n",
    "        for i, ae in enumerate(model.autoencoders):\n",
    "            if i == len(model.autoencoders) - 1:\n",
    "                _, _, classification = ae(latent)\n",
    "                return classification.cpu().numpy().flatten()\n",
    "            else:\n",
    "                _, latent, _ = ae(latent)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        y_pred_proba = get_classifier_predictions(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "y_pred_proba = get_classifier_predictions(autoencoder, X_val_all)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4883\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4962\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4798\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4899\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4891\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5601\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5523\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5427\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5716\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5667\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5749\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5518\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5528\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5561\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5651\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5383\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5543\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5627\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5559\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5559\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5395\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5445\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5326\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5651\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5552\n",
      "среднее 0.5416584147827284\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        y_pred_proba = get_classifier_predictions(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше идет блок с denoising автоэнкодером"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:34:20,905] A new study created in memory with name: no-name-66a90a6d-59d6-40a1-81d3-4a91b8db6afe\n",
      "[I 2025-05-10 09:35:37,231] Trial 0 finished with value: 0.5688022390920942 and parameters: {'latent_dim': 67, 'hidden_dim': 223, 'lr': 0.0010951245778528767, 'epochs': 48, 'dropout_rate': 0.21879284834938717, 'noise_level': 0.10021623300028747, 'C': 0.22479931058773298, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5688022390920942.\n",
      "[I 2025-05-10 09:35:56,667] Trial 1 finished with value: 0.5589678705620735 and parameters: {'latent_dim': 94, 'hidden_dim': 250, 'lr': 0.002978663344092539, 'epochs': 11, 'dropout_rate': 0.4576640204686515, 'noise_level': 0.17887554465906186, 'C': 27.688578296917395, 'solver': 'liblinear'}. Best is trial 0 with value: 0.5688022390920942.\n",
      "[I 2025-05-10 09:36:20,540] Trial 2 finished with value: 0.5537152058891189 and parameters: {'latent_dim': 10, 'hidden_dim': 202, 'lr': 0.0001836662482007323, 'epochs': 16, 'dropout_rate': 0.12883191881840142, 'noise_level': 0.1260731774185639, 'C': 10.793926520674187, 'solver': 'saga'}. Best is trial 0 with value: 0.5688022390920942.\n",
      "[I 2025-05-10 09:36:56,474] Trial 3 finished with value: 0.5442450732305805 and parameters: {'latent_dim': 29, 'hidden_dim': 126, 'lr': 0.0030138909137144977, 'epochs': 31, 'dropout_rate': 0.3279052136475461, 'noise_level': 0.18229918376805326, 'C': 26.252018824899242, 'solver': 'saga'}. Best is trial 0 with value: 0.5688022390920942.\n",
      "[I 2025-05-10 09:37:32,506] Trial 4 finished with value: 0.5099302200751477 and parameters: {'latent_dim': 32, 'hidden_dim': 138, 'lr': 0.0006205177238031469, 'epochs': 29, 'dropout_rate': 0.22500877528830113, 'noise_level': 0.2609941143223164, 'C': 0.03925904084491369, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5688022390920942.\n",
      "[I 2025-05-10 09:38:03,188] Trial 5 finished with value: 0.5202438463308029 and parameters: {'latent_dim': 100, 'hidden_dim': 121, 'lr': 0.00025600606306771785, 'epochs': 26, 'dropout_rate': 0.25605766638617233, 'noise_level': 0.12519662291075911, 'C': 0.017955094137422276, 'solver': 'saga'}. Best is trial 0 with value: 0.5688022390920942.\n",
      "[I 2025-05-10 09:39:02,539] Trial 6 finished with value: 0.5883367839889578 and parameters: {'latent_dim': 96, 'hidden_dim': 220, 'lr': 0.008582816298837627, 'epochs': 37, 'dropout_rate': 0.39245944273586275, 'noise_level': 0.0802588384258064, 'C': 1.1806481682549101, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.5883367839889578.\n",
      "[I 2025-05-10 09:40:12,074] Trial 7 finished with value: 0.5581243769649566 and parameters: {'latent_dim': 16, 'hidden_dim': 241, 'lr': 0.0002792919402100788, 'epochs': 41, 'dropout_rate': 0.15027506056400153, 'noise_level': 0.20060152647578228, 'C': 0.7676521872822736, 'solver': 'liblinear'}. Best is trial 6 with value: 0.5883367839889578.\n",
      "[I 2025-05-10 09:40:37,480] Trial 8 finished with value: 0.5183843263553408 and parameters: {'latent_dim': 40, 'hidden_dim': 80, 'lr': 0.008557247485507324, 'epochs': 26, 'dropout_rate': 0.18283318028965928, 'noise_level': 0.18538700391184615, 'C': 0.06959276310797839, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.5883367839889578.\n",
      "[I 2025-05-10 09:41:02,525] Trial 9 finished with value: 0.49631930066712676 and parameters: {'latent_dim': 79, 'hidden_dim': 256, 'lr': 0.0004007202613216236, 'epochs': 12, 'dropout_rate': 0.35673183717331025, 'noise_level': 0.2248928165207172, 'C': 75.53566188776627, 'solver': 'saga'}. Best is trial 6 with value: 0.5883367839889578.\n",
      "[I 2025-05-10 09:41:58,144] Trial 10 finished with value: 0.5250939345142244 and parameters: {'latent_dim': 58, 'hidden_dim': 186, 'lr': 0.005684463687637198, 'epochs': 39, 'dropout_rate': 0.49111892240861615, 'noise_level': 0.0501241033485135, 'C': 3.1956557252142606, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.5883367839889578.\n",
      "[I 2025-05-10 09:43:15,345] Trial 11 finished with value: 0.5464496587684994 and parameters: {'latent_dim': 71, 'hidden_dim': 212, 'lr': 0.0014439804586173165, 'epochs': 50, 'dropout_rate': 0.39598569114633553, 'noise_level': 0.0508939415330434, 'C': 0.3496399103042238, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.5883367839889578.\n",
      "[I 2025-05-10 09:44:24,473] Trial 12 finished with value: 0.5349283030442451 and parameters: {'latent_dim': 79, 'hidden_dim': 176, 'lr': 0.00011242231185836302, 'epochs': 50, 'dropout_rate': 0.28426592126646777, 'noise_level': 0.1150744695168184, 'C': 0.23974868892178114, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.5883367839889578.\n",
      "[I 2025-05-10 09:45:31,513] Trial 13 finished with value: 0.5740932443830994 and parameters: {'latent_dim': 60, 'hidden_dim': 222, 'lr': 0.0013245932761836484, 'epochs': 41, 'dropout_rate': 0.3997275798284838, 'noise_level': 0.09057997156317887, 'C': 2.1213683295430332, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.5883367839889578.\n",
      "[I 2025-05-10 09:46:23,228] Trial 14 finished with value: 0.5693581780538303 and parameters: {'latent_dim': 50, 'hidden_dim': 154, 'lr': 0.002809188446516859, 'epochs': 39, 'dropout_rate': 0.4111672254326108, 'noise_level': 0.0838135531319174, 'C': 2.0037817787587917, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.5883367839889578.\n",
      "[I 2025-05-10 09:47:20,052] Trial 15 finished with value: 0.5638754696725711 and parameters: {'latent_dim': 90, 'hidden_dim': 230, 'lr': 0.00808337830653183, 'epochs': 34, 'dropout_rate': 0.4071073222545915, 'noise_level': 0.14647470616905864, 'C': 3.8029045780657267, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.5883367839889578.\n",
      "[I 2025-05-10 09:48:22,685] Trial 16 finished with value: 0.60426731078905 and parameters: {'latent_dim': 57, 'hidden_dim': 194, 'lr': 0.0017756972355648677, 'epochs': 43, 'dropout_rate': 0.35773872288965974, 'noise_level': 0.07475464519114713, 'C': 1.0035515571641236, 'solver': 'liblinear'}. Best is trial 16 with value: 0.60426731078905.\n",
      "[I 2025-05-10 09:49:29,251] Trial 17 finished with value: 0.5647956445057895 and parameters: {'latent_dim': 47, 'hidden_dim': 189, 'lr': 0.004382248238997918, 'epochs': 46, 'dropout_rate': 0.34692044944155975, 'noise_level': 0.29740038847219996, 'C': 0.5951873297487178, 'solver': 'liblinear'}. Best is trial 16 with value: 0.60426731078905.\n",
      "[I 2025-05-10 09:50:21,644] Trial 18 finished with value: 0.5508971704623878 and parameters: {'latent_dim': 82, 'hidden_dim': 165, 'lr': 0.0019422899464635111, 'epochs': 36, 'dropout_rate': 0.2910310401137972, 'noise_level': 0.07002282429197941, 'C': 0.10396848449493763, 'solver': 'liblinear'}. Best is trial 16 with value: 0.60426731078905.\n",
      "[I 2025-05-10 09:51:29,522] Trial 19 finished with value: 0.5253431485315543 and parameters: {'latent_dim': 68, 'hidden_dim': 200, 'lr': 0.0006872655044173526, 'epochs': 44, 'dropout_rate': 0.4514374492636117, 'noise_level': 0.15663149669003051, 'C': 7.771075124858142, 'solver': 'liblinear'}. Best is trial 16 with value: 0.60426731078905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5878\n"
     ]
    }
   ],
   "source": [
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "    \n",
    "def train_denoising_autoencoder(model, X_train, epochs, batch_size, lr, noise_level=0.1):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_target in train_loader:\n",
    "            # Add noise to input data\n",
    "            noisy_batch = batch_x + noise_level * torch.randn_like(batch_x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _ = model(noisy_batch)\n",
    "            # Target is the original data (not noisy)\n",
    "            loss = criterion(reconstructed, batch_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs, batch_size, lr, noise_level)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5139\n",
      "ROC-AUC autoencoded: 0.4736\n",
      "ROC-AUC autoencoded: 0.5043\n",
      "ROC-AUC autoencoded: 0.4601\n",
      "ROC-AUC autoencoded: 0.4561\n",
      "ROC-AUC autoencoded: 0.4864\n",
      "ROC-AUC autoencoded: 0.4773\n",
      "ROC-AUC autoencoded: 0.4191\n",
      "ROC-AUC autoencoded: 0.5034\n",
      "ROC-AUC autoencoded: 0.5553\n",
      "ROC-AUC autoencoded: 0.5900\n",
      "ROC-AUC autoencoded: 0.4793\n",
      "ROC-AUC autoencoded: 0.4830\n",
      "ROC-AUC autoencoded: 0.6223\n",
      "ROC-AUC autoencoded: 0.5860\n",
      "ROC-AUC autoencoded: 0.4793\n",
      "ROC-AUC autoencoded: 0.5448\n",
      "ROC-AUC autoencoded: 0.4527\n",
      "ROC-AUC autoencoded: 0.5876\n",
      "ROC-AUC autoencoded: 0.5407\n",
      "ROC-AUC autoencoded: 0.5301\n",
      "ROC-AUC autoencoded: 0.5237\n",
      "ROC-AUC autoencoded: 0.5518\n",
      "ROC-AUC autoencoded: 0.5261\n",
      "ROC-AUC autoencoded: 0.5159\n",
      "среднее 0.5145231713208342\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:58:54,228] A new study created in memory with name: no-name-d7a500ee-42f1-45d2-976c-654da19866d8\n",
      "[I 2025-05-10 09:59:57,266] Trial 0 finished with value: 0.4925044091710758 and parameters: {'latent_dim': 27, 'hidden_dim': 234, 'lr': 0.0005135644374093489, 'epochs': 31, 'dropout_rate': 0.23646504104697869, 'noise_level': 0.05947577075237785, 'n_estimators': 273, 'max_depth': 7, 'learning_rate': 0.09180432179633136, 'subsample': 0.7511576159352686, 'min_samples_split': 12, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.4925044091710758.\n",
      "[I 2025-05-10 10:01:06,598] Trial 1 finished with value: 0.5366536308565294 and parameters: {'latent_dim': 32, 'hidden_dim': 118, 'lr': 0.0003503683073574494, 'epochs': 41, 'dropout_rate': 0.28775747485715053, 'noise_level': 0.22955557626043022, 'n_estimators': 467, 'max_depth': 6, 'learning_rate': 0.24201778588058145, 'subsample': 0.7068495689738908, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.5366536308565294.\n",
      "[I 2025-05-10 10:02:15,508] Trial 2 finished with value: 0.5513380875699715 and parameters: {'latent_dim': 51, 'hidden_dim': 165, 'lr': 0.000281958550198355, 'epochs': 35, 'dropout_rate': 0.32064871526836625, 'noise_level': 0.18551204578399466, 'n_estimators': 337, 'max_depth': 4, 'learning_rate': 0.03983570025249144, 'subsample': 0.9044305573854605, 'min_samples_split': 16, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.5513380875699715.\n",
      "[I 2025-05-10 10:03:01,064] Trial 3 finished with value: 0.5045817038570661 and parameters: {'latent_dim': 16, 'hidden_dim': 189, 'lr': 0.00048668709014235096, 'epochs': 27, 'dropout_rate': 0.391508330159156, 'noise_level': 0.18467681327071528, 'n_estimators': 237, 'max_depth': 4, 'learning_rate': 0.22256769219248176, 'subsample': 0.8295412029906994, 'min_samples_split': 15, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.5513380875699715.\n",
      "[I 2025-05-10 10:04:46,801] Trial 4 finished with value: 0.519649566751016 and parameters: {'latent_dim': 80, 'hidden_dim': 246, 'lr': 0.0019161894920801217, 'epochs': 23, 'dropout_rate': 0.3403769099783098, 'noise_level': 0.12463987879357614, 'n_estimators': 254, 'max_depth': 10, 'learning_rate': 0.0785900514389475, 'subsample': 0.9472337554099982, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.5513380875699715.\n",
      "[I 2025-05-10 10:05:31,616] Trial 5 finished with value: 0.5013802622498275 and parameters: {'latent_dim': 92, 'hidden_dim': 69, 'lr': 0.0005061256667538146, 'epochs': 12, 'dropout_rate': 0.22841175638239047, 'noise_level': 0.29751415616739235, 'n_estimators': 252, 'max_depth': 5, 'learning_rate': 0.09004656018602435, 'subsample': 0.6906730336072319, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.5513380875699715.\n",
      "[I 2025-05-10 10:06:42,300] Trial 6 finished with value: 0.5021662449198682 and parameters: {'latent_dim': 82, 'hidden_dim': 165, 'lr': 0.00013496004514185526, 'epochs': 19, 'dropout_rate': 0.2509781039141719, 'noise_level': 0.22767944466306678, 'n_estimators': 422, 'max_depth': 3, 'learning_rate': 0.07361387043970691, 'subsample': 0.9939253071308076, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.5513380875699715.\n",
      "[I 2025-05-10 10:08:04,406] Trial 7 finished with value: 0.5206847634383865 and parameters: {'latent_dim': 68, 'hidden_dim': 252, 'lr': 0.00046310386288047077, 'epochs': 32, 'dropout_rate': 0.13449823785589296, 'noise_level': 0.09877827514349717, 'n_estimators': 271, 'max_depth': 5, 'learning_rate': 0.04873748158834702, 'subsample': 0.7184969062717155, 'min_samples_split': 19, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.5513380875699715.\n",
      "[I 2025-05-10 10:08:49,207] Trial 8 finished with value: 0.4912199984663754 and parameters: {'latent_dim': 47, 'hidden_dim': 173, 'lr': 0.0016659993990421782, 'epochs': 11, 'dropout_rate': 0.31785432058418156, 'noise_level': 0.17874699520416898, 'n_estimators': 336, 'max_depth': 8, 'learning_rate': 0.20823382395733062, 'subsample': 0.6511190201174923, 'min_samples_split': 15, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.5513380875699715.\n",
      "[I 2025-05-10 10:10:07,475] Trial 9 finished with value: 0.5394524959742352 and parameters: {'latent_dim': 98, 'hidden_dim': 192, 'lr': 0.006663534879319226, 'epochs': 18, 'dropout_rate': 0.3042846380451365, 'noise_level': 0.1380458176122108, 'n_estimators': 166, 'max_depth': 10, 'learning_rate': 0.013341389335728645, 'subsample': 0.9024610512202333, 'min_samples_split': 12, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.5513380875699715.\n",
      "[I 2025-05-10 10:11:06,934] Trial 10 finished with value: 0.5338931063568745 and parameters: {'latent_dim': 50, 'hidden_dim': 120, 'lr': 0.00013225356704624298, 'epochs': 49, 'dropout_rate': 0.49995225126650256, 'noise_level': 0.28422746772602475, 'n_estimators': 66, 'max_depth': 3, 'learning_rate': 0.02183307853893646, 'subsample': 0.8443302568468417, 'min_samples_split': 20, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.5513380875699715.\n",
      "[I 2025-05-10 10:12:49,111] Trial 11 finished with value: 0.5036615290238479 and parameters: {'latent_dim': 100, 'hidden_dim': 203, 'lr': 0.008665504347952836, 'epochs': 39, 'dropout_rate': 0.40328783845365934, 'noise_level': 0.13788326716372026, 'n_estimators': 142, 'max_depth': 10, 'learning_rate': 0.012655048389316938, 'subsample': 0.9001487515572729, 'min_samples_split': 16, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.5513380875699715.\n",
      "[I 2025-05-10 10:13:37,514] Trial 12 finished with value: 0.49447895100069017 and parameters: {'latent_dim': 63, 'hidden_dim': 129, 'lr': 0.009465319475944374, 'epochs': 18, 'dropout_rate': 0.16971661065091886, 'noise_level': 0.2155015383929152, 'n_estimators': 157, 'max_depth': 8, 'learning_rate': 0.028248635058711623, 'subsample': 0.892153073881678, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.5513380875699715.\n",
      "[I 2025-05-10 10:15:23,238] Trial 13 finished with value: 0.5089333640058277 and parameters: {'latent_dim': 41, 'hidden_dim': 211, 'lr': 0.004020579098344326, 'epochs': 39, 'dropout_rate': 0.3887037144569727, 'noise_level': 0.15123479643542737, 'n_estimators': 368, 'max_depth': 9, 'learning_rate': 0.012546999351459366, 'subsample': 0.894088785985643, 'min_samples_split': 17, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.5513380875699715.\n",
      "[I 2025-05-10 10:16:16,508] Trial 14 finished with value: 0.553216777854459 and parameters: {'latent_dim': 62, 'hidden_dim': 141, 'lr': 0.0011309602634257448, 'epochs': 26, 'dropout_rate': 0.4443018291002334, 'noise_level': 0.09454023970896128, 'n_estimators': 169, 'max_depth': 6, 'learning_rate': 0.0317236237806261, 'subsample': 0.7978103102509917, 'min_samples_split': 12, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.553216777854459.\n",
      "[I 2025-05-10 10:17:35,120] Trial 15 finished with value: 0.5527183498197991 and parameters: {'latent_dim': 62, 'hidden_dim': 141, 'lr': 0.0011511973906072053, 'epochs': 35, 'dropout_rate': 0.49565264238281487, 'noise_level': 0.07442277964843255, 'n_estimators': 343, 'max_depth': 5, 'learning_rate': 0.037674393338437015, 'subsample': 0.7667402665808366, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.553216777854459.\n",
      "[I 2025-05-10 10:18:17,304] Trial 16 finished with value: 0.512460700866498 and parameters: {'latent_dim': 66, 'hidden_dim': 137, 'lr': 0.0010742836945166379, 'epochs': 27, 'dropout_rate': 0.48003416198537163, 'noise_level': 0.05218954531149181, 'n_estimators': 74, 'max_depth': 6, 'learning_rate': 0.023677925355528647, 'subsample': 0.7743650312723696, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.553216777854459.\n",
      "[I 2025-05-10 10:19:31,457] Trial 17 finished with value: 0.5232919254658385 and parameters: {'latent_dim': 77, 'hidden_dim': 91, 'lr': 0.002686045959925073, 'epochs': 47, 'dropout_rate': 0.4463100237101755, 'noise_level': 0.09458507174673503, 'n_estimators': 208, 'max_depth': 7, 'learning_rate': 0.03640397276366646, 'subsample': 0.6107903362165588, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.553216777854459.\n",
      "[I 2025-05-10 10:20:59,689] Trial 18 finished with value: 0.5004025764895329 and parameters: {'latent_dim': 60, 'hidden_dim': 144, 'lr': 0.0009047769521713988, 'epochs': 44, 'dropout_rate': 0.44588277317060254, 'noise_level': 0.0910697479264571, 'n_estimators': 329, 'max_depth': 5, 'learning_rate': 0.15039417588229106, 'subsample': 0.7913662963337124, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.553216777854459.\n",
      "[I 2025-05-10 10:22:10,316] Trial 19 finished with value: 0.5283145464304885 and parameters: {'latent_dim': 40, 'hidden_dim': 98, 'lr': 0.0008770298334205156, 'epochs': 35, 'dropout_rate': 0.43498660587234456, 'noise_level': 0.07856778486619775, 'n_estimators': 396, 'max_depth': 6, 'learning_rate': 0.01734461941219964, 'subsample': 0.8285537319314155, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.553216777854459.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.4792\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs, batch_size, lr, noise_level)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5129\n",
      "ROC-AUC autoencoded: 0.4298\n",
      "ROC-AUC autoencoded: 0.5081\n",
      "ROC-AUC autoencoded: 0.5129\n",
      "ROC-AUC autoencoded: 0.5311\n",
      "ROC-AUC autoencoded: 0.4901\n",
      "ROC-AUC autoencoded: 0.4797\n",
      "ROC-AUC autoencoded: 0.4843\n",
      "ROC-AUC autoencoded: 0.4462\n",
      "ROC-AUC autoencoded: 0.4852\n",
      "ROC-AUC autoencoded: 0.4964\n",
      "ROC-AUC autoencoded: 0.4724\n",
      "ROC-AUC autoencoded: 0.4912\n",
      "ROC-AUC autoencoded: 0.4378\n",
      "ROC-AUC autoencoded: 0.5137\n",
      "ROC-AUC autoencoded: 0.5659\n",
      "ROC-AUC autoencoded: 0.5026\n",
      "ROC-AUC autoencoded: 0.4892\n",
      "ROC-AUC autoencoded: 0.5321\n",
      "ROC-AUC autoencoded: 0.5079\n",
      "ROC-AUC autoencoded: 0.5050\n",
      "ROC-AUC autoencoded: 0.5879\n",
      "ROC-AUC autoencoded: 0.4900\n",
      "ROC-AUC autoencoded: 0.4795\n",
      "ROC-AUC autoencoded: 0.4949\n",
      "среднее 0.49786777924894793\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:28:34,039] A new study created in memory with name: no-name-4ae0e5df-1b49-4264-8bee-8eb2be7079f2\n",
      "[I 2025-05-10 10:40:56,874] Trial 0 finished with value: 0.5318802239092094 and parameters: {'latent_dim': 38, 'hidden_dim': 214, 'lr': 0.009930569236523273, 'epochs': 22, 'dropout_rate': 0.19359989521328133, 'noise_level': 0.21113597906851772, 'C': 30.13049900501369, 'kernel': 'linear'}. Best is trial 0 with value: 0.5318802239092094.\n",
      "[I 2025-05-10 10:42:18,368] Trial 1 finished with value: 0.5201288244766505 and parameters: {'latent_dim': 19, 'hidden_dim': 245, 'lr': 0.004566098744827496, 'epochs': 49, 'dropout_rate': 0.11083195685041042, 'noise_level': 0.0929515672872779, 'C': 0.11612171023195093, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.5318802239092094.\n",
      "[I 2025-05-10 10:43:03,020] Trial 2 finished with value: 0.501763668430335 and parameters: {'latent_dim': 79, 'hidden_dim': 83, 'lr': 0.00018984319350135218, 'epochs': 45, 'dropout_rate': 0.46637332817234933, 'noise_level': 0.07891622867897889, 'C': 3.5643783948850714, 'kernel': 'linear'}. Best is trial 0 with value: 0.5318802239092094.\n",
      "[I 2025-05-10 10:43:36,666] Trial 3 finished with value: 0.5054060271451575 and parameters: {'latent_dim': 43, 'hidden_dim': 211, 'lr': 0.0001370211255779897, 'epochs': 22, 'dropout_rate': 0.39451446415303193, 'noise_level': 0.10469800425599345, 'C': 1.823711174117868, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.5318802239092094.\n",
      "[I 2025-05-10 10:44:25,201] Trial 4 finished with value: 0.5391649413388544 and parameters: {'latent_dim': 45, 'hidden_dim': 160, 'lr': 0.00011728318651636744, 'epochs': 39, 'dropout_rate': 0.2533719100080336, 'noise_level': 0.17649547141500999, 'C': 6.590755850863869, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 10:45:20,729] Trial 5 finished with value: 0.5208572962196151 and parameters: {'latent_dim': 88, 'hidden_dim': 197, 'lr': 0.00013215057684760325, 'epochs': 38, 'dropout_rate': 0.2046084860141566, 'noise_level': 0.1839308752693662, 'C': 0.8339889597623386, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 10:46:16,047] Trial 6 finished with value: 0.5122306571581934 and parameters: {'latent_dim': 66, 'hidden_dim': 133, 'lr': 0.0043417369414195045, 'epochs': 46, 'dropout_rate': 0.24928452226679565, 'noise_level': 0.13218568169996675, 'C': 0.28888894531672377, 'kernel': 'linear'}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 10:47:06,514] Trial 7 finished with value: 0.4715896020243846 and parameters: {'latent_dim': 12, 'hidden_dim': 252, 'lr': 0.001608111686964614, 'epochs': 30, 'dropout_rate': 0.29709478593344585, 'noise_level': 0.0706218155325908, 'C': 0.68200439279892, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 10:47:51,207] Trial 8 finished with value: 0.5030097385169848 and parameters: {'latent_dim': 52, 'hidden_dim': 222, 'lr': 0.00019754434278388823, 'epochs': 29, 'dropout_rate': 0.4915485727500485, 'noise_level': 0.23020190670290036, 'C': 3.408973084440517, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 10:48:15,011] Trial 9 finished with value: 0.478395061728395 and parameters: {'latent_dim': 97, 'hidden_dim': 189, 'lr': 0.0042257252251216475, 'epochs': 16, 'dropout_rate': 0.3204592477584865, 'noise_level': 0.2764635026136288, 'C': 0.21675160013772904, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 10:48:57,562] Trial 10 finished with value: 0.48399279196380646 and parameters: {'latent_dim': 29, 'hidden_dim': 139, 'lr': 0.0007286542180879766, 'epochs': 36, 'dropout_rate': 0.1005710961252157, 'noise_level': 0.14531550900062545, 'C': 22.916630594840665, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 11:03:19,438] Trial 11 finished with value: 0.5273368606701941 and parameters: {'latent_dim': 36, 'hidden_dim': 166, 'lr': 0.009462950477347137, 'epochs': 11, 'dropout_rate': 0.18868030999710603, 'noise_level': 0.20079265037535318, 'C': 72.26224221609696, 'kernel': 'linear'}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 11:03:55,514] Trial 12 finished with value: 0.5024537995552488 and parameters: {'latent_dim': 60, 'hidden_dim': 103, 'lr': 0.0007528857028611394, 'epochs': 22, 'dropout_rate': 0.18997583936845386, 'noise_level': 0.2379211650683154, 'C': 13.804446551201442, 'kernel': 'linear'}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 11:04:51,865] Trial 13 finished with value: 0.5032397822252895 and parameters: {'latent_dim': 49, 'hidden_dim': 179, 'lr': 0.00041156427532010597, 'epochs': 39, 'dropout_rate': 0.27956406780009113, 'noise_level': 0.29908411723602635, 'C': 12.99411565631393, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 11:05:24,664] Trial 14 finished with value: 0.5174449812130971 and parameters: {'latent_dim': 28, 'hidden_dim': 140, 'lr': 0.0021361106901197635, 'epochs': 25, 'dropout_rate': 0.3517499994547179, 'noise_level': 0.15002750814776178, 'C': 79.58864747550874, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 11:18:31,829] Trial 15 finished with value: 0.5245571658615137 and parameters: {'latent_dim': 71, 'hidden_dim': 227, 'lr': 0.00032060420653120885, 'epochs': 34, 'dropout_rate': 0.2264872725470452, 'noise_level': 0.22239060019139373, 'C': 28.575858064292486, 'kernel': 'linear'}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 11:18:56,239] Trial 16 finished with value: 0.5122498274672188 and parameters: {'latent_dim': 41, 'hidden_dim': 159, 'lr': 0.0016571326626726236, 'epochs': 17, 'dropout_rate': 0.15078842413528698, 'noise_level': 0.1722370311405144, 'C': 7.648953278265604, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 11:19:38,075] Trial 17 finished with value: 0.4740625718886588 and parameters: {'latent_dim': 29, 'hidden_dim': 66, 'lr': 0.008946178564876306, 'epochs': 42, 'dropout_rate': 0.2606583201375633, 'noise_level': 0.25732014605892717, 'C': 48.11844592807823, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 11:20:09,652] Trial 18 finished with value: 0.4702860210106587 and parameters: {'latent_dim': 56, 'hidden_dim': 112, 'lr': 0.00039842318408636845, 'epochs': 28, 'dropout_rate': 0.14927486469819856, 'noise_level': 0.1923565330233245, 'C': 6.7002843483303645, 'kernel': 'linear'}. Best is trial 4 with value: 0.5391649413388544.\n",
      "[I 2025-05-10 11:20:53,293] Trial 19 finished with value: 0.5061728395061729 and parameters: {'latent_dim': 19, 'hidden_dim': 163, 'lr': 0.0009946516121922897, 'epochs': 33, 'dropout_rate': 0.35126026931757737, 'noise_level': 0.12274835551420771, 'C': 28.508558737544284, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.5391649413388544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5198\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs, batch_size, lr, noise_level)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4778\n",
      "ROC-AUC autoencoded: 0.4521\n",
      "ROC-AUC autoencoded: 0.5109\n",
      "ROC-AUC autoencoded: 0.5602\n",
      "ROC-AUC autoencoded: 0.5030\n",
      "ROC-AUC autoencoded: 0.4981\n",
      "ROC-AUC autoencoded: 0.4902\n",
      "ROC-AUC autoencoded: 0.4945\n",
      "ROC-AUC autoencoded: 0.4919\n",
      "ROC-AUC autoencoded: 0.4952\n",
      "ROC-AUC autoencoded: 0.5029\n",
      "ROC-AUC autoencoded: 0.5096\n",
      "ROC-AUC autoencoded: 0.5065\n",
      "ROC-AUC autoencoded: 0.4756\n",
      "ROC-AUC autoencoded: 0.4909\n",
      "ROC-AUC autoencoded: 0.4552\n",
      "ROC-AUC autoencoded: 0.4631\n",
      "ROC-AUC autoencoded: 0.4987\n",
      "ROC-AUC autoencoded: 0.4656\n",
      "ROC-AUC autoencoded: 0.4753\n",
      "ROC-AUC autoencoded: 0.5329\n",
      "ROC-AUC autoencoded: 0.4923\n",
      "ROC-AUC autoencoded: 0.5358\n",
      "ROC-AUC autoencoded: 0.5314\n",
      "ROC-AUC autoencoded: 0.5136\n",
      "среднее 0.49692389734407\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 11:26:31,669] A new study created in memory with name: no-name-03efb61a-c3bc-481f-974f-febf72433a15\n",
      "[I 2025-05-10 11:27:03,920] Trial 0 finished with value: 0.5016678168852081 and parameters: {'latent_dim': 32, 'hidden_dim_ae': 88, 'lr_ae': 0.0001393943087018091, 'epochs_ae': 31, 'dropout_rate_ae': 0.24332852987179884, 'noise_level': 0.2218027492554821, 'hidden_dim_mlp': 84, 'lr_mlp': 0.002985092172936521, 'epochs_mlp': 18, 'dropout_rate_mlp': 0.28475308713474035}. Best is trial 0 with value: 0.5016678168852081.\n",
      "[I 2025-05-10 11:27:33,330] Trial 1 finished with value: 0.5341231500651791 and parameters: {'latent_dim': 59, 'hidden_dim_ae': 165, 'lr_ae': 0.0017415900718985528, 'epochs_ae': 19, 'dropout_rate_ae': 0.10689869057706934, 'noise_level': 0.22075189612540363, 'hidden_dim_mlp': 74, 'lr_mlp': 0.002111110559294737, 'epochs_mlp': 27, 'dropout_rate_mlp': 0.12048454089458485}. Best is trial 1 with value: 0.5341231500651791.\n",
      "[I 2025-05-10 11:28:23,375] Trial 2 finished with value: 0.566386780154896 and parameters: {'latent_dim': 71, 'hidden_dim_ae': 80, 'lr_ae': 0.003600819769818151, 'epochs_ae': 48, 'dropout_rate_ae': 0.11291335362755142, 'noise_level': 0.216510185862688, 'hidden_dim_mlp': 122, 'lr_mlp': 0.00870969398248567, 'epochs_mlp': 33, 'dropout_rate_mlp': 0.3651429694332172}. Best is trial 2 with value: 0.566386780154896.\n",
      "[I 2025-05-10 11:29:38,465] Trial 3 finished with value: 0.5668085269534545 and parameters: {'latent_dim': 14, 'hidden_dim_ae': 233, 'lr_ae': 0.0011002631693396358, 'epochs_ae': 47, 'dropout_rate_ae': 0.2975054584469361, 'noise_level': 0.16957082882049979, 'hidden_dim_mlp': 91, 'lr_mlp': 0.0007942305899427875, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.10340869059074156}. Best is trial 3 with value: 0.5668085269534545.\n",
      "[I 2025-05-10 11:30:07,819] Trial 4 finished with value: 0.5207614446744881 and parameters: {'latent_dim': 51, 'hidden_dim_ae': 194, 'lr_ae': 0.00801094900985883, 'epochs_ae': 20, 'dropout_rate_ae': 0.38810618889120674, 'noise_level': 0.2349580554745544, 'hidden_dim_mlp': 66, 'lr_mlp': 0.003045617877286411, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.18724951808347}. Best is trial 3 with value: 0.5668085269534545.\n",
      "[I 2025-05-10 11:30:58,465] Trial 5 finished with value: 0.5220075147611379 and parameters: {'latent_dim': 82, 'hidden_dim_ae': 123, 'lr_ae': 0.000673184811824145, 'epochs_ae': 38, 'dropout_rate_ae': 0.18662384730319542, 'noise_level': 0.14211081624598848, 'hidden_dim_mlp': 101, 'lr_mlp': 0.00025790539626138287, 'epochs_mlp': 43, 'dropout_rate_mlp': 0.30436929293702797}. Best is trial 3 with value: 0.5668085269534545.\n",
      "[I 2025-05-10 11:31:53,109] Trial 6 finished with value: 0.5747258645809371 and parameters: {'latent_dim': 100, 'hidden_dim_ae': 157, 'lr_ae': 0.0005141763185810197, 'epochs_ae': 38, 'dropout_rate_ae': 0.21344746736232625, 'noise_level': 0.19706252573278132, 'hidden_dim_mlp': 73, 'lr_mlp': 0.0015753713984954648, 'epochs_mlp': 38, 'dropout_rate_mlp': 0.14619067418083045}. Best is trial 6 with value: 0.5747258645809371.\n",
      "[I 2025-05-10 11:32:47,820] Trial 7 finished with value: 0.5381489149605092 and parameters: {'latent_dim': 30, 'hidden_dim_ae': 223, 'lr_ae': 0.002919698370700721, 'epochs_ae': 33, 'dropout_rate_ae': 0.3134274547969591, 'noise_level': 0.20768659858878286, 'hidden_dim_mlp': 113, 'lr_mlp': 0.0002330162284548747, 'epochs_mlp': 13, 'dropout_rate_mlp': 0.21850789447316288}. Best is trial 6 with value: 0.5747258645809371.\n",
      "[I 2025-05-10 11:33:18,426] Trial 8 finished with value: 0.5451460777547735 and parameters: {'latent_dim': 46, 'hidden_dim_ae': 248, 'lr_ae': 0.0009499963867552527, 'epochs_ae': 16, 'dropout_rate_ae': 0.3224946957369238, 'noise_level': 0.12436162691842452, 'hidden_dim_mlp': 114, 'lr_mlp': 0.0001660929034573802, 'epochs_mlp': 22, 'dropout_rate_mlp': 0.46965514644753625}. Best is trial 6 with value: 0.5747258645809371.\n",
      "[I 2025-05-10 11:34:35,694] Trial 9 finished with value: 0.5838509316770186 and parameters: {'latent_dim': 54, 'hidden_dim_ae': 225, 'lr_ae': 0.0008221152957123156, 'epochs_ae': 48, 'dropout_rate_ae': 0.27632606217288824, 'noise_level': 0.2386169710114306, 'hidden_dim_mlp': 79, 'lr_mlp': 0.00016720315259836948, 'epochs_mlp': 21, 'dropout_rate_mlp': 0.3919621643798218}. Best is trial 9 with value: 0.5838509316770186.\n",
      "[I 2025-05-10 11:35:00,103] Trial 10 finished with value: 0.5110229276895943 and parameters: {'latent_dim': 81, 'hidden_dim_ae': 198, 'lr_ae': 0.00021506300506869057, 'epochs_ae': 11, 'dropout_rate_ae': 0.49791563125144006, 'noise_level': 0.2978474543280989, 'hidden_dim_mlp': 39, 'lr_mlp': 0.00010119996386220159, 'epochs_mlp': 49, 'dropout_rate_mlp': 0.470632694871336}. Best is trial 9 with value: 0.5838509316770186.\n",
      "[I 2025-05-10 11:35:57,813] Trial 11 finished with value: 0.5434399202515144 and parameters: {'latent_dim': 100, 'hidden_dim_ae': 150, 'lr_ae': 0.0003953274855346602, 'epochs_ae': 42, 'dropout_rate_ae': 0.20971509321838466, 'noise_level': 0.0527887918772707, 'hidden_dim_mlp': 57, 'lr_mlp': 0.0006178011633275004, 'epochs_mlp': 36, 'dropout_rate_mlp': 0.369982064754741}. Best is trial 9 with value: 0.5838509316770186.\n",
      "[I 2025-05-10 11:36:53,035] Trial 12 finished with value: 0.5054443677632082 and parameters: {'latent_dim': 93, 'hidden_dim_ae': 142, 'lr_ae': 0.00031807494077787564, 'epochs_ae': 40, 'dropout_rate_ae': 0.39326032244119935, 'noise_level': 0.28197007202669755, 'hidden_dim_mlp': 55, 'lr_mlp': 0.001356318764073062, 'epochs_mlp': 40, 'dropout_rate_mlp': 0.3893839289022114}. Best is trial 9 with value: 0.5838509316770186.\n",
      "[I 2025-05-10 11:38:05,822] Trial 13 finished with value: 0.5087224906065485 and parameters: {'latent_dim': 66, 'hidden_dim_ae': 182, 'lr_ae': 0.0005265133084334766, 'epochs_ae': 50, 'dropout_rate_ae': 0.17904033341806375, 'noise_level': 0.2606120806022995, 'hidden_dim_mlp': 95, 'lr_mlp': 0.00045481641474450846, 'epochs_mlp': 26, 'dropout_rate_mlp': 0.20791132565073153}. Best is trial 9 with value: 0.5838509316770186.\n",
      "[I 2025-05-10 11:38:36,639] Trial 14 finished with value: 0.5666168238632006 and parameters: {'latent_dim': 42, 'hidden_dim_ae': 115, 'lr_ae': 0.0015170635193980449, 'epochs_ae': 26, 'dropout_rate_ae': 0.26915207705588756, 'noise_level': 0.1758497299891237, 'hidden_dim_mlp': 74, 'lr_mlp': 0.007196222257942414, 'epochs_mlp': 19, 'dropout_rate_mlp': 0.4171563259763086}. Best is trial 9 with value: 0.5838509316770186.\n",
      "[I 2025-05-10 11:39:47,955] Trial 15 finished with value: 0.47594126217314625 and parameters: {'latent_dim': 79, 'hidden_dim_ae': 216, 'lr_ae': 0.00022760748203865392, 'epochs_ae': 43, 'dropout_rate_ae': 0.3752466322824398, 'noise_level': 0.09598508545872272, 'hidden_dim_mlp': 46, 'lr_mlp': 0.0013393902670590463, 'epochs_mlp': 32, 'dropout_rate_mlp': 0.29673124663836914}. Best is trial 9 with value: 0.5838509316770186.\n",
      "[I 2025-05-10 11:41:03,367] Trial 16 finished with value: 0.5430373437619814 and parameters: {'latent_dim': 59, 'hidden_dim_ae': 254, 'lr_ae': 0.00010247628041781096, 'epochs_ae': 35, 'dropout_rate_ae': 0.15186096764875384, 'noise_level': 0.18582000468724996, 'hidden_dim_mlp': 65, 'lr_mlp': 0.0004032458717506397, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.25434476412880447}. Best is trial 9 with value: 0.5838509316770186.\n",
      "[I 2025-05-10 11:41:50,315] Trial 17 finished with value: 0.5515106203512 and parameters: {'latent_dim': 35, 'hidden_dim_ae': 176, 'lr_ae': 0.0006803027103128647, 'epochs_ae': 27, 'dropout_rate_ae': 0.2321937854427208, 'noise_level': 0.2466377448777869, 'hidden_dim_mlp': 81, 'lr_mlp': 0.003573886140047176, 'epochs_mlp': 40, 'dropout_rate_mlp': 0.1402510181099565}. Best is trial 9 with value: 0.5838509316770186.\n",
      "[I 2025-05-10 11:42:40,209] Trial 18 finished with value: 0.5455678245533319 and parameters: {'latent_dim': 18, 'hidden_dim_ae': 128, 'lr_ae': 0.0025687811853407445, 'epochs_ae': 37, 'dropout_rate_ae': 0.34990788380506377, 'noise_level': 0.27067847763414404, 'hidden_dim_mlp': 104, 'lr_mlp': 0.00010228780786926746, 'epochs_mlp': 27, 'dropout_rate_mlp': 0.3372858689839102}. Best is trial 9 with value: 0.5838509316770186.\n",
      "[I 2025-05-10 11:43:54,003] Trial 19 finished with value: 0.5592170845794033 and parameters: {'latent_dim': 69, 'hidden_dim_ae': 199, 'lr_ae': 0.006638404126473878, 'epochs_ae': 45, 'dropout_rate_ae': 0.441569436756012, 'noise_level': 0.19214033065134212, 'hidden_dim_mlp': 85, 'lr_mlp': 0.0010591349799538583, 'epochs_mlp': 22, 'dropout_rate_mlp': 0.4263474864749023}. Best is trial 9 with value: 0.5838509316770186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6267\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae, noise_level)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(latent_dim, hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "mlp = MLP(best_params['latent_dim'], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4924\n",
      "ROC-AUC autoencoded: 0.5775\n",
      "ROC-AUC autoencoded: 0.3799\n",
      "ROC-AUC autoencoded: 0.4945\n",
      "ROC-AUC autoencoded: 0.5265\n",
      "ROC-AUC autoencoded: 0.5298\n",
      "ROC-AUC autoencoded: 0.4528\n",
      "ROC-AUC autoencoded: 0.5614\n",
      "ROC-AUC autoencoded: 0.5140\n",
      "ROC-AUC autoencoded: 0.4535\n",
      "ROC-AUC autoencoded: 0.5078\n",
      "ROC-AUC autoencoded: 0.4860\n",
      "ROC-AUC autoencoded: 0.6298\n",
      "ROC-AUC autoencoded: 0.5332\n",
      "ROC-AUC autoencoded: 0.5193\n",
      "ROC-AUC autoencoded: 0.5147\n",
      "ROC-AUC autoencoded: 0.4826\n",
      "ROC-AUC autoencoded: 0.5383\n",
      "ROC-AUC autoencoded: 0.4467\n",
      "ROC-AUC autoencoded: 0.5481\n",
      "ROC-AUC autoencoded: 0.5547\n",
      "ROC-AUC autoencoded: 0.5559\n",
      "ROC-AUC autoencoded: 0.5129\n",
      "ROC-AUC autoencoded: 0.5337\n",
      "ROC-AUC autoencoded: 0.6050\n",
      "среднее 0.5180317294814301\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(best_params['latent_dim'], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь блок с denoising автоэнкодером с дополнительной классифицирующей головой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 11:53:41,280] A new study created in memory with name: no-name-75c8130a-002c-4e0a-8a85-1fc052620488\n",
      "[I 2025-05-10 11:54:08,943] Trial 0 finished with value: 0.5207422743654627 and parameters: {'latent_dim': 30, 'hidden_dim': 220, 'lr': 0.0008862372928950264, 'epochs': 16, 'dropout_rate': 0.37287877592796004, 'noise_level': 0.20591979055987158, 'classification_weight': 0.1002588859544738, 'C': 31.935165518411274, 'solver': 'liblinear'}. Best is trial 0 with value: 0.5207422743654627.\n",
      "[I 2025-05-10 11:54:51,146] Trial 1 finished with value: 0.5211065102369451 and parameters: {'latent_dim': 83, 'hidden_dim': 99, 'lr': 0.00027014045220362734, 'epochs': 32, 'dropout_rate': 0.18022217169029686, 'noise_level': 0.1026568364649761, 'classification_weight': 0.7376434477294462, 'C': 99.1194773429361, 'solver': 'saga'}. Best is trial 1 with value: 0.5211065102369451.\n",
      "[I 2025-05-10 11:55:59,015] Trial 2 finished with value: 0.5161030595813204 and parameters: {'latent_dim': 61, 'hidden_dim': 168, 'lr': 0.002079133860207517, 'epochs': 44, 'dropout_rate': 0.23869426232951396, 'noise_level': 0.2769150427985175, 'classification_weight': 0.3220454937314219, 'C': 0.02424618699614463, 'solver': 'liblinear'}. Best is trial 1 with value: 0.5211065102369451.\n",
      "[I 2025-05-10 11:56:59,153] Trial 3 finished with value: 0.49756537075377655 and parameters: {'latent_dim': 39, 'hidden_dim': 179, 'lr': 0.0012498882302716952, 'epochs': 38, 'dropout_rate': 0.3367430772132528, 'noise_level': 0.13543334591973466, 'classification_weight': 0.5241844732813828, 'C': 4.079243332926712, 'solver': 'liblinear'}. Best is trial 1 with value: 0.5211065102369451.\n",
      "[I 2025-05-10 11:57:34,141] Trial 4 finished with value: 0.5041599570585078 and parameters: {'latent_dim': 46, 'hidden_dim': 95, 'lr': 0.00012436240476416648, 'epochs': 30, 'dropout_rate': 0.25846445969916654, 'noise_level': 0.1420668295548631, 'classification_weight': 0.2806123274956079, 'C': 0.07507933567163277, 'solver': 'liblinear'}. Best is trial 1 with value: 0.5211065102369451.\n",
      "[I 2025-05-10 11:58:10,441] Trial 5 finished with value: 0.5073805689747718 and parameters: {'latent_dim': 95, 'hidden_dim': 108, 'lr': 0.0040393755569887784, 'epochs': 29, 'dropout_rate': 0.11844211833007323, 'noise_level': 0.1010940159900406, 'classification_weight': 0.6336851890566891, 'C': 2.0563241997280963, 'solver': 'liblinear'}. Best is trial 1 with value: 0.5211065102369451.\n",
      "[I 2025-05-10 11:59:09,309] Trial 6 finished with value: 0.49595506479564455 and parameters: {'latent_dim': 38, 'hidden_dim': 153, 'lr': 0.000489119408554342, 'epochs': 47, 'dropout_rate': 0.12997132366161607, 'noise_level': 0.10272224460123854, 'classification_weight': 0.7841117123465717, 'C': 0.8856866915531857, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.5211065102369451.\n",
      "[I 2025-05-10 11:59:59,080] Trial 7 finished with value: 0.5019745418296143 and parameters: {'latent_dim': 20, 'hidden_dim': 189, 'lr': 0.0017994851956950198, 'epochs': 37, 'dropout_rate': 0.16699052656107632, 'noise_level': 0.24591047823893897, 'classification_weight': 0.7734232981957273, 'C': 9.629918735963283, 'solver': 'liblinear'}. Best is trial 1 with value: 0.5211065102369451.\n",
      "[I 2025-05-10 12:00:49,540] Trial 8 finished with value: 0.5163714439076758 and parameters: {'latent_dim': 18, 'hidden_dim': 125, 'lr': 0.0014207953027959967, 'epochs': 45, 'dropout_rate': 0.4657029660765535, 'noise_level': 0.1920205659078319, 'classification_weight': 0.6235959529877154, 'C': 28.50919398472939, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.5211065102369451.\n",
      "[I 2025-05-10 12:01:27,447] Trial 9 finished with value: 0.5 and parameters: {'latent_dim': 28, 'hidden_dim': 235, 'lr': 0.00024741417071703377, 'epochs': 24, 'dropout_rate': 0.2597684285075993, 'noise_level': 0.22636577730610724, 'classification_weight': 0.580979381188809, 'C': 0.05331070771938771, 'solver': 'saga'}. Best is trial 1 with value: 0.5211065102369451.\n",
      "[I 2025-05-10 12:01:39,969] Trial 10 finished with value: 0.5052718349819799 and parameters: {'latent_dim': 91, 'hidden_dim': 72, 'lr': 0.00010110045697674593, 'epochs': 12, 'dropout_rate': 0.1856116567888066, 'noise_level': 0.05199947869897973, 'classification_weight': 0.8987682715765339, 'C': 0.6138251448505935, 'solver': 'saga'}. Best is trial 1 with value: 0.5211065102369451.\n",
      "[I 2025-05-10 12:02:12,089] Trial 11 finished with value: 0.5231864887661989 and parameters: {'latent_dim': 70, 'hidden_dim': 248, 'lr': 0.000448267089231636, 'epochs': 18, 'dropout_rate': 0.3761514450707199, 'noise_level': 0.19167455924550877, 'classification_weight': 0.12953730306555455, 'C': 92.02027546287145, 'solver': 'saga'}. Best is trial 11 with value: 0.5231864887661989.\n",
      "[I 2025-05-10 12:02:46,567] Trial 12 finished with value: 0.5098343685300207 and parameters: {'latent_dim': 72, 'hidden_dim': 249, 'lr': 0.0003418394837739097, 'epochs': 19, 'dropout_rate': 0.41196093318261984, 'noise_level': 0.15768440196494266, 'classification_weight': 0.3551082021259049, 'C': 96.3005231647299, 'solver': 'saga'}. Best is trial 11 with value: 0.5231864887661989.\n",
      "[I 2025-05-10 12:03:18,710] Trial 13 finished with value: 0.5089333640058278 and parameters: {'latent_dim': 77, 'hidden_dim': 133, 'lr': 0.0005610486861012365, 'epochs': 24, 'dropout_rate': 0.3226659620084081, 'noise_level': 0.05709596530742059, 'classification_weight': 0.10720112984721457, 'C': 65.53295856208531, 'solver': 'saga'}. Best is trial 11 with value: 0.5231864887661989.\n",
      "[I 2025-05-10 12:03:53,691] Trial 14 finished with value: 0.5122210720036806 and parameters: {'latent_dim': 80, 'hidden_dim': 69, 'lr': 0.00021267472602096667, 'epochs': 36, 'dropout_rate': 0.4538196039214694, 'noise_level': 0.17700353921663137, 'classification_weight': 0.4029185334881668, 'C': 8.828480799504765, 'solver': 'saga'}. Best is trial 11 with value: 0.5231864887661989.\n",
      "[I 2025-05-10 12:04:27,806] Trial 15 finished with value: 0.5238382792730619 and parameters: {'latent_dim': 60, 'hidden_dim': 207, 'lr': 0.006519868384283856, 'epochs': 22, 'dropout_rate': 0.3887853711483641, 'noise_level': 0.10339426769306936, 'classification_weight': 0.21957504538893768, 'C': 15.68870233122867, 'solver': 'saga'}. Best is trial 15 with value: 0.5238382792730619.\n",
      "[I 2025-05-10 12:04:45,926] Trial 16 finished with value: 0.5258319914117016 and parameters: {'latent_dim': 62, 'hidden_dim': 207, 'lr': 0.009457047613842293, 'epochs': 11, 'dropout_rate': 0.39733505753351067, 'noise_level': 0.2725107072378813, 'classification_weight': 0.22458137557777574, 'C': 16.79565591640802, 'solver': 'saga'}. Best is trial 16 with value: 0.5258319914117016.\n",
      "[I 2025-05-10 12:05:05,012] Trial 17 finished with value: 0.5188635840809753 and parameters: {'latent_dim': 55, 'hidden_dim': 207, 'lr': 0.008686204546814149, 'epochs': 12, 'dropout_rate': 0.4928417830185611, 'noise_level': 0.298015618286012, 'classification_weight': 0.2269226681011943, 'C': 0.39388469012771116, 'solver': 'saga'}. Best is trial 16 with value: 0.5258319914117016.\n",
      "[I 2025-05-10 12:05:19,839] Trial 18 finished with value: 0.5329537612146308 and parameters: {'latent_dim': 60, 'hidden_dim': 208, 'lr': 0.006453075035500262, 'epochs': 10, 'dropout_rate': 0.4160825220505243, 'noise_level': 0.254626075150319, 'classification_weight': 0.44428164005608173, 'C': 12.584282519602937, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.5329537612146308.\n",
      "[I 2025-05-10 12:05:35,297] Trial 19 finished with value: 0.5006901311249137 and parameters: {'latent_dim': 47, 'hidden_dim': 193, 'lr': 0.003483841590904443, 'epochs': 11, 'dropout_rate': 0.41820914628629835, 'noise_level': 0.25957785277139334, 'classification_weight': 0.4507477397778865, 'C': 4.112232542661413, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.5329537612146308.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5202\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingDenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(ClassifyingDenoisingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "    \n",
    "def train_classifying_denoising_autoencoder(model, X_train, y_train, epochs, batch_size, lr, noise_level=0.1, classification_weight=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    class_criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_target, batch_y in train_loader:\n",
    "            # Add noise to input data\n",
    "            noisy_batch = batch_x + noise_level * torch.randn_like(batch_x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _, classification = model(noisy_batch)\n",
    "            \n",
    "            # Reconstruction loss (target is the original data)\n",
    "            recon_loss = recon_criterion(reconstructed, batch_target)\n",
    "            \n",
    "            # Classification loss\n",
    "            class_loss = class_criterion(classification, batch_y)\n",
    "            \n",
    "            # Combined loss with weights\n",
    "            loss = (1 - classification_weight) * recon_loss + classification_weight * class_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent, _ = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def get_classification(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, _, classification = model(X_tensor)\n",
    "    return classification.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4866\n",
      "ROC-AUC autoencoded: 0.5031\n",
      "ROC-AUC autoencoded: 0.5346\n",
      "ROC-AUC autoencoded: 0.5049\n",
      "ROC-AUC autoencoded: 0.4980\n",
      "ROC-AUC autoencoded: 0.5597\n",
      "ROC-AUC autoencoded: 0.5531\n",
      "ROC-AUC autoencoded: 0.5786\n",
      "ROC-AUC autoencoded: 0.5506\n",
      "ROC-AUC autoencoded: 0.5928\n",
      "ROC-AUC autoencoded: 0.5616\n",
      "ROC-AUC autoencoded: 0.5710\n",
      "ROC-AUC autoencoded: 0.5855\n",
      "ROC-AUC autoencoded: 0.5667\n",
      "ROC-AUC autoencoded: 0.5372\n",
      "ROC-AUC autoencoded: 0.5426\n",
      "ROC-AUC autoencoded: 0.5755\n",
      "ROC-AUC autoencoded: 0.5680\n",
      "ROC-AUC autoencoded: 0.5592\n",
      "ROC-AUC autoencoded: 0.6095\n",
      "ROC-AUC autoencoded: 0.5657\n",
      "ROC-AUC autoencoded: 0.5741\n",
      "ROC-AUC autoencoded: 0.5909\n",
      "ROC-AUC autoencoded: 0.5354\n",
      "ROC-AUC autoencoded: 0.5267\n",
      "среднее 0.5532734853127067\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 12:07:21,918] A new study created in memory with name: no-name-f3efaf92-1f92-4567-8629-43672ff08451\n",
      "[I 2025-05-10 12:08:38,682] Trial 0 finished with value: 0.4892071160187102 and parameters: {'latent_dim': 23, 'hidden_dim': 224, 'lr': 0.0005173830441551255, 'epochs': 49, 'dropout_rate': 0.1456443207674433, 'noise_level': 0.15384804877456626, 'classification_weight': 0.3161058135666375, 'n_estimators': 70, 'max_depth': 6, 'learning_rate': 0.2584710074263253, 'subsample': 0.6819163906513, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.4892071160187102.\n",
      "[I 2025-05-10 12:09:51,163] Trial 1 finished with value: 0.4652634000460088 and parameters: {'latent_dim': 91, 'hidden_dim': 160, 'lr': 0.002520851606035184, 'epochs': 49, 'dropout_rate': 0.4413801870157317, 'noise_level': 0.13029736849704487, 'classification_weight': 0.6200485473746745, 'n_estimators': 424, 'max_depth': 8, 'learning_rate': 0.08497863433711944, 'subsample': 0.8497484698027171, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.4892071160187102.\n",
      "[I 2025-05-10 12:10:49,766] Trial 2 finished with value: 0.49357794647649716 and parameters: {'latent_dim': 67, 'hidden_dim': 148, 'lr': 0.0010478016678206025, 'epochs': 34, 'dropout_rate': 0.10566240940214469, 'noise_level': 0.24582052987636194, 'classification_weight': 0.6480279280155627, 'n_estimators': 260, 'max_depth': 7, 'learning_rate': 0.16408783013287143, 'subsample': 0.8842917074489228, 'min_samples_split': 18, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.49357794647649716.\n",
      "[I 2025-05-10 12:11:33,332] Trial 3 finished with value: 0.5144352426961122 and parameters: {'latent_dim': 70, 'hidden_dim': 158, 'lr': 0.00014378828262637632, 'epochs': 20, 'dropout_rate': 0.30572074364722185, 'noise_level': 0.05931168874423183, 'classification_weight': 0.6874890011785902, 'n_estimators': 485, 'max_depth': 3, 'learning_rate': 0.040976861338192776, 'subsample': 0.6218312663235038, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.5144352426961122.\n",
      "[I 2025-05-10 12:12:15,536] Trial 4 finished with value: 0.5059332106433555 and parameters: {'latent_dim': 48, 'hidden_dim': 171, 'lr': 0.0002620906013919988, 'epochs': 28, 'dropout_rate': 0.4022581681478836, 'noise_level': 0.1276846358593643, 'classification_weight': 0.48366408694754937, 'n_estimators': 171, 'max_depth': 3, 'learning_rate': 0.04267707997481985, 'subsample': 0.6376819144411926, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.5144352426961122.\n",
      "[I 2025-05-10 12:12:48,744] Trial 5 finished with value: 0.49456521739130427 and parameters: {'latent_dim': 33, 'hidden_dim': 74, 'lr': 0.002697166198912857, 'epochs': 34, 'dropout_rate': 0.40936006613246756, 'noise_level': 0.2284798331042962, 'classification_weight': 0.6633263340722757, 'n_estimators': 407, 'max_depth': 7, 'learning_rate': 0.17698139950105635, 'subsample': 0.6608842545932834, 'min_samples_split': 20, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.5144352426961122.\n",
      "[I 2025-05-10 12:13:58,533] Trial 6 finished with value: 0.5024921401732995 and parameters: {'latent_dim': 20, 'hidden_dim': 162, 'lr': 0.00025575184435682065, 'epochs': 46, 'dropout_rate': 0.3722876313447925, 'noise_level': 0.24699032579277225, 'classification_weight': 0.718855740705968, 'n_estimators': 327, 'max_depth': 8, 'learning_rate': 0.019949995081903815, 'subsample': 0.6102503966603668, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.5144352426961122.\n",
      "[I 2025-05-10 12:14:34,085] Trial 7 finished with value: 0.48905375354650715 and parameters: {'latent_dim': 81, 'hidden_dim': 93, 'lr': 0.0010829574522263174, 'epochs': 29, 'dropout_rate': 0.3759457517590058, 'noise_level': 0.17822503837336406, 'classification_weight': 0.4948425009790899, 'n_estimators': 110, 'max_depth': 9, 'learning_rate': 0.21413535786248178, 'subsample': 0.8214946235449341, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.5144352426961122.\n",
      "[I 2025-05-10 12:15:20,393] Trial 8 finished with value: 0.484318687217238 and parameters: {'latent_dim': 90, 'hidden_dim': 111, 'lr': 0.001846633775382793, 'epochs': 23, 'dropout_rate': 0.47028703041061726, 'noise_level': 0.27687598440312033, 'classification_weight': 0.7149138472377684, 'n_estimators': 263, 'max_depth': 4, 'learning_rate': 0.026568219560465303, 'subsample': 0.6141191323047069, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.5144352426961122.\n",
      "[I 2025-05-10 12:16:00,975] Trial 9 finished with value: 0.5103040411011426 and parameters: {'latent_dim': 15, 'hidden_dim': 74, 'lr': 0.000646711955624321, 'epochs': 37, 'dropout_rate': 0.31615481526441025, 'noise_level': 0.24676967378711195, 'classification_weight': 0.6452261273000378, 'n_estimators': 248, 'max_depth': 8, 'learning_rate': 0.021567113405503664, 'subsample': 0.6414032891214035, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.5144352426961122.\n",
      "[I 2025-05-10 12:17:07,229] Trial 10 finished with value: 0.5181542826470363 and parameters: {'latent_dim': 58, 'hidden_dim': 256, 'lr': 0.00011226503157913034, 'epochs': 10, 'dropout_rate': 0.22507832300069708, 'noise_level': 0.05026133919624326, 'classification_weight': 0.8592659750345264, 'n_estimators': 481, 'max_depth': 5, 'learning_rate': 0.012041455713196567, 'subsample': 0.9793298920172023, 'min_samples_split': 14, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.5181542826470363.\n",
      "[I 2025-05-10 12:18:19,862] Trial 11 finished with value: 0.5005463538072233 and parameters: {'latent_dim': 61, 'hidden_dim': 244, 'lr': 0.00010265094920338889, 'epochs': 12, 'dropout_rate': 0.21291459445518335, 'noise_level': 0.07553648645595344, 'classification_weight': 0.8972154336174363, 'n_estimators': 498, 'max_depth': 5, 'learning_rate': 0.01021145348727313, 'subsample': 0.9818262383239262, 'min_samples_split': 13, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.5181542826470363.\n",
      "[I 2025-05-10 12:18:53,880] Trial 12 finished with value: 0.48961927766275587 and parameters: {'latent_dim': 46, 'hidden_dim': 203, 'lr': 0.009284557551305727, 'epochs': 10, 'dropout_rate': 0.2469632011707185, 'noise_level': 0.05036892538499075, 'classification_weight': 0.884578928731428, 'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.010550525032264677, 'subsample': 0.7501178139079819, 'min_samples_split': 16, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.5181542826470363.\n",
      "[I 2025-05-10 12:19:48,513] Trial 13 finished with value: 0.5148665746491834 and parameters: {'latent_dim': 75, 'hidden_dim': 197, 'lr': 0.00010249974956232534, 'epochs': 17, 'dropout_rate': 0.28344302759626017, 'noise_level': 0.08816433133452287, 'classification_weight': 0.12296883854476448, 'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.07761812019424914, 'subsample': 0.9967974943981694, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.5181542826470363.\n",
      "[I 2025-05-10 12:20:36,192] Trial 14 finished with value: 0.49503488996242623 and parameters: {'latent_dim': 77, 'hidden_dim': 254, 'lr': 0.0002025514487893779, 'epochs': 16, 'dropout_rate': 0.22306187799186672, 'noise_level': 0.09242812012155817, 'classification_weight': 0.192005662695032, 'n_estimators': 374, 'max_depth': 5, 'learning_rate': 0.08755502754334495, 'subsample': 0.9894767470223705, 'min_samples_split': 12, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.5181542826470363.\n",
      "[I 2025-05-10 12:21:23,111] Trial 15 finished with value: 0.49745993405413697 and parameters: {'latent_dim': 99, 'hidden_dim': 212, 'lr': 0.00039343181192698557, 'epochs': 16, 'dropout_rate': 0.2634895330316891, 'noise_level': 0.10113154047216395, 'classification_weight': 0.3066084225788581, 'n_estimators': 341, 'max_depth': 5, 'learning_rate': 0.08464449172356336, 'subsample': 0.920108622761531, 'min_samples_split': 16, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.5181542826470363.\n",
      "[I 2025-05-10 12:22:15,633] Trial 16 finished with value: 0.4964343225212791 and parameters: {'latent_dim': 53, 'hidden_dim': 231, 'lr': 0.00010155743441749846, 'epochs': 23, 'dropout_rate': 0.18047959971878524, 'noise_level': 0.18902941893805073, 'classification_weight': 0.1021162494770409, 'n_estimators': 429, 'max_depth': 6, 'learning_rate': 0.11678070481574004, 'subsample': 0.9356395636118143, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.5181542826470363.\n",
      "[I 2025-05-10 12:22:52,893] Trial 17 finished with value: 0.4697971781305115 and parameters: {'latent_dim': 36, 'hidden_dim': 196, 'lr': 0.0001794868936438324, 'epochs': 15, 'dropout_rate': 0.32600398823867227, 'noise_level': 0.10751018847696348, 'classification_weight': 0.38081210856655284, 'n_estimators': 448, 'max_depth': 10, 'learning_rate': 0.05497065513982582, 'subsample': 0.7610288515758398, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 10 with value: 0.5181542826470363.\n",
      "[I 2025-05-10 12:23:44,279] Trial 18 finished with value: 0.5160838892722951 and parameters: {'latent_dim': 60, 'hidden_dim': 190, 'lr': 0.00035244110019849197, 'epochs': 20, 'dropout_rate': 0.27521366935027625, 'noise_level': 0.06615052966125974, 'classification_weight': 0.7995065701354246, 'n_estimators': 331, 'max_depth': 4, 'learning_rate': 0.03198234780569442, 'subsample': 0.9462655552796438, 'min_samples_split': 15, 'min_samples_leaf': 9}. Best is trial 10 with value: 0.5181542826470363.\n",
      "[I 2025-05-10 12:24:27,042] Trial 19 finished with value: 0.4903669197147457 and parameters: {'latent_dim': 61, 'hidden_dim': 132, 'lr': 0.000349559437030761, 'epochs': 24, 'dropout_rate': 0.18197231520530482, 'noise_level': 0.14199581683991874, 'classification_weight': 0.8109994786666659, 'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.01406712262860964, 'subsample': 0.9459167138336506, 'min_samples_split': 15, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.5181542826470363.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5151\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5051\n",
      "ROC-AUC autoencoded: 0.4737\n",
      "ROC-AUC autoencoded: 0.5129\n",
      "ROC-AUC autoencoded: 0.4852\n",
      "ROC-AUC autoencoded: 0.5052\n",
      "ROC-AUC autoencoded: 0.5272\n",
      "ROC-AUC autoencoded: 0.5760\n",
      "ROC-AUC autoencoded: 0.5589\n",
      "ROC-AUC autoencoded: 0.5634\n",
      "ROC-AUC autoencoded: 0.5519\n",
      "ROC-AUC autoencoded: 0.5124\n",
      "ROC-AUC autoencoded: 0.5423\n",
      "ROC-AUC autoencoded: 0.5637\n",
      "ROC-AUC autoencoded: 0.5594\n",
      "ROC-AUC autoencoded: 0.5643\n",
      "ROC-AUC autoencoded: 0.5479\n",
      "ROC-AUC autoencoded: 0.5096\n",
      "ROC-AUC autoencoded: 0.5379\n",
      "ROC-AUC autoencoded: 0.5792\n",
      "ROC-AUC autoencoded: 0.5698\n",
      "ROC-AUC autoencoded: 0.5213\n",
      "ROC-AUC autoencoded: 0.5777\n",
      "ROC-AUC autoencoded: 0.6233\n",
      "ROC-AUC autoencoded: 0.5468\n",
      "ROC-AUC autoencoded: 0.5512\n",
      "среднее 0.5426500313387476\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 12:31:54,287] A new study created in memory with name: no-name-87f02757-bf94-42b3-917b-961260850f53\n",
      "[I 2025-05-10 12:32:47,243] Trial 0 finished with value: 0.5196687370600414 and parameters: {'latent_dim': 77, 'hidden_dim': 145, 'lr': 0.00015087912097357545, 'epochs': 44, 'dropout_rate': 0.23046618095377613, 'noise_level': 0.06917269445269379, 'classification_weight': 0.44130811777926315, 'C': 1.4285150516462295, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 0 with value: 0.5196687370600414.\n",
      "[I 2025-05-10 12:33:21,874] Trial 1 finished with value: 0.5225826240318994 and parameters: {'latent_dim': 71, 'hidden_dim': 131, 'lr': 0.0002858587945823752, 'epochs': 30, 'dropout_rate': 0.39446345642119407, 'noise_level': 0.20402364883165974, 'classification_weight': 0.1117908381632474, 'C': 4.261362188515436, 'kernel': 'linear'}. Best is trial 1 with value: 0.5225826240318994.\n",
      "[I 2025-05-10 12:34:23,999] Trial 2 finished with value: 0.4978337550801319 and parameters: {'latent_dim': 65, 'hidden_dim': 193, 'lr': 0.00010659585036811478, 'epochs': 44, 'dropout_rate': 0.23015281064736906, 'noise_level': 0.25865454360718254, 'classification_weight': 0.7607423681663773, 'C': 20.14022335887569, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 1 with value: 0.5225826240318994.\n",
      "[I 2025-05-10 12:35:26,077] Trial 3 finished with value: 0.5190361168622039 and parameters: {'latent_dim': 83, 'hidden_dim': 189, 'lr': 0.0002278548493619137, 'epochs': 45, 'dropout_rate': 0.24842320009577645, 'noise_level': 0.06847943932430182, 'classification_weight': 0.4964342483159414, 'C': 0.4357014418672181, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.5225826240318994.\n",
      "[I 2025-05-10 12:35:39,909] Trial 4 finished with value: 0.49188137412775096 and parameters: {'latent_dim': 23, 'hidden_dim': 165, 'lr': 0.00020702746297101887, 'epochs': 11, 'dropout_rate': 0.43591187568223233, 'noise_level': 0.1292175910453382, 'classification_weight': 0.304263246666001, 'C': 56.79413016435109, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.5225826240318994.\n",
      "[I 2025-05-10 12:36:31,404] Trial 5 finished with value: 0.5333371673951384 and parameters: {'latent_dim': 36, 'hidden_dim': 135, 'lr': 0.001556223419734654, 'epochs': 45, 'dropout_rate': 0.18283987191808493, 'noise_level': 0.1544855746549551, 'classification_weight': 0.26938851425148036, 'C': 1.683672213587343, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:37:01,366] Trial 6 finished with value: 0.5096043248217161 and parameters: {'latent_dim': 45, 'hidden_dim': 168, 'lr': 0.0004670775165842132, 'epochs': 23, 'dropout_rate': 0.1744778609938228, 'noise_level': 0.1505847701874815, 'classification_weight': 0.13210174992692797, 'C': 0.6261520100897388, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:37:26,513] Trial 7 finished with value: 0.5192278199524577 and parameters: {'latent_dim': 51, 'hidden_dim': 171, 'lr': 0.00012877562631852157, 'epochs': 19, 'dropout_rate': 0.33003434137079407, 'noise_level': 0.16288158194222346, 'classification_weight': 0.6151097338183434, 'C': 27.90130854381703, 'kernel': 'linear'}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:38:48,753] Trial 8 finished with value: 0.5236369910282953 and parameters: {'latent_dim': 98, 'hidden_dim': 241, 'lr': 0.008868863681054653, 'epochs': 50, 'dropout_rate': 0.3094503701361183, 'noise_level': 0.0650668352353259, 'classification_weight': 0.6212016034086857, 'C': 0.4778549399598781, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:39:23,786] Trial 9 finished with value: 0.51859519975462 and parameters: {'latent_dim': 29, 'hidden_dim': 163, 'lr': 0.0002945805542091266, 'epochs': 27, 'dropout_rate': 0.24883795861438116, 'noise_level': 0.06688788768290614, 'classification_weight': 0.5279588517223979, 'C': 24.67492060728213, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:39:56,943] Trial 10 finished with value: 0.520953147764742 and parameters: {'latent_dim': 12, 'hidden_dim': 71, 'lr': 0.0016849784394275553, 'epochs': 37, 'dropout_rate': 0.11510507530472192, 'noise_level': 0.22443944581390848, 'classification_weight': 0.3001612803114005, 'C': 0.10656942907422765, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:41:20,970] Trial 11 finished with value: 0.5022333410014569 and parameters: {'latent_dim': 97, 'hidden_dim': 253, 'lr': 0.008682134553847067, 'epochs': 49, 'dropout_rate': 0.3531350715921291, 'noise_level': 0.11209794665764491, 'classification_weight': 0.8480140260274227, 'C': 4.642888255728472, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:42:20,351] Trial 12 finished with value: 0.5171765968867418 and parameters: {'latent_dim': 41, 'hidden_dim': 243, 'lr': 0.0072406168820411815, 'epochs': 37, 'dropout_rate': 0.10079835267817042, 'noise_level': 0.11199497886207821, 'classification_weight': 0.6670634926626301, 'C': 0.24262859385441723, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:43:13,447] Trial 13 finished with value: 0.5154225136109193 and parameters: {'latent_dim': 95, 'hidden_dim': 109, 'lr': 0.0022337756981492016, 'epochs': 50, 'dropout_rate': 0.29675903435649353, 'noise_level': 0.2884981631543947, 'classification_weight': 0.30994626923624247, 'C': 1.5137207435425022, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:44:10,384] Trial 14 finished with value: 0.5174066405950465 and parameters: {'latent_dim': 60, 'hidden_dim': 223, 'lr': 0.0037746436145165946, 'epochs': 37, 'dropout_rate': 0.1686989953340399, 'noise_level': 0.18517721991102143, 'classification_weight': 0.4214354779172709, 'C': 1.3345975735275246, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:44:53,954] Trial 15 finished with value: 0.5215474273445287 and parameters: {'latent_dim': 34, 'hidden_dim': 108, 'lr': 0.0008381882019996221, 'epochs': 41, 'dropout_rate': 0.49224234169625014, 'noise_level': 0.09445299873264681, 'classification_weight': 0.6411386660183802, 'C': 8.224129248949994, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:46:08,825] Trial 16 finished with value: 0.5108312245993405 and parameters: {'latent_dim': 11, 'hidden_dim': 215, 'lr': 0.004020751642808404, 'epochs': 50, 'dropout_rate': 0.29856956280874575, 'noise_level': 0.14156557122566477, 'classification_weight': 0.23508001295760667, 'C': 0.21477412550591723, 'kernel': 'linear'}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:46:39,607] Trial 17 finished with value: 0.5065754159957058 and parameters: {'latent_dim': 87, 'hidden_dim': 79, 'lr': 0.0009654308511995234, 'epochs': 33, 'dropout_rate': 0.1716537258780568, 'noise_level': 0.22911364415083402, 'classification_weight': 0.5580877813672483, 'C': 0.7304242694361986, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:47:27,628] Trial 18 finished with value: 0.512364849321371 and parameters: {'latent_dim': 52, 'hidden_dim': 125, 'lr': 0.004381015653924337, 'epochs': 42, 'dropout_rate': 0.37579670861205094, 'noise_level': 0.1825790265448726, 'classification_weight': 0.746996816803878, 'C': 2.252149347369911, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 5 with value: 0.5333371673951384.\n",
      "[I 2025-05-10 12:48:35,436] Trial 19 finished with value: 0.5193811824246607 and parameters: {'latent_dim': 24, 'hidden_dim': 195, 'lr': 0.0017722027314529126, 'epochs': 47, 'dropout_rate': 0.2789998156506458, 'noise_level': 0.09996514396914066, 'classification_weight': 0.39705802904998555, 'C': 8.682863702192858, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 5 with value: 0.5333371673951384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5196\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4847\n",
      "ROC-AUC autoencoded: 0.5421\n",
      "ROC-AUC autoencoded: 0.4990\n",
      "ROC-AUC autoencoded: 0.5190\n",
      "ROC-AUC autoencoded: 0.4514\n",
      "ROC-AUC autoencoded: 0.5843\n",
      "ROC-AUC autoencoded: 0.5656\n",
      "ROC-AUC autoencoded: 0.5641\n",
      "ROC-AUC autoencoded: 0.5625\n",
      "ROC-AUC autoencoded: 0.5243\n",
      "ROC-AUC autoencoded: 0.5890\n",
      "ROC-AUC autoencoded: 0.5776\n",
      "ROC-AUC autoencoded: 0.5641\n",
      "ROC-AUC autoencoded: 0.5725\n",
      "ROC-AUC autoencoded: 0.5932\n",
      "ROC-AUC autoencoded: 0.5785\n",
      "ROC-AUC autoencoded: 0.5169\n",
      "ROC-AUC autoencoded: 0.5654\n",
      "ROC-AUC autoencoded: 0.5562\n",
      "ROC-AUC autoencoded: 0.5703\n",
      "ROC-AUC autoencoded: 0.5407\n",
      "ROC-AUC autoencoded: 0.5582\n",
      "ROC-AUC autoencoded: 0.5626\n",
      "ROC-AUC autoencoded: 0.5553\n",
      "ROC-AUC autoencoded: 0.5419\n",
      "среднее 0.5495883380524104\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 12:54:49,178] A new study created in memory with name: no-name-a2d76241-d25b-47f2-b73b-71fa392fe7fa\n",
      "[I 2025-05-10 12:55:31,036] Trial 0 finished with value: 0.5006422053523503 and parameters: {'latent_dim': 33, 'hidden_dim': 93, 'lr': 0.0013367528342621735, 'epochs': 42, 'dropout_rate': 0.17064358614213182, 'noise_level': 0.19320062301154345, 'classification_weight': 0.14573820763589068}. Best is trial 0 with value: 0.5006422053523503.\n",
      "[I 2025-05-10 12:55:46,251] Trial 1 finished with value: 0.509853538839046 and parameters: {'latent_dim': 26, 'hidden_dim': 124, 'lr': 0.0004780367422352286, 'epochs': 13, 'dropout_rate': 0.21108298182960553, 'noise_level': 0.14302398706440916, 'classification_weight': 0.809044701365011}. Best is trial 1 with value: 0.509853538839046.\n",
      "[I 2025-05-10 12:56:29,686] Trial 2 finished with value: 0.526157886665133 and parameters: {'latent_dim': 24, 'hidden_dim': 247, 'lr': 0.005220349475592429, 'epochs': 26, 'dropout_rate': 0.16569807704946582, 'noise_level': 0.2473466316088483, 'classification_weight': 0.5785390255729476}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 12:57:19,172] Trial 3 finished with value: 0.4930411778237865 and parameters: {'latent_dim': 33, 'hidden_dim': 255, 'lr': 0.00549043512666865, 'epochs': 28, 'dropout_rate': 0.1148109592652995, 'noise_level': 0.22996383024105516, 'classification_weight': 0.7069454277437409}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 12:57:53,578] Trial 4 finished with value: 0.507035503412315 and parameters: {'latent_dim': 39, 'hidden_dim': 180, 'lr': 0.0005613511196565473, 'epochs': 25, 'dropout_rate': 0.49216520902858696, 'noise_level': 0.23667177595484895, 'classification_weight': 0.7806920184012077}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 12:58:27,873] Trial 5 finished with value: 0.5112338010888736 and parameters: {'latent_dim': 16, 'hidden_dim': 217, 'lr': 0.0021355492840565223, 'epochs': 23, 'dropout_rate': 0.2789028272321177, 'noise_level': 0.06013975645739296, 'classification_weight': 0.3028089650012105}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 12:59:15,958] Trial 6 finished with value: 0.5099206349206349 and parameters: {'latent_dim': 73, 'hidden_dim': 238, 'lr': 0.002733170417018039, 'epochs': 30, 'dropout_rate': 0.11085298587883496, 'noise_level': 0.21588189565174543, 'classification_weight': 0.14836887087789308}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 13:00:04,864] Trial 7 finished with value: 0.5122689977762441 and parameters: {'latent_dim': 41, 'hidden_dim': 210, 'lr': 0.0037043416928209645, 'epochs': 34, 'dropout_rate': 0.3869182189540188, 'noise_level': 0.2321438505387708, 'classification_weight': 0.24426980132564813}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 13:00:35,320] Trial 8 finished with value: 0.5065179050686297 and parameters: {'latent_dim': 39, 'hidden_dim': 236, 'lr': 0.007216844687018534, 'epochs': 19, 'dropout_rate': 0.14045578238236545, 'noise_level': 0.19925340216520038, 'classification_weight': 0.7041774825522082}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 13:01:17,619] Trial 9 finished with value: 0.49716279426424353 and parameters: {'latent_dim': 46, 'hidden_dim': 80, 'lr': 0.00029561532594657517, 'epochs': 46, 'dropout_rate': 0.20114175710799578, 'noise_level': 0.22220129192238713, 'classification_weight': 0.899544581504571}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 13:02:04,069] Trial 10 finished with value: 0.5075914423740511 and parameters: {'latent_dim': 97, 'hidden_dim': 159, 'lr': 0.00010070011142497806, 'epochs': 36, 'dropout_rate': 0.284076584564838, 'noise_level': 0.29447449734846864, 'classification_weight': 0.5152488218698795}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 13:02:57,617] Trial 11 finished with value: 0.5077543900007668 and parameters: {'latent_dim': 63, 'hidden_dim': 198, 'lr': 0.009905167559375363, 'epochs': 37, 'dropout_rate': 0.4113370070044689, 'noise_level': 0.28996690381307855, 'classification_weight': 0.41533971949722814}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 13:03:46,617] Trial 12 finished with value: 0.5175216624491986 and parameters: {'latent_dim': 11, 'hidden_dim': 205, 'lr': 0.0035899578360203857, 'epochs': 34, 'dropout_rate': 0.36770670335865413, 'noise_level': 0.13431598510562498, 'classification_weight': 0.5397843594530545}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 13:04:09,757] Trial 13 finished with value: 0.5058277739437159 and parameters: {'latent_dim': 12, 'hidden_dim': 165, 'lr': 0.0015560223881362259, 'epochs': 18, 'dropout_rate': 0.356971720549412, 'noise_level': 0.13625285877141702, 'classification_weight': 0.5361932067845843}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 13:05:19,451] Trial 14 finished with value: 0.4960892569588222 and parameters: {'latent_dim': 22, 'hidden_dim': 253, 'lr': 0.003918282479868123, 'epochs': 41, 'dropout_rate': 0.24644279816624004, 'noise_level': 0.0904734568525233, 'classification_weight': 0.6095033588559063}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 13:05:32,884] Trial 15 finished with value: 0.5153170769112798 and parameters: {'latent_dim': 11, 'hidden_dim': 187, 'lr': 0.0008077442627866325, 'epochs': 10, 'dropout_rate': 0.3247660122443851, 'noise_level': 0.14898876155049473, 'classification_weight': 0.4397216773731165}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 13:06:50,843] Trial 16 finished with value: 0.5142339544513457 and parameters: {'latent_dim': 57, 'hidden_dim': 227, 'lr': 0.0061222404771654765, 'epochs': 50, 'dropout_rate': 0.4360010015708389, 'noise_level': 0.10360211680710164, 'classification_weight': 0.5949758890158522}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 13:07:20,626] Trial 17 finished with value: 0.5150774480484626 and parameters: {'latent_dim': 25, 'hidden_dim': 144, 'lr': 0.0027997545443970797, 'epochs': 25, 'dropout_rate': 0.32607685750409426, 'noise_level': 0.26281449237930266, 'classification_weight': 0.4019752200646844}. Best is trial 2 with value: 0.526157886665133.\n",
      "[I 2025-05-10 13:08:07,155] Trial 18 finished with value: 0.5277969480868031 and parameters: {'latent_dim': 83, 'hidden_dim': 215, 'lr': 0.0017809503363113424, 'epochs': 31, 'dropout_rate': 0.46247272678498547, 'noise_level': 0.17330631659310464, 'classification_weight': 0.6264021164567111}. Best is trial 18 with value: 0.5277969480868031.\n",
      "[I 2025-05-10 13:08:55,173] Trial 19 finished with value: 0.5004217467985583 and parameters: {'latent_dim': 88, 'hidden_dim': 233, 'lr': 0.0010419819981190809, 'epochs': 30, 'dropout_rate': 0.4913139653099559, 'noise_level': 0.17209751525134268, 'classification_weight': 0.6896777281666489}. Best is trial 18 with value: 0.5277969480868031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5253\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        y_pred_proba = get_classification(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "y_pred_proba = get_classification(autoencoder, X_val_all)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4948\n",
      "ROC-AUC autoencoded: 0.4959\n",
      "ROC-AUC autoencoded: 0.5261\n",
      "ROC-AUC autoencoded: 0.5037\n",
      "ROC-AUC autoencoded: 0.5140\n",
      "ROC-AUC autoencoded: 0.5720\n",
      "ROC-AUC autoencoded: 0.5340\n",
      "ROC-AUC autoencoded: 0.5924\n",
      "ROC-AUC autoencoded: 0.5720\n",
      "ROC-AUC autoencoded: 0.5553\n",
      "ROC-AUC autoencoded: 0.5427\n",
      "ROC-AUC autoencoded: 0.5641\n",
      "ROC-AUC autoencoded: 0.5282\n",
      "ROC-AUC autoencoded: 0.5894\n",
      "ROC-AUC autoencoded: 0.5431\n",
      "ROC-AUC autoencoded: 0.5672\n",
      "ROC-AUC autoencoded: 0.5799\n",
      "ROC-AUC autoencoded: 0.5534\n",
      "ROC-AUC autoencoded: 0.5377\n",
      "ROC-AUC autoencoded: 0.5712\n",
      "ROC-AUC autoencoded: 0.5369\n",
      "ROC-AUC autoencoded: 0.5269\n",
      "ROC-AUC autoencoded: 0.5641\n",
      "ROC-AUC autoencoded: 0.5305\n",
      "ROC-AUC autoencoded: 0.5868\n",
      "среднее 0.5472890719694574\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_all_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_all_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = get_classification(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_dipl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
