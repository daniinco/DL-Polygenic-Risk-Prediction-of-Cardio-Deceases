{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_snp_all = pd.read_csv(\"./csv/all_train_snp_selected.csv\")\n",
    "validation_snp_all = pd.read_csv(\"./csv/validation_snp_selected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all_ = all_train_snp_all.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "X_val_all_ = validation_snp_all.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "y_all_train = all_train_snp_all[\"target\"] - 1\n",
    "y_val = validation_snp_all[\"target\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_classif, k=40)\n",
    "X_train_all_ = selector.fit_transform(X_train_all_, y_all_train)\n",
    "X_val_all_ = selector.transform(X_val_all_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_pgs = pd.read_csv(\"./pgs_results_calculated/all_train_pgs.csv\").drop(columns=[\"FID\", \"IID\", \"y\"])\n",
    "validation_pgs = pd.read_csv(\"./pgs_results_calculated/validation_pgs.csv\").drop(columns=[\"FID\", \"IID\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pgs = all_train_pgs.to_numpy()\n",
    "X_val_pgs = validation_pgs.to_numpy()\n",
    "ss = StandardScaler()\n",
    "X_train_pgs = ss.fit_transform(X_train_pgs)\n",
    "X_val_pgs = ss.transform(X_val_pgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_classif, k=19)\n",
    "X_train_pgs = selector.fit_transform(X_train_pgs, y_all_train)\n",
    "X_val_pgs = selector.transform(X_val_pgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(train_snp, test_snp, k=40):\n",
    "    train_id = train_snp[\"Unnamed: 0\"]\n",
    "    train_target = train_snp[\"target\"]\n",
    "    test_id = test_snp[\"Unnamed: 0\"]\n",
    "    test_target = test_snp[\"target\"]\n",
    "    \n",
    "    X_train = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"])\n",
    "    y_train = train_snp[\"target\"]\n",
    "    X_test = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"])\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "    selected_features = X_train.columns[selected_indices]\n",
    "    X_train_selected_df = pd.DataFrame(X_train_selected, columns=selected_features)\n",
    "    X_test_selected_df = pd.DataFrame(X_test_selected, columns=selected_features)\n",
    "    \n",
    "    X_train_selected_df.insert(0, \"Unnamed: 0\", train_id.values)\n",
    "    X_train_selected_df[\"target\"] = train_target.values\n",
    "    \n",
    "    X_test_selected_df.insert(0, \"Unnamed: 0\", test_id.values)\n",
    "    X_test_selected_df[\"target\"] = test_target.values\n",
    "    \n",
    "    return X_train_selected_df, X_test_selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snps = []\n",
    "test_snps = []\n",
    "train_pgss = []\n",
    "test_pgss = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "    train_selected, test_selected = select_features(train_snp, test_snp, k=40)\n",
    "    train_snps.append(train_selected)\n",
    "    test_snps.append(test_selected)\n",
    "    ss = StandardScaler()\n",
    "    train_pgs = ss.fit_transform(pd.read_csv(f\"./pgs_results_calculated/train_{i}_pgs.csv\").drop(columns=[\"FID\", \"IID\", \"y\"]).to_numpy())\n",
    "    test_pgs = ss.transform(pd.read_csv(f\"./pgs_results_calculated/test_{i}_pgs.csv\").drop(columns=[\"FID\", \"IID\", \"y\"]).to_numpy())\n",
    "    selector = SelectKBest(f_classif, k=19)\n",
    "    train_pgs = selector.fit_transform(train_pgs, y_train)\n",
    "    test_pgs = selector.transform(test_pgs)\n",
    "    train_pgss.append(train_pgs)\n",
    "    test_pgss.append(test_pgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регрессия на всех SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC bigset: 0.7721\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(np.concatenate([X_train_all_, X_train_pgs], axis=1))\n",
    "X_val_all = ss.transform(np.concatenate([X_val_all_, X_val_pgs], axis=1))\n",
    "\n",
    "model_gb = LogisticRegression()\n",
    "model_gb.fit(X_train_all, y_all_train)\n",
    "\n",
    "y_pred_proba = model_gb.predict_proba(X_val_all)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.7622\n",
      "ROC-AUC: 0.7489\n",
      "ROC-AUC: 0.7218\n",
      "ROC-AUC: 0.6694\n",
      "ROC-AUC: 0.7354\n",
      "среднее 0.727524787379042\n"
     ]
    }
   ],
   "source": [
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = np.concatenate([train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), train_pgs], axis=1)\n",
    "    X_val_ = np.concatenate([test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), test_pgs], axis=1)\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    model_gb = LogisticRegression()\n",
    "    model_gb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг на всех SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC bigset: 0.7354\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(np.concatenate([X_train_all_, X_train_pgs], axis=1))\n",
    "X_val_all = ss.transform(np.concatenate([X_val_all_, X_val_pgs], axis=1))\n",
    "\n",
    "model_gb = GradientBoostingClassifier()\n",
    "model_gb.fit(X_train_all, y_all_train)\n",
    "\n",
    "y_pred_proba = model_gb.predict_proba(X_val_all)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.7504\n",
      "ROC-AUC: 0.7202\n",
      "ROC-AUC: 0.7389\n",
      "ROC-AUC: 0.7043\n",
      "ROC-AUC: 0.7549\n",
      "среднее 0.7337237227808442\n"
     ]
    }
   ],
   "source": [
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = np.concatenate([train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), train_pgs], axis=1)\n",
    "    X_val_ = np.concatenate([test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), test_pgs], axis=1)\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    model_gb = GradientBoostingClassifier()\n",
    "    model_gb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC на всех SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC bigset: 0.7424\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(np.concatenate([X_train_all_, X_train_pgs], axis=1))\n",
    "X_val_all = ss.transform(np.concatenate([X_val_all_, X_val_pgs], axis=1))\n",
    "\n",
    "model_gb = SVC(probability=True)\n",
    "model_gb.fit(X_train_all, y_all_train)\n",
    "\n",
    "y_pred_proba = model_gb.predict_proba(X_val_all)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.7263\n",
      "ROC-AUC: 0.7288\n",
      "ROC-AUC: 0.7115\n",
      "ROC-AUC: 0.6915\n",
      "ROC-AUC: 0.7792\n",
      "среднее 0.7274670129770875\n"
     ]
    }
   ],
   "source": [
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = np.concatenate([train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), train_pgs], axis=1)\n",
    "    X_val_ = np.concatenate([test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), test_pgs], axis=1)\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    model_gb = SVC(probability=True)\n",
    "    model_gb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полносвязная сеть на всех snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7790\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(np.concatenate([X_train_all_, X_train_pgs], axis=1))\n",
    "X_val_all = ss.transform(np.concatenate([X_val_all_, X_val_pgs], axis=1))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train_all)\n",
    "y_train_tensor = torch.FloatTensor(y_all_train.values).reshape(-1, 1)\n",
    "\n",
    "model = Net(X_train_all.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_val_tensor = torch.FloatTensor(X_val_all)\n",
    "    y_pred_proba = model(X_val_tensor).numpy().flatten()\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7449\n",
      "ROC-AUC autoencoded: 0.7622\n",
      "ROC-AUC autoencoded: 0.7328\n",
      "ROC-AUC autoencoded: 0.7230\n",
      "ROC-AUC autoencoded: 0.7522\n",
      "среднее 0.7430376082353283\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = np.concatenate([train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), train_pgs], axis=1)\n",
    "    X_val_ = np.concatenate([test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), test_pgs], axis=1)\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "    \n",
    "    model = Net(X_train.shape[1])\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val_tensor = torch.FloatTensor(X_val)\n",
    "        y_pred_proba = model(X_val_tensor).numpy().flatten()\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок обучения с использованием классического автоэнкодера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С использованием логистической регрессии для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 05:43:30,090] A new study created in memory with name: no-name-6c8af431-f6de-40ea-9acc-ac85937c8cc6\n",
      "[I 2025-05-12 05:43:35,806] Trial 0 finished with value: 0.7705314009661834 and parameters: {'latent_dim': 63, 'hidden_dim': 107, 'lr': 0.00011106583986771314, 'epochs': 47, 'C': 0.0021606672097472077, 'dropout_rate': 0.48945666638017205}. Best is trial 0 with value: 0.7705314009661834.\n",
      "[I 2025-05-12 05:43:41,437] Trial 1 finished with value: 0.7648378191856454 and parameters: {'latent_dim': 50, 'hidden_dim': 221, 'lr': 0.004853023049452625, 'epochs': 42, 'C': 2.8855869238203815, 'dropout_rate': 0.3126944993889007}. Best is trial 0 with value: 0.7705314009661834.\n",
      "[I 2025-05-12 05:43:45,798] Trial 2 finished with value: 0.7788129744651483 and parameters: {'latent_dim': 29, 'hidden_dim': 195, 'lr': 0.0013074820228356802, 'epochs': 42, 'C': 0.017649490535465096, 'dropout_rate': 0.1686005541897902}. Best is trial 2 with value: 0.7788129744651483.\n",
      "[I 2025-05-12 05:43:49,422] Trial 3 finished with value: 0.777432712215321 and parameters: {'latent_dim': 76, 'hidden_dim': 188, 'lr': 0.0002202132412148782, 'epochs': 33, 'C': 0.011236533179175284, 'dropout_rate': 0.4251279268587509}. Best is trial 2 with value: 0.7788129744651483.\n",
      "[I 2025-05-12 05:43:53,933] Trial 4 finished with value: 0.771911663216011 and parameters: {'latent_dim': 40, 'hidden_dim': 74, 'lr': 0.0018873914104923196, 'epochs': 47, 'C': 0.31458586941568506, 'dropout_rate': 0.19687495395365434}. Best is trial 2 with value: 0.7788129744651483.\n",
      "[I 2025-05-12 05:43:56,563] Trial 5 finished with value: 0.7684034966643662 and parameters: {'latent_dim': 44, 'hidden_dim': 186, 'lr': 0.0001282912258942796, 'epochs': 24, 'C': 0.11782468625050486, 'dropout_rate': 0.3063861218096774}. Best is trial 2 with value: 0.7788129744651483.\n",
      "[I 2025-05-12 05:43:59,740] Trial 6 finished with value: 0.7723717506326202 and parameters: {'latent_dim': 59, 'hidden_dim': 114, 'lr': 0.0037443794545548503, 'epochs': 35, 'C': 0.00281465315500479, 'dropout_rate': 0.44257149061049594}. Best is trial 2 with value: 0.7788129744651483.\n",
      "[I 2025-05-12 05:44:02,130] Trial 7 finished with value: 0.7668507016333103 and parameters: {'latent_dim': 12, 'hidden_dim': 118, 'lr': 0.001435953313725594, 'epochs': 17, 'C': 0.29923023264382553, 'dropout_rate': 0.22304223506381438}. Best is trial 2 with value: 0.7788129744651483.\n",
      "[I 2025-05-12 05:44:05,512] Trial 8 finished with value: 0.7821486082355648 and parameters: {'latent_dim': 58, 'hidden_dim': 225, 'lr': 0.0034981838764764697, 'epochs': 31, 'C': 0.1730781314042369, 'dropout_rate': 0.21666924405443738}. Best is trial 8 with value: 0.7821486082355648.\n",
      "[I 2025-05-12 05:44:10,435] Trial 9 finished with value: 0.7736369910282953 and parameters: {'latent_dim': 21, 'hidden_dim': 225, 'lr': 0.00023495453818526494, 'epochs': 46, 'C': 0.008133223632481822, 'dropout_rate': 0.4446710196669724}. Best is trial 8 with value: 0.7821486082355648.\n",
      "[I 2025-05-12 05:44:11,827] Trial 10 finished with value: 0.7237750172532782 and parameters: {'latent_dim': 97, 'hidden_dim': 249, 'lr': 0.007499922417259881, 'epochs': 11, 'C': 9.016409785814242, 'dropout_rate': 0.10032234091940861}. Best is trial 8 with value: 0.7821486082355648.\n",
      "[I 2025-05-12 05:44:14,305] Trial 11 finished with value: 0.7896825396825397 and parameters: {'latent_dim': 27, 'hidden_dim': 168, 'lr': 0.0005640334952942813, 'epochs': 26, 'C': 0.027113157929723943, 'dropout_rate': 0.166188585496128}. Best is trial 11 with value: 0.7896825396825397.\n",
      "[I 2025-05-12 05:44:16,859] Trial 12 finished with value: 0.7760524499654935 and parameters: {'latent_dim': 74, 'hidden_dim': 157, 'lr': 0.0004978782016890203, 'epochs': 26, 'C': 0.04617312223166855, 'dropout_rate': 0.2550384770768054}. Best is trial 11 with value: 0.7896825396825397.\n",
      "[I 2025-05-12 05:44:19,283] Trial 13 finished with value: 0.7635725787899701 and parameters: {'latent_dim': 33, 'hidden_dim': 151, 'lr': 0.0006867956741946335, 'epochs': 22, 'C': 0.8800919678823751, 'dropout_rate': 0.12814860201354816}. Best is trial 11 with value: 0.7896825396825397.\n",
      "[I 2025-05-12 05:44:22,929] Trial 14 finished with value: 0.7744996549344374 and parameters: {'latent_dim': 75, 'hidden_dim': 255, 'lr': 0.002736819156015715, 'epochs': 35, 'C': 0.05500147774122042, 'dropout_rate': 0.2598588856872058}. Best is trial 11 with value: 0.7896825396825397.\n",
      "[I 2025-05-12 05:44:26,048] Trial 15 finished with value: 0.766333103289625 and parameters: {'latent_dim': 91, 'hidden_dim': 219, 'lr': 0.0007088003793819289, 'epochs': 29, 'C': 0.18895434803801553, 'dropout_rate': 0.3629224162042062}. Best is trial 11 with value: 0.7896825396825397.\n",
      "[I 2025-05-12 05:44:27,798] Trial 16 finished with value: 0.771911663216011 and parameters: {'latent_dim': 16, 'hidden_dim': 138, 'lr': 0.009297931161547663, 'epochs': 18, 'C': 0.8172730056643, 'dropout_rate': 0.15612288263915908}. Best is trial 11 with value: 0.7896825396825397.\n",
      "[I 2025-05-12 05:44:30,804] Trial 17 finished with value: 0.7804232804232805 and parameters: {'latent_dim': 64, 'hidden_dim': 199, 'lr': 0.00036314442163046576, 'epochs': 30, 'C': 0.028950889475129422, 'dropout_rate': 0.20552578081858466}. Best is trial 11 with value: 0.7896825396825397.\n",
      "[I 2025-05-12 05:44:34,852] Trial 18 finished with value: 0.7777777777777778 and parameters: {'latent_dim': 51, 'hidden_dim': 177, 'lr': 0.0009037830482282969, 'epochs': 39, 'C': 0.005742942424855363, 'dropout_rate': 0.2556515304435867}. Best is trial 11 with value: 0.7896825396825397.\n",
      "[I 2025-05-12 05:44:36,524] Trial 19 finished with value: 0.7729468599033816 and parameters: {'latent_dim': 31, 'hidden_dim': 72, 'lr': 0.002628047589546234, 'epochs': 19, 'C': 0.6655073897590124, 'dropout_rate': 0.15831516685064406}. Best is trial 11 with value: 0.7896825396825397.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7823\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "    \n",
    "def train_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, _ in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _ = model(batch_x)\n",
    "            loss = criterion(reconstructed, batch_x)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    C = trial.suggest_float('C', 1e-3, 10.0, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "    autoencoder = train_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "    \n",
    "    X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "    X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "    \n",
    "    logreg = LogisticRegression(C=C, max_iter=1000)\n",
    "    logreg.fit(X_train_latent, y_train)\n",
    "    \n",
    "    y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(C=best_params['C'], max_iter=1000)\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latent_dim': 27,\n",
       " 'hidden_dim': 168,\n",
       " 'lr': 0.0005640334952942813,\n",
       " 'epochs': 26,\n",
       " 'C': 0.027113157929723943,\n",
       " 'dropout_rate': 0.166188585496128}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7715\n",
      "ROC-AUC autoencoded: 0.7801\n",
      "ROC-AUC autoencoded: 0.7473\n",
      "ROC-AUC autoencoded: 0.7297\n",
      "ROC-AUC autoencoded: 0.7766\n",
      "среднее 0.7610350410902782\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "    autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "    \n",
    "    X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "    X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "    \n",
    "    logreg = LogisticRegression(C=best_params['C'], max_iter=1000)\n",
    "    logreg.fit(X_train_latent, y_train)\n",
    "    \n",
    "    y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "с градиентным бустингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 05:45:14,680] A new study created in memory with name: no-name-2980a782-bb79-41cf-887f-4def00378bcb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 05:45:55,589] Trial 0 finished with value: 0.7593359404953608 and parameters: {'latent_dim': 84, 'hidden_dim': 200, 'lr': 0.0006388102962847999, 'epochs': 13, 'dropout_rate': 0.30593953417020836, 'n_estimators': 334, 'max_depth': 3, 'learning_rate': 0.022957940442808987, 'subsample': 0.7878747897629108, 'min_samples_split': 18, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7593359404953608.\n",
      "[I 2025-05-12 05:47:22,924] Trial 1 finished with value: 0.751111877923472 and parameters: {'latent_dim': 71, 'hidden_dim': 85, 'lr': 0.0003392358044519743, 'epochs': 38, 'dropout_rate': 0.156777688052391, 'n_estimators': 367, 'max_depth': 9, 'learning_rate': 0.048304696867927044, 'subsample': 0.6283578819643862, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7593359404953608.\n",
      "[I 2025-05-12 05:49:05,563] Trial 2 finished with value: 0.7567479487769342 and parameters: {'latent_dim': 57, 'hidden_dim': 137, 'lr': 0.006676495365048187, 'epochs': 23, 'dropout_rate': 0.17507562229846943, 'n_estimators': 439, 'max_depth': 9, 'learning_rate': 0.029962718456002728, 'subsample': 0.9718164810541752, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7593359404953608.\n",
      "[I 2025-05-12 05:49:16,447] Trial 3 finished with value: 0.7602944559466298 and parameters: {'latent_dim': 56, 'hidden_dim': 187, 'lr': 0.0044643021942006025, 'epochs': 18, 'dropout_rate': 0.49841943941917477, 'n_estimators': 86, 'max_depth': 4, 'learning_rate': 0.03636971174494297, 'subsample': 0.6326193748065297, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.7602944559466298.\n",
      "[I 2025-05-12 05:49:50,855] Trial 4 finished with value: 0.7423510466988729 and parameters: {'latent_dim': 91, 'hidden_dim': 121, 'lr': 0.0004405540513534086, 'epochs': 34, 'dropout_rate': 0.21144456891404906, 'n_estimators': 129, 'max_depth': 8, 'learning_rate': 0.23562393225486053, 'subsample': 0.7204335145044524, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.7602944559466298.\n",
      "[I 2025-05-12 05:50:46,196] Trial 5 finished with value: 0.7545433632390154 and parameters: {'latent_dim': 29, 'hidden_dim': 227, 'lr': 0.0003384017121041978, 'epochs': 49, 'dropout_rate': 0.24508771797115242, 'n_estimators': 428, 'max_depth': 7, 'learning_rate': 0.01936386887747824, 'subsample': 0.8076462317921106, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.7602944559466298.\n",
      "[I 2025-05-12 05:51:27,158] Trial 6 finished with value: 0.7438271604938271 and parameters: {'latent_dim': 84, 'hidden_dim': 194, 'lr': 0.007225164325806888, 'epochs': 14, 'dropout_rate': 0.16015967787000107, 'n_estimators': 276, 'max_depth': 5, 'learning_rate': 0.2354031661848075, 'subsample': 0.7249612021154859, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.7602944559466298.\n",
      "[I 2025-05-12 05:51:50,203] Trial 7 finished with value: 0.7488306111494518 and parameters: {'latent_dim': 46, 'hidden_dim': 210, 'lr': 0.00211641612713141, 'epochs': 33, 'dropout_rate': 0.358240189886211, 'n_estimators': 86, 'max_depth': 8, 'learning_rate': 0.012722206996459784, 'subsample': 0.9284893883907931, 'min_samples_split': 18, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.7602944559466298.\n",
      "[I 2025-05-12 05:52:26,321] Trial 8 finished with value: 0.7346062418526187 and parameters: {'latent_dim': 10, 'hidden_dim': 145, 'lr': 0.0011923215924596869, 'epochs': 41, 'dropout_rate': 0.47652192965024465, 'n_estimators': 443, 'max_depth': 8, 'learning_rate': 0.14247098836507793, 'subsample': 0.697359633250984, 'min_samples_split': 15, 'min_samples_leaf': 7}. Best is trial 3 with value: 0.7602944559466298.\n",
      "[I 2025-05-12 05:52:54,354] Trial 9 finished with value: 0.7456675101602638 and parameters: {'latent_dim': 20, 'hidden_dim': 256, 'lr': 0.0001928794179108348, 'epochs': 44, 'dropout_rate': 0.3169793332864386, 'n_estimators': 246, 'max_depth': 6, 'learning_rate': 0.29266424149203346, 'subsample': 0.7145986304428361, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.7602944559466298.\n",
      "[I 2025-05-12 05:53:08,814] Trial 10 finished with value: 0.7401081205429031 and parameters: {'latent_dim': 44, 'hidden_dim': 173, 'lr': 0.0025919428278114334, 'epochs': 24, 'dropout_rate': 0.48944132886658737, 'n_estimators': 177, 'max_depth': 3, 'learning_rate': 0.08448923242638265, 'subsample': 0.6158936043149932, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.7602944559466298.\n",
      "[I 2025-05-12 05:53:38,740] Trial 11 finished with value: 0.7507859826700406 and parameters: {'latent_dim': 70, 'hidden_dim': 179, 'lr': 0.0008024556438911475, 'epochs': 10, 'dropout_rate': 0.4017870476651213, 'n_estimators': 324, 'max_depth': 3, 'learning_rate': 0.03594026697913631, 'subsample': 0.8473392174190746, 'min_samples_split': 13, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.7602944559466298.\n",
      "[I 2025-05-12 05:54:15,053] Trial 12 finished with value: 0.767790046775554 and parameters: {'latent_dim': 98, 'hidden_dim': 227, 'lr': 0.0033836238651905083, 'epochs': 18, 'dropout_rate': 0.4134220733410736, 'n_estimators': 207, 'max_depth': 4, 'learning_rate': 0.018772257167736704, 'subsample': 0.8784245612064685, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.767790046775554.\n",
      "[I 2025-05-12 05:54:52,092] Trial 13 finished with value: 0.7690744574802547 and parameters: {'latent_dim': 99, 'hidden_dim': 240, 'lr': 0.004041760485639844, 'epochs': 20, 'dropout_rate': 0.42659489183032234, 'n_estimators': 172, 'max_depth': 5, 'learning_rate': 0.010139322916877185, 'subsample': 0.8854949356218518, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 13 with value: 0.7690744574802547.\n",
      "[I 2025-05-12 05:55:34,845] Trial 14 finished with value: 0.7623648493213712 and parameters: {'latent_dim': 99, 'hidden_dim': 256, 'lr': 0.0026480306797642275, 'epochs': 25, 'dropout_rate': 0.4224989196395022, 'n_estimators': 196, 'max_depth': 5, 'learning_rate': 0.010659131797660962, 'subsample': 0.9004470744192814, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 13 with value: 0.7690744574802547.\n",
      "[I 2025-05-12 05:56:15,811] Trial 15 finished with value: 0.7671957671957671 and parameters: {'latent_dim': 98, 'hidden_dim': 229, 'lr': 0.009722394719069877, 'epochs': 19, 'dropout_rate': 0.4171062842118413, 'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.013588347182800728, 'subsample': 0.8791179044973698, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.7690744574802547.\n",
      "[I 2025-05-12 05:57:08,671] Trial 16 finished with value: 0.7543324898397361 and parameters: {'latent_dim': 69, 'hidden_dim': 224, 'lr': 0.0014540315741999163, 'epochs': 28, 'dropout_rate': 0.37452182698119507, 'n_estimators': 245, 'max_depth': 6, 'learning_rate': 0.017275969507720774, 'subsample': 0.9915569808962909, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 13 with value: 0.7690744574802547.\n",
      "[I 2025-05-12 05:57:31,657] Trial 17 finished with value: 0.7615980369603558 and parameters: {'latent_dim': 82, 'hidden_dim': 241, 'lr': 0.004031183261377659, 'epochs': 19, 'dropout_rate': 0.10029045400331038, 'n_estimators': 144, 'max_depth': 4, 'learning_rate': 0.010222537634197271, 'subsample': 0.8295612172552675, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.7690744574802547.\n",
      "[I 2025-05-12 05:57:44,511] Trial 18 finished with value: 0.7510351966873706 and parameters: {'latent_dim': 91, 'hidden_dim': 97, 'lr': 0.004122738533950235, 'epochs': 16, 'dropout_rate': 0.45237599718425614, 'n_estimators': 59, 'max_depth': 4, 'learning_rate': 0.07660264246238208, 'subsample': 0.9320902074082423, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 13 with value: 0.7690744574802547.\n",
      "[I 2025-05-12 05:58:40,943] Trial 19 finished with value: 0.7522237558469441 and parameters: {'latent_dim': 76, 'hidden_dim': 159, 'lr': 0.00012392117350202845, 'epochs': 10, 'dropout_rate': 0.3416130349144241, 'n_estimators': 263, 'max_depth': 10, 'learning_rate': 0.02655639228623798, 'subsample': 0.777272450718561, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 13 with value: 0.7690744574802547.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7794\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры градиентного бустинга\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7379\n",
      "ROC-AUC autoencoded: 0.7279\n",
      "ROC-AUC autoencoded: 0.7371\n",
      "ROC-AUC autoencoded: 0.7453\n",
      "ROC-AUC autoencoded: 0.7640\n",
      "ROC-AUC autoencoded: 0.7487\n",
      "ROC-AUC autoencoded: 0.7313\n",
      "ROC-AUC autoencoded: 0.7317\n",
      "ROC-AUC autoencoded: 0.7370\n",
      "ROC-AUC autoencoded: 0.7340\n",
      "ROC-AUC autoencoded: 0.7254\n",
      "ROC-AUC autoencoded: 0.7209\n",
      "ROC-AUC autoencoded: 0.7113\n",
      "ROC-AUC autoencoded: 0.7313\n",
      "ROC-AUC autoencoded: 0.7157\n",
      "ROC-AUC autoencoded: 0.7066\n",
      "ROC-AUC autoencoded: 0.7042\n",
      "ROC-AUC autoencoded: 0.7050\n",
      "ROC-AUC autoencoded: 0.7044\n",
      "ROC-AUC autoencoded: 0.6984\n",
      "ROC-AUC autoencoded: 0.7668\n",
      "ROC-AUC autoencoded: 0.7525\n",
      "ROC-AUC autoencoded: 0.7782\n",
      "ROC-AUC autoencoded: 0.7595\n",
      "ROC-AUC autoencoded: 0.7506\n",
      "среднее 0.7330400099780411\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь с SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 06:02:49,373] A new study created in memory with name: no-name-b5fc7571-d841-49ac-a184-67e486b5614b\n",
      "[I 2025-05-12 06:02:54,209] Trial 0 finished with value: 0.630578559926386 and parameters: {'latent_dim': 87, 'hidden_dim': 191, 'lr': 0.0012527882948584835, 'epochs': 14, 'dropout_rate': 0.2725479564296007, 'C': 1.9657298584416383, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.630578559926386.\n",
      "[I 2025-05-12 06:02:59,910] Trial 1 finished with value: 0.6972433095621501 and parameters: {'latent_dim': 70, 'hidden_dim': 234, 'lr': 0.0015311327643555016, 'epochs': 14, 'dropout_rate': 0.3328983472631857, 'C': 28.770943859471153, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 1 with value: 0.6972433095621501.\n",
      "[I 2025-05-12 06:03:12,196] Trial 2 finished with value: 0.7297561536691971 and parameters: {'latent_dim': 32, 'hidden_dim': 119, 'lr': 0.003032040067324558, 'epochs': 30, 'dropout_rate': 0.4990933703431676, 'C': 0.10378849162022666, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 2 with value: 0.7297561536691971.\n",
      "[I 2025-05-12 06:03:30,752] Trial 3 finished with value: 0.7548309178743962 and parameters: {'latent_dim': 36, 'hidden_dim': 227, 'lr': 0.0010268517091555763, 'epochs': 50, 'dropout_rate': 0.11705615694240544, 'C': 0.17026054252654493, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.7548309178743962.\n",
      "[I 2025-05-12 06:03:37,105] Trial 4 finished with value: 0.6881949237021701 and parameters: {'latent_dim': 96, 'hidden_dim': 166, 'lr': 0.0012540783481834249, 'epochs': 19, 'dropout_rate': 0.42200395612968555, 'C': 1.3552804522857982, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 3 with value: 0.7548309178743962.\n",
      "[I 2025-05-12 06:03:42,651] Trial 5 finished with value: 0.6404800245379957 and parameters: {'latent_dim': 75, 'hidden_dim': 80, 'lr': 0.0076354226683836585, 'epochs': 20, 'dropout_rate': 0.13119697077129988, 'C': 22.31254551260221, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 3 with value: 0.7548309178743962.\n",
      "[I 2025-05-12 06:03:46,324] Trial 6 finished with value: 0.7625277969480867 and parameters: {'latent_dim': 31, 'hidden_dim': 98, 'lr': 0.0002756153827055648, 'epochs': 11, 'dropout_rate': 0.22470524050526916, 'C': 0.3046888969729205, 'kernel': 'linear'}. Best is trial 6 with value: 0.7625277969480867.\n",
      "[I 2025-05-12 06:03:59,286] Trial 7 finished with value: 0.5398742427727935 and parameters: {'latent_dim': 10, 'hidden_dim': 210, 'lr': 0.004796681822628278, 'epochs': 43, 'dropout_rate': 0.32829162319013055, 'C': 2.3337087072655573, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 6 with value: 0.7625277969480867.\n",
      "[I 2025-05-12 06:04:06,240] Trial 8 finished with value: 0.6860574342458401 and parameters: {'latent_dim': 73, 'hidden_dim': 73, 'lr': 0.008072064276451602, 'epochs': 22, 'dropout_rate': 0.1709323066065303, 'C': 2.683331532458882, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 6 with value: 0.7625277969480867.\n",
      "[I 2025-05-12 06:04:15,655] Trial 9 finished with value: 0.7411241469212483 and parameters: {'latent_dim': 28, 'hidden_dim': 183, 'lr': 0.00016457564780471853, 'epochs': 29, 'dropout_rate': 0.43195443115051435, 'C': 0.16214098913625655, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 6 with value: 0.7625277969480867.\n",
      "[I 2025-05-12 06:04:27,676] Trial 10 finished with value: 0.7676750249214018 and parameters: {'latent_dim': 52, 'hidden_dim': 122, 'lr': 0.0002472750083670084, 'epochs': 39, 'dropout_rate': 0.22922722201917772, 'C': 0.5241847022652434, 'kernel': 'linear'}. Best is trial 10 with value: 0.7676750249214018.\n",
      "[I 2025-05-12 06:04:39,609] Trial 11 finished with value: 0.7619047619047619 and parameters: {'latent_dim': 49, 'hidden_dim': 124, 'lr': 0.00027549622650238273, 'epochs': 38, 'dropout_rate': 0.23238348527120212, 'C': 0.5385462833485793, 'kernel': 'linear'}. Best is trial 10 with value: 0.7676750249214018.\n",
      "[I 2025-05-12 06:04:51,493] Trial 12 finished with value: 0.7478337550801318 and parameters: {'latent_dim': 51, 'hidden_dim': 122, 'lr': 0.00039794924988166493, 'epochs': 38, 'dropout_rate': 0.2324092847303728, 'C': 0.5618989085484621, 'kernel': 'linear'}. Best is trial 10 with value: 0.7676750249214018.\n",
      "[I 2025-05-12 06:05:07,042] Trial 13 finished with value: 0.7679338240932445 and parameters: {'latent_dim': 15, 'hidden_dim': 103, 'lr': 0.00010379342793012889, 'epochs': 38, 'dropout_rate': 0.18658068868128116, 'C': 9.78168242024382, 'kernel': 'linear'}. Best is trial 13 with value: 0.7679338240932445.\n",
      "[I 2025-05-12 06:05:23,288] Trial 14 finished with value: 0.7718349819799095 and parameters: {'latent_dim': 16, 'hidden_dim': 149, 'lr': 0.00010532209641893483, 'epochs': 37, 'dropout_rate': 0.19122575073047246, 'C': 10.847385338766248, 'kernel': 'linear'}. Best is trial 14 with value: 0.7718349819799095.\n",
      "[I 2025-05-12 06:05:41,271] Trial 15 finished with value: 0.7601027528563761 and parameters: {'latent_dim': 12, 'hidden_dim': 149, 'lr': 0.000103866784770315, 'epochs': 46, 'dropout_rate': 0.1760428812098537, 'C': 9.449516297977201, 'kernel': 'linear'}. Best is trial 14 with value: 0.7718349819799095.\n",
      "[I 2025-05-12 06:06:57,728] Trial 16 finished with value: 0.7661318150448585 and parameters: {'latent_dim': 20, 'hidden_dim': 155, 'lr': 0.0006002822367397208, 'epochs': 34, 'dropout_rate': 0.17840960989268026, 'C': 94.81912980872004, 'kernel': 'linear'}. Best is trial 14 with value: 0.7718349819799095.\n",
      "[I 2025-05-12 06:07:15,508] Trial 17 finished with value: 0.760505329345909 and parameters: {'latent_dim': 18, 'hidden_dim': 93, 'lr': 0.00010545581147702398, 'epochs': 34, 'dropout_rate': 0.29946319254422826, 'C': 7.784868453854948, 'kernel': 'linear'}. Best is trial 14 with value: 0.7718349819799095.\n",
      "[I 2025-05-12 06:07:39,685] Trial 18 finished with value: 0.7634767272448432 and parameters: {'latent_dim': 42, 'hidden_dim': 142, 'lr': 0.0001635052509964191, 'epochs': 43, 'dropout_rate': 0.1108916025953894, 'C': 6.50752541405116, 'kernel': 'linear'}. Best is trial 14 with value: 0.7718349819799095.\n",
      "[I 2025-05-12 06:07:48,241] Trial 19 finished with value: 0.7066655164481251 and parameters: {'latent_dim': 23, 'hidden_dim': 101, 'lr': 0.0005182440001236162, 'epochs': 26, 'dropout_rate': 0.15554497045874563, 'C': 30.051627051540265, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 14 with value: 0.7718349819799095.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7760\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры SVC\n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if best_params['kernel'] in ['rbf', 'poly', 'sigmoid'] else 'scale',\n",
    "    degree=best_params['degree'] if best_params['kernel'] == 'poly' else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7818\n",
      "ROC-AUC autoencoded: 0.7515\n",
      "ROC-AUC autoencoded: 0.7437\n",
      "ROC-AUC autoencoded: 0.7458\n",
      "ROC-AUC autoencoded: 0.7661\n",
      "ROC-AUC autoencoded: 0.7540\n",
      "ROC-AUC autoencoded: 0.7840\n",
      "ROC-AUC autoencoded: 0.7695\n",
      "ROC-AUC autoencoded: 0.7798\n",
      "ROC-AUC autoencoded: 0.7559\n",
      "ROC-AUC autoencoded: 0.7482\n",
      "ROC-AUC autoencoded: 0.7590\n",
      "ROC-AUC autoencoded: 0.7264\n",
      "ROC-AUC autoencoded: 0.7336\n",
      "ROC-AUC autoencoded: 0.7613\n",
      "ROC-AUC autoencoded: 0.7094\n",
      "ROC-AUC autoencoded: 0.7267\n",
      "ROC-AUC autoencoded: 0.6959\n",
      "ROC-AUC autoencoded: 0.7216\n",
      "ROC-AUC autoencoded: 0.7084\n",
      "ROC-AUC autoencoded: 0.7495\n",
      "ROC-AUC autoencoded: 0.7441\n",
      "ROC-AUC autoencoded: 0.7343\n",
      "ROC-AUC autoencoded: 0.7345\n",
      "ROC-AUC autoencoded: 0.7403\n",
      "среднее 0.745022075194766\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if best_params['kernel'] in ['rbf', 'poly', 'sigmoid'] else 'scale',\n",
    "            degree=best_params['degree'] if best_params['kernel'] == 'poly' else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 06:09:38,422] A new study created in memory with name: no-name-c4efd536-64dd-44d6-b63a-00ee9cce4aea\n",
      "[I 2025-05-12 06:09:53,742] Trial 0 finished with value: 0.7192124837052373 and parameters: {'latent_dim': 70, 'hidden_dim_ae': 114, 'lr_ae': 0.004107250369895147, 'epochs_ae': 43, 'dropout_rate_ae': 0.356202405349448, 'hidden_dim_mlp': 112, 'lr_mlp': 0.0021539876477346593, 'batch_size_mlp': 64, 'epochs_mlp': 43, 'dropout_rate_mlp': 0.20263084335730738}. Best is trial 0 with value: 0.7192124837052373.\n",
      "[I 2025-05-12 06:10:02,196] Trial 1 finished with value: 0.7394755003450655 and parameters: {'latent_dim': 39, 'hidden_dim_ae': 147, 'lr_ae': 0.00140977958540418, 'epochs_ae': 22, 'dropout_rate_ae': 0.1730520761697238, 'hidden_dim_mlp': 80, 'lr_mlp': 0.0013549126947154351, 'batch_size_mlp': 64, 'epochs_mlp': 28, 'dropout_rate_mlp': 0.33050532120097886}. Best is trial 1 with value: 0.7394755003450655.\n",
      "[I 2025-05-12 06:10:18,624] Trial 2 finished with value: 0.7578023157733303 and parameters: {'latent_dim': 40, 'hidden_dim_ae': 251, 'lr_ae': 0.007969115014390264, 'epochs_ae': 16, 'dropout_rate_ae': 0.48330847628329376, 'hidden_dim_mlp': 51, 'lr_mlp': 0.0008928007193929492, 'batch_size_mlp': 16, 'epochs_mlp': 44, 'dropout_rate_mlp': 0.35451661924602207}. Best is trial 2 with value: 0.7578023157733303.\n",
      "[I 2025-05-12 06:10:33,754] Trial 3 finished with value: 0.7801740664059503 and parameters: {'latent_dim': 36, 'hidden_dim_ae': 255, 'lr_ae': 0.00020080998677421394, 'epochs_ae': 42, 'dropout_rate_ae': 0.33042479424579946, 'hidden_dim_mlp': 97, 'lr_mlp': 0.0001951884767987449, 'batch_size_mlp': 64, 'epochs_mlp': 26, 'dropout_rate_mlp': 0.3932688059559809}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:10:48,402] Trial 4 finished with value: 0.7320949313702937 and parameters: {'latent_dim': 88, 'hidden_dim_ae': 156, 'lr_ae': 0.00021136283384362215, 'epochs_ae': 44, 'dropout_rate_ae': 0.1308852123462949, 'hidden_dim_mlp': 46, 'lr_mlp': 0.006064898768946829, 'batch_size_mlp': 64, 'epochs_mlp': 19, 'dropout_rate_mlp': 0.28228782344838366}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:10:57,539] Trial 5 finished with value: 0.768691051299747 and parameters: {'latent_dim': 94, 'hidden_dim_ae': 162, 'lr_ae': 0.0005761288345591434, 'epochs_ae': 16, 'dropout_rate_ae': 0.2555529761831226, 'hidden_dim_mlp': 104, 'lr_mlp': 0.00010208439071308863, 'batch_size_mlp': 32, 'epochs_mlp': 28, 'dropout_rate_mlp': 0.41672172553423237}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:11:13,859] Trial 6 finished with value: 0.7685568591365692 and parameters: {'latent_dim': 50, 'hidden_dim_ae': 252, 'lr_ae': 0.003991046090067737, 'epochs_ae': 43, 'dropout_rate_ae': 0.19656033379659413, 'hidden_dim_mlp': 51, 'lr_mlp': 0.00993054184193723, 'batch_size_mlp': 32, 'epochs_mlp': 19, 'dropout_rate_mlp': 0.46888588909319806}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:11:25,044] Trial 7 finished with value: 0.75954681389464 and parameters: {'latent_dim': 87, 'hidden_dim_ae': 194, 'lr_ae': 0.0008706110050516469, 'epochs_ae': 29, 'dropout_rate_ae': 0.24038221040021865, 'hidden_dim_mlp': 33, 'lr_mlp': 0.0006347851245690037, 'batch_size_mlp': 64, 'epochs_mlp': 34, 'dropout_rate_mlp': 0.30265341811107727}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:11:43,898] Trial 8 finished with value: 0.7427152825703551 and parameters: {'latent_dim': 34, 'hidden_dim_ae': 149, 'lr_ae': 0.0001658776274358216, 'epochs_ae': 50, 'dropout_rate_ae': 0.49245776236432726, 'hidden_dim_mlp': 95, 'lr_mlp': 0.0036848010602708327, 'batch_size_mlp': 32, 'epochs_mlp': 32, 'dropout_rate_mlp': 0.4932368536050725}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:12:09,824] Trial 9 finished with value: 0.7096848401196226 and parameters: {'latent_dim': 80, 'hidden_dim_ae': 200, 'lr_ae': 0.00015707692798084763, 'epochs_ae': 50, 'dropout_rate_ae': 0.43981706557651734, 'hidden_dim_mlp': 58, 'lr_mlp': 0.007460757427418271, 'batch_size_mlp': 16, 'epochs_mlp': 40, 'dropout_rate_mlp': 0.22034922778581648}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:12:19,326] Trial 10 finished with value: 0.7605820105820107 and parameters: {'latent_dim': 11, 'hidden_dim_ae': 64, 'lr_ae': 0.0004564798997100464, 'epochs_ae': 34, 'dropout_rate_ae': 0.3530876085502536, 'hidden_dim_mlp': 126, 'lr_mlp': 0.0002002094586657657, 'batch_size_mlp': 64, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.1163798102923494}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:12:26,632] Trial 11 finished with value: 0.7760907905835442 and parameters: {'latent_dim': 64, 'hidden_dim_ae': 213, 'lr_ae': 0.00043493391032142255, 'epochs_ae': 11, 'dropout_rate_ae': 0.28764930279015044, 'hidden_dim_mlp': 88, 'lr_mlp': 0.0001008325717345885, 'batch_size_mlp': 32, 'epochs_mlp': 26, 'dropout_rate_mlp': 0.4246268878841414}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:12:32,808] Trial 12 finished with value: 0.7624031899394218 and parameters: {'latent_dim': 62, 'hidden_dim_ae': 220, 'lr_ae': 0.00033412040291932554, 'epochs_ae': 10, 'dropout_rate_ae': 0.3274358462959841, 'hidden_dim_mlp': 80, 'lr_mlp': 0.0002960921923155288, 'batch_size_mlp': 32, 'epochs_mlp': 22, 'dropout_rate_mlp': 0.3971587817676053}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:12:46,411] Trial 13 finished with value: 0.769745418296143 and parameters: {'latent_dim': 20, 'hidden_dim_ae': 226, 'lr_ae': 0.0011346336693609288, 'epochs_ae': 33, 'dropout_rate_ae': 0.3949221136516428, 'hidden_dim_mlp': 94, 'lr_mlp': 0.00010547213817560646, 'batch_size_mlp': 32, 'epochs_mlp': 24, 'dropout_rate_mlp': 0.43191422973841737}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:12:57,223] Trial 14 finished with value: 0.7649145004217468 and parameters: {'latent_dim': 54, 'hidden_dim_ae': 229, 'lr_ae': 0.00010038343362894366, 'epochs_ae': 26, 'dropout_rate_ae': 0.28736862988085393, 'hidden_dim_mlp': 75, 'lr_mlp': 0.0003755003882956544, 'batch_size_mlp': 16, 'epochs_mlp': 11, 'dropout_rate_mlp': 0.3641757538170622}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:13:11,418] Trial 15 finished with value: 0.7751131048232498 and parameters: {'latent_dim': 70, 'hidden_dim_ae': 191, 'lr_ae': 0.0003418178268689706, 'epochs_ae': 38, 'dropout_rate_ae': 0.29781400493232624, 'hidden_dim_mlp': 66, 'lr_mlp': 0.00019448482737398205, 'batch_size_mlp': 64, 'epochs_mlp': 35, 'dropout_rate_mlp': 0.44661174911063173}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:13:25,769] Trial 16 finished with value: 0.7764166858369758 and parameters: {'latent_dim': 21, 'hidden_dim_ae': 249, 'lr_ae': 0.0006934868541654144, 'epochs_ae': 22, 'dropout_rate_ae': 0.3969718179946326, 'hidden_dim_mlp': 94, 'lr_mlp': 0.00017069101328875358, 'batch_size_mlp': 32, 'epochs_mlp': 49, 'dropout_rate_mlp': 0.3938508440436456}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:13:37,242] Trial 17 finished with value: 0.7594893029675638 and parameters: {'latent_dim': 26, 'hidden_dim_ae': 256, 'lr_ae': 0.001966293856230368, 'epochs_ae': 23, 'dropout_rate_ae': 0.40223231274470306, 'hidden_dim_mlp': 113, 'lr_mlp': 0.00037957708877254826, 'batch_size_mlp': 64, 'epochs_mlp': 48, 'dropout_rate_mlp': 0.2589737986797763}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:13:54,927] Trial 18 finished with value: 0.7668123610152596 and parameters: {'latent_dim': 10, 'hidden_dim_ae': 111, 'lr_ae': 0.0007152683462734448, 'epochs_ae': 37, 'dropout_rate_ae': 0.4244520469696313, 'hidden_dim_mlp': 105, 'lr_mlp': 0.00019821829755336382, 'batch_size_mlp': 32, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.3782070367830035}. Best is trial 3 with value: 0.7801740664059503.\n",
      "[I 2025-05-12 06:14:05,237] Trial 19 finished with value: 0.7636109194080207 and parameters: {'latent_dim': 25, 'hidden_dim_ae': 236, 'lr_ae': 0.00026264300169683805, 'epochs_ae': 19, 'dropout_rate_ae': 0.3655943375293763, 'hidden_dim_mlp': 120, 'lr_mlp': 0.0005970877978672199, 'batch_size_mlp': 16, 'epochs_mlp': 16, 'dropout_rate_mlp': 0.32902183611612834}. Best is trial 3 with value: 0.7801740664059503.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7844\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры MLP\n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    batch_size_mlp = trial.suggest_categorical('batch_size_mlp', [16, 32, 64])\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size_mlp, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], best_params['batch_size_mlp'], best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7688\n",
      "ROC-AUC autoencoded: 0.7628\n",
      "ROC-AUC autoencoded: 0.7632\n",
      "ROC-AUC autoencoded: 0.7412\n",
      "ROC-AUC autoencoded: 0.7567\n",
      "ROC-AUC autoencoded: 0.7725\n",
      "ROC-AUC autoencoded: 0.7747\n",
      "ROC-AUC autoencoded: 0.7606\n",
      "ROC-AUC autoencoded: 0.7631\n",
      "ROC-AUC autoencoded: 0.7715\n",
      "ROC-AUC autoencoded: 0.7468\n",
      "ROC-AUC autoencoded: 0.7277\n",
      "ROC-AUC autoencoded: 0.7468\n",
      "ROC-AUC autoencoded: 0.7475\n",
      "ROC-AUC autoencoded: 0.7552\n",
      "ROC-AUC autoencoded: 0.7267\n",
      "ROC-AUC autoencoded: 0.7195\n",
      "ROC-AUC autoencoded: 0.7348\n",
      "ROC-AUC autoencoded: 0.7225\n",
      "ROC-AUC autoencoded: 0.7298\n",
      "ROC-AUC autoencoded: 0.7796\n",
      "ROC-AUC autoencoded: 0.7633\n",
      "ROC-AUC autoencoded: 0.7786\n",
      "ROC-AUC autoencoded: 0.7816\n",
      "ROC-AUC autoencoded: 0.7632\n",
      "среднее 0.7543517857237504\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], best_params['batch_size_mlp'], best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок с классическим автоэнкодером с второй классифицирующей головой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "логситическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 06:15:52,602] A new study created in memory with name: no-name-49435977-5f55-4594-a037-772cc8ea16cd\n",
      "[I 2025-05-12 06:16:10,482] Trial 0 finished with value: 0.6157503258952534 and parameters: {'latent_dim': 95, 'hidden_dim': 183, 'lr': 0.006577630294304436, 'epochs': 49, 'dropout_rate': 0.47441377509145444, 'recon_weight': 0.13849671815130052, 'C': 6.3465769028642445}. Best is trial 0 with value: 0.6157503258952534.\n",
      "[I 2025-05-12 06:16:26,308] Trial 1 finished with value: 0.6928533087953378 and parameters: {'latent_dim': 20, 'hidden_dim': 230, 'lr': 0.0034229236324209897, 'epochs': 44, 'dropout_rate': 0.20186191802150302, 'recon_weight': 0.2827226666883006, 'C': 0.01853193107909476}. Best is trial 1 with value: 0.6928533087953378.\n",
      "[I 2025-05-12 06:16:37,200] Trial 2 finished with value: 0.6303772716816195 and parameters: {'latent_dim': 78, 'hidden_dim': 181, 'lr': 0.008955111118752147, 'epochs': 30, 'dropout_rate': 0.1793422865510065, 'recon_weight': 0.514404440124913, 'C': 0.015460917441153932}. Best is trial 1 with value: 0.6928533087953378.\n",
      "[I 2025-05-12 06:16:45,852] Trial 3 finished with value: 0.5943466758684149 and parameters: {'latent_dim': 58, 'hidden_dim': 175, 'lr': 0.002758938166492363, 'epochs': 24, 'dropout_rate': 0.18559645481661946, 'recon_weight': 0.4429181490116676, 'C': 21.36494407391144}. Best is trial 1 with value: 0.6928533087953378.\n",
      "[I 2025-05-12 06:16:58,814] Trial 4 finished with value: 0.5831991411701557 and parameters: {'latent_dim': 61, 'hidden_dim': 190, 'lr': 0.000810069934614143, 'epochs': 36, 'dropout_rate': 0.1068231357188516, 'recon_weight': 0.8401078321008608, 'C': 12.153558479650291}. Best is trial 1 with value: 0.6928533087953378.\n",
      "[I 2025-05-12 06:17:07,839] Trial 5 finished with value: 0.7429644965876849 and parameters: {'latent_dim': 25, 'hidden_dim': 233, 'lr': 0.00020448061943231674, 'epochs': 25, 'dropout_rate': 0.22334806360024137, 'recon_weight': 0.6220851912879015, 'C': 0.0979646797707119}. Best is trial 5 with value: 0.7429644965876849.\n",
      "[I 2025-05-12 06:17:15,267] Trial 6 finished with value: 0.7329767655854612 and parameters: {'latent_dim': 57, 'hidden_dim': 112, 'lr': 0.0006648910938949448, 'epochs': 22, 'dropout_rate': 0.22839074808786483, 'recon_weight': 0.5072111921424839, 'C': 0.011067301886775929}. Best is trial 5 with value: 0.7429644965876849.\n",
      "[I 2025-05-12 06:17:24,319] Trial 7 finished with value: 0.6554136952687678 and parameters: {'latent_dim': 97, 'hidden_dim': 87, 'lr': 0.00662998035157093, 'epochs': 27, 'dropout_rate': 0.28520185062538794, 'recon_weight': 0.7161085976569609, 'C': 87.27151532919241}. Best is trial 5 with value: 0.7429644965876849.\n",
      "[I 2025-05-12 06:17:28,339] Trial 8 finished with value: 0.6433939115098535 and parameters: {'latent_dim': 61, 'hidden_dim': 172, 'lr': 0.0014820102096223125, 'epochs': 11, 'dropout_rate': 0.19713277365356105, 'recon_weight': 0.5004500693284089, 'C': 1.1086909463710715}. Best is trial 5 with value: 0.7429644965876849.\n",
      "[I 2025-05-12 06:17:44,100] Trial 9 finished with value: 0.7401081205429033 and parameters: {'latent_dim': 58, 'hidden_dim': 97, 'lr': 0.003133093059025916, 'epochs': 48, 'dropout_rate': 0.3095550589216566, 'recon_weight': 0.8705692300525595, 'C': 0.08568585564468773}. Best is trial 5 with value: 0.7429644965876849.\n",
      "[I 2025-05-12 06:17:50,169] Trial 10 finished with value: 0.7720650256882141 and parameters: {'latent_dim': 15, 'hidden_dim': 248, 'lr': 0.00014784613136147626, 'epochs': 16, 'dropout_rate': 0.3939971012237228, 'recon_weight': 0.6791775559523805, 'C': 0.21187086703186012}. Best is trial 10 with value: 0.7720650256882141.\n",
      "[I 2025-05-12 06:17:55,665] Trial 11 finished with value: 0.7723334100145695 and parameters: {'latent_dim': 11, 'hidden_dim': 252, 'lr': 0.00015795979769539931, 'epochs': 15, 'dropout_rate': 0.4154206877301195, 'recon_weight': 0.6824146065345988, 'C': 0.22257983255501393}. Best is trial 11 with value: 0.7723334100145695.\n",
      "[I 2025-05-12 06:18:00,632] Trial 12 finished with value: 0.773215244229737 and parameters: {'latent_dim': 10, 'hidden_dim': 256, 'lr': 0.00010585619439656732, 'epochs': 12, 'dropout_rate': 0.432301520055933, 'recon_weight': 0.7071837310455682, 'C': 0.4762272118637704}. Best is trial 12 with value: 0.773215244229737.\n",
      "[I 2025-05-12 06:18:04,949] Trial 13 finished with value: 0.7597385169848937 and parameters: {'latent_dim': 35, 'hidden_dim': 214, 'lr': 0.0003076909676554466, 'epochs': 10, 'dropout_rate': 0.49647585007290396, 'recon_weight': 0.768394205358924, 'C': 0.7380273305676432}. Best is trial 12 with value: 0.773215244229737.\n",
      "[I 2025-05-12 06:18:11,559] Trial 14 finished with value: 0.7567096081588836 and parameters: {'latent_dim': 38, 'hidden_dim': 135, 'lr': 0.00010555133313172077, 'epochs': 17, 'dropout_rate': 0.4028365294544228, 'recon_weight': 0.6216470222558528, 'C': 1.07239582139788}. Best is trial 12 with value: 0.773215244229737.\n",
      "[I 2025-05-12 06:18:18,794] Trial 15 finished with value: 0.756537075377655 and parameters: {'latent_dim': 12, 'hidden_dim': 249, 'lr': 0.0003520633000143409, 'epochs': 18, 'dropout_rate': 0.4131076279764956, 'recon_weight': 0.36465292973356594, 'C': 0.3197870836445248}. Best is trial 12 with value: 0.773215244229737.\n",
      "[I 2025-05-12 06:18:23,697] Trial 16 finished with value: 0.7522620964649951 and parameters: {'latent_dim': 36, 'hidden_dim': 213, 'lr': 0.00039589481239512967, 'epochs': 13, 'dropout_rate': 0.35079563119667034, 'recon_weight': 0.7623437876890993, 'C': 3.3288249910442933}. Best is trial 12 with value: 0.773215244229737.\n",
      "[I 2025-05-12 06:18:36,933] Trial 17 finished with value: 0.7621923165401426 and parameters: {'latent_dim': 27, 'hidden_dim': 206, 'lr': 0.00020507901560910385, 'epochs': 36, 'dropout_rate': 0.4435186833469115, 'recon_weight': 0.6045902737512439, 'C': 0.04654086578825358}. Best is trial 12 with value: 0.773215244229737.\n",
      "[I 2025-05-12 06:18:43,696] Trial 18 finished with value: 0.7793689134268845 and parameters: {'latent_dim': 45, 'hidden_dim': 149, 'lr': 0.00010035664194743873, 'epochs': 19, 'dropout_rate': 0.3541678267655193, 'recon_weight': 0.7902399757161276, 'C': 0.5088748542708232}. Best is trial 18 with value: 0.7793689134268845.\n",
      "[I 2025-05-12 06:18:50,952] Trial 19 finished with value: 0.7558086036346906 and parameters: {'latent_dim': 75, 'hidden_dim': 140, 'lr': 0.00010065164925720954, 'epochs': 20, 'dropout_rate': 0.34233519154414094, 'recon_weight': 0.8938376387816277, 'C': 2.9459891286250186}. Best is trial 18 with value: 0.7793689134268845.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7545\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(ClassifyingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "\n",
    "def train_classifying_autoencoder(model, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    class_criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _, classification = model(batch_x)\n",
    "            \n",
    "            recon_loss = recon_criterion(reconstructed, batch_x)\n",
    "            class_loss = class_criterion(classification, batch_y)\n",
    "            \n",
    "            loss = recon_weight * recon_loss + class_weight * class_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent, _ = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Веса для объединенной функции потерь\n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    # Параметры логистической регрессии\n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(C=C, max_iter=1000, random_state=42)\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(C=best_params['C'], max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7381\n",
      "ROC-AUC autoencoded: 0.7544\n",
      "ROC-AUC autoencoded: 0.7246\n",
      "ROC-AUC autoencoded: 0.7405\n",
      "ROC-AUC autoencoded: 0.7507\n",
      "ROC-AUC autoencoded: 0.7894\n",
      "ROC-AUC autoencoded: 0.7705\n",
      "ROC-AUC autoencoded: 0.7552\n",
      "ROC-AUC autoencoded: 0.7666\n",
      "ROC-AUC autoencoded: 0.7613\n",
      "ROC-AUC autoencoded: 0.7287\n",
      "ROC-AUC autoencoded: 0.7284\n",
      "ROC-AUC autoencoded: 0.7267\n",
      "ROC-AUC autoencoded: 0.7662\n",
      "ROC-AUC autoencoded: 0.7185\n",
      "ROC-AUC autoencoded: 0.7156\n",
      "ROC-AUC autoencoded: 0.6846\n",
      "ROC-AUC autoencoded: 0.7050\n",
      "ROC-AUC autoencoded: 0.6913\n",
      "ROC-AUC autoencoded: 0.7150\n",
      "ROC-AUC autoencoded: 0.7716\n",
      "ROC-AUC autoencoded: 0.7492\n",
      "ROC-AUC autoencoded: 0.7411\n",
      "ROC-AUC autoencoded: 0.7666\n",
      "ROC-AUC autoencoded: 0.7337\n",
      "среднее 0.7397349137436232\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(C=best_params['C'], max_iter=1000, random_state=42)\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 06:19:39,876] A new study created in memory with name: no-name-900828db-f4ed-471e-a71f-71770c39e0ce\n",
      "[I 2025-05-12 06:20:26,236] Trial 0 finished with value: 0.7117168928763133 and parameters: {'latent_dim': 80, 'hidden_dim': 209, 'lr': 0.000253666386046076, 'epochs': 17, 'dropout_rate': 0.4379253978599863, 'recon_weight': 0.6470045563852512, 'n_estimators': 492, 'max_depth': 4, 'learning_rate': 0.2954080344910506, 'subsample': 0.6045057239868353, 'min_samples_split': 13, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7117168928763133.\n",
      "[I 2025-05-12 06:20:56,005] Trial 1 finished with value: 0.6435856146001074 and parameters: {'latent_dim': 15, 'hidden_dim': 167, 'lr': 0.008303442896611179, 'epochs': 30, 'dropout_rate': 0.3165962903513129, 'recon_weight': 0.15877667195642636, 'n_estimators': 309, 'max_depth': 8, 'learning_rate': 0.08570807326251753, 'subsample': 0.7068066070727819, 'min_samples_split': 13, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7117168928763133.\n",
      "[I 2025-05-12 06:21:54,638] Trial 2 finished with value: 0.7269764588605168 and parameters: {'latent_dim': 69, 'hidden_dim': 81, 'lr': 0.00018429243497692372, 'epochs': 28, 'dropout_rate': 0.4896721829284222, 'recon_weight': 0.8938805919460572, 'n_estimators': 308, 'max_depth': 9, 'learning_rate': 0.04452159826018346, 'subsample': 0.6902692185438191, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.7269764588605168.\n",
      "[I 2025-05-12 06:22:14,279] Trial 3 finished with value: 0.743462924622345 and parameters: {'latent_dim': 42, 'hidden_dim': 202, 'lr': 0.00013322171702972283, 'epochs': 17, 'dropout_rate': 0.44836023294251726, 'recon_weight': 0.3080594343521662, 'n_estimators': 236, 'max_depth': 4, 'learning_rate': 0.03162287549351051, 'subsample': 0.6769867532986318, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.743462924622345.\n",
      "[I 2025-05-12 06:23:31,812] Trial 4 finished with value: 0.6988536155202821 and parameters: {'latent_dim': 85, 'hidden_dim': 119, 'lr': 0.003316505141548121, 'epochs': 19, 'dropout_rate': 0.4250092152207956, 'recon_weight': 0.5336092820432982, 'n_estimators': 460, 'max_depth': 5, 'learning_rate': 0.12739963967315354, 'subsample': 0.7922387519720888, 'min_samples_split': 15, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.743462924622345.\n",
      "[I 2025-05-12 06:24:02,725] Trial 5 finished with value: 0.6521547427344528 and parameters: {'latent_dim': 45, 'hidden_dim': 209, 'lr': 0.0007576645588188055, 'epochs': 47, 'dropout_rate': 0.1061069511640561, 'recon_weight': 0.5489303679034241, 'n_estimators': 255, 'max_depth': 6, 'learning_rate': 0.2777330024499074, 'subsample': 0.8373975261892722, 'min_samples_split': 15, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.743462924622345.\n",
      "[I 2025-05-12 06:24:40,994] Trial 6 finished with value: 0.6398090637221072 and parameters: {'latent_dim': 26, 'hidden_dim': 225, 'lr': 0.000754606447714559, 'epochs': 24, 'dropout_rate': 0.24198842660546088, 'recon_weight': 0.24291907738929164, 'n_estimators': 498, 'max_depth': 4, 'learning_rate': 0.01455744005650805, 'subsample': 0.906505211137717, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.743462924622345.\n",
      "[I 2025-05-12 06:25:04,300] Trial 7 finished with value: 0.6640786749482402 and parameters: {'latent_dim': 87, 'hidden_dim': 213, 'lr': 0.00010490955990067207, 'epochs': 36, 'dropout_rate': 0.14440023611053154, 'recon_weight': 0.273652068936601, 'n_estimators': 71, 'max_depth': 4, 'learning_rate': 0.2842653748312003, 'subsample': 0.965413647668927, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.743462924622345.\n",
      "[I 2025-05-12 06:25:55,190] Trial 8 finished with value: 0.6383521202361782 and parameters: {'latent_dim': 97, 'hidden_dim': 161, 'lr': 0.005727107803873979, 'epochs': 19, 'dropout_rate': 0.3814166253778094, 'recon_weight': 0.20885303206790137, 'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.06600299788546496, 'subsample': 0.8986456034577509, 'min_samples_split': 20, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.743462924622345.\n",
      "[I 2025-05-12 06:26:49,574] Trial 9 finished with value: 0.7019592055823939 and parameters: {'latent_dim': 84, 'hidden_dim': 229, 'lr': 0.001905734499033289, 'epochs': 43, 'dropout_rate': 0.28250633220264265, 'recon_weight': 0.8188191674631734, 'n_estimators': 168, 'max_depth': 7, 'learning_rate': 0.04753530568553884, 'subsample': 0.9269832277547285, 'min_samples_split': 11, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.743462924622345.\n",
      "[I 2025-05-12 06:27:19,485] Trial 10 finished with value: 0.762211486849168 and parameters: {'latent_dim': 48, 'hidden_dim': 251, 'lr': 0.0003670576599073514, 'epochs': 11, 'dropout_rate': 0.4925012847348656, 'recon_weight': 0.37295815812119804, 'n_estimators': 184, 'max_depth': 10, 'learning_rate': 0.01813834360995075, 'subsample': 0.6548092612314783, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.762211486849168.\n",
      "[I 2025-05-12 06:27:47,156] Trial 11 finished with value: 0.7492523579480102 and parameters: {'latent_dim': 46, 'hidden_dim': 255, 'lr': 0.00032882105648418075, 'epochs': 10, 'dropout_rate': 0.48800816944353537, 'recon_weight': 0.365029002941157, 'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.014680332535914714, 'subsample': 0.6207482690497151, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.762211486849168.\n",
      "[I 2025-05-12 06:28:13,061] Trial 12 finished with value: 0.7404723564143855 and parameters: {'latent_dim': 58, 'hidden_dim': 252, 'lr': 0.0004230473548763692, 'epochs': 10, 'dropout_rate': 0.490403675470863, 'recon_weight': 0.3764396001862513, 'n_estimators': 144, 'max_depth': 10, 'learning_rate': 0.012292681903823847, 'subsample': 0.6006932874267404, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.762211486849168.\n",
      "[I 2025-05-12 06:28:41,196] Trial 13 finished with value: 0.7478145847711065 and parameters: {'latent_dim': 36, 'hidden_dim': 256, 'lr': 0.00035493472262853335, 'epochs': 10, 'dropout_rate': 0.3587442592873824, 'recon_weight': 0.4188475410796358, 'n_estimators': 180, 'max_depth': 10, 'learning_rate': 0.02166399706972922, 'subsample': 0.7444577127855974, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.762211486849168.\n",
      "[I 2025-05-12 06:28:56,481] Trial 14 finished with value: 0.7148608235564757 and parameters: {'latent_dim': 61, 'hidden_dim': 186, 'lr': 0.0014393768200832832, 'epochs': 11, 'dropout_rate': 0.3859627655632317, 'recon_weight': 0.10019984959577766, 'n_estimators': 77, 'max_depth': 9, 'learning_rate': 0.020048931890020466, 'subsample': 0.6457339006084963, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.762211486849168.\n",
      "[I 2025-05-12 06:30:06,657] Trial 15 finished with value: 0.6803159266927382 and parameters: {'latent_dim': 51, 'hidden_dim': 132, 'lr': 0.000507389048718596, 'epochs': 36, 'dropout_rate': 0.21156579618036803, 'recon_weight': 0.42250049355124786, 'n_estimators': 409, 'max_depth': 8, 'learning_rate': 0.0102156657138309, 'subsample': 0.7521268487401702, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.762211486849168.\n",
      "[I 2025-05-12 06:30:24,981] Trial 16 finished with value: 0.7548117475653707 and parameters: {'latent_dim': 32, 'hidden_dim': 247, 'lr': 0.00022082489373689582, 'epochs': 14, 'dropout_rate': 0.4750955743672009, 'recon_weight': 0.6140961936003676, 'n_estimators': 121, 'max_depth': 10, 'learning_rate': 0.02597351859026842, 'subsample': 0.6502508451117551, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.762211486849168.\n",
      "[I 2025-05-12 06:30:46,832] Trial 17 finished with value: 0.7476803926079288 and parameters: {'latent_dim': 20, 'hidden_dim': 231, 'lr': 0.00016408510629282007, 'epochs': 23, 'dropout_rate': 0.3376619698494145, 'recon_weight': 0.6287009044773154, 'n_estimators': 134, 'max_depth': 9, 'learning_rate': 0.025450174534552332, 'subsample': 0.8213399768383409, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.762211486849168.\n",
      "[I 2025-05-12 06:31:00,339] Trial 18 finished with value: 0.7470669427191167 and parameters: {'latent_dim': 33, 'hidden_dim': 128, 'lr': 0.00021632329970208434, 'epochs': 15, 'dropout_rate': 0.41267199986093084, 'recon_weight': 0.7107676817388486, 'n_estimators': 110, 'max_depth': 7, 'learning_rate': 0.03452678112383645, 'subsample': 0.6600861632522121, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.762211486849168.\n",
      "[I 2025-05-12 06:31:23,717] Trial 19 finished with value: 0.7416225749559082 and parameters: {'latent_dim': 10, 'hidden_dim': 178, 'lr': 0.0006004902098773491, 'epochs': 23, 'dropout_rate': 0.4620429143151531, 'recon_weight': 0.4771932861953868, 'n_estimators': 221, 'max_depth': 8, 'learning_rate': 0.0184425378693933, 'subsample': 0.7382882875482357, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.762211486849168.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7371\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Веса для объединенной функции потерь\n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    # Параметры градиентного бустинга\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7386\n",
      "ROC-AUC autoencoded: 0.7220\n",
      "ROC-AUC autoencoded: 0.7180\n",
      "ROC-AUC autoencoded: 0.7447\n",
      "ROC-AUC autoencoded: 0.7162\n",
      "ROC-AUC autoencoded: 0.7026\n",
      "ROC-AUC autoencoded: 0.7276\n",
      "ROC-AUC autoencoded: 0.7174\n",
      "ROC-AUC autoencoded: 0.7177\n",
      "ROC-AUC autoencoded: 0.7017\n",
      "ROC-AUC autoencoded: 0.7012\n",
      "ROC-AUC autoencoded: 0.6924\n",
      "ROC-AUC autoencoded: 0.6988\n",
      "ROC-AUC autoencoded: 0.7206\n",
      "ROC-AUC autoencoded: 0.7081\n",
      "ROC-AUC autoencoded: 0.6827\n",
      "ROC-AUC autoencoded: 0.7035\n",
      "ROC-AUC autoencoded: 0.6942\n",
      "ROC-AUC autoencoded: 0.6823\n",
      "ROC-AUC autoencoded: 0.6874\n",
      "ROC-AUC autoencoded: 0.7273\n",
      "ROC-AUC autoencoded: 0.7498\n",
      "ROC-AUC autoencoded: 0.7655\n",
      "ROC-AUC autoencoded: 0.7358\n",
      "ROC-AUC autoencoded: 0.7346\n",
      "среднее 0.7156351422639271\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 06:34:46,348] A new study created in memory with name: no-name-0bc86201-b40a-4ea8-8f75-dbbcdf006ffa\n",
      "[I 2025-05-12 06:34:50,432] Trial 0 finished with value: 0.6192584924468982 and parameters: {'latent_dim': 22, 'hidden_dim': 183, 'lr': 0.001203425276754481, 'epochs': 11, 'dropout_rate': 0.1830486340323197, 'recon_weight': 0.18449062706393207, 'C': 0.8905755301441848, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 0 with value: 0.6192584924468982.\n",
      "[I 2025-05-12 06:35:06,830] Trial 1 finished with value: 0.7483321831147919 and parameters: {'latent_dim': 68, 'hidden_dim': 164, 'lr': 0.00010030977098521204, 'epochs': 43, 'dropout_rate': 0.12580084789311952, 'recon_weight': 0.6617056800261307, 'C': 0.6925976489534625, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:35:14,552] Trial 2 finished with value: 0.7088413465225059 and parameters: {'latent_dim': 72, 'hidden_dim': 140, 'lr': 0.00020370564317560917, 'epochs': 19, 'dropout_rate': 0.18857065223470526, 'recon_weight': 0.1958473410128371, 'C': 45.5675531630355, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:35:31,075] Trial 3 finished with value: 0.6703761214630779 and parameters: {'latent_dim': 63, 'hidden_dim': 234, 'lr': 0.0008212600304067278, 'epochs': 44, 'dropout_rate': 0.474572544535534, 'recon_weight': 0.15002195727879047, 'C': 1.4282730136969377, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:35:50,125] Trial 4 finished with value: 0.6491258339084425 and parameters: {'latent_dim': 53, 'hidden_dim': 239, 'lr': 0.0009134154484414957, 'epochs': 50, 'dropout_rate': 0.3545439460259928, 'recon_weight': 0.32653288973271, 'C': 25.359922493213485, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:35:54,372] Trial 5 finished with value: 0.7101640978452574 and parameters: {'latent_dim': 29, 'hidden_dim': 182, 'lr': 0.0009948923503462254, 'epochs': 11, 'dropout_rate': 0.15288300822413212, 'recon_weight': 0.3637714722505424, 'C': 4.46371118019926, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:36:07,370] Trial 6 finished with value: 0.6895080898704086 and parameters: {'latent_dim': 71, 'hidden_dim': 176, 'lr': 0.00030901267495506645, 'epochs': 34, 'dropout_rate': 0.18742713012171652, 'recon_weight': 0.8378828928859849, 'C': 2.371004668109686, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:36:24,951] Trial 7 finished with value: 0.7337627482555019 and parameters: {'latent_dim': 85, 'hidden_dim': 166, 'lr': 0.00010114334398895271, 'epochs': 47, 'dropout_rate': 0.15625808160749638, 'recon_weight': 0.20639731085875326, 'C': 0.19441857379825433, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:36:46,825] Trial 8 finished with value: 0.7380281420136493 and parameters: {'latent_dim': 19, 'hidden_dim': 235, 'lr': 0.0014712548007417094, 'epochs': 26, 'dropout_rate': 0.3457500846490319, 'recon_weight': 0.8271243178201945, 'C': 22.158363965855354, 'kernel': 'linear'}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:36:51,102] Trial 9 finished with value: 0.7350184034966644 and parameters: {'latent_dim': 32, 'hidden_dim': 164, 'lr': 0.0025712411718802645, 'epochs': 11, 'dropout_rate': 0.4018643937255967, 'recon_weight': 0.8796759896026892, 'C': 1.7164516341413927, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:37:03,788] Trial 10 finished with value: 0.700502262096465 and parameters: {'latent_dim': 100, 'hidden_dim': 80, 'lr': 0.006123919796856532, 'epochs': 37, 'dropout_rate': 0.10097241793301949, 'recon_weight': 0.5480988957802164, 'C': 0.10907358161203963, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:37:20,295] Trial 11 finished with value: 0.6658806839966259 and parameters: {'latent_dim': 45, 'hidden_dim': 116, 'lr': 0.002805634917486462, 'epochs': 25, 'dropout_rate': 0.29741348083223274, 'recon_weight': 0.6876154944616916, 'C': 10.37884580911523, 'kernel': 'linear'}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:37:30,594] Trial 12 finished with value: 0.726506786289395 and parameters: {'latent_dim': 12, 'hidden_dim': 212, 'lr': 0.0003975925513587575, 'epochs': 28, 'dropout_rate': 0.28381597425543514, 'recon_weight': 0.6747814439876642, 'C': 0.5219991192879793, 'kernel': 'linear'}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:37:46,654] Trial 13 finished with value: 0.5750901004524193 and parameters: {'latent_dim': 43, 'hidden_dim': 256, 'lr': 0.002673178529569762, 'epochs': 41, 'dropout_rate': 0.24994852464233647, 'recon_weight': 0.7271719709287393, 'C': 89.23099255820966, 'kernel': 'linear'}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:38:12,006] Trial 14 finished with value: 0.6963902308105206 and parameters: {'latent_dim': 85, 'hidden_dim': 210, 'lr': 0.00013411804317025862, 'epochs': 25, 'dropout_rate': 0.37721728329517423, 'recon_weight': 0.5567531658078253, 'C': 8.196264279082415, 'kernel': 'linear'}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:38:20,069] Trial 15 finished with value: 0.7477954144620811 and parameters: {'latent_dim': 10, 'hidden_dim': 126, 'lr': 0.00040337021041656786, 'epochs': 20, 'dropout_rate': 0.45389445810879636, 'recon_weight': 0.7838129395312033, 'C': 0.3878546412075431, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.7483321831147919.\n",
      "[I 2025-05-12 06:38:28,032] Trial 16 finished with value: 0.7532110267617513 and parameters: {'latent_dim': 58, 'hidden_dim': 123, 'lr': 0.0004550259259272624, 'epochs': 19, 'dropout_rate': 0.44390268160579205, 'recon_weight': 0.6086457879355084, 'C': 0.4411569121477444, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 16 with value: 0.7532110267617513.\n",
      "[I 2025-05-12 06:38:40,574] Trial 17 finished with value: 0.7479008511617207 and parameters: {'latent_dim': 59, 'hidden_dim': 92, 'lr': 0.00021131607160284775, 'epochs': 33, 'dropout_rate': 0.4206556399974201, 'recon_weight': 0.4511572576654374, 'C': 0.42398397539277566, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 16 with value: 0.7532110267617513.\n",
      "[I 2025-05-12 06:38:48,947] Trial 18 finished with value: 0.7263246683536538 and parameters: {'latent_dim': 76, 'hidden_dim': 142, 'lr': 0.0005660685557901564, 'epochs': 20, 'dropout_rate': 0.23808787118443583, 'recon_weight': 0.6076597991448683, 'C': 0.8780728352729918, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 16 with value: 0.7532110267617513.\n",
      "[I 2025-05-12 06:39:03,328] Trial 19 finished with value: 0.7354113948316846 and parameters: {'latent_dim': 47, 'hidden_dim': 100, 'lr': 0.00018616427291030108, 'epochs': 38, 'dropout_rate': 0.10545651556955529, 'recon_weight': 0.4650207721330465, 'C': 0.1752908114963815, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 16 with value: 0.7532110267617513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7459\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7480\n",
      "ROC-AUC autoencoded: 0.7383\n",
      "ROC-AUC autoencoded: 0.7365\n",
      "ROC-AUC autoencoded: 0.7363\n",
      "ROC-AUC autoencoded: 0.7254\n",
      "ROC-AUC autoencoded: 0.7315\n",
      "ROC-AUC autoencoded: 0.7532\n",
      "ROC-AUC autoencoded: 0.7482\n",
      "ROC-AUC autoencoded: 0.7440\n",
      "ROC-AUC autoencoded: 0.7367\n",
      "ROC-AUC autoencoded: 0.7224\n",
      "ROC-AUC autoencoded: 0.7334\n",
      "ROC-AUC autoencoded: 0.7278\n",
      "ROC-AUC autoencoded: 0.7312\n",
      "ROC-AUC autoencoded: 0.7317\n",
      "ROC-AUC autoencoded: 0.6991\n",
      "ROC-AUC autoencoded: 0.6999\n",
      "ROC-AUC autoencoded: 0.6914\n",
      "ROC-AUC autoencoded: 0.6882\n",
      "ROC-AUC autoencoded: 0.7051\n",
      "ROC-AUC autoencoded: 0.7920\n",
      "ROC-AUC autoencoded: 0.7878\n",
      "ROC-AUC autoencoded: 0.7801\n",
      "ROC-AUC autoencoded: 0.7824\n",
      "ROC-AUC autoencoded: 0.7757\n",
      "среднее 0.7378397401928545\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 06:39:59,151] A new study created in memory with name: no-name-9cc95721-131c-4ef1-9fba-e7581ba05f07\n",
      "[I 2025-05-12 06:40:23,775] Trial 0 finished with value: 0.7589908749329038 and parameters: {'latent_dim': 14, 'hidden_dim_ae': 171, 'hidden_dim_combined': 39, 'lr_ae': 0.00020185556002551302, 'lr_combined': 0.00020202240781551676, 'epochs_ae': 45, 'epochs_freeze': 12, 'epochs_unfreeze': 8, 'dropout_rate_ae': 0.35795717343316846, 'dropout_rate_combined': 0.23813131647432237, 'recon_weight': 0.4827934403996471}. Best is trial 0 with value: 0.7589908749329038.\n",
      "[I 2025-05-12 06:40:48,198] Trial 1 finished with value: 0.7250594279579786 and parameters: {'latent_dim': 50, 'hidden_dim_ae': 143, 'hidden_dim_combined': 73, 'lr_ae': 0.0010011672596565537, 'lr_combined': 0.0008923569558743225, 'epochs_ae': 48, 'epochs_freeze': 5, 'epochs_unfreeze': 14, 'dropout_rate_ae': 0.49034498034725027, 'dropout_rate_combined': 0.44734175487185857, 'recon_weight': 0.11241272087487691}. Best is trial 0 with value: 0.7589908749329038.\n",
      "[I 2025-05-12 06:40:59,254] Trial 2 finished with value: 0.7610420979986197 and parameters: {'latent_dim': 99, 'hidden_dim_ae': 165, 'hidden_dim_combined': 87, 'lr_ae': 0.0007005598825423129, 'lr_combined': 0.0021412849521098187, 'epochs_ae': 11, 'epochs_freeze': 11, 'epochs_unfreeze': 7, 'dropout_rate_ae': 0.44678671348622834, 'dropout_rate_combined': 0.13599160078056563, 'recon_weight': 0.7161696385083132}. Best is trial 2 with value: 0.7610420979986197.\n",
      "[I 2025-05-12 06:41:20,499] Trial 3 finished with value: 0.6120696265623802 and parameters: {'latent_dim': 56, 'hidden_dim_ae': 192, 'hidden_dim_combined': 66, 'lr_ae': 0.003386606415631182, 'lr_combined': 0.0015791827865320692, 'epochs_ae': 32, 'epochs_freeze': 11, 'epochs_unfreeze': 14, 'dropout_rate_ae': 0.14448131930693356, 'dropout_rate_combined': 0.33401900634538234, 'recon_weight': 0.579586625875444}. Best is trial 2 with value: 0.7610420979986197.\n",
      "[I 2025-05-12 06:41:40,092] Trial 4 finished with value: 0.7551951537458783 and parameters: {'latent_dim': 30, 'hidden_dim_ae': 98, 'hidden_dim_combined': 85, 'lr_ae': 0.0003719528090939294, 'lr_combined': 0.0002047678908083488, 'epochs_ae': 36, 'epochs_freeze': 7, 'epochs_unfreeze': 10, 'dropout_rate_ae': 0.1923002155217613, 'dropout_rate_combined': 0.10799360190509573, 'recon_weight': 0.36083098315966244}. Best is trial 2 with value: 0.7610420979986197.\n",
      "[I 2025-05-12 06:41:58,353] Trial 5 finished with value: 0.7467985583927613 and parameters: {'latent_dim': 39, 'hidden_dim_ae': 137, 'hidden_dim_combined': 36, 'lr_ae': 0.004922648895460731, 'lr_combined': 0.00025936196547324925, 'epochs_ae': 37, 'epochs_freeze': 5, 'epochs_unfreeze': 8, 'dropout_rate_ae': 0.17262611432210895, 'dropout_rate_combined': 0.36650343527707163, 'recon_weight': 0.7833451269081299}. Best is trial 2 with value: 0.7610420979986197.\n",
      "[I 2025-05-12 06:42:13,968] Trial 6 finished with value: 0.6944444444444445 and parameters: {'latent_dim': 90, 'hidden_dim_ae': 106, 'hidden_dim_combined': 46, 'lr_ae': 0.009258306485201158, 'lr_combined': 0.000531778960403218, 'epochs_ae': 16, 'epochs_freeze': 16, 'epochs_unfreeze': 14, 'dropout_rate_ae': 0.2346721496239296, 'dropout_rate_combined': 0.10737785012155775, 'recon_weight': 0.3014171974533933}. Best is trial 2 with value: 0.7610420979986197.\n",
      "[I 2025-05-12 06:42:33,420] Trial 7 finished with value: 0.6992178513917645 and parameters: {'latent_dim': 21, 'hidden_dim_ae': 236, 'hidden_dim_combined': 109, 'lr_ae': 0.002097228579752131, 'lr_combined': 0.00027576401893084356, 'epochs_ae': 33, 'epochs_freeze': 10, 'epochs_unfreeze': 8, 'dropout_rate_ae': 0.41381832118929085, 'dropout_rate_combined': 0.24713111367082702, 'recon_weight': 0.1853170908070676}. Best is trial 2 with value: 0.7610420979986197.\n",
      "[I 2025-05-12 06:42:49,976] Trial 8 finished with value: 0.6606663599417223 and parameters: {'latent_dim': 11, 'hidden_dim_ae': 152, 'hidden_dim_combined': 55, 'lr_ae': 0.00768885154956537, 'lr_combined': 0.009458860011614539, 'epochs_ae': 32, 'epochs_freeze': 7, 'epochs_unfreeze': 8, 'dropout_rate_ae': 0.28300829378090064, 'dropout_rate_combined': 0.35204223158274184, 'recon_weight': 0.401293908186677}. Best is trial 2 with value: 0.7610420979986197.\n",
      "[I 2025-05-12 06:43:13,094] Trial 9 finished with value: 0.750805152979066 and parameters: {'latent_dim': 22, 'hidden_dim_ae': 194, 'hidden_dim_combined': 121, 'lr_ae': 0.009103172692478222, 'lr_combined': 0.00011948216864089792, 'epochs_ae': 34, 'epochs_freeze': 17, 'epochs_unfreeze': 12, 'dropout_rate_ae': 0.44118973755487023, 'dropout_rate_combined': 0.34460981109023303, 'recon_weight': 0.6961846751747054}. Best is trial 2 with value: 0.7610420979986197.\n",
      "[I 2025-05-12 06:43:32,373] Trial 10 finished with value: 0.7319032282800398 and parameters: {'latent_dim': 100, 'hidden_dim_ae': 232, 'hidden_dim_combined': 93, 'lr_ae': 0.0005841721483010994, 'lr_combined': 0.003290411089285663, 'epochs_ae': 15, 'epochs_freeze': 15, 'epochs_unfreeze': 20, 'dropout_rate_ae': 0.3452774091782501, 'dropout_rate_combined': 0.18799833099718113, 'recon_weight': 0.8641440375651374}. Best is trial 2 with value: 0.7610420979986197.\n",
      "[I 2025-05-12 06:43:48,631] Trial 11 finished with value: 0.7398589065255732 and parameters: {'latent_dim': 74, 'hidden_dim_ae': 179, 'hidden_dim_combined': 96, 'lr_ae': 0.00015127704623667387, 'lr_combined': 0.002761642707071888, 'epochs_ae': 22, 'epochs_freeze': 20, 'epochs_unfreeze': 5, 'dropout_rate_ae': 0.3634240020680999, 'dropout_rate_combined': 0.20406823360165316, 'recon_weight': 0.5799537459069736}. Best is trial 2 with value: 0.7610420979986197.\n",
      "[I 2025-05-12 06:44:14,508] Trial 12 finished with value: 0.7632850241545893 and parameters: {'latent_dim': 73, 'hidden_dim_ae': 210, 'hidden_dim_combined': 61, 'lr_ae': 0.00010015024389631987, 'lr_combined': 0.0006339039082887227, 'epochs_ae': 50, 'epochs_freeze': 13, 'epochs_unfreeze': 5, 'dropout_rate_ae': 0.41458968761546866, 'dropout_rate_combined': 0.17489789723445667, 'recon_weight': 0.5398201866289938}. Best is trial 12 with value: 0.7632850241545893.\n",
      "[I 2025-05-12 06:44:25,461] Trial 13 finished with value: 0.7674066405950465 and parameters: {'latent_dim': 76, 'hidden_dim_ae': 211, 'hidden_dim_combined': 63, 'lr_ae': 0.0014761920651693327, 'lr_combined': 0.0006913687075838077, 'epochs_ae': 11, 'epochs_freeze': 14, 'epochs_unfreeze': 6, 'dropout_rate_ae': 0.4795783400965877, 'dropout_rate_combined': 0.14328096171467913, 'recon_weight': 0.681658376971032}. Best is trial 13 with value: 0.7674066405950465.\n",
      "[I 2025-05-12 06:44:42,197] Trial 14 finished with value: 0.7338777701096543 and parameters: {'latent_dim': 73, 'hidden_dim_ae': 255, 'hidden_dim_combined': 60, 'lr_ae': 0.0015655934836841618, 'lr_combined': 0.0006041686817608304, 'epochs_ae': 25, 'epochs_freeze': 14, 'epochs_unfreeze': 5, 'dropout_rate_ae': 0.4850291028403429, 'dropout_rate_combined': 0.16447300589072641, 'recon_weight': 0.5900215705230046}. Best is trial 13 with value: 0.7674066405950465.\n",
      "[I 2025-05-12 06:45:10,834] Trial 15 finished with value: 0.7752472969864274 and parameters: {'latent_dim': 71, 'hidden_dim_ae': 215, 'hidden_dim_combined': 73, 'lr_ae': 0.00010444265838003387, 'lr_combined': 0.0005374788475154089, 'epochs_ae': 42, 'epochs_freeze': 18, 'epochs_unfreeze': 17, 'dropout_rate_ae': 0.3968557062451494, 'dropout_rate_combined': 0.2768765211354501, 'recon_weight': 0.6778044752391295}. Best is trial 15 with value: 0.7752472969864274.\n",
      "[I 2025-05-12 06:45:37,347] Trial 16 finished with value: 0.7678667280116556 and parameters: {'latent_dim': 59, 'hidden_dim_ae': 68, 'hidden_dim_combined': 73, 'lr_ae': 0.00029617962550278627, 'lr_combined': 0.0011388408627384966, 'epochs_ae': 42, 'epochs_freeze': 19, 'epochs_unfreeze': 18, 'dropout_rate_ae': 0.3122719502659098, 'dropout_rate_combined': 0.2693192264482314, 'recon_weight': 0.6748739905179206}. Best is trial 15 with value: 0.7752472969864274.\n",
      "[I 2025-05-12 06:46:04,467] Trial 17 finished with value: 0.7586266390614217 and parameters: {'latent_dim': 59, 'hidden_dim_ae': 76, 'hidden_dim_combined': 75, 'lr_ae': 0.00025981792990812616, 'lr_combined': 0.0014083107530702286, 'epochs_ae': 42, 'epochs_freeze': 20, 'epochs_unfreeze': 18, 'dropout_rate_ae': 0.28211221401550485, 'dropout_rate_combined': 0.28116768474885867, 'recon_weight': 0.8920141917045881}. Best is trial 15 with value: 0.7752472969864274.\n",
      "[I 2025-05-12 06:46:30,876] Trial 18 finished with value: 0.7397055440533702 and parameters: {'latent_dim': 43, 'hidden_dim_ae': 127, 'hidden_dim_combined': 104, 'lr_ae': 0.00010798949111874231, 'lr_combined': 0.005461671154161098, 'epochs_ae': 41, 'epochs_freeze': 18, 'epochs_unfreeze': 17, 'dropout_rate_ae': 0.32244860812688514, 'dropout_rate_combined': 0.39758169368754614, 'recon_weight': 0.7756662389824727}. Best is trial 15 with value: 0.7752472969864274.\n",
      "[I 2025-05-12 06:46:50,878] Trial 19 finished with value: 0.7595851545126907 and parameters: {'latent_dim': 61, 'hidden_dim_ae': 79, 'hidden_dim_combined': 51, 'lr_ae': 0.0003526292983566876, 'lr_combined': 0.0003643846856535774, 'epochs_ae': 26, 'epochs_freeze': 18, 'epochs_unfreeze': 17, 'dropout_rate_ae': 0.2417643186933824, 'dropout_rate_combined': 0.2969545088636063, 'recon_weight': 0.6236096041898812}. Best is trial 15 with value: 0.7752472969864274.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7757\n"
     ]
    }
   ],
   "source": [
    "class CombinedClassifier(nn.Module):\n",
    "    def __init__(self, autoencoder, pgs_input_dim, hidden_dim=64, dropout_rate=0.2):\n",
    "        super(CombinedClassifier, self).__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "        self.pgs_branch = nn.Sequential(\n",
    "            nn.Linear(pgs_input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        latent_dim = list(autoencoder.classifier[0].parameters())[0].shape[1]\n",
    "        self.combined_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim // 2 + latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_snp, x_pgs):\n",
    "        _, latent, _ = self.autoencoder(x_snp)\n",
    "        pgs_features = self.pgs_branch(x_pgs)\n",
    "        combined = torch.cat([latent, pgs_features], dim=1)\n",
    "        output = self.combined_classifier(combined)\n",
    "        return output\n",
    "\n",
    "def train_combined_classifier(model, X_train_snp, X_train_pgs, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_snp_tensor = torch.FloatTensor(X_train_snp).to(device)\n",
    "    X_train_pgs_tensor = torch.FloatTensor(X_train_pgs).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_snp_tensor, X_train_pgs_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Этап 1: Заморозить автоэнкодер и его голову\n",
    "    for param in model.autoencoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs_freeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Этап 2: Разморозить всё и обучать вместе\n",
    "    for param in model.autoencoder.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr/10)  # Уменьшаем скорость обучения для всей сети\n",
    "    \n",
    "    for epoch in range(epochs_unfreeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_combined(model, X_snp, X_pgs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_snp_tensor = torch.FloatTensor(X_snp).to(device)\n",
    "    X_pgs_tensor = torch.FloatTensor(X_pgs).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_snp_tensor, X_pgs_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    hidden_dim_combined = trial.suggest_int('hidden_dim_combined', 32, 128)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    lr_combined = trial.suggest_float('lr_combined', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    epochs_freeze = trial.suggest_int('epochs_freeze', 5, 20)\n",
    "    epochs_unfreeze = trial.suggest_int('epochs_unfreeze', 5, 20)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    dropout_rate_combined = trial.suggest_float('dropout_rate_combined', 0.1, 0.5)\n",
    "    \n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs_ae, batch_size, lr_ae, recon_weight, class_weight)\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, X_pgs_train.shape[1], hidden_dim_combined, dropout_rate_combined)\n",
    "        combined_model = train_combined_classifier(combined_model, X_train, X_pgs_train, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr_combined)\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, X_pgs_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs_ae'], 32, \n",
    "    best_params['lr_ae'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "combined_model = CombinedClassifier(autoencoder, X_train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "combined_model = train_combined_classifier(\n",
    "    combined_model, X_train_all, X_train_pgs, y_all_train, \n",
    "    best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    ")\n",
    "\n",
    "y_pred_proba = predict_combined(combined_model, X_val_all, X_val_pgs)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7414\n",
      "ROC-AUC autoencoded: 0.7356\n",
      "ROC-AUC autoencoded: 0.7492\n",
      "ROC-AUC autoencoded: 0.7488\n",
      "ROC-AUC autoencoded: 0.7502\n",
      "ROC-AUC autoencoded: 0.7527\n",
      "ROC-AUC autoencoded: 0.7591\n",
      "ROC-AUC autoencoded: 0.7483\n",
      "ROC-AUC autoencoded: 0.7524\n",
      "ROC-AUC autoencoded: 0.7598\n",
      "ROC-AUC autoencoded: 0.7406\n",
      "ROC-AUC autoencoded: 0.7260\n",
      "ROC-AUC autoencoded: 0.7165\n",
      "ROC-AUC autoencoded: 0.7413\n",
      "ROC-AUC autoencoded: 0.7265\n",
      "ROC-AUC autoencoded: 0.6919\n",
      "ROC-AUC autoencoded: 0.7017\n",
      "ROC-AUC autoencoded: 0.6931\n",
      "ROC-AUC autoencoded: 0.6970\n",
      "ROC-AUC autoencoded: 0.6969\n",
      "ROC-AUC autoencoded: 0.7576\n",
      "ROC-AUC autoencoded: 0.7550\n",
      "ROC-AUC autoencoded: 0.7779\n",
      "ROC-AUC autoencoded: 0.7543\n",
      "ROC-AUC autoencoded: 0.7584\n",
      "среднее 0.7372818724906172\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs_ae'], 32, \n",
    "            best_params['lr_ae'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "        combined_model = train_combined_classifier(\n",
    "            combined_model, X_train, train_pgs, y_train, \n",
    "            best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, test_pgs)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше идет блок со sparse автоэнкодером без классифицирующей головы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 06:50:15,075] A new study created in memory with name: no-name-8209abd0-dde9-4e47-a674-13c4b8ab3c3a\n",
      "[I 2025-05-12 06:50:24,600] Trial 0 finished with value: 0.772314239705544 and parameters: {'latent_dim': 76, 'hidden_dim': 153, 'lr': 0.00014106265207840994, 'epochs': 29, 'dropout_rate': 0.20741498846609976, 'sparsity_weight': 0.0004393536427997831, 'C': 0.016183110505094803, 'solver': 'liblinear'}. Best is trial 0 with value: 0.772314239705544.\n",
      "[I 2025-05-12 06:50:31,310] Trial 1 finished with value: 0.7768959435626103 and parameters: {'latent_dim': 56, 'hidden_dim': 256, 'lr': 0.001464643901565987, 'epochs': 18, 'dropout_rate': 0.13067638351540378, 'sparsity_weight': 0.00011802370864463197, 'C': 0.1364055995353432, 'solver': 'saga'}. Best is trial 1 with value: 0.7768959435626103.\n",
      "[I 2025-05-12 06:50:45,976] Trial 2 finished with value: 0.7636300897170463 and parameters: {'latent_dim': 91, 'hidden_dim': 67, 'lr': 0.0012011432351422785, 'epochs': 49, 'dropout_rate': 0.3412182686957538, 'sparsity_weight': 0.0218126463629976, 'C': 0.5026846963550027, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7768959435626103.\n",
      "[I 2025-05-12 06:50:53,975] Trial 3 finished with value: 0.7518978605935128 and parameters: {'latent_dim': 59, 'hidden_dim': 209, 'lr': 0.008610471756166587, 'epochs': 21, 'dropout_rate': 0.276342228176361, 'sparsity_weight': 0.002748979708100924, 'C': 6.845781686064405, 'solver': 'saga'}. Best is trial 1 with value: 0.7768959435626103.\n",
      "[I 2025-05-12 06:51:03,249] Trial 4 finished with value: 0.7724292615596964 and parameters: {'latent_dim': 90, 'hidden_dim': 247, 'lr': 0.002012298911725573, 'epochs': 25, 'dropout_rate': 0.19661210450777125, 'sparsity_weight': 0.00035161447450911477, 'C': 0.09532823296046877, 'solver': 'saga'}. Best is trial 1 with value: 0.7768959435626103.\n",
      "[I 2025-05-12 06:51:18,594] Trial 5 finished with value: 0.7769534544896864 and parameters: {'latent_dim': 11, 'hidden_dim': 203, 'lr': 0.007802720964804586, 'epochs': 48, 'dropout_rate': 0.43441327615980774, 'sparsity_weight': 0.00047427238532668514, 'C': 0.014235907630267882, 'solver': 'saga'}. Best is trial 5 with value: 0.7769534544896864.\n",
      "[I 2025-05-12 06:51:27,122] Trial 6 finished with value: 0.7524921401732997 and parameters: {'latent_dim': 65, 'hidden_dim': 241, 'lr': 0.000692269744211303, 'epochs': 25, 'dropout_rate': 0.24056300842224126, 'sparsity_weight': 0.009971283589930241, 'C': 13.03264688115136, 'solver': 'liblinear'}. Best is trial 5 with value: 0.7769534544896864.\n",
      "[I 2025-05-12 06:51:42,266] Trial 7 finished with value: 0.776129131201595 and parameters: {'latent_dim': 26, 'hidden_dim': 158, 'lr': 0.0007534602701749103, 'epochs': 48, 'dropout_rate': 0.299670755201779, 'sparsity_weight': 0.00014071962323339128, 'C': 25.361624885925355, 'solver': 'liblinear'}. Best is trial 5 with value: 0.7769534544896864.\n",
      "[I 2025-05-12 06:51:47,937] Trial 8 finished with value: 0.7803849398052295 and parameters: {'latent_dim': 21, 'hidden_dim': 209, 'lr': 0.0020874609288165998, 'epochs': 17, 'dropout_rate': 0.2969763923155194, 'sparsity_weight': 0.0018034223154991477, 'C': 0.05067861295008571, 'solver': 'saga'}. Best is trial 8 with value: 0.7803849398052295.\n",
      "[I 2025-05-12 06:51:57,188] Trial 9 finished with value: 0.7789279963193007 and parameters: {'latent_dim': 23, 'hidden_dim': 231, 'lr': 0.002706939300546756, 'epochs': 27, 'dropout_rate': 0.21208216578018027, 'sparsity_weight': 0.0011334733516504463, 'C': 1.4558138303679455, 'solver': 'saga'}. Best is trial 8 with value: 0.7803849398052295.\n",
      "[I 2025-05-12 06:52:00,573] Trial 10 finished with value: 0.7629591289011578 and parameters: {'latent_dim': 40, 'hidden_dim': 116, 'lr': 0.00025516593838046216, 'epochs': 11, 'dropout_rate': 0.39264317295298257, 'sparsity_weight': 0.04688203135818607, 'C': 88.36876456905087, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.7803849398052295.\n",
      "[I 2025-05-12 06:52:12,917] Trial 11 finished with value: 0.7687677325358485 and parameters: {'latent_dim': 10, 'hidden_dim': 201, 'lr': 0.003307684162431189, 'epochs': 37, 'dropout_rate': 0.14311345997391778, 'sparsity_weight': 0.0020818280379145187, 'C': 2.3198371282712547, 'solver': 'saga'}. Best is trial 8 with value: 0.7803849398052295.\n",
      "[I 2025-05-12 06:52:16,647] Trial 12 finished with value: 0.769553715205889 and parameters: {'latent_dim': 36, 'hidden_dim': 215, 'lr': 0.003544369462550659, 'epochs': 11, 'dropout_rate': 0.36629266290517115, 'sparsity_weight': 0.0014425214358371402, 'C': 0.7242579487585089, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.7803849398052295.\n",
      "[I 2025-05-12 06:52:28,617] Trial 13 finished with value: 0.7754390000766812 and parameters: {'latent_dim': 27, 'hidden_dim': 184, 'lr': 0.003846244750290063, 'epochs': 37, 'dropout_rate': 0.49052048078713434, 'sparsity_weight': 0.006376355921001808, 'C': 0.1118803061260517, 'solver': 'saga'}. Best is trial 8 with value: 0.7803849398052295.\n",
      "[I 2025-05-12 06:52:35,038] Trial 14 finished with value: 0.7665823173069549 and parameters: {'latent_dim': 43, 'hidden_dim': 231, 'lr': 0.0003790904724537489, 'epochs': 18, 'dropout_rate': 0.2536169825663378, 'sparsity_weight': 0.0011622532885686143, 'C': 2.2233933020787937, 'solver': 'saga'}. Best is trial 8 with value: 0.7803849398052295.\n",
      "[I 2025-05-12 06:52:46,539] Trial 15 finished with value: 0.7801357257878997 and parameters: {'latent_dim': 23, 'hidden_dim': 181, 'lr': 0.0022371332813976236, 'epochs': 35, 'dropout_rate': 0.1798764496540696, 'sparsity_weight': 0.00563388320110588, 'C': 0.283243473491066, 'solver': 'saga'}. Best is trial 8 with value: 0.7803849398052295.\n",
      "[I 2025-05-12 06:52:57,690] Trial 16 finished with value: 0.7787171229200215 and parameters: {'latent_dim': 46, 'hidden_dim': 132, 'lr': 0.0050974792294167385, 'epochs': 36, 'dropout_rate': 0.10236304775919394, 'sparsity_weight': 0.00693305006223059, 'C': 0.0405003520166633, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.7803849398052295.\n",
      "[I 2025-05-12 06:53:07,769] Trial 17 finished with value: 0.7755348516218081 and parameters: {'latent_dim': 20, 'hidden_dim': 172, 'lr': 0.0018059127498247867, 'epochs': 32, 'dropout_rate': 0.3319310266023858, 'sparsity_weight': 0.017357514592148824, 'C': 0.31087840373795256, 'solver': 'saga'}. Best is trial 8 with value: 0.7803849398052295.\n",
      "[I 2025-05-12 06:53:21,679] Trial 18 finished with value: 0.7765892186182043 and parameters: {'latent_dim': 33, 'hidden_dim': 185, 'lr': 0.000621678513507058, 'epochs': 41, 'dropout_rate': 0.18042968658072817, 'sparsity_weight': 0.08734922961738886, 'C': 0.04304461656417517, 'solver': 'saga'}. Best is trial 8 with value: 0.7803849398052295.\n",
      "[I 2025-05-12 06:53:31,228] Trial 19 finished with value: 0.7714515757994018 and parameters: {'latent_dim': 16, 'hidden_dim': 122, 'lr': 0.0056034176230057115, 'epochs': 32, 'dropout_rate': 0.4206295107188076, 'sparsity_weight': 0.003611507505781711, 'C': 0.2361402590087837, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.7803849398052295.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7859\n"
     ]
    }
   ],
   "source": [
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "    \n",
    "def train_sparse_autoencoder(model, X_train, epochs, batch_size, lr, sparsity_weight):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, _ in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, latent = model(batch_x)\n",
    "            \n",
    "            recon_loss = criterion(reconstructed, batch_x)\n",
    "            \n",
    "            sparsity_loss = torch.mean(torch.abs(latent))\n",
    "            \n",
    "            loss = recon_loss + sparsity_weight * sparsity_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs, batch_size, lr, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7843\n",
      "ROC-AUC autoencoded: 0.7592\n",
      "ROC-AUC autoencoded: 0.7700\n",
      "ROC-AUC autoencoded: 0.7686\n",
      "ROC-AUC autoencoded: 0.7724\n",
      "ROC-AUC autoencoded: 0.7775\n",
      "ROC-AUC autoencoded: 0.7767\n",
      "ROC-AUC autoencoded: 0.7903\n",
      "ROC-AUC autoencoded: 0.7872\n",
      "ROC-AUC autoencoded: 0.7770\n",
      "ROC-AUC autoencoded: 0.7609\n",
      "ROC-AUC autoencoded: 0.7518\n",
      "ROC-AUC autoencoded: 0.7399\n",
      "ROC-AUC autoencoded: 0.7402\n",
      "ROC-AUC autoencoded: 0.7588\n",
      "ROC-AUC autoencoded: 0.7130\n",
      "ROC-AUC autoencoded: 0.7163\n",
      "ROC-AUC autoencoded: 0.7230\n",
      "ROC-AUC autoencoded: 0.7049\n",
      "ROC-AUC autoencoded: 0.7165\n",
      "ROC-AUC autoencoded: 0.7678\n",
      "ROC-AUC autoencoded: 0.7727\n",
      "ROC-AUC autoencoded: 0.7696\n",
      "ROC-AUC autoencoded: 0.7737\n",
      "ROC-AUC autoencoded: 0.7678\n",
      "среднее 0.7576120147540649\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 06:54:10,609] A new study created in memory with name: no-name-966416ec-9fd9-4da0-97e2-770ed1c23fb2\n",
      "[I 2025-05-12 06:54:39,216] Trial 0 finished with value: 0.7348171152518979 and parameters: {'latent_dim': 18, 'hidden_dim': 67, 'lr': 0.0014531563429113748, 'epochs': 21, 'dropout_rate': 0.14222463608469416, 'sparsity_weight': 0.0006702542835990643, 'n_estimators': 373, 'max_depth': 5, 'learning_rate': 0.016625324689282833, 'subsample': 0.8752142949648689, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7348171152518979.\n",
      "[I 2025-05-12 06:55:04,512] Trial 1 finished with value: 0.7338969404186795 and parameters: {'latent_dim': 53, 'hidden_dim': 229, 'lr': 0.001005103456102176, 'epochs': 22, 'dropout_rate': 0.16250023082738674, 'sparsity_weight': 0.0016947792135799296, 'n_estimators': 158, 'max_depth': 7, 'learning_rate': 0.21168873419694925, 'subsample': 0.6831849709534891, 'min_samples_split': 12, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7348171152518979.\n",
      "[I 2025-05-12 06:55:27,640] Trial 2 finished with value: 0.7610612683076451 and parameters: {'latent_dim': 69, 'hidden_dim': 216, 'lr': 0.0010266925893151432, 'epochs': 41, 'dropout_rate': 0.3014020849078466, 'sparsity_weight': 0.0006640317950319582, 'n_estimators': 132, 'max_depth': 3, 'learning_rate': 0.15821173371468894, 'subsample': 0.7521892594102613, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.7610612683076451.\n",
      "[I 2025-05-12 06:56:06,864] Trial 3 finished with value: 0.720151828847481 and parameters: {'latent_dim': 38, 'hidden_dim': 104, 'lr': 0.000340164372247294, 'epochs': 27, 'dropout_rate': 0.430286414757011, 'sparsity_weight': 0.00028589704561516525, 'n_estimators': 442, 'max_depth': 9, 'learning_rate': 0.2534444536672705, 'subsample': 0.9510156814971593, 'min_samples_split': 11, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.7610612683076451.\n",
      "[I 2025-05-12 06:56:23,105] Trial 4 finished with value: 0.7409132735219691 and parameters: {'latent_dim': 40, 'hidden_dim': 75, 'lr': 0.000498092923592326, 'epochs': 13, 'dropout_rate': 0.13928265330686684, 'sparsity_weight': 0.0019716555752559805, 'n_estimators': 105, 'max_depth': 8, 'learning_rate': 0.2668015878115969, 'subsample': 0.7175933761085823, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.7610612683076451.\n",
      "[I 2025-05-12 06:56:47,865] Trial 5 finished with value: 0.7198642742121003 and parameters: {'latent_dim': 65, 'hidden_dim': 165, 'lr': 0.0036316764678880494, 'epochs': 34, 'dropout_rate': 0.12316643345323613, 'sparsity_weight': 0.0019935772574572208, 'n_estimators': 144, 'max_depth': 4, 'learning_rate': 0.13577918494228167, 'subsample': 0.8192142166309253, 'min_samples_split': 17, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7610612683076451.\n",
      "[I 2025-05-12 06:57:28,247] Trial 6 finished with value: 0.7374242772793499 and parameters: {'latent_dim': 99, 'hidden_dim': 159, 'lr': 0.007697804853923049, 'epochs': 22, 'dropout_rate': 0.3217475079024503, 'sparsity_weight': 0.0216117020429644, 'n_estimators': 320, 'max_depth': 4, 'learning_rate': 0.10554456861507829, 'subsample': 0.6327717217206251, 'min_samples_split': 19, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7610612683076451.\n",
      "[I 2025-05-12 06:57:58,489] Trial 7 finished with value: 0.7648569894946706 and parameters: {'latent_dim': 41, 'hidden_dim': 245, 'lr': 0.0004086853557822461, 'epochs': 22, 'dropout_rate': 0.4800596843655658, 'sparsity_weight': 0.0006080180416979318, 'n_estimators': 397, 'max_depth': 3, 'learning_rate': 0.015503087283343257, 'subsample': 0.8672111416172927, 'min_samples_split': 11, 'min_samples_leaf': 8}. Best is trial 7 with value: 0.7648569894946706.\n",
      "[I 2025-05-12 06:58:59,466] Trial 8 finished with value: 0.7564603941415534 and parameters: {'latent_dim': 100, 'hidden_dim': 157, 'lr': 0.007285714234648281, 'epochs': 30, 'dropout_rate': 0.2753175215720701, 'sparsity_weight': 0.00016714832041267374, 'n_estimators': 197, 'max_depth': 10, 'learning_rate': 0.0672357704467514, 'subsample': 0.7509954536115071, 'min_samples_split': 15, 'min_samples_leaf': 4}. Best is trial 7 with value: 0.7648569894946706.\n",
      "[I 2025-05-12 07:00:44,077] Trial 9 finished with value: 0.7552718349819799 and parameters: {'latent_dim': 66, 'hidden_dim': 239, 'lr': 0.0019253692973563764, 'epochs': 36, 'dropout_rate': 0.22247507135105116, 'sparsity_weight': 0.002122796053600628, 'n_estimators': 421, 'max_depth': 10, 'learning_rate': 0.03067146180599664, 'subsample': 0.8452676183102465, 'min_samples_split': 20, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.7648569894946706.\n",
      "[I 2025-05-12 07:01:03,744] Trial 10 finished with value: 0.724676021777471 and parameters: {'latent_dim': 10, 'hidden_dim': 202, 'lr': 0.00010022144010509163, 'epochs': 11, 'dropout_rate': 0.4744098451296557, 'sparsity_weight': 0.015592911286956971, 'n_estimators': 263, 'max_depth': 6, 'learning_rate': 0.010373731889187148, 'subsample': 0.9938058984193787, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 7 with value: 0.7648569894946706.\n",
      "[I 2025-05-12 07:01:25,255] Trial 11 finished with value: 0.7624031899394218 and parameters: {'latent_dim': 80, 'hidden_dim': 254, 'lr': 0.0003528061229677412, 'epochs': 49, 'dropout_rate': 0.37505869649948864, 'sparsity_weight': 0.0004960277157048297, 'n_estimators': 52, 'max_depth': 3, 'learning_rate': 0.03576784638460406, 'subsample': 0.9010614513147135, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 7 with value: 0.7648569894946706.\n",
      "[I 2025-05-12 07:02:06,349] Trial 12 finished with value: 0.7665823173069549 and parameters: {'latent_dim': 84, 'hidden_dim': 254, 'lr': 0.0002591301087885632, 'epochs': 47, 'dropout_rate': 0.37417294007485924, 'sparsity_weight': 0.008927992610312142, 'n_estimators': 246, 'max_depth': 3, 'learning_rate': 0.031193883757131273, 'subsample': 0.8994722994290134, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 12 with value: 0.7665823173069549.\n",
      "[I 2025-05-12 07:03:04,801] Trial 13 finished with value: 0.7426002607162028 and parameters: {'latent_dim': 33, 'hidden_dim': 200, 'lr': 0.0001432628773068601, 'epochs': 50, 'dropout_rate': 0.47901963228321687, 'sparsity_weight': 0.007831440044881306, 'n_estimators': 495, 'max_depth': 5, 'learning_rate': 0.021615673958683596, 'subsample': 0.9104968545840706, 'min_samples_split': 13, 'min_samples_leaf': 6}. Best is trial 12 with value: 0.7665823173069549.\n",
      "[I 2025-05-12 07:03:40,675] Trial 14 finished with value: 0.7688827543900008 and parameters: {'latent_dim': 81, 'hidden_dim': 256, 'lr': 0.00022465120843193371, 'epochs': 43, 'dropout_rate': 0.3807684705251979, 'sparsity_weight': 0.004801144235618576, 'n_estimators': 258, 'max_depth': 3, 'learning_rate': 0.010983706618250781, 'subsample': 0.7912530626586101, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 14 with value: 0.7688827543900008.\n",
      "[I 2025-05-12 07:04:28,312] Trial 15 finished with value: 0.7583007438079902 and parameters: {'latent_dim': 86, 'hidden_dim': 180, 'lr': 0.0001807290400784084, 'epochs': 43, 'dropout_rate': 0.3761869677458451, 'sparsity_weight': 0.09103664323857712, 'n_estimators': 245, 'max_depth': 5, 'learning_rate': 0.05194046819749808, 'subsample': 0.7870771405134516, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 14 with value: 0.7688827543900008.\n",
      "[I 2025-05-12 07:05:17,870] Trial 16 finished with value: 0.7634000460087417 and parameters: {'latent_dim': 83, 'hidden_dim': 129, 'lr': 0.0002041265748695844, 'epochs': 43, 'dropout_rate': 0.3850147186828413, 'sparsity_weight': 0.006083470309180824, 'n_estimators': 327, 'max_depth': 4, 'learning_rate': 0.010366287872000751, 'subsample': 0.7948162475299855, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 14 with value: 0.7688827543900008.\n",
      "[I 2025-05-12 07:06:11,817] Trial 17 finished with value: 0.7541407867494824 and parameters: {'latent_dim': 75, 'hidden_dim': 217, 'lr': 0.0006184216737768594, 'epochs': 46, 'dropout_rate': 0.41781090358208295, 'sparsity_weight': 0.04552751372295481, 'n_estimators': 217, 'max_depth': 6, 'learning_rate': 0.02907242354519227, 'subsample': 0.9457257358750789, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.7688827543900008.\n",
      "[I 2025-05-12 07:07:32,305] Trial 18 finished with value: 0.7498466375277969 and parameters: {'latent_dim': 92, 'hidden_dim': 252, 'lr': 0.0002501572808594637, 'epochs': 40, 'dropout_rate': 0.3351814909740764, 'sparsity_weight': 0.004545210243352532, 'n_estimators': 325, 'max_depth': 7, 'learning_rate': 0.06117353007699349, 'subsample': 0.8341595758685285, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 14 with value: 0.7688827543900008.\n",
      "[I 2025-05-12 07:07:58,505] Trial 19 finished with value: 0.756575415995706 and parameters: {'latent_dim': 61, 'hidden_dim': 194, 'lr': 0.0001055976808988385, 'epochs': 36, 'dropout_rate': 0.20485469401553563, 'sparsity_weight': 0.013031992863680003, 'n_estimators': 278, 'max_depth': 3, 'learning_rate': 0.04094769515814995, 'subsample': 0.6053647042188627, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.7688827543900008.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7651\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs, batch_size, lr, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7518\n",
      "ROC-AUC autoencoded: 0.7516\n",
      "ROC-AUC autoencoded: 0.7583\n",
      "ROC-AUC autoencoded: 0.7608\n",
      "ROC-AUC autoencoded: 0.7619\n",
      "ROC-AUC autoencoded: 0.7276\n",
      "ROC-AUC autoencoded: 0.7421\n",
      "ROC-AUC autoencoded: 0.7471\n",
      "ROC-AUC autoencoded: 0.7516\n",
      "ROC-AUC autoencoded: 0.7408\n",
      "ROC-AUC autoencoded: 0.7409\n",
      "ROC-AUC autoencoded: 0.7396\n",
      "ROC-AUC autoencoded: 0.7298\n",
      "ROC-AUC autoencoded: 0.7548\n",
      "ROC-AUC autoencoded: 0.7580\n",
      "ROC-AUC autoencoded: 0.7049\n",
      "ROC-AUC autoencoded: 0.7288\n",
      "ROC-AUC autoencoded: 0.7289\n",
      "ROC-AUC autoencoded: 0.7196\n",
      "ROC-AUC autoencoded: 0.7212\n",
      "ROC-AUC autoencoded: 0.7648\n",
      "ROC-AUC autoencoded: 0.7734\n",
      "ROC-AUC autoencoded: 0.7507\n",
      "ROC-AUC autoencoded: 0.7659\n",
      "ROC-AUC autoencoded: 0.7639\n",
      "среднее 0.7455487114060257\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:12:11,650] A new study created in memory with name: no-name-f900372b-b470-4d39-87c5-a36884c6ee53\n",
      "[I 2025-05-12 07:12:20,046] Trial 0 finished with value: 0.7402614830151061 and parameters: {'latent_dim': 93, 'hidden_dim': 114, 'lr': 0.00022029119412758256, 'epochs': 18, 'dropout_rate': 0.13297626939762652, 'sparsity_weight': 0.04443224493203249, 'C': 1.1851079476063706, 'kernel': 'linear'}. Best is trial 0 with value: 0.7402614830151061.\n",
      "[I 2025-05-12 07:12:25,180] Trial 1 finished with value: 0.6334157656621424 and parameters: {'latent_dim': 12, 'hidden_dim': 97, 'lr': 0.00039649377251665756, 'epochs': 16, 'dropout_rate': 0.40855186015524836, 'sparsity_weight': 0.00014519541390273607, 'C': 0.15017379743611228, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 0 with value: 0.7402614830151061.\n",
      "[I 2025-05-12 07:12:39,513] Trial 2 finished with value: 0.675427497891266 and parameters: {'latent_dim': 49, 'hidden_dim': 175, 'lr': 0.00011577956719167442, 'epochs': 43, 'dropout_rate': 0.3316543200977652, 'sparsity_weight': 0.006982176702629575, 'C': 14.98073150900428, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 0 with value: 0.7402614830151061.\n",
      "[I 2025-05-12 07:12:49,446] Trial 3 finished with value: 0.7635534084809447 and parameters: {'latent_dim': 71, 'hidden_dim': 162, 'lr': 0.004707560046053872, 'epochs': 28, 'dropout_rate': 0.2811513636270585, 'sparsity_weight': 0.00019041685144391434, 'C': 0.11076755099976544, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.7635534084809447.\n",
      "[I 2025-05-12 07:13:01,428] Trial 4 finished with value: 0.757342228356721 and parameters: {'latent_dim': 85, 'hidden_dim': 195, 'lr': 0.0002160436316103949, 'epochs': 34, 'dropout_rate': 0.20525991953714554, 'sparsity_weight': 0.00010415996327491992, 'C': 0.3194389039896642, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.7635534084809447.\n",
      "[I 2025-05-12 07:13:13,867] Trial 5 finished with value: 0.6141591902461467 and parameters: {'latent_dim': 54, 'hidden_dim': 97, 'lr': 0.0030053248357032793, 'epochs': 41, 'dropout_rate': 0.4283534417021809, 'sparsity_weight': 0.0034605336072630354, 'C': 1.0759323983843, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 3 with value: 0.7635534084809447.\n",
      "[I 2025-05-12 07:13:29,337] Trial 6 finished with value: 0.6879073690667893 and parameters: {'latent_dim': 19, 'hidden_dim': 138, 'lr': 0.00015987296828752072, 'epochs': 50, 'dropout_rate': 0.4746527014079738, 'sparsity_weight': 0.027937024081290552, 'C': 0.2789570676899656, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 3 with value: 0.7635534084809447.\n",
      "[I 2025-05-12 07:13:35,188] Trial 7 finished with value: 0.6865750325895252 and parameters: {'latent_dim': 61, 'hidden_dim': 254, 'lr': 0.00011173787374027378, 'epochs': 15, 'dropout_rate': 0.17951569633860345, 'sparsity_weight': 0.03731620195176577, 'C': 0.4640574371275468, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 3 with value: 0.7635534084809447.\n",
      "[I 2025-05-12 07:13:50,624] Trial 8 finished with value: 0.7679529944022697 and parameters: {'latent_dim': 76, 'hidden_dim': 230, 'lr': 0.0002927724394234633, 'epochs': 42, 'dropout_rate': 0.12524175000924737, 'sparsity_weight': 0.0033364835160055685, 'C': 0.16789377135403577, 'kernel': 'linear'}. Best is trial 8 with value: 0.7679529944022697.\n",
      "[I 2025-05-12 07:14:05,185] Trial 9 finished with value: 0.770703933747412 and parameters: {'latent_dim': 28, 'hidden_dim': 87, 'lr': 0.0003026183323517203, 'epochs': 49, 'dropout_rate': 0.4711402899352235, 'sparsity_weight': 0.07216299697833727, 'C': 0.14579068044982973, 'kernel': 'linear'}. Best is trial 9 with value: 0.770703933747412.\n",
      "[I 2025-05-12 07:15:19,762] Trial 10 finished with value: 0.7586074687523962 and parameters: {'latent_dim': 31, 'hidden_dim': 64, 'lr': 0.0009643464165457115, 'epochs': 30, 'dropout_rate': 0.34355331120041843, 'sparsity_weight': 0.0005094995353136714, 'C': 82.5385127645726, 'kernel': 'linear'}. Best is trial 9 with value: 0.770703933747412.\n",
      "[I 2025-05-12 07:15:39,713] Trial 11 finished with value: 0.7663331032896249 and parameters: {'latent_dim': 37, 'hidden_dim': 230, 'lr': 0.0008441645723807555, 'epochs': 48, 'dropout_rate': 0.1051170963516107, 'sparsity_weight': 0.0011404445155608768, 'C': 3.7823356434277766, 'kernel': 'linear'}. Best is trial 9 with value: 0.770703933747412.\n",
      "[I 2025-05-12 07:15:59,763] Trial 12 finished with value: 0.7556744114715128 and parameters: {'latent_dim': 75, 'hidden_dim': 206, 'lr': 0.0004576242183903706, 'epochs': 37, 'dropout_rate': 0.26830918367275364, 'sparsity_weight': 0.010143096785549468, 'C': 3.110504996900658, 'kernel': 'linear'}. Best is trial 9 with value: 0.770703933747412.\n",
      "[I 2025-05-12 07:16:12,100] Trial 13 finished with value: 0.7637259412621732 and parameters: {'latent_dim': 41, 'hidden_dim': 66, 'lr': 0.00044150717476529577, 'epochs': 44, 'dropout_rate': 0.22257985842116948, 'sparsity_weight': 0.08147009639219878, 'C': 0.5948926245144839, 'kernel': 'linear'}. Best is trial 9 with value: 0.770703933747412.\n",
      "[I 2025-05-12 07:16:19,975] Trial 14 finished with value: 0.7474311785905989 and parameters: {'latent_dim': 100, 'hidden_dim': 126, 'lr': 0.0019773440505056502, 'epochs': 24, 'dropout_rate': 0.3884709011438987, 'sparsity_weight': 0.0009783092247919753, 'C': 0.12115213745000436, 'kernel': 'linear'}. Best is trial 9 with value: 0.770703933747412.\n",
      "[I 2025-05-12 07:16:34,163] Trial 15 finished with value: 0.7652979066022545 and parameters: {'latent_dim': 26, 'hidden_dim': 222, 'lr': 0.0002915612221591733, 'epochs': 37, 'dropout_rate': 0.48767774348891074, 'sparsity_weight': 0.011591466977428648, 'C': 2.9260990824361817, 'kernel': 'linear'}. Best is trial 9 with value: 0.770703933747412.\n",
      "[I 2025-05-12 07:17:11,833] Trial 16 finished with value: 0.7551951537458784 and parameters: {'latent_dim': 64, 'hidden_dim': 144, 'lr': 0.009523986766606301, 'epochs': 46, 'dropout_rate': 0.15178726099796652, 'sparsity_weight': 0.0030381234929024387, 'C': 11.444998264664658, 'kernel': 'linear'}. Best is trial 9 with value: 0.770703933747412.\n",
      "[I 2025-05-12 07:17:28,945] Trial 17 finished with value: 0.6501131048232498 and parameters: {'latent_dim': 77, 'hidden_dim': 254, 'lr': 0.0006853999185172479, 'epochs': 50, 'dropout_rate': 0.23844214516534856, 'sparsity_weight': 0.003030481460600435, 'C': 0.9918115723924154, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 9 with value: 0.770703933747412.\n",
      "[I 2025-05-12 07:17:43,303] Trial 18 finished with value: 0.7484184495054059 and parameters: {'latent_dim': 46, 'hidden_dim': 195, 'lr': 0.0014821877423241473, 'epochs': 40, 'dropout_rate': 0.3559884277784118, 'sparsity_weight': 0.0004131028125086631, 'C': 0.22403000021798186, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 9 with value: 0.770703933747412.\n",
      "[I 2025-05-12 07:18:23,394] Trial 19 finished with value: 0.7635821639444828 and parameters: {'latent_dim': 10, 'hidden_dim': 169, 'lr': 0.0005321234169129127, 'epochs': 34, 'dropout_rate': 0.4471418490281628, 'sparsity_weight': 0.016803945747018767, 'C': 74.78027352221454, 'kernel': 'linear'}. Best is trial 9 with value: 0.770703933747412.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7742\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs, batch_size, lr, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7655\n",
      "ROC-AUC autoencoded: 0.7474\n",
      "ROC-AUC autoencoded: 0.7530\n",
      "ROC-AUC autoencoded: 0.7556\n",
      "ROC-AUC autoencoded: 0.7629\n",
      "ROC-AUC autoencoded: 0.7699\n",
      "ROC-AUC autoencoded: 0.7857\n",
      "ROC-AUC autoencoded: 0.7815\n",
      "ROC-AUC autoencoded: 0.7706\n",
      "ROC-AUC autoencoded: 0.7600\n",
      "ROC-AUC autoencoded: 0.7380\n",
      "ROC-AUC autoencoded: 0.7529\n",
      "ROC-AUC autoencoded: 0.7567\n",
      "ROC-AUC autoencoded: 0.7521\n",
      "ROC-AUC autoencoded: 0.7474\n",
      "ROC-AUC autoencoded: 0.7334\n",
      "ROC-AUC autoencoded: 0.7213\n",
      "ROC-AUC autoencoded: 0.7153\n",
      "ROC-AUC autoencoded: 0.7119\n",
      "ROC-AUC autoencoded: 0.7167\n",
      "ROC-AUC autoencoded: 0.7601\n",
      "ROC-AUC autoencoded: 0.7506\n",
      "ROC-AUC autoencoded: 0.7622\n",
      "ROC-AUC autoencoded: 0.7453\n",
      "ROC-AUC autoencoded: 0.7537\n",
      "среднее 0.7507824064037071\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:20:04,144] A new study created in memory with name: no-name-ef8e9660-4edf-4e8c-a629-6e28e68a45cc\n",
      "[I 2025-05-12 07:20:23,526] Trial 0 finished with value: 0.7204968944099379 and parameters: {'latent_dim': 69, 'hidden_dim_ae': 245, 'lr_ae': 0.00031910900396024883, 'epochs_ae': 46, 'dropout_rate_ae': 0.4094128876797579, 'sparsity_weight': 0.010887888045612422, 'hidden_dim_mlp': 38, 'lr_mlp': 0.006369384553862981, 'epochs_mlp': 26, 'dropout_rate_mlp': 0.28595062708094077}. Best is trial 0 with value: 0.7204968944099379.\n",
      "[I 2025-05-12 07:20:33,740] Trial 1 finished with value: 0.7399164174526494 and parameters: {'latent_dim': 75, 'hidden_dim_ae': 129, 'lr_ae': 0.002015931938723441, 'epochs_ae': 22, 'dropout_rate_ae': 0.38408150962818655, 'sparsity_weight': 0.059885748857245215, 'hidden_dim_mlp': 121, 'lr_mlp': 0.0024141190538581095, 'epochs_mlp': 21, 'dropout_rate_mlp': 0.35598367190219615}. Best is trial 1 with value: 0.7399164174526494.\n",
      "[I 2025-05-12 07:20:48,161] Trial 2 finished with value: 0.7681926232650871 and parameters: {'latent_dim': 42, 'hidden_dim_ae': 239, 'lr_ae': 0.006519997980511931, 'epochs_ae': 36, 'dropout_rate_ae': 0.25015817780035, 'sparsity_weight': 0.001243789028737038, 'hidden_dim_mlp': 63, 'lr_mlp': 0.0001834502628113105, 'epochs_mlp': 15, 'dropout_rate_mlp': 0.269703595792406}. Best is trial 2 with value: 0.7681926232650871.\n",
      "[I 2025-05-12 07:21:06,937] Trial 3 finished with value: 0.7069434859289933 and parameters: {'latent_dim': 62, 'hidden_dim_ae': 125, 'lr_ae': 0.006436452771694851, 'epochs_ae': 36, 'dropout_rate_ae': 0.2902088461430631, 'sparsity_weight': 0.00021864481356669095, 'hidden_dim_mlp': 128, 'lr_mlp': 0.0009567814250323322, 'epochs_mlp': 45, 'dropout_rate_mlp': 0.11920028580211778}. Best is trial 2 with value: 0.7681926232650871.\n",
      "[I 2025-05-12 07:21:15,797] Trial 4 finished with value: 0.7592784295682846 and parameters: {'latent_dim': 100, 'hidden_dim_ae': 135, 'lr_ae': 0.0007876049110721769, 'epochs_ae': 12, 'dropout_rate_ae': 0.33852433360044343, 'sparsity_weight': 0.004007897704192352, 'hidden_dim_mlp': 62, 'lr_mlp': 0.0002661301295317962, 'epochs_mlp': 31, 'dropout_rate_mlp': 0.3004329967247008}. Best is trial 2 with value: 0.7681926232650871.\n",
      "[I 2025-05-12 07:21:27,915] Trial 5 finished with value: 0.7188099072157043 and parameters: {'latent_dim': 73, 'hidden_dim_ae': 218, 'lr_ae': 0.00012135417701277318, 'epochs_ae': 22, 'dropout_rate_ae': 0.462951761944451, 'sparsity_weight': 0.00668038192583686, 'hidden_dim_mlp': 75, 'lr_mlp': 0.008444267750034847, 'epochs_mlp': 31, 'dropout_rate_mlp': 0.19399053479269346}. Best is trial 2 with value: 0.7681926232650871.\n",
      "[I 2025-05-12 07:21:43,397] Trial 6 finished with value: 0.7530097385169849 and parameters: {'latent_dim': 37, 'hidden_dim_ae': 218, 'lr_ae': 0.000468257336943997, 'epochs_ae': 25, 'dropout_rate_ae': 0.30301032395424776, 'sparsity_weight': 0.0009883444417212537, 'hidden_dim_mlp': 84, 'lr_mlp': 0.00047371532605142196, 'epochs_mlp': 46, 'dropout_rate_mlp': 0.3738818966364462}. Best is trial 2 with value: 0.7681926232650871.\n",
      "[I 2025-05-12 07:21:58,679] Trial 7 finished with value: 0.7036270224676021 and parameters: {'latent_dim': 85, 'hidden_dim_ae': 75, 'lr_ae': 0.0005788906828977162, 'epochs_ae': 34, 'dropout_rate_ae': 0.42028796146550207, 'sparsity_weight': 0.09045384610414012, 'hidden_dim_mlp': 89, 'lr_mlp': 0.004210540379298296, 'epochs_mlp': 31, 'dropout_rate_mlp': 0.1542937847799688}. Best is trial 2 with value: 0.7681926232650871.\n",
      "[I 2025-05-12 07:22:10,339] Trial 8 finished with value: 0.7737903535004985 and parameters: {'latent_dim': 78, 'hidden_dim_ae': 247, 'lr_ae': 0.004038266648695509, 'epochs_ae': 25, 'dropout_rate_ae': 0.3378337932846366, 'sparsity_weight': 0.010064852563408973, 'hidden_dim_mlp': 115, 'lr_mlp': 0.00010372353362371224, 'epochs_mlp': 18, 'dropout_rate_mlp': 0.2452965846413614}. Best is trial 8 with value: 0.7737903535004985.\n",
      "[I 2025-05-12 07:22:30,941] Trial 9 finished with value: 0.7567862893949852 and parameters: {'latent_dim': 65, 'hidden_dim_ae': 179, 'lr_ae': 0.0014589123398780599, 'epochs_ae': 47, 'dropout_rate_ae': 0.2645882571310034, 'sparsity_weight': 0.000288822519631544, 'hidden_dim_mlp': 41, 'lr_mlp': 0.006421974900342165, 'epochs_mlp': 38, 'dropout_rate_mlp': 0.4797083240527351}. Best is trial 8 with value: 0.7737903535004985.\n",
      "[I 2025-05-12 07:22:36,368] Trial 10 finished with value: 0.7714707461084273 and parameters: {'latent_dim': 18, 'hidden_dim_ae': 181, 'lr_ae': 0.003021939317943124, 'epochs_ae': 12, 'dropout_rate_ae': 0.1338601857313819, 'sparsity_weight': 0.021886156190733058, 'hidden_dim_mlp': 110, 'lr_mlp': 0.00011778287298290116, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.21684611142570526}. Best is trial 8 with value: 0.7737903535004985.\n",
      "[I 2025-05-12 07:22:41,099] Trial 11 finished with value: 0.7771834981979909 and parameters: {'latent_dim': 18, 'hidden_dim_ae': 178, 'lr_ae': 0.003455526537827659, 'epochs_ae': 10, 'dropout_rate_ae': 0.11668328334611974, 'sparsity_weight': 0.021646089606007585, 'hidden_dim_mlp': 107, 'lr_mlp': 0.00010578188972851903, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.2139421287888496}. Best is trial 11 with value: 0.7771834981979909.\n",
      "[I 2025-05-12 07:22:46,138] Trial 12 finished with value: 0.7766083889272295 and parameters: {'latent_dim': 10, 'hidden_dim_ae': 199, 'lr_ae': 0.00355290127869655, 'epochs_ae': 10, 'dropout_rate_ae': 0.1361254068365677, 'sparsity_weight': 0.02673914626125196, 'hidden_dim_mlp': 104, 'lr_mlp': 0.00010700494621987628, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.2250812372606087}. Best is trial 11 with value: 0.7771834981979909.\n",
      "[I 2025-05-12 07:22:51,023] Trial 13 finished with value: 0.7632083429184878 and parameters: {'latent_dim': 10, 'hidden_dim_ae': 190, 'lr_ae': 0.00958067611628526, 'epochs_ae': 10, 'dropout_rate_ae': 0.10253873073848288, 'sparsity_weight': 0.029588885149627722, 'hidden_dim_mlp': 100, 'lr_mlp': 0.00042155902112382074, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.17383782467240877}. Best is trial 11 with value: 0.7771834981979909.\n",
      "[I 2025-05-12 07:22:59,647] Trial 14 finished with value: 0.7365232727551567 and parameters: {'latent_dim': 25, 'hidden_dim_ae': 163, 'lr_ae': 0.002780250372589815, 'epochs_ae': 16, 'dropout_rate_ae': 0.18322111642490985, 'sparsity_weight': 0.02837577746728541, 'hidden_dim_mlp': 102, 'lr_mlp': 0.0010368550259195694, 'epochs_mlp': 22, 'dropout_rate_mlp': 0.10000335255469672}. Best is trial 11 with value: 0.7771834981979909.\n",
      "[I 2025-05-12 07:23:07,465] Trial 15 finished with value: 0.7768576029445594 and parameters: {'latent_dim': 34, 'hidden_dim_ae': 202, 'lr_ae': 0.0012814424760373892, 'epochs_ae': 17, 'dropout_rate_ae': 0.19149258079051545, 'sparsity_weight': 0.0020232512872716893, 'hidden_dim_mlp': 101, 'lr_mlp': 0.00020517903576874812, 'epochs_mlp': 15, 'dropout_rate_mlp': 0.370203221592068}. Best is trial 11 with value: 0.7771834981979909.\n",
      "[I 2025-05-12 07:23:15,781] Trial 16 finished with value: 0.7727934974311785 and parameters: {'latent_dim': 45, 'hidden_dim_ae': 147, 'lr_ae': 0.001157023063497952, 'epochs_ae': 17, 'dropout_rate_ae': 0.20321225428894843, 'sparsity_weight': 0.0015257436221221058, 'hidden_dim_mlp': 92, 'lr_mlp': 0.00026967924579334194, 'epochs_mlp': 18, 'dropout_rate_mlp': 0.42256201525936593}. Best is trial 11 with value: 0.7771834981979909.\n",
      "[I 2025-05-12 07:23:23,199] Trial 17 finished with value: 0.7675600030672493 and parameters: {'latent_dim': 30, 'hidden_dim_ae': 105, 'lr_ae': 0.00023990293753215904, 'epochs_ae': 17, 'dropout_rate_ae': 0.20122399889302767, 'sparsity_weight': 0.0005892129753242695, 'hidden_dim_mlp': 74, 'lr_mlp': 0.0006545258004558389, 'epochs_mlp': 15, 'dropout_rate_mlp': 0.3406256314451692}. Best is trial 11 with value: 0.7771834981979909.\n",
      "[I 2025-05-12 07:23:37,148] Trial 18 finished with value: 0.7740395675178284 and parameters: {'latent_dim': 52, 'hidden_dim_ae': 207, 'lr_ae': 0.0017252528746475846, 'epochs_ae': 30, 'dropout_rate_ae': 0.17060064075391473, 'sparsity_weight': 0.0025666909609364276, 'hidden_dim_mlp': 98, 'lr_mlp': 0.00019585486258856833, 'epochs_mlp': 25, 'dropout_rate_mlp': 0.4208848915710959}. Best is trial 11 with value: 0.7771834981979909.\n",
      "[I 2025-05-12 07:23:44,461] Trial 19 finished with value: 0.7649911816578484 and parameters: {'latent_dim': 24, 'hidden_dim_ae': 164, 'lr_ae': 0.0009549673719327611, 'epochs_ae': 16, 'dropout_rate_ae': 0.10235407903352262, 'sparsity_weight': 0.003725030339802575, 'hidden_dim_mlp': 110, 'lr_mlp': 0.0013829749675898424, 'epochs_mlp': 15, 'dropout_rate_mlp': 0.318308577860914}. Best is trial 11 with value: 0.7771834981979909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7680\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7606\n",
      "ROC-AUC autoencoded: 0.7722\n",
      "ROC-AUC autoencoded: 0.7557\n",
      "ROC-AUC autoencoded: 0.7646\n",
      "ROC-AUC autoencoded: 0.7664\n",
      "ROC-AUC autoencoded: 0.7544\n",
      "ROC-AUC autoencoded: 0.7722\n",
      "ROC-AUC autoencoded: 0.7740\n",
      "ROC-AUC autoencoded: 0.7669\n",
      "ROC-AUC autoencoded: 0.7567\n",
      "ROC-AUC autoencoded: 0.7553\n",
      "ROC-AUC autoencoded: 0.7494\n",
      "ROC-AUC autoencoded: 0.7532\n",
      "ROC-AUC autoencoded: 0.7434\n",
      "ROC-AUC autoencoded: 0.7473\n",
      "ROC-AUC autoencoded: 0.7472\n",
      "ROC-AUC autoencoded: 0.7169\n",
      "ROC-AUC autoencoded: 0.7366\n",
      "ROC-AUC autoencoded: 0.7401\n",
      "ROC-AUC autoencoded: 0.7248\n",
      "ROC-AUC autoencoded: 0.7650\n",
      "ROC-AUC autoencoded: 0.7511\n",
      "ROC-AUC autoencoded: 0.7680\n",
      "ROC-AUC autoencoded: 0.7561\n",
      "ROC-AUC autoencoded: 0.7663\n",
      "среднее 0.7545694593824854\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь блок с sparse автоэнкодером с классифицирующей головой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:24:18,327] A new study created in memory with name: no-name-919c305a-2289-4563-b723-c6734843808c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:24:37,821] Trial 0 finished with value: 0.7037995552488305 and parameters: {'latent_dim': 97, 'hidden_dim': 255, 'lr': 0.006845564709760329, 'epochs': 43, 'dropout_rate': 0.39150437206351596, 'sparsity_weight': 0.013380230367380005, 'classification_weight': 0.16195837734201712, 'C': 0.08992248613511357, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7037995552488305.\n",
      "[I 2025-05-12 07:24:51,094] Trial 1 finished with value: 0.67889732382486 and parameters: {'latent_dim': 57, 'hidden_dim': 76, 'lr': 0.0023315604806050166, 'epochs': 32, 'dropout_rate': 0.2790373591268221, 'sparsity_weight': 0.004548977947412401, 'classification_weight': 0.4666794129779479, 'C': 0.06313034652992804, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7037995552488305.\n",
      "[I 2025-05-12 07:24:57,698] Trial 2 finished with value: 0.7052948393528103 and parameters: {'latent_dim': 16, 'hidden_dim': 189, 'lr': 0.0003585850439930856, 'epochs': 15, 'dropout_rate': 0.19752376990998594, 'sparsity_weight': 0.018591795379536247, 'classification_weight': 0.8810921180586662, 'C': 0.15664148272563855, 'solver': 'liblinear'}. Best is trial 2 with value: 0.7052948393528103.\n",
      "[I 2025-05-12 07:25:12,371] Trial 3 finished with value: 0.6971474580170233 and parameters: {'latent_dim': 38, 'hidden_dim': 128, 'lr': 0.0003898144097182686, 'epochs': 38, 'dropout_rate': 0.3608757769685629, 'sparsity_weight': 0.00037472596018478, 'classification_weight': 0.7079160173431439, 'C': 3.2135705314966785, 'solver': 'saga'}. Best is trial 2 with value: 0.7052948393528103.\n",
      "[I 2025-05-12 07:25:23,491] Trial 4 finished with value: 0.6709416455793268 and parameters: {'latent_dim': 98, 'hidden_dim': 180, 'lr': 0.00035987181527962424, 'epochs': 24, 'dropout_rate': 0.27804004016834405, 'sparsity_weight': 0.0006688025387193864, 'classification_weight': 0.5430053727686044, 'C': 4.745693974493255, 'solver': 'saga'}. Best is trial 2 with value: 0.7052948393528103.\n",
      "[I 2025-05-12 07:25:42,227] Trial 5 finished with value: 0.629495437466452 and parameters: {'latent_dim': 71, 'hidden_dim': 106, 'lr': 0.0028230356407923044, 'epochs': 50, 'dropout_rate': 0.47924931786185343, 'sparsity_weight': 0.03447904656164967, 'classification_weight': 0.81768108035625, 'C': 13.080221674573831, 'solver': 'liblinear'}. Best is trial 2 with value: 0.7052948393528103.\n",
      "[I 2025-05-12 07:25:56,668] Trial 6 finished with value: 0.7788704853922245 and parameters: {'latent_dim': 30, 'hidden_dim': 230, 'lr': 0.00014093232733769625, 'epochs': 36, 'dropout_rate': 0.42665333681497375, 'sparsity_weight': 0.003310525466179431, 'classification_weight': 0.1759822588511213, 'C': 0.017350409246959443, 'solver': 'liblinear'}. Best is trial 6 with value: 0.7788704853922245.\n",
      "[I 2025-05-12 07:26:09,833] Trial 7 finished with value: 0.7494248907292386 and parameters: {'latent_dim': 88, 'hidden_dim': 114, 'lr': 0.0006589195814977927, 'epochs': 34, 'dropout_rate': 0.44884720267578737, 'sparsity_weight': 0.00044560007166566016, 'classification_weight': 0.4730862088769282, 'C': 0.08126652792500119, 'solver': 'saga'}. Best is trial 6 with value: 0.7788704853922245.\n",
      "[I 2025-05-12 07:26:19,643] Trial 8 finished with value: 0.6158461774403804 and parameters: {'latent_dim': 33, 'hidden_dim': 228, 'lr': 0.0011350757830418821, 'epochs': 24, 'dropout_rate': 0.18563429741572987, 'sparsity_weight': 0.008951557917667616, 'classification_weight': 0.8755492062337755, 'C': 0.24719704216825827, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.7788704853922245.\n",
      "[I 2025-05-12 07:26:33,839] Trial 9 finished with value: 0.6654397668890423 and parameters: {'latent_dim': 38, 'hidden_dim': 108, 'lr': 0.0009054360559689832, 'epochs': 39, 'dropout_rate': 0.1988986888256672, 'sparsity_weight': 0.0029454571489889564, 'classification_weight': 0.6576797269351353, 'C': 0.06249970099701377, 'solver': 'liblinear'}. Best is trial 6 with value: 0.7788704853922245.\n",
      "[I 2025-05-12 07:26:43,731] Trial 10 finished with value: 0.7753048079135034 and parameters: {'latent_dim': 19, 'hidden_dim': 216, 'lr': 0.00010293572181039261, 'epochs': 25, 'dropout_rate': 0.37127887108560287, 'sparsity_weight': 0.09329636378336319, 'classification_weight': 0.11061910539158146, 'C': 0.015566725146654671, 'solver': 'liblinear'}. Best is trial 6 with value: 0.7788704853922245.\n",
      "[I 2025-05-12 07:26:53,274] Trial 11 finished with value: 0.7751897860593512 and parameters: {'latent_dim': 10, 'hidden_dim': 216, 'lr': 0.00014714686458724743, 'epochs': 24, 'dropout_rate': 0.3797941531503718, 'sparsity_weight': 0.0847700769133777, 'classification_weight': 0.10273820312044009, 'C': 0.010481043338480208, 'solver': 'liblinear'}. Best is trial 6 with value: 0.7788704853922245.\n",
      "[I 2025-05-12 07:26:59,422] Trial 12 finished with value: 0.7717199601257573 and parameters: {'latent_dim': 25, 'hidden_dim': 246, 'lr': 0.00010346784712888038, 'epochs': 15, 'dropout_rate': 0.42323108484989874, 'sparsity_weight': 0.001829581262253088, 'classification_weight': 0.24240951166643743, 'C': 0.0102788036564103, 'solver': 'liblinear'}. Best is trial 6 with value: 0.7788704853922245.\n",
      "[I 2025-05-12 07:27:10,688] Trial 13 finished with value: 0.7404723564143855 and parameters: {'latent_dim': 50, 'hidden_dim': 205, 'lr': 0.00018182724872548966, 'epochs': 26, 'dropout_rate': 0.33317848144317175, 'sparsity_weight': 0.00011679103538671763, 'classification_weight': 0.3138656434717512, 'C': 90.42604469831366, 'solver': 'liblinear'}. Best is trial 6 with value: 0.7788704853922245.\n",
      "[I 2025-05-12 07:27:14,816] Trial 14 finished with value: 0.7656429721647114 and parameters: {'latent_dim': 21, 'hidden_dim': 157, 'lr': 0.00020134501271369017, 'epochs': 11, 'dropout_rate': 0.48513141995784215, 'sparsity_weight': 0.09634327235591585, 'classification_weight': 0.28174471032616943, 'C': 0.5191146026550576, 'solver': 'liblinear'}. Best is trial 6 with value: 0.7788704853922245.\n",
      "[I 2025-05-12 07:27:26,108] Trial 15 finished with value: 0.7669273828694118 and parameters: {'latent_dim': 53, 'hidden_dim': 158, 'lr': 0.0001200001363110032, 'epochs': 29, 'dropout_rate': 0.3154078422340638, 'sparsity_weight': 0.039023954268669545, 'classification_weight': 0.36580037032036217, 'C': 0.020069283384287883, 'solver': 'liblinear'}. Best is trial 6 with value: 0.7788704853922245.\n",
      "[I 2025-05-12 07:27:34,098] Trial 16 finished with value: 0.7759757687293919 and parameters: {'latent_dim': 29, 'hidden_dim': 234, 'lr': 0.0002553573488605604, 'epochs': 19, 'dropout_rate': 0.4171066682017046, 'sparsity_weight': 0.001869136982026198, 'classification_weight': 0.17893876653161261, 'C': 0.028559064676892728, 'solver': 'liblinear'}. Best is trial 6 with value: 0.7788704853922245.\n",
      "[I 2025-05-12 07:27:41,482] Trial 17 finished with value: 0.7443255885284872 and parameters: {'latent_dim': 29, 'hidden_dim': 236, 'lr': 0.0002798482829473423, 'epochs': 18, 'dropout_rate': 0.42418529824293144, 'sparsity_weight': 0.0012533826479530106, 'classification_weight': 0.2405439921861786, 'C': 0.7696685497612175, 'solver': 'liblinear'}. Best is trial 6 with value: 0.7788704853922245.\n",
      "[I 2025-05-12 07:27:59,222] Trial 18 finished with value: 0.7670424047235641 and parameters: {'latent_dim': 45, 'hidden_dim': 187, 'lr': 0.0006126341023511464, 'epochs': 45, 'dropout_rate': 0.49885760623128345, 'sparsity_weight': 0.006829941648973461, 'classification_weight': 0.21096774333681836, 'C': 0.027548559733975644, 'solver': 'saga'}. Best is trial 6 with value: 0.7788704853922245.\n",
      "[I 2025-05-12 07:28:07,293] Trial 19 finished with value: 0.6621999846637528 and parameters: {'latent_dim': 64, 'hidden_dim': 254, 'lr': 0.00023324656694658638, 'epochs': 19, 'dropout_rate': 0.1372517814273576, 'sparsity_weight': 0.0012613599992260841, 'classification_weight': 0.384478820516941, 'C': 2.1639818310026175, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.7788704853922245.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7790\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingSparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(ClassifyingSparseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "    \n",
    "def train_classifying_sparse_autoencoder(model, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    class_criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, latent, classification = model(batch_x)\n",
    "            \n",
    "            recon_loss = recon_criterion(reconstructed, batch_x)\n",
    "            sparsity_loss = torch.mean(torch.abs(latent))\n",
    "            class_loss = class_criterion(classification, batch_y)\n",
    "            \n",
    "            loss = (1 - classification_weight) * (recon_loss + sparsity_weight * sparsity_loss) + classification_weight * class_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent, _ = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7718\n",
      "ROC-AUC autoencoded: 0.7820\n",
      "ROC-AUC autoencoded: 0.7660\n",
      "ROC-AUC autoencoded: 0.7716\n",
      "ROC-AUC autoencoded: 0.7433\n",
      "ROC-AUC autoencoded: 0.7667\n",
      "ROC-AUC autoencoded: 0.7901\n",
      "ROC-AUC autoencoded: 0.7602\n",
      "ROC-AUC autoencoded: 0.7800\n",
      "ROC-AUC autoencoded: 0.7842\n",
      "ROC-AUC autoencoded: 0.7548\n",
      "ROC-AUC autoencoded: 0.7432\n",
      "ROC-AUC autoencoded: 0.7477\n",
      "ROC-AUC autoencoded: 0.7532\n",
      "ROC-AUC autoencoded: 0.7624\n",
      "ROC-AUC autoencoded: 0.7287\n",
      "ROC-AUC autoencoded: 0.7029\n",
      "ROC-AUC autoencoded: 0.7193\n",
      "ROC-AUC autoencoded: 0.7221\n",
      "ROC-AUC autoencoded: 0.7152\n",
      "ROC-AUC autoencoded: 0.7641\n",
      "ROC-AUC autoencoded: 0.7763\n",
      "ROC-AUC autoencoded: 0.7714\n",
      "ROC-AUC autoencoded: 0.7758\n",
      "ROC-AUC autoencoded: 0.7687\n",
      "среднее 0.7568653096795431\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:29:50,255] A new study created in memory with name: no-name-c3223fd1-2dda-464f-b83a-eade89b7c02d\n",
      "[I 2025-05-12 07:30:06,204] Trial 0 finished with value: 0.7399164174526494 and parameters: {'latent_dim': 77, 'hidden_dim': 68, 'lr': 0.00020992982870001416, 'epochs': 10, 'dropout_rate': 0.265705109657795, 'sparsity_weight': 0.0003574387263813089, 'classification_weight': 0.5275361043390077, 'n_estimators': 61, 'max_depth': 7, 'learning_rate': 0.01722863136783286, 'subsample': 0.9572375317967756, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7399164174526494.\n",
      "[I 2025-05-12 07:31:36,690] Trial 1 finished with value: 0.7256153669197146 and parameters: {'latent_dim': 80, 'hidden_dim': 139, 'lr': 0.00041739437276639563, 'epochs': 43, 'dropout_rate': 0.27982559431792936, 'sparsity_weight': 0.0020084556374390613, 'classification_weight': 0.2912756186236444, 'n_estimators': 474, 'max_depth': 5, 'learning_rate': 0.02037212351841493, 'subsample': 0.9063506747947985, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7399164174526494.\n",
      "[I 2025-05-12 07:32:22,318] Trial 2 finished with value: 0.7510543669963959 and parameters: {'latent_dim': 29, 'hidden_dim': 181, 'lr': 0.00016834115197151596, 'epochs': 10, 'dropout_rate': 0.18111700892752935, 'sparsity_weight': 0.0071115722708797995, 'classification_weight': 0.20894687081607657, 'n_estimators': 431, 'max_depth': 7, 'learning_rate': 0.013453989170716406, 'subsample': 0.7868016950786607, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.7510543669963959.\n",
      "[I 2025-05-12 07:32:48,959] Trial 3 finished with value: 0.656583084119316 and parameters: {'latent_dim': 66, 'hidden_dim': 176, 'lr': 0.0013871948835403752, 'epochs': 45, 'dropout_rate': 0.15093948534363794, 'sparsity_weight': 0.018279615240592805, 'classification_weight': 0.37596271096791956, 'n_estimators': 67, 'max_depth': 8, 'learning_rate': 0.22091251528493663, 'subsample': 0.6976343685246136, 'min_samples_split': 19, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.7510543669963959.\n",
      "[I 2025-05-12 07:33:42,598] Trial 4 finished with value: 0.7137297753239781 and parameters: {'latent_dim': 81, 'hidden_dim': 134, 'lr': 0.003737356839186569, 'epochs': 39, 'dropout_rate': 0.48885722595286185, 'sparsity_weight': 0.0003360018328607633, 'classification_weight': 0.23723423674540955, 'n_estimators': 448, 'max_depth': 8, 'learning_rate': 0.2815136927255475, 'subsample': 0.8157418902886608, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.7510543669963959.\n",
      "[I 2025-05-12 07:34:14,287] Trial 5 finished with value: 0.5946054750402575 and parameters: {'latent_dim': 33, 'hidden_dim': 233, 'lr': 0.0034313009804518117, 'epochs': 37, 'dropout_rate': 0.10709868032825134, 'sparsity_weight': 0.0003371451106486208, 'classification_weight': 0.8126306547304016, 'n_estimators': 159, 'max_depth': 10, 'learning_rate': 0.11951919332666931, 'subsample': 0.7451896211034553, 'min_samples_split': 17, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.7510543669963959.\n",
      "[I 2025-05-12 07:34:44,174] Trial 6 finished with value: 0.7498274672187716 and parameters: {'latent_dim': 24, 'hidden_dim': 112, 'lr': 0.00028936647767095807, 'epochs': 25, 'dropout_rate': 0.15825092582651756, 'sparsity_weight': 0.0010324314610719303, 'classification_weight': 0.32573612228898785, 'n_estimators': 346, 'max_depth': 4, 'learning_rate': 0.010517344082769555, 'subsample': 0.9464374621198726, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.7510543669963959.\n",
      "[I 2025-05-12 07:35:19,151] Trial 7 finished with value: 0.6119162640901771 and parameters: {'latent_dim': 36, 'hidden_dim': 239, 'lr': 0.005730491892314944, 'epochs': 21, 'dropout_rate': 0.38703755422941033, 'sparsity_weight': 0.0006053496035401104, 'classification_weight': 0.7790471957612508, 'n_estimators': 425, 'max_depth': 5, 'learning_rate': 0.02713964395776919, 'subsample': 0.6555773585043266, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.7510543669963959.\n",
      "[I 2025-05-12 07:35:39,895] Trial 8 finished with value: 0.6444866191243003 and parameters: {'latent_dim': 21, 'hidden_dim': 142, 'lr': 0.00038256661109511265, 'epochs': 38, 'dropout_rate': 0.20108628384978547, 'sparsity_weight': 0.0015327149051323817, 'classification_weight': 0.8013048910830806, 'n_estimators': 176, 'max_depth': 4, 'learning_rate': 0.05716362875779018, 'subsample': 0.6648112338612487, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7510543669963959.\n",
      "[I 2025-05-12 07:36:26,905] Trial 9 finished with value: 0.6954413005137643 and parameters: {'latent_dim': 77, 'hidden_dim': 115, 'lr': 0.00663973158586354, 'epochs': 41, 'dropout_rate': 0.12656132604898482, 'sparsity_weight': 0.0034447487166283115, 'classification_weight': 0.1416564336937329, 'n_estimators': 190, 'max_depth': 8, 'learning_rate': 0.028427692500259272, 'subsample': 0.7224486543685376, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.7510543669963959.\n",
      "[I 2025-05-12 07:37:31,361] Trial 10 finished with value: 0.7481788206425887 and parameters: {'latent_dim': 49, 'hidden_dim': 193, 'lr': 0.00011157038110160723, 'epochs': 10, 'dropout_rate': 0.3822201296754503, 'sparsity_weight': 0.09103749089579206, 'classification_weight': 0.5340423530090632, 'n_estimators': 345, 'max_depth': 10, 'learning_rate': 0.05563494891017945, 'subsample': 0.8296689261973894, 'min_samples_split': 12, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7510543669963959.\n",
      "[I 2025-05-12 07:37:50,101] Trial 11 finished with value: 0.761808910359635 and parameters: {'latent_dim': 10, 'hidden_dim': 94, 'lr': 0.00011408654672514445, 'epochs': 24, 'dropout_rate': 0.201339730720138, 'sparsity_weight': 0.008675372380229468, 'classification_weight': 0.10556983452086185, 'n_estimators': 335, 'max_depth': 3, 'learning_rate': 0.010441467048205526, 'subsample': 0.8876746163323312, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.761808910359635.\n",
      "[I 2025-05-12 07:38:06,975] Trial 12 finished with value: 0.757438079901848 and parameters: {'latent_dim': 10, 'hidden_dim': 64, 'lr': 0.00010623816505300514, 'epochs': 20, 'dropout_rate': 0.21034627817534185, 'sparsity_weight': 0.008248418696467936, 'classification_weight': 0.10743452113733509, 'n_estimators': 335, 'max_depth': 3, 'learning_rate': 0.011444857473496934, 'subsample': 0.8552142683227644, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.761808910359635.\n",
      "[I 2025-05-12 07:38:46,251] Trial 13 finished with value: 0.7602369450195537 and parameters: {'latent_dim': 100, 'hidden_dim': 72, 'lr': 0.0008704524019949863, 'epochs': 20, 'dropout_rate': 0.21156670420521817, 'sparsity_weight': 0.016546400660969213, 'classification_weight': 0.10009683936989622, 'n_estimators': 288, 'max_depth': 3, 'learning_rate': 0.010446148262516747, 'subsample': 0.8768393614634593, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.761808910359635.\n",
      "[I 2025-05-12 07:39:25,737] Trial 14 finished with value: 0.6631585001150219 and parameters: {'latent_dim': 98, 'hidden_dim': 103, 'lr': 0.0007977633165892875, 'epochs': 31, 'dropout_rate': 0.23576810335805448, 'sparsity_weight': 0.03866893063493693, 'classification_weight': 0.4585727556669824, 'n_estimators': 250, 'max_depth': 3, 'learning_rate': 0.03487472270849077, 'subsample': 0.889322517399601, 'min_samples_split': 15, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.761808910359635.\n",
      "[I 2025-05-12 07:40:08,554] Trial 15 finished with value: 0.6866421286711143 and parameters: {'latent_dim': 55, 'hidden_dim': 89, 'lr': 0.001122033498266673, 'epochs': 18, 'dropout_rate': 0.32704747017093094, 'sparsity_weight': 0.021081212333778333, 'classification_weight': 0.6737575401525658, 'n_estimators': 286, 'max_depth': 5, 'learning_rate': 0.08745596397277701, 'subsample': 0.988361977554308, 'min_samples_split': 11, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.761808910359635.\n",
      "[I 2025-05-12 07:40:50,079] Trial 16 finished with value: 0.7610229276895942 and parameters: {'latent_dim': 95, 'hidden_dim': 87, 'lr': 0.0006407194752463816, 'epochs': 29, 'dropout_rate': 0.3194790968826703, 'sparsity_weight': 0.0065527793810771446, 'classification_weight': 0.1767417583142425, 'n_estimators': 282, 'max_depth': 3, 'learning_rate': 0.017441023254844625, 'subsample': 0.8920354488968787, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.761808910359635.\n",
      "[I 2025-05-12 07:41:16,258] Trial 17 finished with value: 0.7008473276589218 and parameters: {'latent_dim': 10, 'hidden_dim': 87, 'lr': 0.0019460098403777878, 'epochs': 31, 'dropout_rate': 0.32075328226527217, 'sparsity_weight': 0.00011965703990920795, 'classification_weight': 0.40459079317445384, 'n_estimators': 385, 'max_depth': 4, 'learning_rate': 0.01837646173418755, 'subsample': 0.9238531646525847, 'min_samples_split': 17, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.761808910359635.\n",
      "[I 2025-05-12 07:41:54,409] Trial 18 finished with value: 0.716528640441684 and parameters: {'latent_dim': 44, 'hidden_dim': 213, 'lr': 0.00048054059202369846, 'epochs': 49, 'dropout_rate': 0.37676089959735726, 'sparsity_weight': 0.006796170635008241, 'classification_weight': 0.20881648494131144, 'n_estimators': 249, 'max_depth': 6, 'learning_rate': 0.03725412224412074, 'subsample': 0.6107129035743084, 'min_samples_split': 11, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.761808910359635.\n",
      "[I 2025-05-12 07:42:23,551] Trial 19 finished with value: 0.7366191243002836 and parameters: {'latent_dim': 66, 'hidden_dim': 159, 'lr': 0.0005507078296932192, 'epochs': 26, 'dropout_rate': 0.4160743586568307, 'sparsity_weight': 0.003896606997279498, 'classification_weight': 0.5872287522509678, 'n_estimators': 208, 'max_depth': 3, 'learning_rate': 0.01515861815246224, 'subsample': 0.9952014523944512, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.761808910359635.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7636\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7529\n",
      "ROC-AUC autoencoded: 0.7523\n",
      "ROC-AUC autoencoded: 0.7598\n",
      "ROC-AUC autoencoded: 0.7373\n",
      "ROC-AUC autoencoded: 0.7539\n",
      "ROC-AUC autoencoded: 0.7349\n",
      "ROC-AUC autoencoded: 0.7337\n",
      "ROC-AUC autoencoded: 0.7277\n",
      "ROC-AUC autoencoded: 0.7426\n",
      "ROC-AUC autoencoded: 0.7247\n",
      "ROC-AUC autoencoded: 0.7445\n",
      "ROC-AUC autoencoded: 0.7468\n",
      "ROC-AUC autoencoded: 0.7636\n",
      "ROC-AUC autoencoded: 0.7396\n",
      "ROC-AUC autoencoded: 0.7470\n",
      "ROC-AUC autoencoded: 0.7242\n",
      "ROC-AUC autoencoded: 0.7121\n",
      "ROC-AUC autoencoded: 0.7263\n",
      "ROC-AUC autoencoded: 0.7151\n",
      "ROC-AUC autoencoded: 0.7177\n",
      "ROC-AUC autoencoded: 0.7581\n",
      "ROC-AUC autoencoded: 0.7405\n",
      "ROC-AUC autoencoded: 0.7358\n",
      "ROC-AUC autoencoded: 0.7549\n",
      "ROC-AUC autoencoded: 0.7370\n",
      "среднее 0.7393197592494309\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:44:36,245] A new study created in memory with name: no-name-199eeb1f-a1d1-42bd-ab90-a33711077015\n",
      "[I 2025-05-12 07:44:43,488] Trial 0 finished with value: 0.6670692431561998 and parameters: {'latent_dim': 38, 'hidden_dim': 139, 'lr': 0.000611542162636268, 'epochs': 17, 'dropout_rate': 0.3022266649943305, 'sparsity_weight': 0.000736813785512342, 'classification_weight': 0.15879701375633523, 'C': 12.503006934062949, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 0 with value: 0.6670692431561998.\n",
      "[I 2025-05-12 07:44:50,740] Trial 1 finished with value: 0.7207269381182425 and parameters: {'latent_dim': 33, 'hidden_dim': 154, 'lr': 0.0004099126146232408, 'epochs': 17, 'dropout_rate': 0.4150423152006675, 'sparsity_weight': 0.0036830492607183856, 'classification_weight': 0.5883618578415203, 'C': 8.9862176571126, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.7207269381182425.\n",
      "[I 2025-05-12 07:45:09,151] Trial 2 finished with value: 0.7368587531631009 and parameters: {'latent_dim': 58, 'hidden_dim': 188, 'lr': 0.004016192191909802, 'epochs': 47, 'dropout_rate': 0.21421585817466338, 'sparsity_weight': 0.001745035383317325, 'classification_weight': 0.10498745647467907, 'C': 0.2552575055560923, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 2 with value: 0.7368587531631009.\n",
      "[I 2025-05-12 07:45:15,376] Trial 3 finished with value: 0.6366076221148684 and parameters: {'latent_dim': 90, 'hidden_dim': 206, 'lr': 0.0020497323619336513, 'epochs': 14, 'dropout_rate': 0.16260858062755573, 'sparsity_weight': 0.01026397423571961, 'classification_weight': 0.63856635297728, 'C': 17.868881582939323, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 2 with value: 0.7368587531631009.\n",
      "[I 2025-05-12 07:45:32,251] Trial 4 finished with value: 0.7336093857832987 and parameters: {'latent_dim': 38, 'hidden_dim': 197, 'lr': 0.0003578667449897642, 'epochs': 40, 'dropout_rate': 0.4901909501896339, 'sparsity_weight': 0.00022286496500815837, 'classification_weight': 0.1917896369081249, 'C': 7.1434137071494535, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.7368587531631009.\n",
      "[I 2025-05-12 07:45:47,376] Trial 5 finished with value: 0.7308392761291312 and parameters: {'latent_dim': 63, 'hidden_dim': 84, 'lr': 0.00026476648175667887, 'epochs': 43, 'dropout_rate': 0.37760410110507825, 'sparsity_weight': 0.05919407422261585, 'classification_weight': 0.8532693160327182, 'C': 1.1478599313465832, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 2 with value: 0.7368587531631009.\n",
      "[I 2025-05-12 07:45:53,135] Trial 6 finished with value: 0.6552603327965647 and parameters: {'latent_dim': 32, 'hidden_dim': 213, 'lr': 0.005531688150910643, 'epochs': 12, 'dropout_rate': 0.34821686256326145, 'sparsity_weight': 0.08944193361618426, 'classification_weight': 0.7165265243114688, 'C': 36.27757084175694, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.7368587531631009.\n",
      "[I 2025-05-12 07:46:05,082] Trial 7 finished with value: 0.7024192929990032 and parameters: {'latent_dim': 66, 'hidden_dim': 65, 'lr': 0.0010799921701607391, 'epochs': 32, 'dropout_rate': 0.4091361724829986, 'sparsity_weight': 0.00033284518454521214, 'classification_weight': 0.3749339721386732, 'C': 5.8617245461331855, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 2 with value: 0.7368587531631009.\n",
      "[I 2025-05-12 07:46:11,688] Trial 8 finished with value: 0.671765968867418 and parameters: {'latent_dim': 76, 'hidden_dim': 94, 'lr': 0.0007235305452522488, 'epochs': 16, 'dropout_rate': 0.14498080708143923, 'sparsity_weight': 0.03775445585935121, 'classification_weight': 0.7604220907511148, 'C': 91.38261981848416, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 2 with value: 0.7368587531631009.\n",
      "[I 2025-05-12 07:46:28,920] Trial 9 finished with value: 0.6773253584847788 and parameters: {'latent_dim': 90, 'hidden_dim': 190, 'lr': 0.00024338186700844605, 'epochs': 41, 'dropout_rate': 0.46184676620732135, 'sparsity_weight': 0.09605340322362242, 'classification_weight': 0.3256510792830649, 'C': 24.177054514812152, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 2 with value: 0.7368587531631009.\n",
      "[I 2025-05-12 07:46:49,447] Trial 10 finished with value: 0.725730388773867 and parameters: {'latent_dim': 16, 'hidden_dim': 252, 'lr': 0.00010043066159471857, 'epochs': 49, 'dropout_rate': 0.23080592289850305, 'sparsity_weight': 0.0017539185416038166, 'classification_weight': 0.40483825390354805, 'C': 0.11808997991598226, 'kernel': 'linear'}. Best is trial 2 with value: 0.7368587531631009.\n",
      "[I 2025-05-12 07:47:05,416] Trial 11 finished with value: 0.6415535618434168 and parameters: {'latent_dim': 48, 'hidden_dim': 179, 'lr': 0.009285151696127194, 'epochs': 36, 'dropout_rate': 0.21752650607753793, 'sparsity_weight': 0.00010519215337297353, 'classification_weight': 0.11216173952867321, 'C': 1.1650835915784103, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 2 with value: 0.7368587531631009.\n",
      "[I 2025-05-12 07:47:26,485] Trial 12 finished with value: 0.692383636224216 and parameters: {'latent_dim': 49, 'hidden_dim': 239, 'lr': 0.0023837577654297715, 'epochs': 50, 'dropout_rate': 0.4941513398928507, 'sparsity_weight': 0.00016295078032856918, 'classification_weight': 0.2216153875842152, 'C': 0.13587660075113003, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 2 with value: 0.7368587531631009.\n",
      "[I 2025-05-12 07:47:42,800] Trial 13 finished with value: 0.6341058967870562 and parameters: {'latent_dim': 16, 'hidden_dim': 128, 'lr': 0.0027572736211645453, 'epochs': 43, 'dropout_rate': 0.23825276128802853, 'sparsity_weight': 0.0008635465598890999, 'classification_weight': 0.2554720958563201, 'C': 1.7123329602329087, 'kernel': 'linear'}. Best is trial 2 with value: 0.7368587531631009.\n",
      "[I 2025-05-12 07:47:54,345] Trial 14 finished with value: 0.6993328732459169 and parameters: {'latent_dim': 59, 'hidden_dim': 221, 'lr': 0.0012952937503274337, 'epochs': 25, 'dropout_rate': 0.29461244673545645, 'sparsity_weight': 0.00398999089056789, 'classification_weight': 0.4800544256178541, 'C': 0.45149390187432736, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.7368587531631009.\n",
      "[I 2025-05-12 07:48:09,921] Trial 15 finished with value: 0.7409707844490452 and parameters: {'latent_dim': 75, 'hidden_dim': 174, 'lr': 0.00012538348570256933, 'epochs': 37, 'dropout_rate': 0.11498247703342626, 'sparsity_weight': 0.011973332116816659, 'classification_weight': 0.10353855396221978, 'C': 3.3484646257782873, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 15 with value: 0.7409707844490452.\n",
      "[I 2025-05-12 07:48:21,573] Trial 16 finished with value: 0.749722030519132 and parameters: {'latent_dim': 77, 'hidden_dim': 171, 'lr': 0.00013246311950409334, 'epochs': 26, 'dropout_rate': 0.10065505817493116, 'sparsity_weight': 0.013338743404082637, 'classification_weight': 0.11674701287771892, 'C': 0.4662059924416792, 'kernel': 'linear'}. Best is trial 16 with value: 0.749722030519132.\n",
      "[I 2025-05-12 07:48:32,874] Trial 17 finished with value: 0.7169024614676788 and parameters: {'latent_dim': 77, 'hidden_dim': 164, 'lr': 0.0001047316311312195, 'epochs': 25, 'dropout_rate': 0.10214157789853817, 'sparsity_weight': 0.014125117782101307, 'classification_weight': 0.28721930048387495, 'C': 0.6794323338420496, 'kernel': 'linear'}. Best is trial 16 with value: 0.749722030519132.\n",
      "[I 2025-05-12 07:48:48,990] Trial 18 finished with value: 0.652768192623265 and parameters: {'latent_dim': 98, 'hidden_dim': 119, 'lr': 0.00016504607323522856, 'epochs': 25, 'dropout_rate': 0.10537729052016126, 'sparsity_weight': 0.01651351799110144, 'classification_weight': 0.5290134486345978, 'C': 3.0389483338310335, 'kernel': 'linear'}. Best is trial 16 with value: 0.749722030519132.\n",
      "[I 2025-05-12 07:49:05,823] Trial 19 finished with value: 0.6850701633310329 and parameters: {'latent_dim': 72, 'hidden_dim': 165, 'lr': 0.00015784781204402634, 'epochs': 32, 'dropout_rate': 0.16260172447616544, 'sparsity_weight': 0.00814924660342371, 'classification_weight': 0.43075283585296714, 'C': 2.7875105357999614, 'kernel': 'linear'}. Best is trial 16 with value: 0.749722030519132.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7352\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7066\n",
      "ROC-AUC autoencoded: 0.7374\n",
      "ROC-AUC autoencoded: 0.7198\n",
      "ROC-AUC autoencoded: 0.7067\n",
      "ROC-AUC autoencoded: 0.6851\n",
      "ROC-AUC autoencoded: 0.7282\n",
      "ROC-AUC autoencoded: 0.7638\n",
      "ROC-AUC autoencoded: 0.7575\n",
      "ROC-AUC autoencoded: 0.7275\n",
      "ROC-AUC autoencoded: 0.7238\n",
      "ROC-AUC autoencoded: 0.7010\n",
      "ROC-AUC autoencoded: 0.6978\n",
      "ROC-AUC autoencoded: 0.7559\n",
      "ROC-AUC autoencoded: 0.7090\n",
      "ROC-AUC autoencoded: 0.7057\n",
      "ROC-AUC autoencoded: 0.6953\n",
      "ROC-AUC autoencoded: 0.6608\n",
      "ROC-AUC autoencoded: 0.6683\n",
      "ROC-AUC autoencoded: 0.6501\n",
      "ROC-AUC autoencoded: 0.6608\n",
      "ROC-AUC autoencoded: 0.7717\n",
      "ROC-AUC autoencoded: 0.7620\n",
      "ROC-AUC autoencoded: 0.7451\n",
      "ROC-AUC autoencoded: 0.7188\n",
      "ROC-AUC autoencoded: 0.7167\n",
      "среднее 0.7150051851835972\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:50:25,417] A new study created in memory with name: no-name-fca84940-6673-48f0-9aaa-641673a3691f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:50:38,316] Trial 0 finished with value: 0.7738286941185493 and parameters: {'latent_dim': 77, 'hidden_dim_ae': 128, 'hidden_dim_combined': 86, 'lr_ae': 0.00038223530398459664, 'lr_combined': 0.0017914743816959012, 'epochs_ae': 16, 'epochs_freeze': 5, 'epochs_unfreeze': 14, 'dropout_rate_ae': 0.4798989998245613, 'dropout_rate_combined': 0.2258136211167595, 'sparsity_weight': 0.016535509834159284, 'classification_weight': 0.15597542484178029}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:50:52,619] Trial 1 finished with value: 0.7658538455639906 and parameters: {'latent_dim': 26, 'hidden_dim_ae': 215, 'hidden_dim_combined': 58, 'lr_ae': 0.001375313384646883, 'lr_combined': 0.00023810199948438762, 'epochs_ae': 22, 'epochs_freeze': 13, 'epochs_unfreeze': 5, 'dropout_rate_ae': 0.1474781887845616, 'dropout_rate_combined': 0.4525876479145011, 'sparsity_weight': 0.032711915322287906, 'classification_weight': 0.11789228309781104}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:51:13,736] Trial 2 finished with value: 0.7129629629629629 and parameters: {'latent_dim': 42, 'hidden_dim_ae': 243, 'hidden_dim_combined': 79, 'lr_ae': 0.003919918265708452, 'lr_combined': 0.00025718881921999907, 'epochs_ae': 33, 'epochs_freeze': 16, 'epochs_unfreeze': 8, 'dropout_rate_ae': 0.321665696098469, 'dropout_rate_combined': 0.38052669218786894, 'sparsity_weight': 0.0003099023053990494, 'classification_weight': 0.30713507929836403}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:51:30,169] Trial 3 finished with value: 0.7051606471896328 and parameters: {'latent_dim': 14, 'hidden_dim_ae': 116, 'hidden_dim_combined': 50, 'lr_ae': 0.0025893455956943015, 'lr_combined': 0.0011830270705106961, 'epochs_ae': 32, 'epochs_freeze': 5, 'epochs_unfreeze': 10, 'dropout_rate_ae': 0.38495273525225604, 'dropout_rate_combined': 0.22187077642730135, 'sparsity_weight': 0.003396296940558113, 'classification_weight': 0.5513063067103394}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:51:52,522] Trial 4 finished with value: 0.7179089026915113 and parameters: {'latent_dim': 36, 'hidden_dim_ae': 143, 'hidden_dim_combined': 121, 'lr_ae': 0.002047379455130266, 'lr_combined': 0.00030461415255824927, 'epochs_ae': 34, 'epochs_freeze': 9, 'epochs_unfreeze': 18, 'dropout_rate_ae': 0.43891314583402286, 'dropout_rate_combined': 0.22348114987882975, 'sparsity_weight': 0.031676923842569725, 'classification_weight': 0.8013118866595713}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:52:20,318] Trial 5 finished with value: 0.7134613909976228 and parameters: {'latent_dim': 74, 'hidden_dim_ae': 124, 'hidden_dim_combined': 110, 'lr_ae': 0.00022787996247434632, 'lr_combined': 0.003388251630618739, 'epochs_ae': 49, 'epochs_freeze': 6, 'epochs_unfreeze': 20, 'dropout_rate_ae': 0.26507890157391345, 'dropout_rate_combined': 0.42342610579472195, 'sparsity_weight': 0.004531032173119324, 'classification_weight': 0.7042285690933028}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:52:36,850] Trial 6 finished with value: 0.767694195230427 and parameters: {'latent_dim': 73, 'hidden_dim_ae': 213, 'hidden_dim_combined': 47, 'lr_ae': 0.0002127726840266579, 'lr_combined': 0.00020332348948632213, 'epochs_ae': 11, 'epochs_freeze': 15, 'epochs_unfreeze': 19, 'dropout_rate_ae': 0.4745901058124823, 'dropout_rate_combined': 0.4877165430402707, 'sparsity_weight': 0.0956400387844134, 'classification_weight': 0.26321470365910865}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:52:51,832] Trial 7 finished with value: 0.7674258109040718 and parameters: {'latent_dim': 53, 'hidden_dim_ae': 195, 'hidden_dim_combined': 69, 'lr_ae': 0.00027279534938550197, 'lr_combined': 0.0029008839336458095, 'epochs_ae': 23, 'epochs_freeze': 9, 'epochs_unfreeze': 8, 'dropout_rate_ae': 0.4080668537529508, 'dropout_rate_combined': 0.4815914775594211, 'sparsity_weight': 0.03614131783943087, 'classification_weight': 0.42561699507279627}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:53:07,679] Trial 8 finished with value: 0.739648033126294 and parameters: {'latent_dim': 86, 'hidden_dim_ae': 176, 'hidden_dim_combined': 81, 'lr_ae': 0.00023305964248534347, 'lr_combined': 0.00240106204238977, 'epochs_ae': 15, 'epochs_freeze': 16, 'epochs_unfreeze': 13, 'dropout_rate_ae': 0.24462220850754168, 'dropout_rate_combined': 0.15309659801058664, 'sparsity_weight': 0.00101701623326358, 'classification_weight': 0.26033777686454035}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:53:23,225] Trial 9 finished with value: 0.7632466835365386 and parameters: {'latent_dim': 92, 'hidden_dim_ae': 73, 'hidden_dim_combined': 77, 'lr_ae': 0.00016218051031373953, 'lr_combined': 0.00034823029684391473, 'epochs_ae': 34, 'epochs_freeze': 5, 'epochs_unfreeze': 5, 'dropout_rate_ae': 0.13731624424239308, 'dropout_rate_combined': 0.27887656188894394, 'sparsity_weight': 0.0021591680735931116, 'classification_weight': 0.6625315936620917}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:53:47,951] Trial 10 finished with value: 0.7321524422973699 and parameters: {'latent_dim': 64, 'hidden_dim_ae': 95, 'hidden_dim_combined': 98, 'lr_ae': 0.009678281441050093, 'lr_combined': 0.00972280114852377, 'epochs_ae': 44, 'epochs_freeze': 10, 'epochs_unfreeze': 15, 'dropout_rate_ae': 0.49754360141751164, 'dropout_rate_combined': 0.1123829915043292, 'sparsity_weight': 0.011946770441730904, 'classification_weight': 0.11666532747995342}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:54:03,586] Trial 11 finished with value: 0.762307338394295 and parameters: {'latent_dim': 76, 'hidden_dim_ae': 160, 'hidden_dim_combined': 33, 'lr_ae': 0.0006087369068901146, 'lr_combined': 0.00010419646526443843, 'epochs_ae': 10, 'epochs_freeze': 20, 'epochs_unfreeze': 16, 'dropout_rate_ae': 0.4902472791538609, 'dropout_rate_combined': 0.31994571679166595, 'sparsity_weight': 0.08453853451310725, 'classification_weight': 0.27025878105889706}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:54:20,425] Trial 12 finished with value: 0.7592209186412084 and parameters: {'latent_dim': 99, 'hidden_dim_ae': 247, 'hidden_dim_combined': 95, 'lr_ae': 0.0005348536823615664, 'lr_combined': 0.0006495137808847412, 'epochs_ae': 10, 'epochs_freeze': 14, 'epochs_unfreeze': 20, 'dropout_rate_ae': 0.35451214079408033, 'dropout_rate_combined': 0.3649232027252604, 'sparsity_weight': 0.07928522242732824, 'classification_weight': 0.3943290656739816}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:54:39,200] Trial 13 finished with value: 0.7605820105820106 and parameters: {'latent_dim': 63, 'hidden_dim_ae': 212, 'hidden_dim_combined': 32, 'lr_ae': 0.0001096015515413769, 'lr_combined': 0.0011691057283546857, 'epochs_ae': 19, 'epochs_freeze': 19, 'epochs_unfreeze': 13, 'dropout_rate_ae': 0.45066817681279553, 'dropout_rate_combined': 0.23122999033249708, 'sparsity_weight': 0.010516558847811806, 'classification_weight': 0.2045334482436923}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:54:57,787] Trial 14 finished with value: 0.7652595659842037 and parameters: {'latent_dim': 79, 'hidden_dim_ae': 174, 'hidden_dim_combined': 50, 'lr_ae': 0.00046854850909815594, 'lr_combined': 0.00010378281684371, 'epochs_ae': 16, 'epochs_freeze': 17, 'epochs_unfreeze': 17, 'dropout_rate_ae': 0.43716958439478315, 'dropout_rate_combined': 0.30328662447911897, 'sparsity_weight': 0.00010143360098587202, 'classification_weight': 0.3757822249514212}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:55:15,926] Trial 15 finished with value: 0.7031477647419676 and parameters: {'latent_dim': 56, 'hidden_dim_ae': 134, 'hidden_dim_combined': 94, 'lr_ae': 0.0009587524419298869, 'lr_combined': 0.0006004437808185291, 'epochs_ae': 26, 'epochs_freeze': 11, 'epochs_unfreeze': 11, 'dropout_rate_ae': 0.22706056105213945, 'dropout_rate_combined': 0.17481111645267383, 'sparsity_weight': 0.01344482798670308, 'classification_weight': 0.5260237082711445}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:55:30,994] Trial 16 finished with value: 0.7608695652173912 and parameters: {'latent_dim': 72, 'hidden_dim_ae': 100, 'hidden_dim_combined': 63, 'lr_ae': 0.0001006234470598148, 'lr_combined': 0.005294875574945932, 'epochs_ae': 14, 'epochs_freeze': 14, 'epochs_unfreeze': 14, 'dropout_rate_ae': 0.3665792918710811, 'dropout_rate_combined': 0.35670977136590387, 'sparsity_weight': 0.022533342480042493, 'classification_weight': 0.17257444968412688}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:55:52,752] Trial 17 finished with value: 0.7345295606165171 and parameters: {'latent_dim': 87, 'hidden_dim_ae': 218, 'hidden_dim_combined': 45, 'lr_ae': 0.00036474206799952776, 'lr_combined': 0.0016325641761035156, 'epochs_ae': 28, 'epochs_freeze': 8, 'epochs_unfreeze': 18, 'dropout_rate_ae': 0.31540000278384556, 'dropout_rate_combined': 0.4108863861980808, 'sparsity_weight': 0.06329358023395203, 'classification_weight': 0.32616858239001245}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:56:11,467] Trial 18 finished with value: 0.7640326662065794 and parameters: {'latent_dim': 47, 'hidden_dim_ae': 154, 'hidden_dim_combined': 106, 'lr_ae': 0.0008459233017406982, 'lr_combined': 0.0006871793146278507, 'epochs_ae': 19, 'epochs_freeze': 12, 'epochs_unfreeze': 18, 'dropout_rate_ae': 0.45555456446552683, 'dropout_rate_combined': 0.48848313656728803, 'sparsity_weight': 0.006378677064335177, 'classification_weight': 0.19452270763759738}. Best is trial 0 with value: 0.7738286941185493.\n",
      "[I 2025-05-12 07:56:27,538] Trial 19 finished with value: 0.7686910512997468 and parameters: {'latent_dim': 66, 'hidden_dim_ae': 180, 'hidden_dim_combined': 87, 'lr_ae': 0.00014581781278230185, 'lr_combined': 0.00019062912859244902, 'epochs_ae': 10, 'epochs_freeze': 17, 'epochs_unfreeze': 16, 'dropout_rate_ae': 0.3957489534718581, 'dropout_rate_combined': 0.2623832590369058, 'sparsity_weight': 0.0014766900657207228, 'classification_weight': 0.46387155898968446}. Best is trial 0 with value: 0.7738286941185493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7723\n"
     ]
    }
   ],
   "source": [
    "class CombinedClassifier(nn.Module):\n",
    "    def __init__(self, autoencoder, pgs_input_dim, hidden_dim=64, dropout_rate=0.2):\n",
    "        super(CombinedClassifier, self).__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "        self.pgs_branch = nn.Sequential(\n",
    "            nn.Linear(pgs_input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        latent_dim = list(autoencoder.classifier[0].parameters())[0].shape[1]\n",
    "        self.combined_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim // 2 + latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_snp, x_pgs):\n",
    "        _, latent, _ = self.autoencoder(x_snp)\n",
    "        pgs_features = self.pgs_branch(x_pgs)\n",
    "        combined = torch.cat([latent, pgs_features], dim=1)\n",
    "        output = self.combined_classifier(combined)\n",
    "        return output\n",
    "\n",
    "def train_combined_classifier(model, X_train_snp, X_train_pgs, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_snp_tensor = torch.FloatTensor(X_train_snp).to(device)\n",
    "    X_train_pgs_tensor = torch.FloatTensor(X_train_pgs).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_snp_tensor, X_train_pgs_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    for param in model.autoencoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs_freeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    for param in model.autoencoder.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr/10)\n",
    "    \n",
    "    for epoch in range(epochs_unfreeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_combined(model, X_snp, X_pgs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_snp_tensor = torch.FloatTensor(X_snp).to(device)\n",
    "    X_pgs_tensor = torch.FloatTensor(X_pgs).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_snp_tensor, X_pgs_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    hidden_dim_combined = trial.suggest_int('hidden_dim_combined', 32, 128)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    lr_combined = trial.suggest_float('lr_combined', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    epochs_freeze = trial.suggest_int('epochs_freeze', 5, 20)\n",
    "    epochs_unfreeze = trial.suggest_int('epochs_unfreeze', 5, 20)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    dropout_rate_combined = trial.suggest_float('dropout_rate_combined', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs_ae, batch_size, lr_ae, sparsity_weight, classification_weight)\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, X_pgs_train.shape[1], hidden_dim_combined, dropout_rate_combined)\n",
    "        combined_model = train_combined_classifier(combined_model, X_train, X_pgs_train, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr_combined)\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, X_pgs_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs_ae'], 32, \n",
    "    best_params['lr_ae'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "combined_model = CombinedClassifier(autoencoder, X_train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "combined_model = train_combined_classifier(\n",
    "    combined_model, X_train_all, X_train_pgs, y_all_train, \n",
    "    best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    ")\n",
    "\n",
    "y_pred_proba = predict_combined(combined_model, X_val_all, X_val_pgs)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7577\n",
      "ROC-AUC autoencoded: 0.7441\n",
      "ROC-AUC autoencoded: 0.7579\n",
      "ROC-AUC autoencoded: 0.7476\n",
      "ROC-AUC autoencoded: 0.7623\n",
      "ROC-AUC autoencoded: 0.7674\n",
      "ROC-AUC autoencoded: 0.7214\n",
      "ROC-AUC autoencoded: 0.7392\n",
      "ROC-AUC autoencoded: 0.7463\n",
      "ROC-AUC autoencoded: 0.7541\n",
      "ROC-AUC autoencoded: 0.7487\n",
      "ROC-AUC autoencoded: 0.7342\n",
      "ROC-AUC autoencoded: 0.7458\n",
      "ROC-AUC autoencoded: 0.7560\n",
      "ROC-AUC autoencoded: 0.7206\n",
      "ROC-AUC autoencoded: 0.7021\n",
      "ROC-AUC autoencoded: 0.7066\n",
      "ROC-AUC autoencoded: 0.7022\n",
      "ROC-AUC autoencoded: 0.6888\n",
      "ROC-AUC autoencoded: 0.7097\n",
      "ROC-AUC autoencoded: 0.7550\n",
      "ROC-AUC autoencoded: 0.7767\n",
      "ROC-AUC autoencoded: 0.7535\n",
      "ROC-AUC autoencoded: 0.7714\n",
      "ROC-AUC autoencoded: 0.7628\n",
      "среднее 0.741287388606396\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs_ae'], 32, \n",
    "            best_params['lr_ae'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "        combined_model = train_combined_classifier(\n",
    "            combined_model, X_train, train_pgs, y_train, \n",
    "            best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, test_pgs)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше идет блок со stacked автоэнкодером"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:58:01,820] A new study created in memory with name: no-name-54e85982-656b-4513-bfdf-60d642ab71b8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:58:04,783] Trial 0 finished with value: 0.7572463768115942 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 9, 'lr': 0.00043753705161607887, 'epochs': 10, 'dropout_rate': 0.3421758471095885, 'C': 35.35914750581923, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7572463768115942.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:58:16,724] Trial 1 finished with value: 0.7670040641055135 and parameters: {'num_layers': 2, 'latent_dim_0': 19, 'latent_dim_1': 8, 'lr': 0.00040757245621592407, 'epochs': 40, 'dropout_rate': 0.13403813568880657, 'C': 0.19479584077055864, 'solver': 'saga'}. Best is trial 1 with value: 0.7670040641055135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:58:26,633] Trial 2 finished with value: 0.7698412698412698 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 8, 'lr': 0.001129496522773002, 'epochs': 35, 'dropout_rate': 0.3208689351138658, 'C': 3.3346200738046097, 'solver': 'saga'}. Best is trial 2 with value: 0.7698412698412698.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:58:35,929] Trial 3 finished with value: 0.7684610075914423 and parameters: {'num_layers': 2, 'latent_dim_0': 17, 'latent_dim_1': 10, 'lr': 0.0007350210318937244, 'epochs': 33, 'dropout_rate': 0.3412816912448362, 'C': 46.05105572379561, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.7698412698412698.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:58:42,148] Trial 4 finished with value: 0.7666398282340312 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 9, 'lr': 0.0038685555493299423, 'epochs': 22, 'dropout_rate': 0.47360473946474146, 'C': 10.446675146744324, 'solver': 'liblinear'}. Best is trial 2 with value: 0.7698412698412698.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:58:46,769] Trial 5 finished with value: 0.7763208342918487 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 9, 'lr': 0.0007457427996993784, 'epochs': 16, 'dropout_rate': 0.3001256565495356, 'C': 0.14307472730671422, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:58:52,693] Trial 6 finished with value: 0.7703205275669044 and parameters: {'num_layers': 2, 'latent_dim_0': 17, 'latent_dim_1': 9, 'lr': 0.00017514874178515443, 'epochs': 21, 'dropout_rate': 0.11911800226375156, 'C': 0.07097964646463331, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:59:07,024] Trial 7 finished with value: 0.76332336477264 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 9, 'lr': 0.00039528805479378923, 'epochs': 50, 'dropout_rate': 0.43096807907364454, 'C': 6.464406843487087, 'solver': 'liblinear'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:59:16,593] Trial 8 finished with value: 0.7654704393834829 and parameters: {'num_layers': 2, 'latent_dim_0': 19, 'latent_dim_1': 10, 'lr': 0.005309032960307141, 'epochs': 34, 'dropout_rate': 0.40465789438194943, 'C': 19.8895778279716, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:59:22,025] Trial 9 finished with value: 0.7728701786672801 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 10, 'lr': 0.0003631810278179766, 'epochs': 18, 'dropout_rate': 0.19190796622657716, 'C': 0.053654812636089295, 'solver': 'saga'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:59:25,441] Trial 10 finished with value: 0.7725251131048232 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 8, 'lr': 0.0019928928508787165, 'epochs': 12, 'dropout_rate': 0.22702531546418808, 'C': 0.013892576109629597, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:59:31,319] Trial 11 finished with value: 0.7692661605705083 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 10, 'lr': 0.00010970704243765788, 'epochs': 20, 'dropout_rate': 0.22326971734666917, 'C': 0.2929533751819549, 'solver': 'saga'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:59:35,933] Trial 12 finished with value: 0.7749022314239706 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 10, 'lr': 0.001413235325441068, 'epochs': 16, 'dropout_rate': 0.22234170605135972, 'C': 0.016642287569372635, 'solver': 'saga'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:59:40,306] Trial 13 finished with value: 0.7707422743654626 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 9, 'lr': 0.0021971629080487372, 'epochs': 15, 'dropout_rate': 0.26969324488744384, 'C': 0.015798539346833715, 'solver': 'saga'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:59:47,885] Trial 14 finished with value: 0.7685376888275438 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 10, 'lr': 0.0014358534487374439, 'epochs': 26, 'dropout_rate': 0.2829864676574774, 'C': 0.4089846446711072, 'solver': 'liblinear'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:59:55,349] Trial 15 finished with value: 0.769246990261483 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 9, 'lr': 0.008928611542058764, 'epochs': 26, 'dropout_rate': 0.1794738750120343, 'C': 1.7470362424526558, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 07:59:59,899] Trial 16 finished with value: 0.7739437159727013 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 10, 'lr': 0.0008149105982695985, 'epochs': 16, 'dropout_rate': 0.25670197999664995, 'C': 0.04713672658152038, 'solver': 'saga'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:00:07,178] Trial 17 finished with value: 0.7683459857372901 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 8, 'lr': 0.002633440096247005, 'epochs': 26, 'dropout_rate': 0.3892716893294161, 'C': 0.7819510250985616, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:00:10,883] Trial 18 finished with value: 0.7735219691741432 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 9, 'lr': 0.0006669631674039729, 'epochs': 13, 'dropout_rate': 0.1719920557990016, 'C': 0.010554598615645195, 'solver': 'saga'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:00:22,927] Trial 19 finished with value: 0.7728510083582547 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 9, 'lr': 0.00024083529195738628, 'epochs': 43, 'dropout_rate': 0.3026337745000435, 'C': 0.1132028478911953, 'solver': 'liblinear'}. Best is trial 5 with value: 0.7763208342918487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7782\n"
     ]
    }
   ],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(SimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "        \n",
    "        return reconstructions, latents\n",
    "    \n",
    "def train_stacked_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    \n",
    "    # Обучаем каждый автоэнкодер последовательно\n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, latent)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, _ in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent = ae(batch_x)\n",
    "                loss = criterion(reconstructed, batch_x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры логистической регрессии\n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7584\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7746\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7709\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7852\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7702\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7675\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7582\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7776\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7765\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7806\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7512\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7370\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7555\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7502\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7578\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7085\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7120\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7198\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7293\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7151\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7651\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7611\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7638\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7564\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7621\n",
      "среднее 0.7545924347872134\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:00:56,053] A new study created in memory with name: no-name-ea3a4293-bb77-4a2d-be42-dac9c2c263c4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:01:19,210] Trial 0 finished with value: 0.7218004754236637 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 10, 'lr': 0.0009024234107797223, 'epochs': 48, 'dropout_rate': 0.451045238453776, 'n_estimators': 226, 'max_depth': 5, 'learning_rate': 0.09982850883138292, 'subsample': 0.6806435862090112, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7218004754236637.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:01:38,705] Trial 1 finished with value: 0.7382677708764666 and parameters: {'num_layers': 2, 'latent_dim_0': 11, 'latent_dim_1': 10, 'lr': 0.001096677530237327, 'epochs': 38, 'dropout_rate': 0.29512624305421986, 'n_estimators': 141, 'max_depth': 10, 'learning_rate': 0.022332837239366517, 'subsample': 0.7935886505803113, 'min_samples_split': 17, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.7382677708764666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:02:01,159] Trial 2 finished with value: 0.7224522659305267 and parameters: {'num_layers': 2, 'latent_dim_0': 11, 'latent_dim_1': 8, 'lr': 0.002155933161237555, 'epochs': 35, 'dropout_rate': 0.16117518830509847, 'n_estimators': 190, 'max_depth': 10, 'learning_rate': 0.09546336324455688, 'subsample': 0.8050618263443936, 'min_samples_split': 17, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.7382677708764666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:02:25,579] Trial 3 finished with value: 0.7331109577486389 and parameters: {'num_layers': 2, 'latent_dim_0': 11, 'latent_dim_1': 8, 'lr': 0.00045217523749545047, 'epochs': 29, 'dropout_rate': 0.40388524422742766, 'n_estimators': 418, 'max_depth': 9, 'learning_rate': 0.26557087321638223, 'subsample': 0.8242152047565959, 'min_samples_split': 16, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7382677708764666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:02:43,714] Trial 4 finished with value: 0.7444022697645886 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 9, 'lr': 0.00019969627172429136, 'epochs': 14, 'dropout_rate': 0.23299290546245702, 'n_estimators': 323, 'max_depth': 9, 'learning_rate': 0.2992341910456869, 'subsample': 0.9074619625057304, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:02:58,445] Trial 5 finished with value: 0.7296027911969941 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 9, 'lr': 0.0008071236348923625, 'epochs': 19, 'dropout_rate': 0.12898037275704102, 'n_estimators': 373, 'max_depth': 3, 'learning_rate': 0.07509993575411315, 'subsample': 0.7971366248969499, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:03:13,350] Trial 6 finished with value: 0.727340694731999 and parameters: {'num_layers': 2, 'latent_dim_0': 11, 'latent_dim_1': 8, 'lr': 0.00013769740662204408, 'epochs': 17, 'dropout_rate': 0.16122492039003192, 'n_estimators': 373, 'max_depth': 3, 'learning_rate': 0.04726300980743728, 'subsample': 0.8803678288583707, 'min_samples_split': 15, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:03:30,445] Trial 7 finished with value: 0.7324975078598267 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 8, 'lr': 0.00013943882596638296, 'epochs': 30, 'dropout_rate': 0.14438681641266277, 'n_estimators': 188, 'max_depth': 7, 'learning_rate': 0.05114479301904952, 'subsample': 0.7557987085790446, 'min_samples_split': 17, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:03:45,137] Trial 8 finished with value: 0.7154934437543133 and parameters: {'num_layers': 2, 'latent_dim_0': 11, 'latent_dim_1': 8, 'lr': 0.0030447349903214276, 'epochs': 10, 'dropout_rate': 0.17860472861198012, 'n_estimators': 307, 'max_depth': 6, 'learning_rate': 0.2532996622015892, 'subsample': 0.6503398589977754, 'min_samples_split': 16, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:04:20,689] Trial 9 finished with value: 0.7116785522582624 and parameters: {'num_layers': 2, 'latent_dim_0': 17, 'latent_dim_1': 8, 'lr': 0.0012288204364635214, 'epochs': 22, 'dropout_rate': 0.3110547028756977, 'n_estimators': 475, 'max_depth': 7, 'learning_rate': 0.14077877332059283, 'subsample': 0.9468586097029019, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:04:29,987] Trial 10 finished with value: 0.6853193773483629 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 9, 'lr': 0.009812938391899898, 'epochs': 10, 'dropout_rate': 0.25808700022987735, 'n_estimators': 70, 'max_depth': 8, 'learning_rate': 0.011765414138393784, 'subsample': 0.9974806807910125, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:04:46,941] Trial 11 finished with value: 0.7433479027681926 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 10, 'lr': 0.00028692420661974543, 'epochs': 41, 'dropout_rate': 0.2878690836586043, 'n_estimators': 90, 'max_depth': 10, 'learning_rate': 0.02121025345622343, 'subsample': 0.8781215641498278, 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:05:23,840] Trial 12 finished with value: 0.7362932290468521 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 10, 'lr': 0.00028121965610060704, 'epochs': 50, 'dropout_rate': 0.24214533710058267, 'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.03045793971340173, 'subsample': 0.899328310711715, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:05:37,866] Trial 13 finished with value: 0.7288551491450042 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 9, 'lr': 0.00032187981579217043, 'epochs': 39, 'dropout_rate': 0.36657672187266716, 'n_estimators': 53, 'max_depth': 9, 'learning_rate': 0.011132137237158363, 'subsample': 0.8884634917764436, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:05:59,702] Trial 14 finished with value: 0.7195000383406179 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 10, 'lr': 0.00022271876204989376, 'epochs': 42, 'dropout_rate': 0.22247693959087406, 'n_estimators': 118, 'max_depth': 10, 'learning_rate': 0.029145409488358007, 'subsample': 0.9657831367648139, 'min_samples_split': 12, 'min_samples_leaf': 6}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:06:21,856] Trial 15 finished with value: 0.7420634920634921 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 9, 'lr': 0.0004376508854153183, 'epochs': 24, 'dropout_rate': 0.33501403210316516, 'n_estimators': 252, 'max_depth': 8, 'learning_rate': 0.01686869668836379, 'subsample': 0.8555201690660965, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:06:58,858] Trial 16 finished with value: 0.7181772870178667 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 9, 'lr': 0.00010846893011371754, 'epochs': 44, 'dropout_rate': 0.2126649923965671, 'n_estimators': 350, 'max_depth': 8, 'learning_rate': 0.1831502115032214, 'subsample': 0.9307728632383355, 'min_samples_split': 20, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:07:27,105] Trial 17 finished with value: 0.732363315696649 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 10, 'lr': 0.0001764575843941026, 'epochs': 34, 'dropout_rate': 0.2792503474772336, 'n_estimators': 485, 'max_depth': 5, 'learning_rate': 0.03725057923534187, 'subsample': 0.7360964971124712, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:07:51,027] Trial 18 finished with value: 0.738037727168162 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 9, 'lr': 0.0005596610282674971, 'epochs': 16, 'dropout_rate': 0.49988825545400695, 'n_estimators': 281, 'max_depth': 9, 'learning_rate': 0.018064296477625762, 'subsample': 0.8476079919950122, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 4 with value: 0.7444022697645886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:08:10,310] Trial 19 finished with value: 0.749693275055594 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 9, 'lr': 0.00023160723211754995, 'epochs': 28, 'dropout_rate': 0.3482026897932583, 'n_estimators': 120, 'max_depth': 10, 'learning_rate': 0.07334068352989961, 'subsample': 0.9205142772286004, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.749693275055594.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7530\n"
     ]
    }
   ],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(SimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "        \n",
    "        return reconstructions, latents\n",
    "    \n",
    "def train_stacked_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    \n",
    "    # Обучаем каждый автоэнкодер последовательно\n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, latent)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, _ in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent = ae(batch_x)\n",
    "                loss = criterion(reconstructed, batch_x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры градиентного бустинга\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7309\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7323\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7415\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7262\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7325\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7208\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6975\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7045\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7251\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6937\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7101\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7133\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6822\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7006\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7121\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6919\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7180\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7262\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7216\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7283\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7258\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7259\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7134\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7543\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7305\n",
      "среднее 0.7183812865766298\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:10:26,760] A new study created in memory with name: no-name-527a4ed0-a8f9-4041-b15a-0bfbb35919ef\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:10:31,295] Trial 0 finished with value: 0.7664385399892647 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 8, 'lr': 0.0012990516663507867, 'epochs': 16, 'dropout_rate': 0.24411557059765185, 'C': 0.13658471276277975, 'kernel': 'linear'}. Best is trial 0 with value: 0.7664385399892647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:10:35,951] Trial 1 finished with value: 0.7270435549421057 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 8, 'lr': 0.0007507929960753462, 'epochs': 15, 'dropout_rate': 0.40019350305876533, 'C': 0.3989759928505953, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.7664385399892647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:10:57,633] Trial 2 finished with value: 0.7672149375047925 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 10, 'lr': 0.0008000108736314294, 'epochs': 19, 'dropout_rate': 0.453874102893713, 'C': 38.94838344897606, 'kernel': 'linear'}. Best is trial 2 with value: 0.7672149375047925.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:11:07,560] Trial 3 finished with value: 0.6647400506096158 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 10, 'lr': 0.0020564331477298287, 'epochs': 37, 'dropout_rate': 0.12388701982414473, 'C': 0.4545522019215677, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 2 with value: 0.7672149375047925.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:11:15,921] Trial 4 finished with value: 0.7604094778007822 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 8, 'lr': 0.00019840326840260737, 'epochs': 27, 'dropout_rate': 0.43768278892609747, 'C': 2.4858764014311903, 'kernel': 'linear'}. Best is trial 2 with value: 0.7672149375047925.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:11:29,312] Trial 5 finished with value: 0.6201499118165785 and parameters: {'num_layers': 2, 'latent_dim_0': 17, 'latent_dim_1': 9, 'lr': 0.00012919510581746528, 'epochs': 48, 'dropout_rate': 0.2327931415081893, 'C': 0.10100855396742991, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 2 with value: 0.7672149375047925.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:11:38,786] Trial 6 finished with value: 0.6461544360095085 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 9, 'lr': 0.008809454711458567, 'epochs': 31, 'dropout_rate': 0.37702984175422327, 'C': 0.6054505082244087, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 2 with value: 0.7672149375047925.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:11:47,148] Trial 7 finished with value: 0.7764646116095392 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 10, 'lr': 0.00011455211383103024, 'epochs': 19, 'dropout_rate': 0.1040139857518566, 'C': 4.935160144950117, 'kernel': 'linear'}. Best is trial 7 with value: 0.7764646116095392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:11:52,754] Trial 8 finished with value: 0.7334751936201211 and parameters: {'num_layers': 2, 'latent_dim_0': 11, 'latent_dim_1': 8, 'lr': 0.004083594790084363, 'epochs': 16, 'dropout_rate': 0.43177588828203184, 'C': 0.9500269834973053, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 7 with value: 0.7764646116095392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:12:03,449] Trial 9 finished with value: 0.657388237098382 and parameters: {'num_layers': 2, 'latent_dim_0': 11, 'latent_dim_1': 10, 'lr': 0.00023214992296866148, 'epochs': 35, 'dropout_rate': 0.40245092473913224, 'C': 16.752303123425353, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 7 with value: 0.7764646116095392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:12:06,788] Trial 10 finished with value: 0.7289701709991565 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 10, 'lr': 0.0004098572059527166, 'epochs': 10, 'dropout_rate': 0.11102079277447935, 'C': 8.239189822111497, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 7 with value: 0.7764646116095392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:12:51,165] Trial 11 finished with value: 0.7652308105206655 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 10, 'lr': 0.0004966243490083892, 'epochs': 24, 'dropout_rate': 0.48810723955661134, 'C': 91.6236643978678, 'kernel': 'linear'}. Best is trial 7 with value: 0.7764646116095392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:13:17,107] Trial 12 finished with value: 0.7630549804462848 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 9, 'lr': 0.0001061051326208229, 'epochs': 21, 'dropout_rate': 0.29998843202626546, 'C': 56.72634093063295, 'kernel': 'linear'}. Best is trial 7 with value: 0.7764646116095392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:13:29,658] Trial 13 finished with value: 0.7689210950080515 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 10, 'lr': 0.002404029104523362, 'epochs': 21, 'dropout_rate': 0.18133249292063652, 'C': 17.2537917793668, 'kernel': 'linear'}. Best is trial 7 with value: 0.7764646116095392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:13:35,168] Trial 14 finished with value: 0.7634958975538687 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 10, 'lr': 0.002787824541199354, 'epochs': 10, 'dropout_rate': 0.17649289927973547, 'C': 5.209020058438158, 'kernel': 'linear'}. Best is trial 7 with value: 0.7764646116095392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:13:50,245] Trial 15 finished with value: 0.7644352426961123 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 9, 'lr': 0.005797493443511398, 'epochs': 28, 'dropout_rate': 0.1726360898145692, 'C': 20.481655175058883, 'kernel': 'linear'}. Best is trial 7 with value: 0.7764646116095392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:14:02,114] Trial 16 finished with value: 0.7668698719423356 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 10, 'lr': 0.0016681862611805896, 'epochs': 41, 'dropout_rate': 0.16798935389936082, 'C': 2.5778924496283215, 'kernel': 'linear'}. Best is trial 7 with value: 0.7764646116095392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:14:08,853] Trial 17 finished with value: 0.6708841346522506 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 9, 'lr': 0.003021937491815221, 'epochs': 22, 'dropout_rate': 0.23527911451449052, 'C': 12.705363723345709, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 7 with value: 0.7764646116095392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:14:15,643] Trial 18 finished with value: 0.6015930526800092 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 10, 'lr': 0.00030812235967631377, 'epochs': 25, 'dropout_rate': 0.10352242764975632, 'C': 4.848735951574282, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 7 with value: 0.7764646116095392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:14:25,187] Trial 19 finished with value: 0.7711256805459703 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 9, 'lr': 0.0009935785987015865, 'epochs': 31, 'dropout_rate': 0.3137784881462673, 'C': 1.7957294615216923, 'kernel': 'linear'}. Best is trial 7 with value: 0.7764646116095392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7600\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры SVC\n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7817\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7668\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7861\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7530\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7760\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7681\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7655\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7664\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7686\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7739\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7483\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7463\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7676\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7282\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7563\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7163\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7218\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7143\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7045\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7235\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7423\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7404\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7559\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7422\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7576\n",
      "среднее 0.7508655363635697\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:15:20,112] A new study created in memory with name: no-name-7850b0e2-dd97-4d8c-9416-e3a1ab3b9229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:15:28,091] Trial 0 finished with value: 0.7674929069856606 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 9, 'lr_ae': 0.009633901720676318, 'epochs_ae': 22, 'dropout_rate_ae': 0.29795908570743235, 'hidden_dim_mlp': 108, 'lr_mlp': 0.00046082869951906023, 'epochs_mlp': 13, 'dropout_rate_mlp': 0.240546271216478}. Best is trial 0 with value: 0.7674929069856606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:15:44,436] Trial 1 finished with value: 0.7587991718426501 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 8, 'lr_ae': 0.00012539546603101517, 'epochs_ae': 38, 'dropout_rate_ae': 0.3290533829160983, 'hidden_dim_mlp': 38, 'lr_mlp': 0.003047884484988468, 'epochs_mlp': 31, 'dropout_rate_mlp': 0.4540395793576498}. Best is trial 0 with value: 0.7674929069856606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:15:54,778] Trial 2 finished with value: 0.7647803082585692 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 9, 'lr_ae': 0.00016041620889701872, 'epochs_ae': 21, 'dropout_rate_ae': 0.13333973042772196, 'hidden_dim_mlp': 71, 'lr_mlp': 0.00038401429082971834, 'epochs_mlp': 26, 'dropout_rate_mlp': 0.4416864244702663}. Best is trial 0 with value: 0.7674929069856606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:16:16,712] Trial 3 finished with value: 0.7646461160953915 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 10, 'lr_ae': 0.00325981122392435, 'epochs_ae': 50, 'dropout_rate_ae': 0.2226673063126049, 'hidden_dim_mlp': 79, 'lr_mlp': 0.0003438772576376195, 'epochs_mlp': 47, 'dropout_rate_mlp': 0.459107637166672}. Best is trial 0 with value: 0.7674929069856606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:16:23,542] Trial 4 finished with value: 0.7637642818802238 and parameters: {'num_layers': 2, 'latent_dim_0': 17, 'latent_dim_1': 9, 'lr_ae': 0.00010361253168271269, 'epochs_ae': 11, 'dropout_rate_ae': 0.422766024020526, 'hidden_dim_mlp': 44, 'lr_mlp': 0.005161712458528094, 'epochs_mlp': 24, 'dropout_rate_mlp': 0.2688332718150843}. Best is trial 0 with value: 0.7674929069856606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:16:43,188] Trial 5 finished with value: 0.7477379035350049 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 10, 'lr_ae': 0.0007176737635312627, 'epochs_ae': 40, 'dropout_rate_ae': 0.19894753591639738, 'hidden_dim_mlp': 85, 'lr_mlp': 0.006746082381147617, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.3823734482743989}. Best is trial 0 with value: 0.7674929069856606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:16:53,876] Trial 6 finished with value: 0.7673491296679703 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 10, 'lr_ae': 0.0015713057071936065, 'epochs_ae': 16, 'dropout_rate_ae': 0.49708847020739366, 'hidden_dim_mlp': 55, 'lr_mlp': 0.0002754726694803684, 'epochs_mlp': 37, 'dropout_rate_mlp': 0.20104608373562802}. Best is trial 0 with value: 0.7674929069856606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:17:08,734] Trial 7 finished with value: 0.7775669043784985 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 10, 'lr_ae': 0.0013148649525730688, 'epochs_ae': 38, 'dropout_rate_ae': 0.3406607059943504, 'hidden_dim_mlp': 40, 'lr_mlp': 0.00016689286256450566, 'epochs_mlp': 21, 'dropout_rate_mlp': 0.20325387381464877}. Best is trial 7 with value: 0.7775669043784985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:17:15,950] Trial 8 finished with value: 0.7651637144390767 and parameters: {'num_layers': 2, 'latent_dim_0': 17, 'latent_dim_1': 9, 'lr_ae': 0.006673556372262758, 'epochs_ae': 18, 'dropout_rate_ae': 0.42194638465397916, 'hidden_dim_mlp': 45, 'lr_mlp': 0.0045381949097992955, 'epochs_mlp': 12, 'dropout_rate_mlp': 0.3773701490836435}. Best is trial 7 with value: 0.7775669043784985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:17:32,864] Trial 9 finished with value: 0.753968253968254 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 8, 'lr_ae': 0.0002097627095939514, 'epochs_ae': 34, 'dropout_rate_ae': 0.10694410725092102, 'hidden_dim_mlp': 45, 'lr_mlp': 0.00023291120421373157, 'epochs_mlp': 44, 'dropout_rate_mlp': 0.1932385124105497}. Best is trial 7 with value: 0.7775669043784985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:17:50,735] Trial 10 finished with value: 0.7595659842036652 and parameters: {'num_layers': 2, 'latent_dim_0': 11, 'latent_dim_1': 10, 'lr_ae': 0.0005670496459669604, 'epochs_ae': 49, 'dropout_rate_ae': 0.32717735091670674, 'hidden_dim_mlp': 128, 'lr_mlp': 0.0001313371032751604, 'epochs_mlp': 21, 'dropout_rate_mlp': 0.10048246889444302}. Best is trial 7 with value: 0.7775669043784985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:17:59,469] Trial 11 finished with value: 0.7689594356261024 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 9, 'lr_ae': 0.0080662427072472, 'epochs_ae': 25, 'dropout_rate_ae': 0.2683724844354629, 'hidden_dim_mlp': 109, 'lr_mlp': 0.000949756780045907, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.2537088970375407}. Best is trial 7 with value: 0.7775669043784985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:18:10,430] Trial 12 finished with value: 0.7336668967103749 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 8, 'lr_ae': 0.0019601566783528377, 'epochs_ae': 29, 'dropout_rate_ae': 0.25926877356883077, 'hidden_dim_mlp': 104, 'lr_mlp': 0.0011787103238718166, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.12644515495700934}. Best is trial 7 with value: 0.7775669043784985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:18:21,663] Trial 13 finished with value: 0.7567862893949849 and parameters: {'num_layers': 2, 'latent_dim_0': 19, 'latent_dim_1': 9, 'lr_ae': 0.004266842055565684, 'epochs_ae': 28, 'dropout_rate_ae': 0.38256346544318703, 'hidden_dim_mlp': 100, 'lr_mlp': 0.001270963986574054, 'epochs_mlp': 18, 'dropout_rate_mlp': 0.3150171409672533}. Best is trial 7 with value: 0.7775669043784985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:18:35,974] Trial 14 finished with value: 0.7608503949083659 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 10, 'lr_ae': 0.00038031920178440055, 'epochs_ae': 43, 'dropout_rate_ae': 0.18509082041166863, 'hidden_dim_mlp': 125, 'lr_mlp': 0.00010296185104424352, 'epochs_mlp': 11, 'dropout_rate_mlp': 0.1663088535927385}. Best is trial 7 with value: 0.7775669043784985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:18:48,585] Trial 15 finished with value: 0.7519937121386396 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 9, 'lr_ae': 0.0012883109253827778, 'epochs_ae': 25, 'dropout_rate_ae': 0.27114134163880493, 'hidden_dim_mlp': 64, 'lr_mlp': 0.0007075911336132683, 'epochs_mlp': 31, 'dropout_rate_mlp': 0.3152361200581805}. Best is trial 7 with value: 0.7775669043784985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:19:02,082] Trial 16 finished with value: 0.743271221532091 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 10, 'lr_ae': 0.002747145870168591, 'epochs_ae': 35, 'dropout_rate_ae': 0.37517442416210006, 'hidden_dim_mlp': 86, 'lr_mlp': 0.0021741339867756555, 'epochs_mlp': 16, 'dropout_rate_mlp': 0.24749727907575686}. Best is trial 7 with value: 0.7775669043784985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:19:17,863] Trial 17 finished with value: 0.7414692124837052 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 8, 'lr_ae': 0.005429424298317556, 'epochs_ae': 34, 'dropout_rate_ae': 0.3515216000024342, 'hidden_dim_mlp': 32, 'lr_mlp': 0.009413141076916718, 'epochs_mlp': 37, 'dropout_rate_mlp': 0.16076212635694698}. Best is trial 7 with value: 0.7775669043784985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:19:32,382] Trial 18 finished with value: 0.7620197837589142 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 9, 'lr_ae': 0.0003221489747009705, 'epochs_ae': 45, 'dropout_rate_ae': 0.2276455210309048, 'hidden_dim_mlp': 115, 'lr_mlp': 0.000718340997657579, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.36044985250565276}. Best is trial 7 with value: 0.7775669043784985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:19:46,117] Trial 19 finished with value: 0.7624798711755233 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 10, 'lr_ae': 0.0008561981869783903, 'epochs_ae': 32, 'dropout_rate_ae': 0.4413912970959641, 'hidden_dim_mlp': 95, 'lr_mlp': 0.00018443075699061412, 'epochs_mlp': 26, 'dropout_rate_mlp': 0.21420379501933595}. Best is trial 7 with value: 0.7775669043784985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7639\n"
     ]
    }
   ],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(SimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "        \n",
    "        return reconstructions, latents\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "def train_stacked_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    \n",
    "    # Обучаем каждый автоэнкодер последовательно\n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, latent)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, _ in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent = ae(batch_x)\n",
    "                loss = criterion(reconstructed, batch_x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры MLP\n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate_ae)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate_ae'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7566\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7682\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7652\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7529\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7832\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7635\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7792\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7505\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7749\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7833\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7548\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7489\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7490\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7441\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7541\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7216\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7340\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7200\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7238\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7288\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7627\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7690\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7610\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7756\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7743\n",
      "среднее 0.7559625322500717\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь блок с stacked автоэнкодером. Но у каждого из автоэнкодеров была дополнительная классифицирующая голова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "логистическая рергрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:21:26,049] A new study created in memory with name: no-name-1dfec213-0198-46e1-9d86-a61512f13e6c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:21:43,920] Trial 0 finished with value: 0.7109692508243232 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 10, 'lr': 0.0021207536106081126, 'epochs': 50, 'dropout_rate': 0.10825760894179944, 'class_weight_0': 0.577634516140996, 'class_weight_1': 0.5393899476099905, 'C': 4.657625526301257, 'solver': 'saga'}. Best is trial 0 with value: 0.7109692508243232.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:21:47,394] Trial 1 finished with value: 0.7587224906065485 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 9, 'lr': 0.006235258981356601, 'epochs': 10, 'dropout_rate': 0.1373548648560553, 'class_weight_0': 0.7294981850723475, 'class_weight_1': 0.7857999455581594, 'C': 0.017264139393089083, 'solver': 'saga'}. Best is trial 1 with value: 0.7587224906065485.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:21:58,704] Trial 2 finished with value: 0.7605244996549344 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 8, 'lr': 0.0007039802122179997, 'epochs': 33, 'dropout_rate': 0.3785499550263599, 'class_weight_0': 0.8113581749063944, 'class_weight_1': 0.7788863767147819, 'C': 12.383466054475013, 'solver': 'saga'}. Best is trial 2 with value: 0.7605244996549344.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:22:07,490] Trial 3 finished with value: 0.7430603481328119 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 10, 'lr': 0.0071716075328070745, 'epochs': 26, 'dropout_rate': 0.17948369442652612, 'class_weight_0': 0.1736888823353427, 'class_weight_1': 0.690970316963883, 'C': 0.15808550598833163, 'solver': 'saga'}. Best is trial 2 with value: 0.7605244996549344.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:22:12,669] Trial 4 finished with value: 0.7616172072693811 and parameters: {'num_layers': 2, 'latent_dim_0': 17, 'latent_dim_1': 9, 'lr': 0.00015654012421478073, 'epochs': 15, 'dropout_rate': 0.4522255021810404, 'class_weight_0': 0.21525058905415495, 'class_weight_1': 0.578269849107626, 'C': 0.4445325977772205, 'solver': 'saga'}. Best is trial 4 with value: 0.7616172072693811.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:22:24,850] Trial 5 finished with value: 0.7558277739437159 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 8, 'lr': 0.0040066175498319825, 'epochs': 35, 'dropout_rate': 0.4078225831205424, 'class_weight_0': 0.2866648556549658, 'class_weight_1': 0.6740455541072687, 'C': 0.47014005218901916, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.7616172072693811.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:22:34,761] Trial 6 finished with value: 0.7598918794570969 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 9, 'lr': 0.0031943961024480045, 'epochs': 28, 'dropout_rate': 0.42202945802050973, 'class_weight_0': 0.4472033543309534, 'class_weight_1': 0.7136715171910633, 'C': 3.2564714545702196, 'solver': 'liblinear'}. Best is trial 4 with value: 0.7616172072693811.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:22:49,865] Trial 7 finished with value: 0.7689402653170769 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 8, 'lr': 0.0034550629470452895, 'epochs': 42, 'dropout_rate': 0.3876605414887755, 'class_weight_0': 0.2612156963053505, 'class_weight_1': 0.45974585517783984, 'C': 0.040142016292841184, 'solver': 'saga'}. Best is trial 7 with value: 0.7689402653170769.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:22:54,791] Trial 8 finished with value: 0.7681542826470363 and parameters: {'num_layers': 2, 'latent_dim_0': 19, 'latent_dim_1': 8, 'lr': 0.0007787046260654568, 'epochs': 14, 'dropout_rate': 0.2191134775292155, 'class_weight_0': 0.6173824754917384, 'class_weight_1': 0.7421226185757289, 'C': 1.1186682966314008, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.7689402653170769.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:22:59,687] Trial 9 finished with value: 0.7585116172072693 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 8, 'lr': 0.0007970857340685658, 'epochs': 14, 'dropout_rate': 0.14363167911334004, 'class_weight_0': 0.8759719711102505, 'class_weight_1': 0.7520037849315373, 'C': 2.44342770941231, 'solver': 'liblinear'}. Best is trial 7 with value: 0.7689402653170769.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:23:15,538] Trial 10 finished with value: 0.7671190859596656 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 8, 'lr': 0.000258331642043168, 'epochs': 47, 'dropout_rate': 0.3019128452513428, 'class_weight_0': 0.4032261646191466, 'class_weight_1': 0.28107848595553925, 'C': 0.014714196279106044, 'solver': 'liblinear'}. Best is trial 7 with value: 0.7689402653170769.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:23:29,432] Trial 11 finished with value: 0.7344720496894409 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 8, 'lr': 0.0015372914843712119, 'epochs': 41, 'dropout_rate': 0.24236968493085131, 'class_weight_0': 0.6165803290201732, 'class_weight_1': 0.3455097154646525, 'C': 93.90605265071655, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.7689402653170769.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:23:37,178] Trial 12 finished with value: 0.7725442834138486 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 8, 'lr': 0.0004050155603130799, 'epochs': 22, 'dropout_rate': 0.32375593377487183, 'class_weight_0': 0.34220749363668523, 'class_weight_1': 0.41870283419095594, 'C': 0.1278048965478735, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.7725442834138486.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:23:45,323] Trial 13 finished with value: 0.7770684763438386 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 9, 'lr': 0.00040249868059632674, 'epochs': 22, 'dropout_rate': 0.3399196255529082, 'class_weight_0': 0.3148444580489314, 'class_weight_1': 0.1468519595866944, 'C': 0.0615656635186711, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.7770684763438386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:23:53,112] Trial 14 finished with value: 0.770052143240549 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 9, 'lr': 0.00031147749345912897, 'epochs': 22, 'dropout_rate': 0.3178857269044445, 'class_weight_0': 0.35945687309131696, 'class_weight_1': 0.10084618224230163, 'C': 0.09345125605078754, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.7770684763438386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:24:00,782] Trial 15 finished with value: 0.7721033663062647 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 10, 'lr': 0.0004074933788745162, 'epochs': 22, 'dropout_rate': 0.3504388948472603, 'class_weight_0': 0.11428217107070851, 'class_weight_1': 0.10809013281132591, 'C': 0.11230859180191471, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.7770684763438386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:24:08,405] Trial 16 finished with value: 0.772812667740204 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 9, 'lr': 0.00013172818446793847, 'epochs': 21, 'dropout_rate': 0.4932890662044987, 'class_weight_0': 0.3433628979174751, 'class_weight_1': 0.2681328727318991, 'C': 0.04410126013439649, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.7770684763438386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:24:14,905] Trial 17 finished with value: 0.7708189556015643 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 9, 'lr': 0.0001001856278521939, 'epochs': 18, 'dropout_rate': 0.49974568709745326, 'class_weight_0': 0.5239628767196495, 'class_weight_1': 0.21647950760627244, 'C': 0.03469114673499373, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.7770684763438386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:24:24,101] Trial 18 finished with value: 0.7706464228203359 and parameters: {'num_layers': 2, 'latent_dim_0': 11, 'latent_dim_1': 9, 'lr': 0.00014012135088706346, 'epochs': 26, 'dropout_rate': 0.4808712182668169, 'class_weight_0': 0.47799835390763096, 'class_weight_1': 0.21636973510705504, 'C': 0.03998585365898492, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.7770684763438386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:24:35,339] Trial 19 finished with value: 0.7725059427957978 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 9, 'lr': 0.00021543214347302688, 'epochs': 32, 'dropout_rate': 0.2571260920712405, 'class_weight_0': 0.3070854678716288, 'class_weight_1': 0.19651342021162782, 'C': 0.010539509615571423, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.7770684763438386.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7688\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingSimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(ClassifyingSimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(output_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "\n",
    "class ClassifyingStackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(ClassifyingStackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(ClassifyingSimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        classifications = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent, classification = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "            classifications.append(classification)\n",
    "        \n",
    "        return reconstructions, latents, classifications\n",
    "    \n",
    "def train_classifying_stacked_autoencoder(model, X_train, y_train, epochs, batch_size, lr, classification_weights):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        recon_criterion = nn.MSELoss()\n",
    "        class_criterion = nn.BCELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent, classification = ae(batch_x)\n",
    "                \n",
    "                recon_loss = recon_criterion(reconstructed, batch_x)\n",
    "                class_loss = class_criterion(classification, batch_y)\n",
    "                \n",
    "                recon_weight = 1.0 - classification_weights[i]\n",
    "                class_weight = classification_weights[i]\n",
    "                loss = recon_weight * recon_loss + class_weight * class_loss\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent, _ = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent, _ = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "# Восстанавливаем список весов классификации\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7669\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7804\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7718\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7646\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7802\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7698\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7719\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7844\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7823\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7724\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7604\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7547\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7442\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7565\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7620\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7226\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7195\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7207\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7178\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7158\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7686\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7647\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7780\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7708\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7699\n",
      "среднее 0.75883744595915\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        # Восстанавливаем список весов классификации\n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:25:30,196] A new study created in memory with name: no-name-bc7e7ce8-98a8-4248-a438-ed54973f685c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:25:49,324] Trial 0 finished with value: 0.73115558622805 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 10, 'lr': 0.0014810681146427817, 'epochs': 25, 'dropout_rate': 0.37107317645245397, 'class_weight_0': 0.7896010852764225, 'class_weight_1': 0.65891698969345, 'n_estimators': 118, 'max_depth': 8, 'learning_rate': 0.11439058682021441, 'subsample': 0.9941977135979615, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.73115558622805.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:26:07,526] Trial 1 finished with value: 0.7362932290468521 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 9, 'lr': 0.0006266098592385966, 'epochs': 10, 'dropout_rate': 0.39628395079159695, 'class_weight_0': 0.5294818975279743, 'class_weight_1': 0.3726941400016609, 'n_estimators': 214, 'max_depth': 10, 'learning_rate': 0.09499729096936683, 'subsample': 0.7414337400530304, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.7362932290468521.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:26:26,623] Trial 2 finished with value: 0.7202285100835826 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 8, 'lr': 0.0022544836332681274, 'epochs': 41, 'dropout_rate': 0.20281068191700002, 'class_weight_0': 0.3650912670907144, 'class_weight_1': 0.82683126435117, 'n_estimators': 221, 'max_depth': 3, 'learning_rate': 0.24266832562570942, 'subsample': 0.9646074210624564, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.7362932290468521.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:26:46,883] Trial 3 finished with value: 0.7264588605168315 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 9, 'lr': 0.00011818213956637854, 'epochs': 17, 'dropout_rate': 0.1270884027554763, 'class_weight_0': 0.5598503072498886, 'class_weight_1': 0.4733541029761633, 'n_estimators': 488, 'max_depth': 4, 'learning_rate': 0.05072016718925669, 'subsample': 0.7110270647835969, 'min_samples_split': 13, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.7362932290468521.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:27:15,096] Trial 4 finished with value: 0.7569588221762135 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 10, 'lr': 0.0003752339101446428, 'epochs': 30, 'dropout_rate': 0.20425807486682937, 'class_weight_0': 0.7545252037430789, 'class_weight_1': 0.11168487673287314, 'n_estimators': 287, 'max_depth': 7, 'learning_rate': 0.026876839718346302, 'subsample': 0.789702629193584, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.7569588221762135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:27:41,750] Trial 5 finished with value: 0.709397285484242 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 9, 'lr': 0.0002076102678200116, 'epochs': 35, 'dropout_rate': 0.4542368187958018, 'class_weight_0': 0.4515754965053518, 'class_weight_1': 0.2022318688089075, 'n_estimators': 442, 'max_depth': 4, 'learning_rate': 0.10027739829061337, 'subsample': 0.8398082010587553, 'min_samples_split': 16, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.7569588221762135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:28:03,084] Trial 6 finished with value: 0.7220880300590444 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 8, 'lr': 0.005185677584555226, 'epochs': 43, 'dropout_rate': 0.1910462270168928, 'class_weight_0': 0.26452456661660784, 'class_weight_1': 0.5656721144752729, 'n_estimators': 104, 'max_depth': 9, 'learning_rate': 0.1724583842072091, 'subsample': 0.8567274093665238, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.7569588221762135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:28:40,995] Trial 7 finished with value: 0.6906870638754697 and parameters: {'num_layers': 2, 'latent_dim_0': 19, 'latent_dim_1': 8, 'lr': 0.0034993317885464574, 'epochs': 43, 'dropout_rate': 0.10454280721257483, 'class_weight_0': 0.662590328920201, 'class_weight_1': 0.6787314216046543, 'n_estimators': 454, 'max_depth': 6, 'learning_rate': 0.027172554626255795, 'subsample': 0.9253424749069407, 'min_samples_split': 19, 'min_samples_leaf': 9}. Best is trial 4 with value: 0.7569588221762135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:28:49,382] Trial 8 finished with value: 0.7224906065485776 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 9, 'lr': 0.0032207461360881334, 'epochs': 12, 'dropout_rate': 0.28403044363814955, 'class_weight_0': 0.8202816667551114, 'class_weight_1': 0.5402730998866677, 'n_estimators': 153, 'max_depth': 4, 'learning_rate': 0.07130066922446761, 'subsample': 0.7176488660211593, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 4 with value: 0.7569588221762135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:29:08,629] Trial 9 finished with value: 0.7456291695422129 and parameters: {'num_layers': 2, 'latent_dim_0': 11, 'latent_dim_1': 10, 'lr': 0.00229860166219832, 'epochs': 41, 'dropout_rate': 0.12688990704506314, 'class_weight_0': 0.43915296659135883, 'class_weight_1': 0.4966205830434247, 'n_estimators': 123, 'max_depth': 6, 'learning_rate': 0.017350019966477618, 'subsample': 0.7992271088049292, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.7569588221762135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:29:35,428] Trial 10 finished with value: 0.7565179050686295 and parameters: {'num_layers': 2, 'latent_dim_0': 17, 'latent_dim_1': 10, 'lr': 0.0005754237285175439, 'epochs': 27, 'dropout_rate': 0.2751017094236966, 'class_weight_0': 0.8751250084255215, 'class_weight_1': 0.12154483016780243, 'n_estimators': 345, 'max_depth': 7, 'learning_rate': 0.01202453013554608, 'subsample': 0.6255265286244405, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.7569588221762135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:30:01,890] Trial 11 finished with value: 0.7490798251667816 and parameters: {'num_layers': 2, 'latent_dim_0': 17, 'latent_dim_1': 10, 'lr': 0.0005428041500794964, 'epochs': 28, 'dropout_rate': 0.27345066997175677, 'class_weight_0': 0.8935585248718915, 'class_weight_1': 0.12158039122057898, 'n_estimators': 338, 'max_depth': 7, 'learning_rate': 0.010374752747210733, 'subsample': 0.6078550829447342, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.7569588221762135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:30:24,491] Trial 12 finished with value: 0.7401081205429031 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 10, 'lr': 0.00033028212990400616, 'epochs': 22, 'dropout_rate': 0.22745035201313624, 'class_weight_0': 0.6892616381886774, 'class_weight_1': 0.28025652014269586, 'n_estimators': 345, 'max_depth': 7, 'learning_rate': 0.030705581556220836, 'subsample': 0.6171253642026896, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.7569588221762135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:30:54,003] Trial 13 finished with value: 0.7467218771566598 and parameters: {'num_layers': 2, 'latent_dim_0': 17, 'latent_dim_1': 10, 'lr': 0.0008514264699249249, 'epochs': 33, 'dropout_rate': 0.3585287733826368, 'class_weight_0': 0.10031902931030218, 'class_weight_1': 0.10093718776747886, 'n_estimators': 332, 'max_depth': 8, 'learning_rate': 0.010878191396921982, 'subsample': 0.6718280699350373, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.7569588221762135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:31:12,440] Trial 14 finished with value: 0.7604478184188329 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 10, 'lr': 0.0002987889841309655, 'epochs': 22, 'dropout_rate': 0.3288499102833053, 'class_weight_0': 0.7140183751376699, 'class_weight_1': 0.2883189176584575, 'n_estimators': 275, 'max_depth': 5, 'learning_rate': 0.020858593383732884, 'subsample': 0.7764726106042483, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.7604478184188329.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:31:29,165] Trial 15 finished with value: 0.7540641055133809 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 10, 'lr': 0.0002670028976433192, 'epochs': 20, 'dropout_rate': 0.33394547618638487, 'class_weight_0': 0.683143009969119, 'class_weight_1': 0.30587170380163453, 'n_estimators': 236, 'max_depth': 5, 'learning_rate': 0.033296456921325546, 'subsample': 0.7743623431114619, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.7604478184188329.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:31:53,576] Trial 16 finished with value: 0.7492906985660609 and parameters: {'num_layers': 2, 'latent_dim_0': 19, 'latent_dim_1': 9, 'lr': 0.00011404855687861279, 'epochs': 35, 'dropout_rate': 0.44145333817222954, 'class_weight_0': 0.7450386899238131, 'class_weight_1': 0.24397957306989487, 'n_estimators': 283, 'max_depth': 5, 'learning_rate': 0.019177518007674917, 'subsample': 0.8608577183991315, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.7604478184188329.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:32:22,375] Trial 17 finished with value: 0.7262671574265777 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 10, 'lr': 0.0003670703931094018, 'epochs': 50, 'dropout_rate': 0.23741193365496593, 'class_weight_0': 0.5938235340233115, 'class_weight_1': 0.39962865885797527, 'n_estimators': 298, 'max_depth': 5, 'learning_rate': 0.05556706153740178, 'subsample': 0.7689718934051346, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.7604478184188329.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:32:41,862] Trial 18 finished with value: 0.7342803465991872 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 10, 'lr': 0.008784648830463386, 'epochs': 16, 'dropout_rate': 0.3328643816286072, 'class_weight_0': 0.6197868638987539, 'class_weight_1': 0.1977353164495663, 'n_estimators': 182, 'max_depth': 8, 'learning_rate': 0.01856569603047797, 'subsample': 0.8971332964150655, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.7604478184188329.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:33:12,250] Trial 19 finished with value: 0.7264780308258568 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 9, 'lr': 0.00018507212600351442, 'epochs': 31, 'dropout_rate': 0.16276317498797455, 'class_weight_0': 0.7601223097449789, 'class_weight_1': 0.36214373761653096, 'n_estimators': 393, 'max_depth': 6, 'learning_rate': 0.04147993723711712, 'subsample': 0.817690319191692, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.7604478184188329.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7379\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7299\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7551\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7119\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7221\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7287\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7189\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6766\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6954\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7210\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6788\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7428\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7313\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7320\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7170\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7218\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7011\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6685\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7004\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7161\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6917\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7089\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7314\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7160\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7163\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7077\n",
      "среднее 0.7136614878769787\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:35:21,866] A new study created in memory with name: no-name-624b167b-107e-4237-bd1a-5587f01f7198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:35:39,423] Trial 0 finished with value: 0.7549651100375739 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 8, 'lr': 0.0012976657282059018, 'epochs': 31, 'dropout_rate': 0.36073565898389826, 'class_weight_0': 0.6706957576223604, 'class_weight_1': 0.436374475466465, 'C': 21.240449768040055, 'kernel': 'linear'}. Best is trial 0 with value: 0.7549651100375739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:35:51,015] Trial 1 finished with value: 0.7368204125450503 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 9, 'lr': 0.0008476351583588282, 'epochs': 36, 'dropout_rate': 0.17928027011325956, 'class_weight_0': 0.774018970298742, 'class_weight_1': 0.36111548667122273, 'C': 0.4686046864078655, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.7549651100375739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:35:54,870] Trial 2 finished with value: 0.7263821792807299 and parameters: {'num_layers': 2, 'latent_dim_0': 11, 'latent_dim_1': 10, 'lr': 0.0005033589014515668, 'epochs': 11, 'dropout_rate': 0.18282101587957303, 'class_weight_0': 0.382839297890017, 'class_weight_1': 0.618186896505247, 'C': 57.315675517128845, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.7549651100375739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:36:12,540] Trial 3 finished with value: 0.7530480791350356 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 8, 'lr': 0.0004239032783328343, 'epochs': 49, 'dropout_rate': 0.27660725863645325, 'class_weight_0': 0.30563096314959887, 'class_weight_1': 0.7978385587883318, 'C': 0.37314044561958826, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.7549651100375739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:36:17,880] Trial 4 finished with value: 0.7244076374511157 and parameters: {'num_layers': 2, 'latent_dim_0': 19, 'latent_dim_1': 8, 'lr': 0.000143034756795671, 'epochs': 14, 'dropout_rate': 0.16202248858243418, 'class_weight_0': 0.7339489233201028, 'class_weight_1': 0.3811376935829125, 'C': 11.801833971467243, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 0 with value: 0.7549651100375739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:36:27,910] Trial 5 finished with value: 0.7419197147458018 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 9, 'lr': 0.005226943218321995, 'epochs': 27, 'dropout_rate': 0.3058521888102541, 'class_weight_0': 0.8349106183802076, 'class_weight_1': 0.8000950621383813, 'C': 86.46861159492606, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.7549651100375739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:36:38,653] Trial 6 finished with value: 0.7401177056974159 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 8, 'lr': 0.009429713501584717, 'epochs': 27, 'dropout_rate': 0.35623463913911635, 'class_weight_0': 0.48585440677846947, 'class_weight_1': 0.8301221791222555, 'C': 0.18878458262961603, 'kernel': 'linear'}. Best is trial 0 with value: 0.7549651100375739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:36:48,309] Trial 7 finished with value: 0.6742197684226668 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 10, 'lr': 0.0003098863084128714, 'epochs': 22, 'dropout_rate': 0.15708431825051672, 'class_weight_0': 0.5029551468422894, 'class_weight_1': 0.4211545459184852, 'C': 39.00799444755828, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.7549651100375739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:36:52,905] Trial 8 finished with value: 0.7458879687140557 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 8, 'lr': 0.0015016601108219915, 'epochs': 12, 'dropout_rate': 0.19949369162461866, 'class_weight_0': 0.48818285696193275, 'class_weight_1': 0.5578680368538577, 'C': 0.27705156980682794, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 0 with value: 0.7549651100375739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:37:01,182] Trial 9 finished with value: 0.7472011348822943 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 8, 'lr': 0.005408834491311659, 'epochs': 22, 'dropout_rate': 0.24262282536707347, 'class_weight_0': 0.2138649953452732, 'class_weight_1': 0.33281056637458556, 'C': 0.713776746826386, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.7549651100375739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:37:16,665] Trial 10 finished with value: 0.7615405260332796 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 9, 'lr': 0.0021141386800524273, 'epochs': 39, 'dropout_rate': 0.4925225643414705, 'class_weight_0': 0.621347428889966, 'class_weight_1': 0.14997223923426017, 'C': 4.325702738831815, 'kernel': 'linear'}. Best is trial 10 with value: 0.7615405260332796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:37:31,417] Trial 11 finished with value: 0.7450061344988882 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 9, 'lr': 0.0021628874278511842, 'epochs': 37, 'dropout_rate': 0.49577606565697996, 'class_weight_0': 0.6456548844824652, 'class_weight_1': 0.12668225939916006, 'C': 4.359296086390389, 'kernel': 'linear'}. Best is trial 10 with value: 0.7615405260332796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:37:51,522] Trial 12 finished with value: 0.7517732535848478 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 9, 'lr': 0.002716678326277127, 'epochs': 44, 'dropout_rate': 0.46819044619637745, 'class_weight_0': 0.6431463497290484, 'class_weight_1': 0.11824668627179241, 'C': 11.332570163555959, 'kernel': 'linear'}. Best is trial 10 with value: 0.7615405260332796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:38:04,721] Trial 13 finished with value: 0.7560674028065333 and parameters: {'num_layers': 2, 'latent_dim_0': 17, 'latent_dim_1': 10, 'lr': 0.0010191184538235504, 'epochs': 35, 'dropout_rate': 0.40996994500962175, 'class_weight_0': 0.6257748606914733, 'class_weight_1': 0.26063266801633816, 'C': 1.780457015275442, 'kernel': 'linear'}. Best is trial 10 with value: 0.7615405260332796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:38:19,128] Trial 14 finished with value: 0.707135189019247 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 10, 'lr': 0.003329176010240288, 'epochs': 40, 'dropout_rate': 0.4281404542233253, 'class_weight_0': 0.8849546584978656, 'class_weight_1': 0.24115651846102726, 'C': 1.4340641515824302, 'kernel': 'linear'}. Best is trial 10 with value: 0.7615405260332796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:38:36,338] Trial 15 finished with value: 0.7045663676098458 and parameters: {'num_layers': 2, 'latent_dim_0': 17, 'latent_dim_1': 10, 'lr': 0.0008405570475906629, 'epochs': 47, 'dropout_rate': 0.41753425447992576, 'class_weight_0': 0.5926359504511776, 'class_weight_1': 0.21726001723608696, 'C': 2.9294913253278607, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 10 with value: 0.7615405260332796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:38:49,933] Trial 16 finished with value: 0.7720650256882141 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 9, 'lr': 0.00019890426457649704, 'epochs': 34, 'dropout_rate': 0.4020485451171242, 'class_weight_0': 0.5729360778665489, 'class_weight_1': 0.24960575727194062, 'C': 3.4407968767005115, 'kernel': 'linear'}. Best is trial 16 with value: 0.7720650256882141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:39:07,419] Trial 17 finished with value: 0.7631029062188484 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 9, 'lr': 0.00010216312002306242, 'epochs': 43, 'dropout_rate': 0.3656055634551596, 'class_weight_0': 0.3849612726496687, 'class_weight_1': 0.10299563806880935, 'C': 5.8466307259068495, 'kernel': 'linear'}. Best is trial 16 with value: 0.7720650256882141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:39:26,019] Trial 18 finished with value: 0.7670328195690516 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 9, 'lr': 0.00010328375463635569, 'epochs': 43, 'dropout_rate': 0.34989852376718517, 'class_weight_0': 0.1611609204193286, 'class_weight_1': 0.28578248625327296, 'C': 8.830710416761578, 'kernel': 'linear'}. Best is trial 16 with value: 0.7720650256882141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:39:37,376] Trial 19 finished with value: 0.7095602331109577 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 9, 'lr': 0.00019299159992265213, 'epochs': 32, 'dropout_rate': 0.3095025339623102, 'class_weight_0': 0.15214965254590596, 'class_weight_1': 0.49490708461413024, 'C': 1.11015053377951, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 16 with value: 0.7720650256882141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7541\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7718\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7379\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7508\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7748\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7639\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7847\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7667\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7725\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7773\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7705\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7722\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7462\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7380\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7563\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7437\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7144\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7079\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7266\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7135\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7315\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7652\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7427\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7364\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7504\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7608\n",
      "среднее 0.7510652068001675\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:41:11,981] A new study created in memory with name: no-name-44b73628-0015-4bcd-8951-926f2e772205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:41:26,828] Trial 0 finished with value: 0.7424852388620504 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 8, 'lr_ae': 0.0020461596924571303, 'epochs_ae': 21, 'dropout_rate_ae': 0.37229953871351484, 'class_weight_0': 0.6389561380345596, 'class_weight_1': 0.33810150519297577, 'hidden_dim_combined': 111, 'lr_combined': 0.001417931365170577, 'epochs_freeze': 13, 'epochs_unfreeze': 13, 'dropout_rate_combined': 0.13931891177565478}. Best is trial 0 with value: 0.7424852388620504.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:41:48,883] Trial 1 finished with value: 0.7567671190859596 and parameters: {'num_layers': 2, 'latent_dim_0': 11, 'latent_dim_1': 10, 'lr_ae': 0.0003324721294376269, 'epochs_ae': 35, 'dropout_rate_ae': 0.21526180707260753, 'class_weight_0': 0.8231357205893817, 'class_weight_1': 0.20227903543738332, 'hidden_dim_combined': 62, 'lr_combined': 0.006039958230518912, 'epochs_freeze': 17, 'epochs_unfreeze': 18, 'dropout_rate_combined': 0.25561154397371355}. Best is trial 1 with value: 0.7567671190859596.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:41:58,902] Trial 2 finished with value: 0.7592592592592592 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 10, 'lr_ae': 0.0009505623682406002, 'epochs_ae': 12, 'dropout_rate_ae': 0.18104676937757969, 'class_weight_0': 0.8871276142494442, 'class_weight_1': 0.3260973811866007, 'hidden_dim_combined': 100, 'lr_combined': 0.00011752101289725098, 'epochs_freeze': 12, 'epochs_unfreeze': 7, 'dropout_rate_combined': 0.1322667091869937}. Best is trial 2 with value: 0.7592592592592592.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:42:24,188] Trial 3 finished with value: 0.7675600030672495 and parameters: {'num_layers': 2, 'latent_dim_0': 17, 'latent_dim_1': 10, 'lr_ae': 0.002215657816813942, 'epochs_ae': 41, 'dropout_rate_ae': 0.36741020582054795, 'class_weight_0': 0.2668341680139976, 'class_weight_1': 0.8435249962529253, 'hidden_dim_combined': 125, 'lr_combined': 0.0006622887429488913, 'epochs_freeze': 15, 'epochs_unfreeze': 20, 'dropout_rate_combined': 0.37003128985751854}. Best is trial 3 with value: 0.7675600030672495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:42:51,935] Trial 4 finished with value: 0.7475653707537765 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 8, 'lr_ae': 0.004700366831390095, 'epochs_ae': 50, 'dropout_rate_ae': 0.16838671711085318, 'class_weight_0': 0.44768569163679883, 'class_weight_1': 0.8778190520314499, 'hidden_dim_combined': 59, 'lr_combined': 0.0005026852894413729, 'epochs_freeze': 15, 'epochs_unfreeze': 18, 'dropout_rate_combined': 0.409635100867487}. Best is trial 3 with value: 0.7675600030672495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:43:16,476] Trial 5 finished with value: 0.760850394908366 and parameters: {'num_layers': 2, 'latent_dim_0': 19, 'latent_dim_1': 10, 'lr_ae': 0.006815316981766868, 'epochs_ae': 46, 'dropout_rate_ae': 0.48972236858646967, 'class_weight_0': 0.759798078291926, 'class_weight_1': 0.6969876350241014, 'hidden_dim_combined': 37, 'lr_combined': 0.0003480828592009253, 'epochs_freeze': 20, 'epochs_unfreeze': 6, 'dropout_rate_combined': 0.2315162421350695}. Best is trial 3 with value: 0.7675600030672495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:43:36,413] Trial 6 finished with value: 0.7541024461314315 and parameters: {'num_layers': 2, 'latent_dim_0': 18, 'latent_dim_1': 8, 'lr_ae': 0.0016457455928828193, 'epochs_ae': 30, 'dropout_rate_ae': 0.10248301910460245, 'class_weight_0': 0.6591791483000058, 'class_weight_1': 0.8053921140021835, 'hidden_dim_combined': 38, 'lr_combined': 0.000917503626191777, 'epochs_freeze': 18, 'epochs_unfreeze': 12, 'dropout_rate_combined': 0.38386957995710047}. Best is trial 3 with value: 0.7675600030672495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:43:47,460] Trial 7 finished with value: 0.7324208266237252 and parameters: {'num_layers': 2, 'latent_dim_0': 19, 'latent_dim_1': 9, 'lr_ae': 0.0005772669034179984, 'epochs_ae': 14, 'dropout_rate_ae': 0.22592373906317187, 'class_weight_0': 0.643426041564419, 'class_weight_1': 0.6200895365960531, 'hidden_dim_combined': 118, 'lr_combined': 0.0043448637953698455, 'epochs_freeze': 16, 'epochs_unfreeze': 5, 'dropout_rate_combined': 0.10724920724120271}. Best is trial 3 with value: 0.7675600030672495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:43:59,522] Trial 8 finished with value: 0.759853538839046 and parameters: {'num_layers': 2, 'latent_dim_0': 19, 'latent_dim_1': 8, 'lr_ae': 0.0045034861955028874, 'epochs_ae': 20, 'dropout_rate_ae': 0.2598135243087184, 'class_weight_0': 0.3726814683288733, 'class_weight_1': 0.8908792829686265, 'hidden_dim_combined': 90, 'lr_combined': 0.00018839902270387018, 'epochs_freeze': 9, 'epochs_unfreeze': 5, 'dropout_rate_combined': 0.34630280663278645}. Best is trial 3 with value: 0.7675600030672495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:44:19,900] Trial 9 finished with value: 0.7534314853155433 and parameters: {'num_layers': 2, 'latent_dim_0': 16, 'latent_dim_1': 9, 'lr_ae': 0.0037638063460535332, 'epochs_ae': 44, 'dropout_rate_ae': 0.41563873335685086, 'class_weight_0': 0.6618895702404528, 'class_weight_1': 0.6664193842112504, 'hidden_dim_combined': 96, 'lr_combined': 0.0012534944706384138, 'epochs_freeze': 12, 'epochs_unfreeze': 6, 'dropout_rate_combined': 0.22942652754578383}. Best is trial 3 with value: 0.7675600030672495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:44:40,265] Trial 10 finished with value: 0.768748562226823 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 10, 'lr_ae': 0.00013224888796616, 'epochs_ae': 36, 'dropout_rate_ae': 0.33820459749421466, 'class_weight_0': 0.12361126132743158, 'class_weight_1': 0.4817121593706762, 'hidden_dim_combined': 127, 'lr_combined': 0.0029181521188703877, 'epochs_freeze': 5, 'epochs_unfreeze': 20, 'dropout_rate_combined': 0.4935041372134858}. Best is trial 10 with value: 0.768748562226823.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:45:01,958] Trial 11 finished with value: 0.7715857679625796 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 10, 'lr_ae': 0.00010545546659490333, 'epochs_ae': 38, 'dropout_rate_ae': 0.34137011779407206, 'class_weight_0': 0.10051830430764608, 'class_weight_1': 0.4608407120937867, 'hidden_dim_combined': 126, 'lr_combined': 0.003339532262789103, 'epochs_freeze': 5, 'epochs_unfreeze': 20, 'dropout_rate_combined': 0.4826077208222861}. Best is trial 11 with value: 0.7715857679625796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:45:21,293] Trial 12 finished with value: 0.7643585614600107 and parameters: {'num_layers': 2, 'latent_dim_0': 14, 'latent_dim_1': 9, 'lr_ae': 0.0001173598810670074, 'epochs_ae': 34, 'dropout_rate_ae': 0.31458163079598883, 'class_weight_0': 0.1219473399527145, 'class_weight_1': 0.434469475725316, 'hidden_dim_combined': 128, 'lr_combined': 0.002712582875498614, 'epochs_freeze': 5, 'epochs_unfreeze': 16, 'dropout_rate_combined': 0.4955942681960066}. Best is trial 11 with value: 0.7715857679625796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:45:39,157] Trial 13 finished with value: 0.7598343685300207 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 10, 'lr_ae': 0.000101698338357438, 'epochs_ae': 28, 'dropout_rate_ae': 0.3097275685701203, 'class_weight_0': 0.11128619137208508, 'class_weight_1': 0.5034638098957174, 'hidden_dim_combined': 109, 'lr_combined': 0.009925307455133392, 'epochs_freeze': 5, 'epochs_unfreeze': 20, 'dropout_rate_combined': 0.48633711258466683}. Best is trial 11 with value: 0.7715857679625796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:45:59,329] Trial 14 finished with value: 0.7699754620044476 and parameters: {'num_layers': 2, 'latent_dim_0': 15, 'latent_dim_1': 10, 'lr_ae': 0.00024408042960683663, 'epochs_ae': 38, 'dropout_rate_ae': 0.4269146996908973, 'class_weight_0': 0.2505354104732014, 'class_weight_1': 0.5191179448645307, 'hidden_dim_combined': 82, 'lr_combined': 0.0023664629629046204, 'epochs_freeze': 7, 'epochs_unfreeze': 15, 'dropout_rate_combined': 0.45321600625605857}. Best is trial 11 with value: 0.7715857679625796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:46:19,929] Trial 15 finished with value: 0.7723334100145695 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 9, 'lr_ae': 0.00029505513238135643, 'epochs_ae': 40, 'dropout_rate_ae': 0.45147770377391044, 'class_weight_0': 0.25521791058219584, 'class_weight_1': 0.5907734028643801, 'hidden_dim_combined': 71, 'lr_combined': 0.0021203522421914976, 'epochs_freeze': 8, 'epochs_unfreeze': 14, 'dropout_rate_combined': 0.43916102341836094}. Best is trial 15 with value: 0.7723334100145695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:46:39,445] Trial 16 finished with value: 0.7687869028448739 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 9, 'lr_ae': 0.0002423953974103301, 'epochs_ae': 42, 'dropout_rate_ae': 0.47359993268172695, 'class_weight_0': 0.2571018087574533, 'class_weight_1': 0.11116284968047507, 'hidden_dim_combined': 66, 'lr_combined': 0.0017404338229407934, 'epochs_freeze': 9, 'epochs_unfreeze': 10, 'dropout_rate_combined': 0.4260723535686335}. Best is trial 15 with value: 0.7723334100145695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:46:54,202] Trial 17 finished with value: 0.7637834521892493 and parameters: {'num_layers': 2, 'latent_dim_0': 10, 'latent_dim_1': 9, 'lr_ae': 0.0004502201894213993, 'epochs_ae': 27, 'dropout_rate_ae': 0.42801803033901314, 'class_weight_0': 0.3551482760851935, 'class_weight_1': 0.5742709495253061, 'hidden_dim_combined': 74, 'lr_combined': 0.005665178175124337, 'epochs_freeze': 9, 'epochs_unfreeze': 10, 'dropout_rate_combined': 0.32342691988093325}. Best is trial 15 with value: 0.7723334100145695.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:47:17,612] Trial 18 finished with value: 0.77336860670194 and parameters: {'num_layers': 2, 'latent_dim_0': 13, 'latent_dim_1': 9, 'lr_ae': 0.000183453113215662, 'epochs_ae': 47, 'dropout_rate_ae': 0.3763818740503254, 'class_weight_0': 0.2041207330096948, 'class_weight_1': 0.37866315195129496, 'hidden_dim_combined': 47, 'lr_combined': 0.009966518086939491, 'epochs_freeze': 7, 'epochs_unfreeze': 15, 'dropout_rate_combined': 0.43280584339195405}. Best is trial 18 with value: 0.77336860670194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:47:41,666] Trial 19 finished with value: 0.7714707461084273 and parameters: {'num_layers': 2, 'latent_dim_0': 12, 'latent_dim_1': 9, 'lr_ae': 0.00020751809392430774, 'epochs_ae': 50, 'dropout_rate_ae': 0.4590992089310067, 'class_weight_0': 0.5305383689725842, 'class_weight_1': 0.3623811504042824, 'hidden_dim_combined': 48, 'lr_combined': 0.009052828927141298, 'epochs_freeze': 7, 'epochs_unfreeze': 14, 'dropout_rate_combined': 0.28190079272943735}. Best is trial 18 with value: 0.77336860670194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7669\n"
     ]
    }
   ],
   "source": [
    "class CombinedClassifier(nn.Module):\n",
    "    def __init__(self, stacked_autoencoder, pgs_input_dim, hidden_dim=64, dropout_rate=0.2):\n",
    "        super(CombinedClassifier, self).__init__()\n",
    "        self.stacked_autoencoder = stacked_autoencoder\n",
    "        self.pgs_branch = nn.Sequential(\n",
    "            nn.Linear(pgs_input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.combined_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim // 2 + stacked_autoencoder.autoencoders[-1].encoder[0].out_features, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_snp, x_pgs):\n",
    "        latent = x_snp\n",
    "        for ae in self.stacked_autoencoder.autoencoders:\n",
    "            _, latent, _ = ae(latent)\n",
    "        \n",
    "        pgs_features = self.pgs_branch(x_pgs)\n",
    "        combined = torch.cat([latent, pgs_features], dim=1)\n",
    "        output = self.combined_classifier(combined)\n",
    "        return output\n",
    "\n",
    "def train_combined_classifier(model, X_train_snp, X_train_pgs, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_snp_tensor = torch.FloatTensor(X_train_snp).to(device)\n",
    "    X_train_pgs_tensor = torch.FloatTensor(X_train_pgs).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_snp_tensor, X_train_pgs_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    for param in model.stacked_autoencoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs_freeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    for param in model.stacked_autoencoder.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr/10)\n",
    "    \n",
    "    for epoch in range(epochs_unfreeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_combined(model, X_snp, X_pgs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_snp_tensor = torch.FloatTensor(X_snp).to(device)\n",
    "    X_pgs_tensor = torch.FloatTensor(X_pgs).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_snp_tensor, X_pgs_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    hidden_dim_combined = trial.suggest_int('hidden_dim_combined', 32, 128)\n",
    "    lr_combined = trial.suggest_float('lr_combined', 1e-4, 1e-2, log=True)\n",
    "    epochs_freeze = trial.suggest_int('epochs_freeze', 5, 20)\n",
    "    epochs_unfreeze = trial.suggest_int('epochs_unfreeze', 5, 20)\n",
    "    dropout_rate_combined = trial.suggest_float('dropout_rate_combined', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate_ae)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs_ae, batch_size, lr_ae, classification_weights)\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, X_pgs_train.shape[1], hidden_dim_combined, dropout_rate_combined)\n",
    "        combined_model = train_combined_classifier(combined_model, X_train, X_pgs_train, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr_combined)\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, X_pgs_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate_ae'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs_ae'], 32, best_params['lr_ae'], classification_weights)\n",
    "\n",
    "combined_model = CombinedClassifier(autoencoder, X_train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "combined_model = train_combined_classifier(\n",
    "    combined_model, X_train_all, X_train_pgs, y_all_train, \n",
    "    best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    ")\n",
    "\n",
    "y_pred_proba = predict_combined(combined_model, X_val_all, X_val_pgs)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7559\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7667\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7510\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7584\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7564\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7642\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7448\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7631\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7517\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7601\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7446\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7402\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7509\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7581\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7559\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7201\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7051\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7068\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7083\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7123\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7609\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7683\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7651\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7698\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7654\n",
      "среднее 0.7481643260620477\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs_ae'], 32, best_params['lr_ae'], classification_weights)\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "        combined_model = train_combined_classifier(\n",
    "            combined_model, X_train, train_pgs, y_train, \n",
    "            best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, test_pgs)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше идет блок с denoising автоэнкодером"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:50:24,625] A new study created in memory with name: no-name-0890e7e5-6397-46cf-bb54-3282776a2ff6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:50:40,725] Trial 0 finished with value: 0.7639559849704778 and parameters: {'latent_dim': 84, 'hidden_dim': 221, 'lr': 0.00015427873522348622, 'epochs': 47, 'dropout_rate': 0.4595298069422794, 'noise_level': 0.1289091171887481, 'C': 0.19075021762056943, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7639559849704778.\n",
      "[I 2025-05-12 08:50:45,082] Trial 1 finished with value: 0.7428111341154819 and parameters: {'latent_dim': 100, 'hidden_dim': 165, 'lr': 0.0034667551940709904, 'epochs': 13, 'dropout_rate': 0.15007663324282003, 'noise_level': 0.15129783751763431, 'C': 10.831543069834739, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7639559849704778.\n",
      "[I 2025-05-12 08:50:57,078] Trial 2 finished with value: 0.7618855915957367 and parameters: {'latent_dim': 89, 'hidden_dim': 74, 'lr': 0.0001504715947709718, 'epochs': 38, 'dropout_rate': 0.18505552209036444, 'noise_level': 0.25564693854465836, 'C': 0.5280976071970762, 'solver': 'saga'}. Best is trial 0 with value: 0.7639559849704778.\n",
      "[I 2025-05-12 08:51:04,361] Trial 3 finished with value: 0.7729852005214325 and parameters: {'latent_dim': 52, 'hidden_dim': 233, 'lr': 0.00014797511684075667, 'epochs': 21, 'dropout_rate': 0.341735410154322, 'noise_level': 0.1634568623104498, 'C': 0.24583499259794514, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.7729852005214325.\n",
      "[I 2025-05-12 08:51:08,909] Trial 4 finished with value: 0.769553715205889 and parameters: {'latent_dim': 49, 'hidden_dim': 125, 'lr': 0.0004069491804035411, 'epochs': 14, 'dropout_rate': 0.15281773737139442, 'noise_level': 0.10130428514421065, 'C': 17.46739974171214, 'solver': 'liblinear'}. Best is trial 3 with value: 0.7729852005214325.\n",
      "[I 2025-05-12 08:51:18,009] Trial 5 finished with value: 0.7754581703857065 and parameters: {'latent_dim': 38, 'hidden_dim': 170, 'lr': 0.0010093648779267233, 'epochs': 27, 'dropout_rate': 0.34116364447703174, 'noise_level': 0.22462755900957854, 'C': 0.21553618054596793, 'solver': 'saga'}. Best is trial 5 with value: 0.7754581703857065.\n",
      "[I 2025-05-12 08:51:21,420] Trial 6 finished with value: 0.7609270761444673 and parameters: {'latent_dim': 27, 'hidden_dim': 69, 'lr': 0.000101975481234386, 'epochs': 11, 'dropout_rate': 0.41822995258727946, 'noise_level': 0.08364938921872551, 'C': 69.92797746879093, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.7754581703857065.\n",
      "[I 2025-05-12 08:51:38,341] Trial 7 finished with value: 0.7335518748562228 and parameters: {'latent_dim': 90, 'hidden_dim': 182, 'lr': 0.008739651461588187, 'epochs': 49, 'dropout_rate': 0.31102373073753387, 'noise_level': 0.2442081983088673, 'C': 72.53615422131763, 'solver': 'liblinear'}. Best is trial 5 with value: 0.7754581703857065.\n",
      "[I 2025-05-12 08:51:52,259] Trial 8 finished with value: 0.7579556782455333 and parameters: {'latent_dim': 69, 'hidden_dim': 212, 'lr': 0.0004633294039364494, 'epochs': 39, 'dropout_rate': 0.39313080062088746, 'noise_level': 0.15953716147023966, 'C': 13.115054036732309, 'solver': 'saga'}. Best is trial 5 with value: 0.7754581703857065.\n",
      "[I 2025-05-12 08:52:06,287] Trial 9 finished with value: 0.7709723180737673 and parameters: {'latent_dim': 94, 'hidden_dim': 125, 'lr': 0.0006784343256650922, 'epochs': 43, 'dropout_rate': 0.18228064624318155, 'noise_level': 0.19974405092129538, 'C': 0.10927851602572863, 'solver': 'saga'}. Best is trial 5 with value: 0.7754581703857065.\n",
      "[I 2025-05-12 08:52:14,908] Trial 10 finished with value: 0.7754965110037574 and parameters: {'latent_dim': 11, 'hidden_dim': 130, 'lr': 0.0015901984609521143, 'epochs': 28, 'dropout_rate': 0.25310490032065347, 'noise_level': 0.21541839770599996, 'C': 0.010633847726183395, 'solver': 'saga'}. Best is trial 10 with value: 0.7754965110037574.\n",
      "[I 2025-05-12 08:52:23,268] Trial 11 finished with value: 0.7768192623265087 and parameters: {'latent_dim': 10, 'hidden_dim': 131, 'lr': 0.0017476802472656786, 'epochs': 27, 'dropout_rate': 0.25342665307839146, 'noise_level': 0.2915629054264845, 'C': 0.012402479482887922, 'solver': 'saga'}. Best is trial 11 with value: 0.7768192623265087.\n",
      "[I 2025-05-12 08:52:32,583] Trial 12 finished with value: 0.7765125373821026 and parameters: {'latent_dim': 10, 'hidden_dim': 121, 'lr': 0.0017822896853482027, 'epochs': 30, 'dropout_rate': 0.24273856261723079, 'noise_level': 0.27129561121667056, 'C': 0.015395000146034656, 'solver': 'saga'}. Best is trial 11 with value: 0.7768192623265087.\n",
      "[I 2025-05-12 08:52:42,493] Trial 13 finished with value: 0.7775093934514224 and parameters: {'latent_dim': 11, 'hidden_dim': 100, 'lr': 0.0028073315145207417, 'epochs': 33, 'dropout_rate': 0.24499437919275405, 'noise_level': 0.2935356572492842, 'C': 0.011002064972309255, 'solver': 'saga'}. Best is trial 13 with value: 0.7775093934514224.\n",
      "[I 2025-05-12 08:52:53,139] Trial 14 finished with value: 0.7771259872709146 and parameters: {'latent_dim': 26, 'hidden_dim': 94, 'lr': 0.0041755286426748695, 'epochs': 35, 'dropout_rate': 0.2469837735815303, 'noise_level': 0.28425594790829123, 'C': 0.03778679357653511, 'solver': 'saga'}. Best is trial 13 with value: 0.7775093934514224.\n",
      "[I 2025-05-12 08:53:03,614] Trial 15 finished with value: 0.783720573575646 and parameters: {'latent_dim': 27, 'hidden_dim': 94, 'lr': 0.004696054339687411, 'epochs': 34, 'dropout_rate': 0.10342576551537647, 'noise_level': 0.29419854972513215, 'C': 0.048258392317289026, 'solver': 'saga'}. Best is trial 15 with value: 0.783720573575646.\n",
      "[I 2025-05-12 08:53:14,580] Trial 16 finished with value: 0.7783337167395138 and parameters: {'latent_dim': 26, 'hidden_dim': 106, 'lr': 0.007381982985652764, 'epochs': 35, 'dropout_rate': 0.10022648620284247, 'noise_level': 0.29895789729095806, 'C': 0.04554427852054451, 'solver': 'liblinear'}. Best is trial 15 with value: 0.783720573575646.\n",
      "[I 2025-05-12 08:53:20,904] Trial 17 finished with value: 0.7737903535004983 and parameters: {'latent_dim': 29, 'hidden_dim': 92, 'lr': 0.009931117982574011, 'epochs': 21, 'dropout_rate': 0.10837267770482259, 'noise_level': 0.19355691421959187, 'C': 1.7781337773024535, 'solver': 'liblinear'}. Best is trial 15 with value: 0.783720573575646.\n",
      "[I 2025-05-12 08:53:34,734] Trial 18 finished with value: 0.7778736293229046 and parameters: {'latent_dim': 65, 'hidden_dim': 145, 'lr': 0.006156879261468584, 'epochs': 43, 'dropout_rate': 0.10312595841800157, 'noise_level': 0.24352450826204436, 'C': 0.0493710345409038, 'solver': 'liblinear'}. Best is trial 15 with value: 0.783720573575646.\n",
      "[I 2025-05-12 08:53:42,595] Trial 19 finished with value: 0.7735603097921939 and parameters: {'latent_dim': 42, 'hidden_dim': 191, 'lr': 0.005906331858718877, 'epochs': 21, 'dropout_rate': 0.19288315188407146, 'noise_level': 0.26122266277858325, 'C': 1.0737005249205702, 'solver': 'liblinear'}. Best is trial 15 with value: 0.783720573575646.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7866\n"
     ]
    }
   ],
   "source": [
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "    \n",
    "def train_denoising_autoencoder(model, X_train, epochs, batch_size, lr, noise_level=0.1):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_target in train_loader:\n",
    "            # Add noise to input data\n",
    "            noisy_batch = batch_x + noise_level * torch.randn_like(batch_x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _ = model(noisy_batch)\n",
    "            # Target is the original data (not noisy)\n",
    "            loss = criterion(reconstructed, batch_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs, batch_size, lr, noise_level)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7715\n",
      "ROC-AUC autoencoded: 0.7685\n",
      "ROC-AUC autoencoded: 0.7722\n",
      "ROC-AUC autoencoded: 0.7773\n",
      "ROC-AUC autoencoded: 0.7640\n",
      "ROC-AUC autoencoded: 0.7705\n",
      "ROC-AUC autoencoded: 0.7800\n",
      "ROC-AUC autoencoded: 0.7677\n",
      "ROC-AUC autoencoded: 0.7820\n",
      "ROC-AUC autoencoded: 0.7812\n",
      "ROC-AUC autoencoded: 0.7478\n",
      "ROC-AUC autoencoded: 0.7535\n",
      "ROC-AUC autoencoded: 0.7490\n",
      "ROC-AUC autoencoded: 0.7415\n",
      "ROC-AUC autoencoded: 0.7648\n",
      "ROC-AUC autoencoded: 0.7148\n",
      "ROC-AUC autoencoded: 0.7257\n",
      "ROC-AUC autoencoded: 0.7184\n",
      "ROC-AUC autoencoded: 0.7161\n",
      "ROC-AUC autoencoded: 0.7219\n",
      "ROC-AUC autoencoded: 0.7704\n",
      "ROC-AUC autoencoded: 0.7682\n",
      "ROC-AUC autoencoded: 0.7638\n",
      "ROC-AUC autoencoded: 0.7727\n",
      "ROC-AUC autoencoded: 0.7691\n",
      "среднее 0.7573023002635982\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 08:54:59,429] A new study created in memory with name: no-name-c46ebe7a-97c0-457b-a7ef-d7f352f776c9\n",
      "[I 2025-05-12 08:55:27,772] Trial 0 finished with value: 0.7571696955754926 and parameters: {'latent_dim': 51, 'hidden_dim': 160, 'lr': 0.0010150011587341044, 'epochs': 29, 'dropout_rate': 0.20909623742119998, 'noise_level': 0.08858717102903886, 'n_estimators': 225, 'max_depth': 5, 'learning_rate': 0.08884345522867987, 'subsample': 0.6446609878200618, 'min_samples_split': 15, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7571696955754926.\n",
      "[I 2025-05-12 08:56:06,610] Trial 1 finished with value: 0.7503258952534315 and parameters: {'latent_dim': 44, 'hidden_dim': 127, 'lr': 0.00039267801474453115, 'epochs': 35, 'dropout_rate': 0.1538248079125996, 'noise_level': 0.10300271839705778, 'n_estimators': 256, 'max_depth': 5, 'learning_rate': 0.02065458819637523, 'subsample': 0.9814991662533162, 'min_samples_split': 13, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7571696955754926.\n",
      "[I 2025-05-12 08:56:38,538] Trial 2 finished with value: 0.7599877310022237 and parameters: {'latent_dim': 61, 'hidden_dim': 193, 'lr': 0.001820155334794754, 'epochs': 42, 'dropout_rate': 0.1147268828837643, 'noise_level': 0.26893374529159897, 'n_estimators': 149, 'max_depth': 7, 'learning_rate': 0.06981718233124086, 'subsample': 0.681497536932681, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.7599877310022237.\n",
      "[I 2025-05-12 08:57:08,792] Trial 3 finished with value: 0.7475270301357257 and parameters: {'latent_dim': 49, 'hidden_dim': 85, 'lr': 0.0002100426195890725, 'epochs': 30, 'dropout_rate': 0.3812798222543804, 'noise_level': 0.06690704482936329, 'n_estimators': 194, 'max_depth': 6, 'learning_rate': 0.031445738990586676, 'subsample': 0.8059922320547992, 'min_samples_split': 12, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.7599877310022237.\n",
      "[I 2025-05-12 08:57:35,161] Trial 4 finished with value: 0.72111034429875 and parameters: {'latent_dim': 53, 'hidden_dim': 237, 'lr': 0.0009708283184769535, 'epochs': 12, 'dropout_rate': 0.4958222518604002, 'noise_level': 0.07095379018206031, 'n_estimators': 457, 'max_depth': 3, 'learning_rate': 0.12630364910198819, 'subsample': 0.6335587290291939, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.7599877310022237.\n",
      "[I 2025-05-12 08:58:06,664] Trial 5 finished with value: 0.7449965493443753 and parameters: {'latent_dim': 91, 'hidden_dim': 81, 'lr': 0.0009372567652675403, 'epochs': 29, 'dropout_rate': 0.1003380410032289, 'noise_level': 0.23971175616907525, 'n_estimators': 97, 'max_depth': 7, 'learning_rate': 0.06899603294303862, 'subsample': 0.9768518855207026, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.7599877310022237.\n",
      "[I 2025-05-12 08:58:33,738] Trial 6 finished with value: 0.7598343685300207 and parameters: {'latent_dim': 21, 'hidden_dim': 170, 'lr': 0.0027368729325625363, 'epochs': 29, 'dropout_rate': 0.10823698435549689, 'noise_level': 0.1816230904162477, 'n_estimators': 212, 'max_depth': 9, 'learning_rate': 0.0572164676679426, 'subsample': 0.7591242110899357, 'min_samples_split': 17, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.7599877310022237.\n",
      "[I 2025-05-12 09:00:13,026] Trial 7 finished with value: 0.748849781458477 and parameters: {'latent_dim': 96, 'hidden_dim': 151, 'lr': 0.001993042021482766, 'epochs': 44, 'dropout_rate': 0.488817575522403, 'noise_level': 0.29841572712888914, 'n_estimators': 372, 'max_depth': 10, 'learning_rate': 0.04563633393274589, 'subsample': 0.6275752974810958, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.7599877310022237.\n",
      "[I 2025-05-12 09:00:56,340] Trial 8 finished with value: 0.737941875623035 and parameters: {'latent_dim': 26, 'hidden_dim': 226, 'lr': 0.0004592157137957904, 'epochs': 28, 'dropout_rate': 0.18990285100435883, 'noise_level': 0.21449434418521846, 'n_estimators': 454, 'max_depth': 5, 'learning_rate': 0.2862084512930507, 'subsample': 0.9336300320884197, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.7599877310022237.\n",
      "[I 2025-05-12 09:01:50,647] Trial 9 finished with value: 0.7518403496664368 and parameters: {'latent_dim': 68, 'hidden_dim': 200, 'lr': 0.002122836491376209, 'epochs': 45, 'dropout_rate': 0.48044413535227337, 'noise_level': 0.06696452369700291, 'n_estimators': 427, 'max_depth': 4, 'learning_rate': 0.042643195018965185, 'subsample': 0.761983371151718, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.7599877310022237.\n",
      "[I 2025-05-12 09:02:16,549] Trial 10 finished with value: 0.7523387777010965 and parameters: {'latent_dim': 74, 'hidden_dim': 251, 'lr': 0.0071276515470578995, 'epochs': 49, 'dropout_rate': 0.2889037101124135, 'noise_level': 0.29542733818976363, 'n_estimators': 64, 'max_depth': 7, 'learning_rate': 0.010656619439941539, 'subsample': 0.7104032441863508, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.7599877310022237.\n",
      "[I 2025-05-12 09:02:33,774] Trial 11 finished with value: 0.728644275745725 and parameters: {'latent_dim': 12, 'hidden_dim': 200, 'lr': 0.006927144960512344, 'epochs': 20, 'dropout_rate': 0.10300117848350407, 'noise_level': 0.15472628410390762, 'n_estimators': 147, 'max_depth': 9, 'learning_rate': 0.1589690083147781, 'subsample': 0.8412250056630785, 'min_samples_split': 18, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.7599877310022237.\n",
      "[I 2025-05-12 09:03:13,870] Trial 12 finished with value: 0.7565562456866806 and parameters: {'latent_dim': 30, 'hidden_dim': 190, 'lr': 0.0036296427508215514, 'epochs': 37, 'dropout_rate': 0.2675110175257685, 'noise_level': 0.17490008271892601, 'n_estimators': 307, 'max_depth': 8, 'learning_rate': 0.02320627664105899, 'subsample': 0.7210728812653873, 'min_samples_split': 16, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7599877310022237.\n",
      "[I 2025-05-12 09:03:54,127] Trial 13 finished with value: 0.756537075377655 and parameters: {'latent_dim': 72, 'hidden_dim': 131, 'lr': 0.0028921730984583227, 'epochs': 21, 'dropout_rate': 0.16434018771449962, 'noise_level': 0.23971633391561242, 'n_estimators': 156, 'max_depth': 9, 'learning_rate': 0.09345338476495411, 'subsample': 0.8672133493287495, 'min_samples_split': 16, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.7599877310022237.\n",
      "[I 2025-05-12 09:04:36,399] Trial 14 finished with value: 0.7615980369603558 and parameters: {'latent_dim': 36, 'hidden_dim': 181, 'lr': 0.004245630076488248, 'epochs': 37, 'dropout_rate': 0.22790321234478542, 'noise_level': 0.1309937626683819, 'n_estimators': 327, 'max_depth': 8, 'learning_rate': 0.1886775007100116, 'subsample': 0.6961392484345581, 'min_samples_split': 20, 'min_samples_leaf': 8}. Best is trial 14 with value: 0.7615980369603558.\n",
      "[I 2025-05-12 09:05:15,963] Trial 15 finished with value: 0.7300628786136031 and parameters: {'latent_dim': 35, 'hidden_dim': 216, 'lr': 0.00010702541123028431, 'epochs': 39, 'dropout_rate': 0.239001978108403, 'noise_level': 0.12940676628410636, 'n_estimators': 310, 'max_depth': 8, 'learning_rate': 0.25081758726794906, 'subsample': 0.6895779592414124, 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 14 with value: 0.7615980369603558.\n",
      "[I 2025-05-12 09:06:11,184] Trial 16 finished with value: 0.7596618357487923 and parameters: {'latent_dim': 62, 'hidden_dim': 181, 'lr': 0.004998809182427772, 'epochs': 42, 'dropout_rate': 0.34497052838878106, 'noise_level': 0.1330577908510203, 'n_estimators': 356, 'max_depth': 6, 'learning_rate': 0.15815991847016572, 'subsample': 0.6824986297217706, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 14 with value: 0.7615980369603558.\n",
      "[I 2025-05-12 09:07:19,341] Trial 17 finished with value: 0.7588375124607009 and parameters: {'latent_dim': 82, 'hidden_dim': 136, 'lr': 0.00138238888625723, 'epochs': 36, 'dropout_rate': 0.3360942052920183, 'noise_level': 0.20643945991803558, 'n_estimators': 358, 'max_depth': 8, 'learning_rate': 0.19130554896707355, 'subsample': 0.760338756541443, 'min_samples_split': 19, 'min_samples_leaf': 8}. Best is trial 14 with value: 0.7615980369603558.\n",
      "[I 2025-05-12 09:07:47,436] Trial 18 finished with value: 0.7500575109270762 and parameters: {'latent_dim': 40, 'hidden_dim': 106, 'lr': 0.009790725710399989, 'epochs': 49, 'dropout_rate': 0.23207782582946943, 'noise_level': 0.26222774118998715, 'n_estimators': 127, 'max_depth': 10, 'learning_rate': 0.10423351532658873, 'subsample': 0.6104953601526235, 'min_samples_split': 14, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.7615980369603558.\n",
      "[I 2025-05-12 09:08:33,853] Trial 19 finished with value: 0.7589525343148531 and parameters: {'latent_dim': 62, 'hidden_dim': 215, 'lr': 0.0005268848741593022, 'epochs': 41, 'dropout_rate': 0.15775476680871514, 'noise_level': 0.1180137077311205, 'n_estimators': 277, 'max_depth': 7, 'learning_rate': 0.07129152527377136, 'subsample': 0.6654146946687632, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 14 with value: 0.7615980369603558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7513\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs, batch_size, lr, noise_level)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7137\n",
      "ROC-AUC autoencoded: 0.7458\n",
      "ROC-AUC autoencoded: 0.7225\n",
      "ROC-AUC autoencoded: 0.7564\n",
      "ROC-AUC autoencoded: 0.7328\n",
      "ROC-AUC autoencoded: 0.7394\n",
      "ROC-AUC autoencoded: 0.7282\n",
      "ROC-AUC autoencoded: 0.7078\n",
      "ROC-AUC autoencoded: 0.7324\n",
      "ROC-AUC autoencoded: 0.7458\n",
      "ROC-AUC autoencoded: 0.7205\n",
      "ROC-AUC autoencoded: 0.7152\n",
      "ROC-AUC autoencoded: 0.7054\n",
      "ROC-AUC autoencoded: 0.7126\n",
      "ROC-AUC autoencoded: 0.7114\n",
      "ROC-AUC autoencoded: 0.7245\n",
      "ROC-AUC autoencoded: 0.7060\n",
      "ROC-AUC autoencoded: 0.7081\n",
      "ROC-AUC autoencoded: 0.6940\n",
      "ROC-AUC autoencoded: 0.6840\n",
      "ROC-AUC autoencoded: 0.7473\n",
      "ROC-AUC autoencoded: 0.7325\n",
      "ROC-AUC autoencoded: 0.7616\n",
      "ROC-AUC autoencoded: 0.7530\n",
      "ROC-AUC autoencoded: 0.7477\n",
      "среднее 0.7259478221801996\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 09:13:28,170] A new study created in memory with name: no-name-e44e8773-30ad-495c-8486-40d47e742330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 09:13:39,944] Trial 0 finished with value: 0.7524442144007363 and parameters: {'latent_dim': 93, 'hidden_dim': 211, 'lr': 0.0001244208374212587, 'epochs': 33, 'dropout_rate': 0.2867721091091167, 'noise_level': 0.12432996929155464, 'C': 0.1167970146542704, 'kernel': 'linear'}. Best is trial 0 with value: 0.7524442144007363.\n",
      "[I 2025-05-12 09:13:52,931] Trial 1 finished with value: 0.7688252434629246 and parameters: {'latent_dim': 20, 'hidden_dim': 202, 'lr': 0.0013679543171939844, 'epochs': 34, 'dropout_rate': 0.20512651352426292, 'noise_level': 0.18277298266666175, 'C': 3.024016735694166, 'kernel': 'linear'}. Best is trial 1 with value: 0.7688252434629246.\n",
      "[I 2025-05-12 09:14:07,171] Trial 2 finished with value: 0.7492523579480102 and parameters: {'latent_dim': 48, 'hidden_dim': 134, 'lr': 0.0073618725685121785, 'epochs': 44, 'dropout_rate': 0.32730352828337256, 'noise_level': 0.1928668019255942, 'C': 5.1608526128119365, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.7688252434629246.\n",
      "[I 2025-05-12 09:14:17,107] Trial 3 finished with value: 0.6481385629936355 and parameters: {'latent_dim': 42, 'hidden_dim': 155, 'lr': 0.00010474995536877493, 'epochs': 31, 'dropout_rate': 0.18220366038455948, 'noise_level': 0.20369008679229367, 'C': 8.130671846499276, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.7688252434629246.\n",
      "[I 2025-05-12 09:14:22,365] Trial 4 finished with value: 0.7741737596810062 and parameters: {'latent_dim': 56, 'hidden_dim': 241, 'lr': 0.0026341458800261245, 'epochs': 14, 'dropout_rate': 0.47630016161028166, 'noise_level': 0.22219842890289865, 'C': 0.10140102699524058, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 4 with value: 0.7741737596810062.\n",
      "[I 2025-05-12 09:14:32,447] Trial 5 finished with value: 0.753776550878 and parameters: {'latent_dim': 47, 'hidden_dim': 205, 'lr': 0.0012937877020679992, 'epochs': 30, 'dropout_rate': 0.49704590569361673, 'noise_level': 0.14714272266635314, 'C': 0.2824760536335493, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 4 with value: 0.7741737596810062.\n",
      "[I 2025-05-12 09:14:44,668] Trial 6 finished with value: 0.7516678168852082 and parameters: {'latent_dim': 92, 'hidden_dim': 137, 'lr': 0.00016403462503150308, 'epochs': 36, 'dropout_rate': 0.17366744737390405, 'noise_level': 0.22441442898406838, 'C': 0.33428919037254745, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 4 with value: 0.7741737596810062.\n",
      "[I 2025-05-12 09:14:52,485] Trial 7 finished with value: 0.732583774250441 and parameters: {'latent_dim': 58, 'hidden_dim': 181, 'lr': 0.00017691913020156713, 'epochs': 21, 'dropout_rate': 0.3719569580199741, 'noise_level': 0.1511935470793921, 'C': 2.87012241470124, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 4 with value: 0.7741737596810062.\n",
      "[I 2025-05-12 09:15:08,089] Trial 8 finished with value: 0.7159439460164098 and parameters: {'latent_dim': 28, 'hidden_dim': 222, 'lr': 0.0005313941757059398, 'epochs': 44, 'dropout_rate': 0.3460063626039116, 'noise_level': 0.1905105448029294, 'C': 34.86635823663945, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 4 with value: 0.7741737596810062.\n",
      "[I 2025-05-12 09:15:24,514] Trial 9 finished with value: 0.7576106126830764 and parameters: {'latent_dim': 44, 'hidden_dim': 187, 'lr': 0.0007062347895895859, 'epochs': 49, 'dropout_rate': 0.10553872343481388, 'noise_level': 0.15449567238855488, 'C': 0.31718415025748153, 'kernel': 'linear'}. Best is trial 4 with value: 0.7741737596810062.\n",
      "[I 2025-05-12 09:15:29,342] Trial 10 finished with value: 0.6929012345679011 and parameters: {'latent_dim': 69, 'hidden_dim': 247, 'lr': 0.0054687584002786034, 'epochs': 12, 'dropout_rate': 0.49343121777570403, 'noise_level': 0.27414350959419787, 'C': 0.7941261662304576, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 4 with value: 0.7741737596810062.\n",
      "[I 2025-05-12 09:15:34,146] Trial 11 finished with value: 0.7030806686603787 and parameters: {'latent_dim': 11, 'hidden_dim': 253, 'lr': 0.0023902039775878176, 'epochs': 12, 'dropout_rate': 0.24174754288471506, 'noise_level': 0.07454560340640937, 'C': 54.96418508544409, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.7741737596810062.\n",
      "[I 2025-05-12 09:15:42,459] Trial 12 finished with value: 0.727743271221532 and parameters: {'latent_dim': 75, 'hidden_dim': 73, 'lr': 0.002567162610777853, 'epochs': 23, 'dropout_rate': 0.4335455032386226, 'noise_level': 0.2587580308224076, 'C': 1.190821249109558, 'kernel': 'linear'}. Best is trial 4 with value: 0.7741737596810062.\n",
      "[I 2025-05-12 09:15:50,616] Trial 13 finished with value: 0.7064738133578713 and parameters: {'latent_dim': 19, 'hidden_dim': 233, 'lr': 0.001729352660351754, 'epochs': 21, 'dropout_rate': 0.24031562670305803, 'noise_level': 0.24521204866736818, 'C': 15.66114380118823, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 4 with value: 0.7741737596810062.\n",
      "[I 2025-05-12 09:16:01,801] Trial 14 finished with value: 0.7724484318687218 and parameters: {'latent_dim': 30, 'hidden_dim': 177, 'lr': 0.005173866182652796, 'epochs': 26, 'dropout_rate': 0.4159637941506695, 'noise_level': 0.2956058604772376, 'C': 1.8922122107561024, 'kernel': 'linear'}. Best is trial 4 with value: 0.7741737596810062.\n",
      "[I 2025-05-12 09:16:07,679] Trial 15 finished with value: 0.6275208956368376 and parameters: {'latent_dim': 31, 'hidden_dim': 97, 'lr': 0.004597475208650699, 'epochs': 17, 'dropout_rate': 0.42145110917935846, 'noise_level': 0.2974556668917038, 'C': 1.016991345726122, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.7741737596810062.\n",
      "[I 2025-05-12 09:16:17,076] Trial 16 finished with value: 0.7771259872709148 and parameters: {'latent_dim': 63, 'hidden_dim': 168, 'lr': 0.0037999492370765385, 'epochs': 26, 'dropout_rate': 0.4258689718369486, 'noise_level': 0.23181361024122363, 'C': 0.12411691314273726, 'kernel': 'linear'}. Best is trial 16 with value: 0.7771259872709148.\n",
      "[I 2025-05-12 09:16:23,477] Trial 17 finished with value: 0.7707902001380261 and parameters: {'latent_dim': 66, 'hidden_dim': 118, 'lr': 0.003519111635023713, 'epochs': 18, 'dropout_rate': 0.4525282566753831, 'noise_level': 0.22732749215253442, 'C': 0.11739673404508583, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 16 with value: 0.7771259872709148.\n",
      "[I 2025-05-12 09:16:28,772] Trial 18 finished with value: 0.7215129207882831 and parameters: {'latent_dim': 79, 'hidden_dim': 162, 'lr': 0.000328186394667744, 'epochs': 15, 'dropout_rate': 0.38169567623612, 'noise_level': 0.22303979108100108, 'C': 0.10063119977189042, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 16 with value: 0.7771259872709148.\n",
      "[I 2025-05-12 09:16:36,612] Trial 19 finished with value: 0.6337320757610613 and parameters: {'latent_dim': 57, 'hidden_dim': 96, 'lr': 0.00801032526683491, 'epochs': 26, 'dropout_rate': 0.4673350405737093, 'noise_level': 0.1017681293915047, 'C': 0.5422458965428681, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 16 with value: 0.7771259872709148.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7476\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs, batch_size, lr, noise_level)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7511\n",
      "ROC-AUC autoencoded: 0.7567\n",
      "ROC-AUC autoencoded: 0.7676\n",
      "ROC-AUC autoencoded: 0.7430\n",
      "ROC-AUC autoencoded: 0.7520\n",
      "ROC-AUC autoencoded: 0.7660\n",
      "ROC-AUC autoencoded: 0.7638\n",
      "ROC-AUC autoencoded: 0.7707\n",
      "ROC-AUC autoencoded: 0.7776\n",
      "ROC-AUC autoencoded: 0.7698\n",
      "ROC-AUC autoencoded: 0.7273\n",
      "ROC-AUC autoencoded: 0.7401\n",
      "ROC-AUC autoencoded: 0.7351\n",
      "ROC-AUC autoencoded: 0.7238\n",
      "ROC-AUC autoencoded: 0.7394\n",
      "ROC-AUC autoencoded: 0.7132\n",
      "ROC-AUC autoencoded: 0.6965\n",
      "ROC-AUC autoencoded: 0.6922\n",
      "ROC-AUC autoencoded: 0.7185\n",
      "ROC-AUC autoencoded: 0.7053\n",
      "ROC-AUC autoencoded: 0.7622\n",
      "ROC-AUC autoencoded: 0.7589\n",
      "ROC-AUC autoencoded: 0.7550\n",
      "ROC-AUC autoencoded: 0.7512\n",
      "ROC-AUC autoencoded: 0.7468\n",
      "среднее 0.7433503745890019\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 09:17:37,676] A new study created in memory with name: no-name-ba7feb1d-5b3b-444e-8b0c-52e41ad702b5\n",
      "[I 2025-05-12 09:17:50,753] Trial 0 finished with value: 0.7480829690974619 and parameters: {'latent_dim': 47, 'hidden_dim_ae': 137, 'lr_ae': 0.0009039463497704431, 'epochs_ae': 28, 'dropout_rate_ae': 0.21995259198748762, 'noise_level': 0.1163222290402952, 'hidden_dim_mlp': 32, 'lr_mlp': 0.004261360502676622, 'epochs_mlp': 28, 'dropout_rate_mlp': 0.187984728809835}. Best is trial 0 with value: 0.7480829690974619.\n",
      "[I 2025-05-12 09:17:58,918] Trial 1 finished with value: 0.7319607392071159 and parameters: {'latent_dim': 62, 'hidden_dim_ae': 249, 'lr_ae': 0.001423947090697403, 'epochs_ae': 15, 'dropout_rate_ae': 0.48156023384090385, 'noise_level': 0.2906778575013996, 'hidden_dim_mlp': 62, 'lr_mlp': 0.0027557289157724937, 'epochs_mlp': 19, 'dropout_rate_mlp': 0.17550398640623943}. Best is trial 0 with value: 0.7480829690974619.\n",
      "[I 2025-05-12 09:18:12,031] Trial 2 finished with value: 0.7575722720650256 and parameters: {'latent_dim': 42, 'hidden_dim_ae': 176, 'lr_ae': 0.000286964347398491, 'epochs_ae': 35, 'dropout_rate_ae': 0.189686147561011, 'noise_level': 0.22790428975572347, 'hidden_dim_mlp': 57, 'lr_mlp': 0.0007420989991974939, 'epochs_mlp': 14, 'dropout_rate_mlp': 0.20647902644284516}. Best is trial 2 with value: 0.7575722720650256.\n",
      "[I 2025-05-12 09:18:22,238] Trial 3 finished with value: 0.7707806149835136 and parameters: {'latent_dim': 32, 'hidden_dim_ae': 165, 'lr_ae': 0.00019490606229037637, 'epochs_ae': 16, 'dropout_rate_ae': 0.2869561380730833, 'noise_level': 0.058705891928574436, 'hidden_dim_mlp': 39, 'lr_mlp': 0.0002988097040731624, 'epochs_mlp': 35, 'dropout_rate_mlp': 0.33161007756491956}. Best is trial 3 with value: 0.7707806149835136.\n",
      "[I 2025-05-12 09:18:41,804] Trial 4 finished with value: 0.764166858369757 and parameters: {'latent_dim': 34, 'hidden_dim_ae': 234, 'lr_ae': 0.0002665837542932572, 'epochs_ae': 43, 'dropout_rate_ae': 0.465709396204255, 'noise_level': 0.19282335805460182, 'hidden_dim_mlp': 93, 'lr_mlp': 0.0006119481408895944, 'epochs_mlp': 34, 'dropout_rate_mlp': 0.462783337823095}. Best is trial 3 with value: 0.7707806149835136.\n",
      "[I 2025-05-12 09:18:56,265] Trial 5 finished with value: 0.7719500038340618 and parameters: {'latent_dim': 61, 'hidden_dim_ae': 184, 'lr_ae': 0.0002083853503746229, 'epochs_ae': 33, 'dropout_rate_ae': 0.41382678715943977, 'noise_level': 0.2883940898588062, 'hidden_dim_mlp': 84, 'lr_mlp': 0.0013749377954282082, 'epochs_mlp': 25, 'dropout_rate_mlp': 0.44646756079840155}. Best is trial 5 with value: 0.7719500038340618.\n",
      "[I 2025-05-12 09:19:14,150] Trial 6 finished with value: 0.7642627099148838 and parameters: {'latent_dim': 16, 'hidden_dim_ae': 106, 'lr_ae': 0.005775194311949266, 'epochs_ae': 49, 'dropout_rate_ae': 0.32946945184169363, 'noise_level': 0.2577072348125518, 'hidden_dim_mlp': 116, 'lr_mlp': 0.0006104377436875284, 'epochs_mlp': 24, 'dropout_rate_mlp': 0.3454726786421136}. Best is trial 5 with value: 0.7719500038340618.\n",
      "[I 2025-05-12 09:19:32,568] Trial 7 finished with value: 0.6916839199447894 and parameters: {'latent_dim': 84, 'hidden_dim_ae': 201, 'lr_ae': 0.007848352587664552, 'epochs_ae': 37, 'dropout_rate_ae': 0.4778014034438931, 'noise_level': 0.12143906141946849, 'hidden_dim_mlp': 78, 'lr_mlp': 0.0023667907182793892, 'epochs_mlp': 41, 'dropout_rate_mlp': 0.10209612508240694}. Best is trial 5 with value: 0.7719500038340618.\n",
      "[I 2025-05-12 09:19:45,573] Trial 8 finished with value: 0.7780461621041331 and parameters: {'latent_dim': 16, 'hidden_dim_ae': 169, 'lr_ae': 0.00012665080984163932, 'epochs_ae': 27, 'dropout_rate_ae': 0.3761266089719082, 'noise_level': 0.17194346612043837, 'hidden_dim_mlp': 110, 'lr_mlp': 0.0002169697436273729, 'epochs_mlp': 27, 'dropout_rate_mlp': 0.40133304255598945}. Best is trial 8 with value: 0.7780461621041331.\n",
      "[I 2025-05-12 09:20:06,090] Trial 9 finished with value: 0.7476420519898781 and parameters: {'latent_dim': 70, 'hidden_dim_ae': 84, 'lr_ae': 0.0004112004955198856, 'epochs_ae': 43, 'dropout_rate_ae': 0.181013913845422, 'noise_level': 0.28339024234812615, 'hidden_dim_mlp': 79, 'lr_mlp': 0.00024132839905890993, 'epochs_mlp': 47, 'dropout_rate_mlp': 0.32826499558622513}. Best is trial 8 with value: 0.7780461621041331.\n",
      "[I 2025-05-12 09:20:14,568] Trial 10 finished with value: 0.7658730158730159 and parameters: {'latent_dim': 18, 'hidden_dim_ae': 132, 'lr_ae': 0.00011225853267268594, 'epochs_ae': 23, 'dropout_rate_ae': 0.36681682909113483, 'noise_level': 0.16171528518828918, 'hidden_dim_mlp': 128, 'lr_mlp': 0.00011057503953672629, 'epochs_mlp': 11, 'dropout_rate_mlp': 0.4054992274190393}. Best is trial 8 with value: 0.7780461621041331.\n",
      "[I 2025-05-12 09:20:26,592] Trial 11 finished with value: 0.7556744114715128 and parameters: {'latent_dim': 88, 'hidden_dim_ae': 201, 'lr_ae': 0.00010624716129898558, 'epochs_ae': 25, 'dropout_rate_ae': 0.39501668901073406, 'noise_level': 0.2047329532143006, 'hidden_dim_mlp': 102, 'lr_mlp': 0.0014496074834157607, 'epochs_mlp': 23, 'dropout_rate_mlp': 0.49175019947423293}. Best is trial 8 with value: 0.7780461621041331.\n",
      "[I 2025-05-12 09:20:42,610] Trial 12 finished with value: 0.7229698642742122 and parameters: {'latent_dim': 70, 'hidden_dim_ae': 191, 'lr_ae': 0.000519857094857562, 'epochs_ae': 35, 'dropout_rate_ae': 0.4105502944685201, 'noise_level': 0.15088594969868335, 'hidden_dim_mlp': 100, 'lr_mlp': 0.007772031346359899, 'epochs_mlp': 30, 'dropout_rate_mlp': 0.4128296012965249}. Best is trial 8 with value: 0.7780461621041331.\n",
      "[I 2025-05-12 09:20:52,112] Trial 13 finished with value: 0.7775669043784985 and parameters: {'latent_dim': 54, 'hidden_dim_ae': 153, 'lr_ae': 0.0020933399830126956, 'epochs_ae': 22, 'dropout_rate_ae': 0.2822195523382151, 'noise_level': 0.23271656694646098, 'hidden_dim_mlp': 110, 'lr_mlp': 0.0001177995575306952, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.4105948898107233}. Best is trial 8 with value: 0.7780461621041331.\n",
      "[I 2025-05-12 09:21:01,212] Trial 14 finished with value: 0.7679242389387317 and parameters: {'latent_dim': 24, 'hidden_dim_ae': 137, 'lr_ae': 0.0027257064381975026, 'epochs_ae': 20, 'dropout_rate_ae': 0.2606319165927497, 'noise_level': 0.23174002043308903, 'hidden_dim_mlp': 113, 'lr_mlp': 0.00010687203537475899, 'epochs_mlp': 19, 'dropout_rate_mlp': 0.38411643170224646}. Best is trial 8 with value: 0.7780461621041331.\n",
      "[I 2025-05-12 09:21:07,435] Trial 15 finished with value: 0.7670615750325895 and parameters: {'latent_dim': 49, 'hidden_dim_ae': 64, 'lr_ae': 0.0026817429083497053, 'epochs_ae': 12, 'dropout_rate_ae': 0.13265873190587135, 'noise_level': 0.2273267649477732, 'hidden_dim_mlp': 127, 'lr_mlp': 0.00020916144535896165, 'epochs_mlp': 16, 'dropout_rate_mlp': 0.2701482365660447}. Best is trial 8 with value: 0.7780461621041331.\n",
      "[I 2025-05-12 09:21:18,594] Trial 16 finished with value: 0.7735411394831685 and parameters: {'latent_dim': 98, 'hidden_dim_ae': 151, 'lr_ae': 0.0012267250956127843, 'epochs_ae': 29, 'dropout_rate_ae': 0.3248105580569768, 'noise_level': 0.13409540594090902, 'hidden_dim_mlp': 111, 'lr_mlp': 0.0003576738243685537, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.2843280524438153}. Best is trial 8 with value: 0.7780461621041331.\n",
      "[I 2025-05-12 09:21:30,036] Trial 17 finished with value: 0.7733302660838892 and parameters: {'latent_dim': 12, 'hidden_dim_ae': 112, 'lr_ae': 0.0033669259618882095, 'epochs_ae': 20, 'dropout_rate_ae': 0.2741006476387459, 'noise_level': 0.07503596010917768, 'hidden_dim_mlp': 92, 'lr_mlp': 0.00016652390009409815, 'epochs_mlp': 36, 'dropout_rate_mlp': 0.37883632117241944}. Best is trial 8 with value: 0.7780461621041331.\n",
      "[I 2025-05-12 09:21:41,309] Trial 18 finished with value: 0.7741929299900314 and parameters: {'latent_dim': 33, 'hidden_dim_ae': 223, 'lr_ae': 0.0006798480275442546, 'epochs_ae': 25, 'dropout_rate_ae': 0.3528988911688793, 'noise_level': 0.18509647079344277, 'hidden_dim_mlp': 67, 'lr_mlp': 0.0003584194201110159, 'epochs_mlp': 19, 'dropout_rate_mlp': 0.4345564789376527}. Best is trial 8 with value: 0.7780461621041331.\n",
      "[I 2025-05-12 09:21:52,284] Trial 19 finished with value: 0.7780078214860824 and parameters: {'latent_dim': 75, 'hidden_dim_ae': 157, 'lr_ae': 0.0016761960767731972, 'epochs_ae': 19, 'dropout_rate_ae': 0.10043003116469423, 'noise_level': 0.2551429727826058, 'hidden_dim_mlp': 118, 'lr_mlp': 0.00015533879142970027, 'epochs_mlp': 29, 'dropout_rate_mlp': 0.4999663381969571}. Best is trial 8 with value: 0.7780461621041331.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7812\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae, noise_level)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7599\n",
      "ROC-AUC autoencoded: 0.7595\n",
      "ROC-AUC autoencoded: 0.7557\n",
      "ROC-AUC autoencoded: 0.7727\n",
      "ROC-AUC autoencoded: 0.7667\n",
      "ROC-AUC autoencoded: 0.7665\n",
      "ROC-AUC autoencoded: 0.7648\n",
      "ROC-AUC autoencoded: 0.7729\n",
      "ROC-AUC autoencoded: 0.7675\n",
      "ROC-AUC autoencoded: 0.7801\n",
      "ROC-AUC autoencoded: 0.7536\n",
      "ROC-AUC autoencoded: 0.7435\n",
      "ROC-AUC autoencoded: 0.7705\n",
      "ROC-AUC autoencoded: 0.7527\n",
      "ROC-AUC autoencoded: 0.7543\n",
      "ROC-AUC autoencoded: 0.7243\n",
      "ROC-AUC autoencoded: 0.7239\n",
      "ROC-AUC autoencoded: 0.7223\n",
      "ROC-AUC autoencoded: 0.7232\n",
      "ROC-AUC autoencoded: 0.7290\n",
      "ROC-AUC autoencoded: 0.7561\n",
      "ROC-AUC autoencoded: 0.7602\n",
      "ROC-AUC autoencoded: 0.7651\n",
      "ROC-AUC autoencoded: 0.7620\n",
      "ROC-AUC autoencoded: 0.7616\n",
      "среднее 0.7547563955878485\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь блок с denoising автоэнкодером с дополнительной классифицирующей головой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 09:23:22,170] A new study created in memory with name: no-name-0340e9d9-571f-4e28-93c7-567d0c462e02\n",
      "[I 2025-05-12 09:23:29,595] Trial 0 finished with value: 0.7096273291925463 and parameters: {'latent_dim': 95, 'hidden_dim': 250, 'lr': 0.00017052237465201467, 'epochs': 17, 'dropout_rate': 0.4936798140651365, 'noise_level': 0.18714951453907125, 'classification_weight': 0.5279815183175111, 'C': 67.06842367020796, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7096273291925463.\n",
      "[I 2025-05-12 09:23:49,349] Trial 1 finished with value: 0.6109194080208572 and parameters: {'latent_dim': 72, 'hidden_dim': 246, 'lr': 0.00866089319491985, 'epochs': 43, 'dropout_rate': 0.45773091575473823, 'noise_level': 0.19992823269343563, 'classification_weight': 0.844322023017896, 'C': 15.925095573880665, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7096273291925463.\n",
      "[I 2025-05-12 09:23:57,481] Trial 2 finished with value: 0.7433095621501419 and parameters: {'latent_dim': 19, 'hidden_dim': 66, 'lr': 0.0008539816503244592, 'epochs': 21, 'dropout_rate': 0.3786459021123221, 'noise_level': 0.053096572745459356, 'classification_weight': 0.7369468023155826, 'C': 0.7263118664478982, 'solver': 'liblinear'}. Best is trial 2 with value: 0.7433095621501419.\n",
      "[I 2025-05-12 09:24:03,529] Trial 3 finished with value: 0.7401081205429033 and parameters: {'latent_dim': 19, 'hidden_dim': 132, 'lr': 0.006725890029467687, 'epochs': 15, 'dropout_rate': 0.15922206139311612, 'noise_level': 0.2082859420709804, 'classification_weight': 0.17227175666767297, 'C': 0.3630385958168229, 'solver': 'liblinear'}. Best is trial 2 with value: 0.7433095621501419.\n",
      "[I 2025-05-12 09:24:10,458] Trial 4 finished with value: 0.6560846560846559 and parameters: {'latent_dim': 13, 'hidden_dim': 117, 'lr': 0.0030989737478724724, 'epochs': 18, 'dropout_rate': 0.2735178566159231, 'noise_level': 0.17813097836479946, 'classification_weight': 0.6511035263870965, 'C': 0.8077365566178806, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.7433095621501419.\n",
      "[I 2025-05-12 09:24:21,330] Trial 5 finished with value: 0.7723909209416456 and parameters: {'latent_dim': 23, 'hidden_dim': 220, 'lr': 0.00017675198888594516, 'epochs': 25, 'dropout_rate': 0.4606637721551049, 'noise_level': 0.28721211306191574, 'classification_weight': 0.2572532281889979, 'C': 0.3431317342764787, 'solver': 'saga'}. Best is trial 5 with value: 0.7723909209416456.\n",
      "[I 2025-05-12 09:24:30,155] Trial 6 finished with value: 0.6943485928993175 and parameters: {'latent_dim': 20, 'hidden_dim': 158, 'lr': 0.0012613430972667568, 'epochs': 21, 'dropout_rate': 0.20032292861557519, 'noise_level': 0.28610996972419556, 'classification_weight': 0.4555452906632571, 'C': 0.19070398887612144, 'solver': 'liblinear'}. Best is trial 5 with value: 0.7723909209416456.\n",
      "[I 2025-05-12 09:24:35,457] Trial 7 finished with value: 0.7112376351506787 and parameters: {'latent_dim': 87, 'hidden_dim': 113, 'lr': 0.00043863960348549774, 'epochs': 13, 'dropout_rate': 0.19917464886557565, 'noise_level': 0.22188301799161142, 'classification_weight': 0.6277901760724838, 'C': 11.912308920663783, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.7723909209416456.\n",
      "[I 2025-05-12 09:24:55,670] Trial 8 finished with value: 0.6452917721033663 and parameters: {'latent_dim': 79, 'hidden_dim': 230, 'lr': 0.00011935663964224865, 'epochs': 46, 'dropout_rate': 0.10784701020704324, 'noise_level': 0.17946916392778095, 'classification_weight': 0.7597016244875839, 'C': 0.12010891890627423, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.7723909209416456.\n",
      "[I 2025-05-12 09:25:13,097] Trial 9 finished with value: 0.6639828234031132 and parameters: {'latent_dim': 90, 'hidden_dim': 124, 'lr': 0.0033481896613065817, 'epochs': 44, 'dropout_rate': 0.3325455762020838, 'noise_level': 0.11994908981026912, 'classification_weight': 0.2300944202867309, 'C': 0.3525874267207407, 'solver': 'liblinear'}. Best is trial 5 with value: 0.7723909209416456.\n",
      "[I 2025-05-12 09:25:26,462] Trial 10 finished with value: 0.7712023617820719 and parameters: {'latent_dim': 37, 'hidden_dim': 204, 'lr': 0.0002950932798189234, 'epochs': 32, 'dropout_rate': 0.40626211708126625, 'noise_level': 0.28947741273651145, 'classification_weight': 0.3296811125411626, 'C': 0.013517059385822606, 'solver': 'saga'}. Best is trial 5 with value: 0.7723909209416456.\n",
      "[I 2025-05-12 09:25:39,623] Trial 11 finished with value: 0.7687485622268232 and parameters: {'latent_dim': 46, 'hidden_dim': 204, 'lr': 0.00028340230279431467, 'epochs': 32, 'dropout_rate': 0.3649646599251055, 'noise_level': 0.29976984034372145, 'classification_weight': 0.31120351355964654, 'C': 0.017829394649309552, 'solver': 'saga'}. Best is trial 5 with value: 0.7723909209416456.\n",
      "[I 2025-05-12 09:25:52,623] Trial 12 finished with value: 0.774173759681006 and parameters: {'latent_dim': 41, 'hidden_dim': 197, 'lr': 0.00035502625633595283, 'epochs': 31, 'dropout_rate': 0.4238889766185694, 'noise_level': 0.24796151595646332, 'classification_weight': 0.3653855277580783, 'C': 0.011536076308453689, 'solver': 'saga'}. Best is trial 12 with value: 0.774173759681006.\n",
      "[I 2025-05-12 09:26:04,576] Trial 13 finished with value: 0.7482938424967411 and parameters: {'latent_dim': 36, 'hidden_dim': 199, 'lr': 0.000517332617611805, 'epochs': 27, 'dropout_rate': 0.4338001192694452, 'noise_level': 0.25206509749124767, 'classification_weight': 0.4134600813822106, 'C': 0.05746316125197453, 'solver': 'saga'}. Best is trial 12 with value: 0.774173759681006.\n",
      "[I 2025-05-12 09:26:20,948] Trial 14 finished with value: 0.7507093014339391 and parameters: {'latent_dim': 59, 'hidden_dim': 171, 'lr': 0.00011969194666353408, 'epochs': 37, 'dropout_rate': 0.49078235041807844, 'noise_level': 0.24864971533325814, 'classification_weight': 0.13918793609243463, 'C': 4.039390348281436, 'solver': 'saga'}. Best is trial 12 with value: 0.774173759681006.\n",
      "[I 2025-05-12 09:26:32,222] Trial 15 finished with value: 0.7688060731538991 and parameters: {'latent_dim': 32, 'hidden_dim': 222, 'lr': 0.0002656631496089357, 'epochs': 26, 'dropout_rate': 0.2998262214100539, 'noise_level': 0.2544720299097679, 'classification_weight': 0.3035690897764963, 'C': 0.04429959813928334, 'solver': 'saga'}. Best is trial 12 with value: 0.774173759681006.\n",
      "[I 2025-05-12 09:26:47,770] Trial 16 finished with value: 0.677689594356261 and parameters: {'latent_dim': 55, 'hidden_dim': 180, 'lr': 0.0007874051863501949, 'epochs': 36, 'dropout_rate': 0.43858384538905315, 'noise_level': 0.12705259790079865, 'classification_weight': 0.39275236257753765, 'C': 2.429003701017293, 'solver': 'saga'}. Best is trial 12 with value: 0.774173759681006.\n",
      "[I 2025-05-12 09:26:58,441] Trial 17 finished with value: 0.7807300053676864 and parameters: {'latent_dim': 28, 'hidden_dim': 146, 'lr': 0.0015030143091546012, 'epochs': 26, 'dropout_rate': 0.35110551356229935, 'noise_level': 0.23116147578234422, 'classification_weight': 0.10232363849667275, 'C': 0.010148329830892663, 'solver': 'saga'}. Best is trial 17 with value: 0.7807300053676864.\n",
      "[I 2025-05-12 09:27:17,352] Trial 18 finished with value: 0.7765892186182041 and parameters: {'latent_dim': 47, 'hidden_dim': 84, 'lr': 0.001712156891800412, 'epochs': 50, 'dropout_rate': 0.3387530563069399, 'noise_level': 0.1415606684552082, 'classification_weight': 0.10806598756536334, 'C': 0.010921386299112703, 'solver': 'saga'}. Best is trial 17 with value: 0.7807300053676864.\n",
      "[I 2025-05-12 09:27:35,794] Trial 19 finished with value: 0.7595659842036654 and parameters: {'latent_dim': 65, 'hidden_dim': 71, 'lr': 0.001824629830858738, 'epochs': 50, 'dropout_rate': 0.2757668714339295, 'noise_level': 0.1355990181236149, 'classification_weight': 0.10843987923576193, 'C': 0.041527585530162316, 'solver': 'saga'}. Best is trial 17 with value: 0.7807300053676864.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7857\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingDenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(ClassifyingDenoisingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "    \n",
    "def train_classifying_denoising_autoencoder(model, X_train, y_train, epochs, batch_size, lr, noise_level=0.1, classification_weight=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    class_criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_target, batch_y in train_loader:\n",
    "            # Add noise to input data\n",
    "            noisy_batch = batch_x + noise_level * torch.randn_like(batch_x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _, classification = model(noisy_batch)\n",
    "            \n",
    "            # Reconstruction loss (target is the original data)\n",
    "            recon_loss = recon_criterion(reconstructed, batch_target)\n",
    "            \n",
    "            # Classification loss\n",
    "            class_loss = class_criterion(classification, batch_y)\n",
    "            \n",
    "            # Combined loss with weights\n",
    "            loss = (1 - classification_weight) * recon_loss + classification_weight * class_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent, _ = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def get_classification(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, _, classification = model(X_tensor)\n",
    "    return classification.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7707\n",
      "ROC-AUC autoencoded: 0.7657\n",
      "ROC-AUC autoencoded: 0.7741\n",
      "ROC-AUC autoencoded: 0.7629\n",
      "ROC-AUC autoencoded: 0.7599\n",
      "ROC-AUC autoencoded: 0.7766\n",
      "ROC-AUC autoencoded: 0.7728\n",
      "ROC-AUC autoencoded: 0.7621\n",
      "ROC-AUC autoencoded: 0.7806\n",
      "ROC-AUC autoencoded: 0.7751\n",
      "ROC-AUC autoencoded: 0.7493\n",
      "ROC-AUC autoencoded: 0.7457\n",
      "ROC-AUC autoencoded: 0.7405\n",
      "ROC-AUC autoencoded: 0.7526\n",
      "ROC-AUC autoencoded: 0.7451\n",
      "ROC-AUC autoencoded: 0.7184\n",
      "ROC-AUC autoencoded: 0.7213\n",
      "ROC-AUC autoencoded: 0.7140\n",
      "ROC-AUC autoencoded: 0.7137\n",
      "ROC-AUC autoencoded: 0.7220\n",
      "ROC-AUC autoencoded: 0.7766\n",
      "ROC-AUC autoencoded: 0.7819\n",
      "ROC-AUC autoencoded: 0.7806\n",
      "ROC-AUC autoencoded: 0.7795\n",
      "ROC-AUC autoencoded: 0.7771\n",
      "среднее 0.7567509914448387\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 09:28:49,585] A new study created in memory with name: no-name-93821616-f8a1-4ab7-b9ea-ef28fabda378\n",
      "[I 2025-05-12 09:29:26,376] Trial 0 finished with value: 0.7155126140633387 and parameters: {'latent_dim': 78, 'hidden_dim': 181, 'lr': 0.0003369798058296457, 'epochs': 31, 'dropout_rate': 0.38295179181171957, 'noise_level': 0.15343306648118182, 'classification_weight': 0.6356986311873801, 'n_estimators': 234, 'max_depth': 4, 'learning_rate': 0.09598497002137467, 'subsample': 0.7507937235887354, 'min_samples_split': 16, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7155126140633387.\n",
      "[I 2025-05-12 09:29:38,829] Trial 1 finished with value: 0.7147841423203741 and parameters: {'latent_dim': 31, 'hidden_dim': 244, 'lr': 0.00020460034728549372, 'epochs': 10, 'dropout_rate': 0.16024700742390194, 'noise_level': 0.16493064315786832, 'classification_weight': 0.8247505858063814, 'n_estimators': 83, 'max_depth': 7, 'learning_rate': 0.07858582874516225, 'subsample': 0.8630592891044885, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7155126140633387.\n",
      "[I 2025-05-12 09:30:37,231] Trial 2 finished with value: 0.5861513687600644 and parameters: {'latent_dim': 100, 'hidden_dim': 120, 'lr': 0.006122037919294549, 'epochs': 39, 'dropout_rate': 0.1116955357540228, 'noise_level': 0.2852046657209023, 'classification_weight': 0.8131803501955628, 'n_estimators': 264, 'max_depth': 6, 'learning_rate': 0.07332069645972403, 'subsample': 0.7082702013337607, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7155126140633387.\n",
      "[I 2025-05-12 09:31:30,337] Trial 3 finished with value: 0.6851276742581089 and parameters: {'latent_dim': 65, 'hidden_dim': 73, 'lr': 0.007665030680617176, 'epochs': 36, 'dropout_rate': 0.44503120171279953, 'noise_level': 0.2077721207781753, 'classification_weight': 0.4899896805359861, 'n_estimators': 248, 'max_depth': 7, 'learning_rate': 0.10702781588677338, 'subsample': 0.8667890334068395, 'min_samples_split': 20, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7155126140633387.\n",
      "[I 2025-05-12 09:33:28,491] Trial 4 finished with value: 0.6912621731462311 and parameters: {'latent_dim': 98, 'hidden_dim': 151, 'lr': 0.005002275667513074, 'epochs': 47, 'dropout_rate': 0.39283180236861903, 'noise_level': 0.22697373481568411, 'classification_weight': 0.30664396393248233, 'n_estimators': 437, 'max_depth': 9, 'learning_rate': 0.05522889395994821, 'subsample': 0.7055327622370426, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7155126140633387.\n",
      "[I 2025-05-12 09:33:46,269] Trial 5 finished with value: 0.5827965646806227 and parameters: {'latent_dim': 59, 'hidden_dim': 181, 'lr': 0.007244494150658795, 'epochs': 33, 'dropout_rate': 0.4051408568323899, 'noise_level': 0.07761379341563672, 'classification_weight': 0.6539404412862053, 'n_estimators': 69, 'max_depth': 3, 'learning_rate': 0.0155873046516091, 'subsample': 0.9281782708817157, 'min_samples_split': 12, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7155126140633387.\n",
      "[I 2025-05-12 09:34:39,984] Trial 6 finished with value: 0.6652480637987884 and parameters: {'latent_dim': 70, 'hidden_dim': 156, 'lr': 0.009379500337740578, 'epochs': 13, 'dropout_rate': 0.1780181997633854, 'noise_level': 0.27727707369092663, 'classification_weight': 0.7019778921694784, 'n_estimators': 359, 'max_depth': 6, 'learning_rate': 0.018938369465721652, 'subsample': 0.7378928861452656, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7155126140633387.\n",
      "[I 2025-05-12 09:35:16,213] Trial 7 finished with value: 0.677382869411855 and parameters: {'latent_dim': 82, 'hidden_dim': 167, 'lr': 0.002233780559083391, 'epochs': 34, 'dropout_rate': 0.14045552014720478, 'noise_level': 0.15964090554502675, 'classification_weight': 0.18800661628182525, 'n_estimators': 79, 'max_depth': 10, 'learning_rate': 0.06360440701089998, 'subsample': 0.9825725270223857, 'min_samples_split': 15, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7155126140633387.\n",
      "[I 2025-05-12 09:35:32,876] Trial 8 finished with value: 0.7661030595813205 and parameters: {'latent_dim': 53, 'hidden_dim': 140, 'lr': 0.0026900100682295787, 'epochs': 34, 'dropout_rate': 0.10333182987029105, 'noise_level': 0.24314358321453827, 'classification_weight': 0.10534114580610794, 'n_estimators': 70, 'max_depth': 3, 'learning_rate': 0.016541960271099398, 'subsample': 0.7656851714107357, 'min_samples_split': 11, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.7661030595813205.\n",
      "[I 2025-05-12 09:36:39,680] Trial 9 finished with value: 0.7111226132965264 and parameters: {'latent_dim': 76, 'hidden_dim': 225, 'lr': 0.009270424895990824, 'epochs': 38, 'dropout_rate': 0.17877607165228376, 'noise_level': 0.14853695462671873, 'classification_weight': 0.1094114629152946, 'n_estimators': 443, 'max_depth': 6, 'learning_rate': 0.011762493450764876, 'subsample': 0.6388487153966617, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.7661030595813205.\n",
      "[I 2025-05-12 09:36:55,776] Trial 10 finished with value: 0.7188290775247297 and parameters: {'latent_dim': 36, 'hidden_dim': 96, 'lr': 0.0009505461770127359, 'epochs': 22, 'dropout_rate': 0.27217160054610806, 'noise_level': 0.23271955179278814, 'classification_weight': 0.3624880001677056, 'n_estimators': 171, 'max_depth': 4, 'learning_rate': 0.029503642298706976, 'subsample': 0.606212209745626, 'min_samples_split': 12, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.7661030595813205.\n",
      "[I 2025-05-12 09:37:09,909] Trial 11 finished with value: 0.7295836208879688 and parameters: {'latent_dim': 37, 'hidden_dim': 92, 'lr': 0.0008721352169406051, 'epochs': 21, 'dropout_rate': 0.27322263473401576, 'noise_level': 0.2350898523777452, 'classification_weight': 0.36078262349569623, 'n_estimators': 167, 'max_depth': 3, 'learning_rate': 0.02924636240854717, 'subsample': 0.6248619945394583, 'min_samples_split': 12, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.7661030595813205.\n",
      "[I 2025-05-12 09:37:21,776] Trial 12 finished with value: 0.7414500421746798 and parameters: {'latent_dim': 10, 'hidden_dim': 116, 'lr': 0.0009213531395324727, 'epochs': 21, 'dropout_rate': 0.2683282684237841, 'noise_level': 0.2535028955187204, 'classification_weight': 0.287416561514983, 'n_estimators': 156, 'max_depth': 3, 'learning_rate': 0.028671314894780798, 'subsample': 0.8047182800539525, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.7661030595813205.\n",
      "[I 2025-05-12 09:37:36,676] Trial 13 finished with value: 0.6946169772256728 and parameters: {'latent_dim': 13, 'hidden_dim': 127, 'lr': 0.0022705514461945847, 'epochs': 24, 'dropout_rate': 0.22126301468864434, 'noise_level': 0.29961345623422075, 'classification_weight': 0.22060394006226247, 'n_estimators': 154, 'max_depth': 4, 'learning_rate': 0.24292872859588935, 'subsample': 0.8179691397600862, 'min_samples_split': 16, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.7661030595813205.\n",
      "[I 2025-05-12 09:37:52,755] Trial 14 finished with value: 0.7512844107047005 and parameters: {'latent_dim': 11, 'hidden_dim': 125, 'lr': 0.0021208310604390545, 'epochs': 27, 'dropout_rate': 0.330783330361051, 'noise_level': 0.2556621169211303, 'classification_weight': 0.11814185675106109, 'n_estimators': 144, 'max_depth': 5, 'learning_rate': 0.026683621418004067, 'subsample': 0.8004045532886658, 'min_samples_split': 20, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.7661030595813205.\n",
      "[I 2025-05-12 09:38:22,588] Trial 15 finished with value: 0.7534123150065181 and parameters: {'latent_dim': 46, 'hidden_dim': 204, 'lr': 0.002543483693941188, 'epochs': 44, 'dropout_rate': 0.3151654765535174, 'noise_level': 0.1983030013684816, 'classification_weight': 0.1142448238887211, 'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.01004395430677214, 'subsample': 0.8600592042383366, 'min_samples_split': 20, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.7661030595813205.\n",
      "[I 2025-05-12 09:39:13,028] Trial 16 finished with value: 0.637336093857833 and parameters: {'latent_dim': 48, 'hidden_dim': 207, 'lr': 0.0034217253318284753, 'epochs': 44, 'dropout_rate': 0.31967274343452184, 'noise_level': 0.19098483448312756, 'classification_weight': 0.46240823092975963, 'n_estimators': 323, 'max_depth': 5, 'learning_rate': 0.011158442341880365, 'subsample': 0.8827629181300232, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 8 with value: 0.7661030595813205.\n",
      "[I 2025-05-12 09:39:34,437] Trial 17 finished with value: 0.7482363315696648 and parameters: {'latent_dim': 48, 'hidden_dim': 194, 'lr': 0.0005012045844866538, 'epochs': 42, 'dropout_rate': 0.48453537673944547, 'noise_level': 0.11150344879296142, 'classification_weight': 0.21473890022875222, 'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.016827204015503014, 'subsample': 0.9348042154670525, 'min_samples_split': 18, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.7661030595813205.\n",
      "[I 2025-05-12 09:40:02,096] Trial 18 finished with value: 0.7459550647956444 and parameters: {'latent_dim': 23, 'hidden_dim': 248, 'lr': 0.0016149019689211672, 'epochs': 48, 'dropout_rate': 0.2225923175540761, 'noise_level': 0.19532868463796385, 'classification_weight': 0.10585546774417967, 'n_estimators': 106, 'max_depth': 8, 'learning_rate': 0.010234006290600428, 'subsample': 0.7606391366460955, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.7661030595813205.\n",
      "[I 2025-05-12 09:40:38,508] Trial 19 finished with value: 0.6303581013725942 and parameters: {'latent_dim': 48, 'hidden_dim': 214, 'lr': 0.0033836433110419582, 'epochs': 50, 'dropout_rate': 0.3469214772246956, 'noise_level': 0.11277729866947832, 'classification_weight': 0.39720310408901194, 'n_estimators': 201, 'max_depth': 4, 'learning_rate': 0.043242173592753286, 'subsample': 0.8380239433656632, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 8 with value: 0.7661030595813205.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7448\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7260\n",
      "ROC-AUC autoencoded: 0.7006\n",
      "ROC-AUC autoencoded: 0.7198\n",
      "ROC-AUC autoencoded: 0.7261\n",
      "ROC-AUC autoencoded: 0.7355\n",
      "ROC-AUC autoencoded: 0.7021\n",
      "ROC-AUC autoencoded: 0.7271\n",
      "ROC-AUC autoencoded: 0.6785\n",
      "ROC-AUC autoencoded: 0.7167\n",
      "ROC-AUC autoencoded: 0.6716\n",
      "ROC-AUC autoencoded: 0.6596\n",
      "ROC-AUC autoencoded: 0.7388\n",
      "ROC-AUC autoencoded: 0.6864\n",
      "ROC-AUC autoencoded: 0.7084\n",
      "ROC-AUC autoencoded: 0.7194\n",
      "ROC-AUC autoencoded: 0.7301\n",
      "ROC-AUC autoencoded: 0.7274\n",
      "ROC-AUC autoencoded: 0.7123\n",
      "ROC-AUC autoencoded: 0.7027\n",
      "ROC-AUC autoencoded: 0.7142\n",
      "ROC-AUC autoencoded: 0.7250\n",
      "ROC-AUC autoencoded: 0.7579\n",
      "ROC-AUC autoencoded: 0.7308\n",
      "ROC-AUC autoencoded: 0.6853\n",
      "ROC-AUC autoencoded: 0.7283\n",
      "среднее 0.7132197619645869\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 09:42:39,039] A new study created in memory with name: no-name-2b8192a0-8822-4506-be49-bf4bc2a090c1\n",
      "[I 2025-05-12 09:42:58,670] Trial 0 finished with value: 0.6087052373284259 and parameters: {'latent_dim': 22, 'hidden_dim': 215, 'lr': 0.004551413145923057, 'epochs': 48, 'dropout_rate': 0.3968442163246627, 'noise_level': 0.17529557656488537, 'classification_weight': 0.8415117572807204, 'C': 2.1259946482668712, 'kernel': 'linear'}. Best is trial 0 with value: 0.6087052373284259.\n",
      "[I 2025-05-12 09:43:05,976] Trial 1 finished with value: 0.6573307261713058 and parameters: {'latent_dim': 56, 'hidden_dim': 96, 'lr': 0.000844855113555464, 'epochs': 19, 'dropout_rate': 0.3585285040182534, 'noise_level': 0.22794953404645663, 'classification_weight': 0.39468971080230586, 'C': 15.532420306296645, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.6573307261713058.\n",
      "[I 2025-05-12 09:43:14,344] Trial 2 finished with value: 0.5963308028525421 and parameters: {'latent_dim': 58, 'hidden_dim': 117, 'lr': 0.0014260594511341254, 'epochs': 21, 'dropout_rate': 0.2066136337517519, 'noise_level': 0.06868087301730662, 'classification_weight': 0.6699482520810329, 'C': 3.021695366894221, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 1 with value: 0.6573307261713058.\n",
      "[I 2025-05-12 09:43:33,847] Trial 3 finished with value: 0.6447933440687064 and parameters: {'latent_dim': 56, 'hidden_dim': 163, 'lr': 0.0011427784296629657, 'epochs': 47, 'dropout_rate': 0.10118297981550706, 'noise_level': 0.24169164367466167, 'classification_weight': 0.4487456645200619, 'C': 1.0861278633714864, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.6573307261713058.\n",
      "[I 2025-05-12 09:43:39,582] Trial 4 finished with value: 0.7244268077601409 and parameters: {'latent_dim': 52, 'hidden_dim': 128, 'lr': 0.00015046867625965527, 'epochs': 13, 'dropout_rate': 0.41850053057803493, 'noise_level': 0.12110531211372243, 'classification_weight': 0.1693209025156957, 'C': 0.6160703994532973, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 4 with value: 0.7244268077601409.\n",
      "[I 2025-05-12 09:43:50,221] Trial 5 finished with value: 0.6665133041944636 and parameters: {'latent_dim': 35, 'hidden_dim': 158, 'lr': 0.007035779689041054, 'epochs': 25, 'dropout_rate': 0.28013796731332935, 'noise_level': 0.11211575214173337, 'classification_weight': 0.2595868345529431, 'C': 2.8375575754678, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 4 with value: 0.7244268077601409.\n",
      "[I 2025-05-12 09:44:04,719] Trial 6 finished with value: 0.6556245686680469 and parameters: {'latent_dim': 21, 'hidden_dim': 156, 'lr': 0.0008165702448012376, 'epochs': 32, 'dropout_rate': 0.30213344661208286, 'noise_level': 0.2557509616901975, 'classification_weight': 0.7956667720030424, 'C': 3.9541752941302017, 'kernel': 'linear'}. Best is trial 4 with value: 0.7244268077601409.\n",
      "[I 2025-05-12 09:44:22,803] Trial 7 finished with value: 0.6275208956368377 and parameters: {'latent_dim': 85, 'hidden_dim': 72, 'lr': 0.008932874375275238, 'epochs': 48, 'dropout_rate': 0.145737669906184, 'noise_level': 0.21781139036296332, 'classification_weight': 0.2757145765720691, 'C': 0.7742855672010681, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.7244268077601409.\n",
      "[I 2025-05-12 09:44:40,914] Trial 8 finished with value: 0.6626696572348746 and parameters: {'latent_dim': 69, 'hidden_dim': 142, 'lr': 0.00021818729670219146, 'epochs': 44, 'dropout_rate': 0.12777726790721033, 'noise_level': 0.05399918113292247, 'classification_weight': 0.4057179056418392, 'C': 1.928093320660971, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 4 with value: 0.7244268077601409.\n",
      "[I 2025-05-12 09:45:06,932] Trial 9 finished with value: 0.6203320297523196 and parameters: {'latent_dim': 81, 'hidden_dim': 216, 'lr': 0.007591379835059287, 'epochs': 43, 'dropout_rate': 0.36910248841282023, 'noise_level': 0.12444282873960956, 'classification_weight': 0.17507528278678325, 'C': 8.177932864983434, 'kernel': 'linear'}. Best is trial 4 with value: 0.7244268077601409.\n",
      "[I 2025-05-12 09:45:11,426] Trial 10 finished with value: 0.7368683383176137 and parameters: {'latent_dim': 40, 'hidden_dim': 256, 'lr': 0.00017957602982240708, 'epochs': 10, 'dropout_rate': 0.4928689730014985, 'noise_level': 0.16175731438772198, 'classification_weight': 0.1029240573662999, 'C': 0.18542004105050805, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 10 with value: 0.7368683383176137.\n",
      "[I 2025-05-12 09:45:15,967] Trial 11 finished with value: 0.749098995475807 and parameters: {'latent_dim': 39, 'hidden_dim': 252, 'lr': 0.00010058207642044173, 'epochs': 10, 'dropout_rate': 0.49756879575266133, 'noise_level': 0.162060375077999, 'classification_weight': 0.10226348990378377, 'C': 0.10438431384148712, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 11 with value: 0.749098995475807.\n",
      "[I 2025-05-12 09:45:20,617] Trial 12 finished with value: 0.7505942795797867 and parameters: {'latent_dim': 35, 'hidden_dim': 250, 'lr': 0.00010505000819402036, 'epochs': 10, 'dropout_rate': 0.4865048250399319, 'noise_level': 0.17465143497537525, 'classification_weight': 0.12708591739825034, 'C': 0.11210021102172142, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 12 with value: 0.7505942795797867.\n",
      "[I 2025-05-12 09:45:27,491] Trial 13 finished with value: 0.7368299976995628 and parameters: {'latent_dim': 11, 'hidden_dim': 247, 'lr': 0.00010172511037124833, 'epochs': 15, 'dropout_rate': 0.48916342135088914, 'noise_level': 0.18063382718809176, 'classification_weight': 0.640871744428923, 'C': 0.10073707850868123, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 12 with value: 0.7505942795797867.\n",
      "[I 2025-05-12 09:45:43,251] Trial 14 finished with value: 0.6337704163791119 and parameters: {'latent_dim': 37, 'hidden_dim': 205, 'lr': 0.0003695669834545178, 'epochs': 35, 'dropout_rate': 0.4694049930001836, 'noise_level': 0.2966877757540516, 'classification_weight': 0.30795288774204105, 'C': 75.9477382331683, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 12 with value: 0.7505942795797867.\n",
      "[I 2025-05-12 09:45:54,283] Trial 15 finished with value: 0.7107775477340694 and parameters: {'latent_dim': 29, 'hidden_dim': 184, 'lr': 0.00035812154712606785, 'epochs': 26, 'dropout_rate': 0.43376583461843404, 'noise_level': 0.15148627568440623, 'classification_weight': 0.10051828923243622, 'C': 0.22984829912894067, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 12 with value: 0.7505942795797867.\n",
      "[I 2025-05-12 09:46:01,883] Trial 16 finished with value: 0.7402614830151061 and parameters: {'latent_dim': 47, 'hidden_dim': 233, 'lr': 0.00010708037633055175, 'epochs': 16, 'dropout_rate': 0.3176349597958174, 'noise_level': 0.20020088601287622, 'classification_weight': 0.5913946591288296, 'C': 0.3276431697234637, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 12 with value: 0.7505942795797867.\n",
      "[I 2025-05-12 09:46:06,845] Trial 17 finished with value: 0.7262767425810903 and parameters: {'latent_dim': 97, 'hidden_dim': 190, 'lr': 0.000359254768205465, 'epochs': 10, 'dropout_rate': 0.4494248428548136, 'noise_level': 0.09237350139172273, 'classification_weight': 0.21117934709684522, 'C': 0.13709603730124129, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 12 with value: 0.7505942795797867.\n",
      "[I 2025-05-12 09:46:15,610] Trial 18 finished with value: 0.6886070853462157 and parameters: {'latent_dim': 11, 'hidden_dim': 235, 'lr': 0.003038227968499868, 'epochs': 20, 'dropout_rate': 0.2390266451814053, 'noise_level': 0.14419059634380782, 'classification_weight': 0.5300048533874518, 'C': 0.39898549117435783, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 12 with value: 0.7505942795797867.\n",
      "[I 2025-05-12 09:46:31,811] Trial 19 finished with value: 0.6859328272371751 and parameters: {'latent_dim': 44, 'hidden_dim': 229, 'lr': 0.00026780354113951476, 'epochs': 37, 'dropout_rate': 0.39400401131405316, 'noise_level': 0.20232162068794643, 'classification_weight': 0.3496070679598113, 'C': 45.32285443736844, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 12 with value: 0.7505942795797867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7450\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7707\n",
      "ROC-AUC autoencoded: 0.7620\n",
      "ROC-AUC autoencoded: 0.7674\n",
      "ROC-AUC autoencoded: 0.7665\n",
      "ROC-AUC autoencoded: 0.7735\n",
      "ROC-AUC autoencoded: 0.7792\n",
      "ROC-AUC autoencoded: 0.7636\n",
      "ROC-AUC autoencoded: 0.7656\n",
      "ROC-AUC autoencoded: 0.7665\n",
      "ROC-AUC autoencoded: 0.7715\n",
      "ROC-AUC autoencoded: 0.7296\n",
      "ROC-AUC autoencoded: 0.7255\n",
      "ROC-AUC autoencoded: 0.7354\n",
      "ROC-AUC autoencoded: 0.7384\n",
      "ROC-AUC autoencoded: 0.7259\n",
      "ROC-AUC autoencoded: 0.7385\n",
      "ROC-AUC autoencoded: 0.7350\n",
      "ROC-AUC autoencoded: 0.7283\n",
      "ROC-AUC autoencoded: 0.7246\n",
      "ROC-AUC autoencoded: 0.7206\n",
      "ROC-AUC autoencoded: 0.7652\n",
      "ROC-AUC autoencoded: 0.7650\n",
      "ROC-AUC autoencoded: 0.7677\n",
      "ROC-AUC autoencoded: 0.7674\n",
      "ROC-AUC autoencoded: 0.7641\n",
      "среднее 0.7527087526737952\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 09:47:05,843] A new study created in memory with name: no-name-84b0e068-c6e0-4f5d-9613-227351f02e4d\n",
      "[I 2025-05-12 09:47:32,008] Trial 0 finished with value: 0.6936009508473276 and parameters: {'latent_dim': 88, 'hidden_dim_ae': 174, 'hidden_dim_combined': 74, 'lr_ae': 0.0013349928356067005, 'lr_combined': 0.0002813518712653887, 'epochs_ae': 42, 'epochs_freeze': 9, 'epochs_unfreeze': 14, 'dropout_rate_ae': 0.32033014423321476, 'dropout_rate_combined': 0.3863727105725038, 'noise_level': 0.08359467530186136, 'classification_weight': 0.5755288992243153}. Best is trial 0 with value: 0.6936009508473276.\n",
      "[I 2025-05-12 09:47:53,052] Trial 1 finished with value: 0.6736254888428802 and parameters: {'latent_dim': 29, 'hidden_dim_ae': 192, 'hidden_dim_combined': 111, 'lr_ae': 0.005072767946173791, 'lr_combined': 0.0049666500358484566, 'epochs_ae': 18, 'epochs_freeze': 19, 'epochs_unfreeze': 19, 'dropout_rate_ae': 0.3530573453222229, 'dropout_rate_combined': 0.11480982837914455, 'noise_level': 0.06255909560580088, 'classification_weight': 0.7098672790566581}. Best is trial 0 with value: 0.6936009508473276.\n",
      "[I 2025-05-12 09:48:07,851] Trial 2 finished with value: 0.7666398282340312 and parameters: {'latent_dim': 66, 'hidden_dim_ae': 96, 'hidden_dim_combined': 65, 'lr_ae': 0.0008862064211490403, 'lr_combined': 0.004431749432967198, 'epochs_ae': 20, 'epochs_freeze': 10, 'epochs_unfreeze': 11, 'dropout_rate_ae': 0.38863640579789094, 'dropout_rate_combined': 0.29577248133296763, 'noise_level': 0.08956065520803681, 'classification_weight': 0.12204538658221731}. Best is trial 2 with value: 0.7666398282340312.\n",
      "[I 2025-05-12 09:48:23,972] Trial 3 finished with value: 0.7629974695192087 and parameters: {'latent_dim': 28, 'hidden_dim_ae': 150, 'hidden_dim_combined': 77, 'lr_ae': 0.0015463262144045332, 'lr_combined': 0.00012286434067644862, 'epochs_ae': 11, 'epochs_freeze': 13, 'epochs_unfreeze': 19, 'dropout_rate_ae': 0.4988996819971019, 'dropout_rate_combined': 0.4232339581587209, 'noise_level': 0.27904407959167443, 'classification_weight': 0.6131847035860437}. Best is trial 2 with value: 0.7666398282340312.\n",
      "[I 2025-05-12 09:48:36,951] Trial 4 finished with value: 0.7630358101372594 and parameters: {'latent_dim': 57, 'hidden_dim_ae': 73, 'hidden_dim_combined': 105, 'lr_ae': 0.00018377475999316, 'lr_combined': 0.0001663216757170335, 'epochs_ae': 18, 'epochs_freeze': 15, 'epochs_unfreeze': 5, 'dropout_rate_ae': 0.35731174135429566, 'dropout_rate_combined': 0.28815385012873795, 'noise_level': 0.08374560435352409, 'classification_weight': 0.755070070119308}. Best is trial 2 with value: 0.7666398282340312.\n",
      "[I 2025-05-12 09:48:50,938] Trial 5 finished with value: 0.6470937811517522 and parameters: {'latent_dim': 61, 'hidden_dim_ae': 211, 'hidden_dim_combined': 78, 'lr_ae': 0.0015710611976844028, 'lr_combined': 0.0031514677377244347, 'epochs_ae': 20, 'epochs_freeze': 5, 'epochs_unfreeze': 8, 'dropout_rate_ae': 0.15011308400465656, 'dropout_rate_combined': 0.14048784644973852, 'noise_level': 0.25066706136396905, 'classification_weight': 0.4671787781899014}. Best is trial 2 with value: 0.7666398282340312.\n",
      "[I 2025-05-12 09:49:07,319] Trial 6 finished with value: 0.6630051376428188 and parameters: {'latent_dim': 92, 'hidden_dim_ae': 160, 'hidden_dim_combined': 74, 'lr_ae': 0.001759677944340347, 'lr_combined': 0.0009971317126633281, 'epochs_ae': 22, 'epochs_freeze': 6, 'epochs_unfreeze': 14, 'dropout_rate_ae': 0.21747515303400766, 'dropout_rate_combined': 0.11949998682340879, 'noise_level': 0.2111484204169169, 'classification_weight': 0.6105565874693317}. Best is trial 2 with value: 0.7666398282340312.\n",
      "[I 2025-05-12 09:49:34,034] Trial 7 finished with value: 0.7635725787899701 and parameters: {'latent_dim': 46, 'hidden_dim_ae': 135, 'hidden_dim_combined': 127, 'lr_ae': 0.003218710661489883, 'lr_combined': 0.00012772344119798884, 'epochs_ae': 40, 'epochs_freeze': 17, 'epochs_unfreeze': 13, 'dropout_rate_ae': 0.31005982250840647, 'dropout_rate_combined': 0.35837709842859855, 'noise_level': 0.2871918430219791, 'classification_weight': 0.1739299987497364}. Best is trial 2 with value: 0.7666398282340312.\n",
      "[I 2025-05-12 09:50:01,778] Trial 8 finished with value: 0.6688329115865348 and parameters: {'latent_dim': 19, 'hidden_dim_ae': 213, 'hidden_dim_combined': 46, 'lr_ae': 0.0038580187374847113, 'lr_combined': 0.0014050600298756227, 'epochs_ae': 45, 'epochs_freeze': 6, 'epochs_unfreeze': 16, 'dropout_rate_ae': 0.3684002622421867, 'dropout_rate_combined': 0.2617862503435189, 'noise_level': 0.08089828401720771, 'classification_weight': 0.4717760427539226}. Best is trial 2 with value: 0.7666398282340312.\n",
      "[I 2025-05-12 09:50:19,113] Trial 9 finished with value: 0.6732804232804233 and parameters: {'latent_dim': 73, 'hidden_dim_ae': 111, 'hidden_dim_combined': 45, 'lr_ae': 0.0028978487239619474, 'lr_combined': 0.0004684900617365227, 'epochs_ae': 27, 'epochs_freeze': 10, 'epochs_unfreeze': 10, 'dropout_rate_ae': 0.1608418670258006, 'dropout_rate_combined': 0.1305715901839681, 'noise_level': 0.200636987131311, 'classification_weight': 0.706297432498402}. Best is trial 2 with value: 0.7666398282340312.\n",
      "[I 2025-05-12 09:50:39,112] Trial 10 finished with value: 0.7650486925849244 and parameters: {'latent_dim': 76, 'hidden_dim_ae': 256, 'hidden_dim_combined': 33, 'lr_ae': 0.0003269259673388589, 'lr_combined': 0.008936159527745761, 'epochs_ae': 31, 'epochs_freeze': 10, 'epochs_unfreeze': 9, 'dropout_rate_ae': 0.44897586616225993, 'dropout_rate_combined': 0.49324510403357297, 'noise_level': 0.12864583041716907, 'classification_weight': 0.10203292504917139}. Best is trial 2 with value: 0.7666398282340312.\n",
      "[I 2025-05-12 09:51:00,524] Trial 11 finished with value: 0.7626715742657773 and parameters: {'latent_dim': 79, 'hidden_dim_ae': 256, 'hidden_dim_combined': 32, 'lr_ae': 0.00036446967438445076, 'lr_combined': 0.009940277199850764, 'epochs_ae': 34, 'epochs_freeze': 10, 'epochs_unfreeze': 9, 'dropout_rate_ae': 0.45893144464604924, 'dropout_rate_combined': 0.48721569285149735, 'noise_level': 0.13966489736884938, 'classification_weight': 0.1225065004219873}. Best is trial 2 with value: 0.7666398282340312.\n",
      "[I 2025-05-12 09:51:18,509] Trial 12 finished with value: 0.75954681389464 and parameters: {'latent_dim': 100, 'hidden_dim_ae': 71, 'hidden_dim_combined': 57, 'lr_ae': 0.0004795428784215306, 'lr_combined': 0.009516120760707061, 'epochs_ae': 32, 'epochs_freeze': 12, 'epochs_unfreeze': 6, 'dropout_rate_ae': 0.42728449211371566, 'dropout_rate_combined': 0.23892153716805392, 'noise_level': 0.13400931475082012, 'classification_weight': 0.2852160527755915}. Best is trial 2 with value: 0.7666398282340312.\n",
      "[I 2025-05-12 09:51:47,470] Trial 13 finished with value: 0.7638026224982747 and parameters: {'latent_dim': 70, 'hidden_dim_ae': 251, 'hidden_dim_combined': 56, 'lr_ae': 0.000101971304097275, 'lr_combined': 0.003330983426051627, 'epochs_ae': 50, 'epochs_freeze': 8, 'epochs_unfreeze': 11, 'dropout_rate_ae': 0.4130724049484166, 'dropout_rate_combined': 0.20715417197684655, 'noise_level': 0.13376591805933347, 'classification_weight': 0.28084233509400974}. Best is trial 2 with value: 0.7666398282340312.\n",
      "[I 2025-05-12 09:52:03,836] Trial 14 finished with value: 0.728682616363776 and parameters: {'latent_dim': 43, 'hidden_dim_ae': 104, 'hidden_dim_combined': 93, 'lr_ae': 0.0006321882332719393, 'lr_combined': 0.004504435117783121, 'epochs_ae': 26, 'epochs_freeze': 12, 'epochs_unfreeze': 7, 'dropout_rate_ae': 0.23486801581279096, 'dropout_rate_combined': 0.336104337125495, 'noise_level': 0.1577275912951966, 'classification_weight': 0.8770724557658953}. Best is trial 2 with value: 0.7666398282340312.\n",
      "[I 2025-05-12 09:52:16,305] Trial 15 finished with value: 0.77789279963193 and parameters: {'latent_dim': 68, 'hidden_dim_ae': 118, 'hidden_dim_combined': 32, 'lr_ae': 0.0002634270324246384, 'lr_combined': 0.0017241529038353701, 'epochs_ae': 10, 'epochs_freeze': 14, 'epochs_unfreeze': 11, 'dropout_rate_ae': 0.41191007179756817, 'dropout_rate_combined': 0.4714305511798961, 'noise_level': 0.10739068495345747, 'classification_weight': 0.26227492933333785}. Best is trial 15 with value: 0.77789279963193.\n",
      "[I 2025-05-12 09:52:29,992] Trial 16 finished with value: 0.737692661605705 and parameters: {'latent_dim': 45, 'hidden_dim_ae': 106, 'hidden_dim_combined': 65, 'lr_ae': 0.009706702027762134, 'lr_combined': 0.0016506172430131622, 'epochs_ae': 10, 'epochs_freeze': 15, 'epochs_unfreeze': 12, 'dropout_rate_ae': 0.25910866833308965, 'dropout_rate_combined': 0.4328238842642866, 'noise_level': 0.10517019723163792, 'classification_weight': 0.31624711571344744}. Best is trial 15 with value: 0.77789279963193.\n",
      "[I 2025-05-12 09:52:46,077] Trial 17 finished with value: 0.767234107813818 and parameters: {'latent_dim': 62, 'hidden_dim_ae': 131, 'hidden_dim_combined': 93, 'lr_ae': 0.0008226858911160278, 'lr_combined': 0.0006880693378500725, 'epochs_ae': 14, 'epochs_freeze': 14, 'epochs_unfreeze': 16, 'dropout_rate_ae': 0.39071431735785667, 'dropout_rate_combined': 0.1972941512947653, 'noise_level': 0.05712584942459073, 'classification_weight': 0.21480337266785315}. Best is trial 15 with value: 0.77789279963193.\n",
      "[I 2025-05-12 09:53:04,703] Trial 18 finished with value: 0.7514569434859291 and parameters: {'latent_dim': 51, 'hidden_dim_ae': 130, 'hidden_dim_combined': 91, 'lr_ae': 0.00020288281390854049, 'lr_combined': 0.0006868124911209354, 'epochs_ae': 14, 'epochs_freeze': 20, 'epochs_unfreeze': 17, 'dropout_rate_ae': 0.4941815868550613, 'dropout_rate_combined': 0.17665464521619356, 'noise_level': 0.05016052292048768, 'classification_weight': 0.37042815243687177}. Best is trial 15 with value: 0.77789279963193.\n",
      "[I 2025-05-12 09:53:21,086] Trial 19 finished with value: 0.7616267924238939 and parameters: {'latent_dim': 37, 'hidden_dim_ae': 126, 'hidden_dim_combined': 89, 'lr_ae': 0.0007833034785851938, 'lr_combined': 0.00042192107576206325, 'epochs_ae': 14, 'epochs_freeze': 15, 'epochs_unfreeze': 16, 'dropout_rate_ae': 0.27818033000459585, 'dropout_rate_combined': 0.20152907864863534, 'noise_level': 0.18879049145960933, 'classification_weight': 0.21847345858264852}. Best is trial 15 with value: 0.77789279963193.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7855\n"
     ]
    }
   ],
   "source": [
    "class CombinedClassifier(nn.Module):\n",
    "    def __init__(self, autoencoder, pgs_input_dim, hidden_dim=64, dropout_rate=0.2):\n",
    "        super(CombinedClassifier, self).__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "        self.pgs_branch = nn.Sequential(\n",
    "            nn.Linear(pgs_input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        latent_dim = list(autoencoder.classifier[0].parameters())[0].shape[1]\n",
    "        self.combined_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim // 2 + latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_snp, x_pgs):\n",
    "        _, latent, _ = self.autoencoder(x_snp)\n",
    "        pgs_features = self.pgs_branch(x_pgs)\n",
    "        combined = torch.cat([latent, pgs_features], dim=1)\n",
    "        output = self.combined_classifier(combined)\n",
    "        return output\n",
    "\n",
    "def train_combined_classifier(model, X_train_snp, X_train_pgs, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_snp_tensor = torch.FloatTensor(X_train_snp).to(device)\n",
    "    X_train_pgs_tensor = torch.FloatTensor(X_train_pgs).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_snp_tensor, X_train_pgs_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    for param in model.autoencoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs_freeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    for param in model.autoencoder.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr/10)\n",
    "    \n",
    "    for epoch in range(epochs_unfreeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_combined(model, X_snp, X_pgs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_snp_tensor = torch.FloatTensor(X_snp).to(device)\n",
    "    X_pgs_tensor = torch.FloatTensor(X_pgs).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_snp_tensor, X_pgs_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    hidden_dim_combined = trial.suggest_int('hidden_dim_combined', 32, 128)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    lr_combined = trial.suggest_float('lr_combined', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    epochs_freeze = trial.suggest_int('epochs_freeze', 5, 20)\n",
    "    epochs_unfreeze = trial.suggest_int('epochs_unfreeze', 5, 20)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    dropout_rate_combined = trial.suggest_float('dropout_rate_combined', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs_ae, batch_size, lr_ae, noise_level, classification_weight)\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, X_pgs_train.shape[1], hidden_dim_combined, dropout_rate_combined)\n",
    "        combined_model = train_combined_classifier(combined_model, X_train, X_pgs_train, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr_combined)\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, X_pgs_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs_ae'], 32, \n",
    "    best_params['lr_ae'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "combined_model = CombinedClassifier(autoencoder, X_train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "combined_model = train_combined_classifier(\n",
    "    combined_model, X_train_all, X_train_pgs, y_all_train, \n",
    "    best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    ")\n",
    "\n",
    "y_pred_proba = predict_combined(combined_model, X_val_all, X_val_pgs)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7527\n",
      "ROC-AUC autoencoded: 0.7584\n",
      "ROC-AUC autoencoded: 0.7714\n",
      "ROC-AUC autoencoded: 0.7746\n",
      "ROC-AUC autoencoded: 0.7625\n",
      "ROC-AUC autoencoded: 0.7802\n",
      "ROC-AUC autoencoded: 0.7723\n",
      "ROC-AUC autoencoded: 0.7623\n",
      "ROC-AUC autoencoded: 0.7686\n",
      "ROC-AUC autoencoded: 0.7717\n",
      "ROC-AUC autoencoded: 0.7301\n",
      "ROC-AUC autoencoded: 0.7546\n",
      "ROC-AUC autoencoded: 0.7614\n",
      "ROC-AUC autoencoded: 0.7470\n",
      "ROC-AUC autoencoded: 0.7520\n",
      "ROC-AUC autoencoded: 0.7130\n",
      "ROC-AUC autoencoded: 0.7107\n",
      "ROC-AUC autoencoded: 0.7201\n",
      "ROC-AUC autoencoded: 0.7160\n",
      "ROC-AUC autoencoded: 0.7118\n",
      "ROC-AUC autoencoded: 0.7698\n",
      "ROC-AUC autoencoded: 0.7708\n",
      "ROC-AUC autoencoded: 0.7855\n",
      "ROC-AUC autoencoded: 0.7668\n",
      "ROC-AUC autoencoded: 0.7809\n",
      "среднее 0.7546105311142647\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs_ae'], 32, \n",
    "            best_params['lr_ae'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "        combined_model = train_combined_classifier(\n",
    "            combined_model, X_train, train_pgs, y_train, \n",
    "            best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, test_pgs)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.20057576e+00,  7.29952508e-01, -7.83539731e-01,  2.58283748e-01,\n",
       "       -6.29326020e-01, -2.55707327e+00,  1.20643719e+00,  5.84722954e-01,\n",
       "       -6.21686368e-02, -4.20488769e-01,  7.46150258e-01, -1.42859235e-01,\n",
       "       -1.01973822e+00, -1.20145829e+00,  6.27932015e-01,  5.00997356e-01,\n",
       "       -1.10079953e+00,  3.89051091e-01, -3.16004181e-01,  1.41701519e+00,\n",
       "        3.65123857e-01, -1.10942083e+00, -8.09720245e-01,  3.79078222e-01,\n",
       "        4.71026638e-01, -7.43362016e-03,  2.99892228e-01, -2.05266349e-01,\n",
       "       -8.66072002e-01,  1.83930047e+00,  4.47156668e-02,  3.84033984e-01,\n",
       "        9.48074640e-01, -4.86537013e-01,  1.00964931e+00,  1.68219101e+00,\n",
       "       -3.25291700e-01,  6.34523127e-02, -2.18950387e+00,  1.24705083e-01,\n",
       "       -1.60695493e-01,  7.35194547e-01,  4.44514334e-01, -6.09160091e-02,\n",
       "       -6.43237510e-01,  1.50744317e+00, -3.85172451e-01,  9.54412316e-01,\n",
       "       -1.29939281e+00, -2.28765606e+00,  8.62173005e-01,  1.35096814e-01,\n",
       "       -1.05561522e+00,  6.06637871e-01,  9.97982521e-01, -4.49472688e-01,\n",
       "        8.29247167e-01,  1.01460903e+00,  8.79098980e-01, -8.97330431e-02,\n",
       "       -1.09431542e+00, -1.01601794e+00,  9.98169195e-01,  2.22186314e+00,\n",
       "        8.81753971e-01,  1.14770617e+00, -1.10992754e-01,  1.04226776e+00,\n",
       "        5.62838050e-01,  6.89889529e-01,  2.16455612e-01, -3.18873549e-01,\n",
       "        5.15931265e-01, -1.67713362e+00,  8.69958558e-01,  1.79702511e+00,\n",
       "       -6.53837682e-01, -6.17894720e-01,  6.18283417e-01, -1.75918436e+00,\n",
       "        1.34315818e-01,  7.63149452e-01, -9.47568661e-01, -2.61697261e-01,\n",
       "       -8.21177930e-01,  2.73624645e-01,  3.31656343e-02, -4.73938177e-01,\n",
       "       -1.21742122e+00, -1.12297616e-02,  1.99755888e-01, -2.01090923e-01,\n",
       "       -1.33073159e+00,  2.83658859e-01,  9.33010785e-01, -3.29150506e-01,\n",
       "       -1.89117531e+00, -1.99806753e+00,  1.50501575e+00,  2.07372457e+00,\n",
       "       -1.11053560e+00,  1.23612085e-01, -8.24535420e-01,  2.17152056e+00,\n",
       "       -8.85649670e-01,  1.58700713e+00,  7.99756656e-01,  1.62566855e-03,\n",
       "        1.57751513e+00, -2.53768689e+00, -1.75688767e-01, -1.74539824e-02,\n",
       "       -4.51101962e-01,  4.00006142e-01, -1.25906334e+00,  3.57214294e-01,\n",
       "        2.52937488e-01,  5.80437437e-01, -5.01002587e-01, -1.05379466e+00,\n",
       "        1.19379746e+00,  8.55091272e-01,  3.08685029e-01, -8.72008626e-01,\n",
       "        1.03365702e+00, -1.36774974e+00, -6.46667559e-01,  2.87004477e-01,\n",
       "        5.84247695e-01,  1.61710042e-01, -3.66531450e-01, -2.16234715e-02,\n",
       "       -1.82033159e+00, -8.04740076e-01,  7.78227818e-01,  1.46914654e-01,\n",
       "       -2.74223538e-01, -5.67029847e-02, -1.29346938e+00,  1.90327749e+00,\n",
       "       -1.15544166e-01,  1.32622561e-01,  1.48665179e+00, -8.58875494e-01,\n",
       "       -2.57713126e-01,  9.56701214e-01, -1.16513815e-01,  2.64117347e-02,\n",
       "        9.92516209e-01,  1.18996767e+00,  4.01338584e-01,  7.58642234e-01,\n",
       "        9.55315342e-01, -4.62355163e-01, -1.09646580e+00,  1.94618609e+00,\n",
       "       -8.98426604e-01, -4.38344816e-01, -1.71104493e+00, -1.35828412e+00,\n",
       "       -3.58444449e-01, -2.32782722e+00, -1.17777776e+00, -1.38670616e-01,\n",
       "       -1.04660475e+00,  1.01304506e+00,  1.51527952e+00, -2.33920455e-01,\n",
       "        2.00712884e+00, -6.80222679e-01,  1.00517375e+00,  2.15550607e-01,\n",
       "        4.45091505e-01, -1.07145282e+00, -1.57954871e+00, -1.48782666e-01,\n",
       "       -2.76992767e-02, -1.70147378e+00, -7.22174825e-01, -1.37085657e+00,\n",
       "        1.62965188e+00,  2.52906366e+00,  1.52117656e+00, -6.37683468e-01,\n",
       "        1.14096744e+00, -1.51550572e+00,  6.91946239e-01, -9.41459339e-02,\n",
       "        2.74226882e-01,  1.13929529e+00,  1.35879670e+00, -4.86787670e-01,\n",
       "       -3.30534522e-02,  1.60369564e+00, -4.66049063e-01,  8.60904546e-01,\n",
       "       -6.74906103e-01,  4.51224038e-01,  6.80487235e-01, -1.43993249e+00,\n",
       "       -8.00399744e-01, -1.26388520e+00, -2.21400774e-01,  5.64159345e-01,\n",
       "        4.55503685e-01, -4.43305195e-01,  2.48378160e-01, -2.25180425e-01,\n",
       "       -5.71694591e-01, -5.62215780e-01, -6.81515544e-01,  8.27288081e-01,\n",
       "        2.38966632e-01,  4.82180236e-01, -6.96342717e-02,  2.31654690e-01,\n",
       "        9.68901637e-01, -8.20188492e-01, -3.90805647e-01, -1.79640040e+00,\n",
       "       -7.94707181e-01,  6.44735564e-01,  4.96377879e-02,  1.80080476e+00,\n",
       "        2.02006528e-01, -1.36965605e+00, -4.27019056e-01, -2.08511703e-01,\n",
       "       -2.31346719e+00,  1.48478506e+00, -4.89439362e-01,  1.53564214e+00,\n",
       "        3.44630629e-01, -8.37121064e-01, -2.50782567e+00,  1.19003562e+00,\n",
       "        4.90612881e-01,  4.08534432e-01,  9.13203568e-01, -4.97229533e-01,\n",
       "       -1.57024140e+00, -1.38117970e+00, -1.76769356e-02, -1.25327183e+00,\n",
       "        9.53257313e-01, -1.92726998e+00,  4.90081883e-01,  9.52311410e-01,\n",
       "        1.55835962e+00, -3.20661133e-01, -1.07777203e+00,  3.59043970e-02,\n",
       "       -3.20918387e-01, -8.47035227e-01,  1.13534335e-01,  1.20116679e+00,\n",
       "        1.32541308e+00, -1.05096487e+00,  2.00833595e+00,  1.81881908e-02,\n",
       "        1.96591548e+00,  9.04729366e-01,  1.41388317e-01,  1.53200220e-01,\n",
       "       -1.92047465e-01, -2.55490190e-01,  5.21652851e-01,  9.38386069e-01,\n",
       "        2.26419906e-01,  1.77010582e+00, -1.09436819e+00,  7.81657867e-01,\n",
       "       -1.50954931e+00, -1.45326232e-01, -7.13362236e-01,  1.12358962e+00,\n",
       "        4.56465418e-01, -6.00388275e-01, -5.61094418e-01, -1.26832447e+00,\n",
       "        3.19567521e-01, -1.82052948e+00, -2.02542098e-01,  5.18402220e-01,\n",
       "       -1.98775679e-03, -1.18656396e+00, -2.21380986e-01, -7.71369652e-01,\n",
       "       -5.14300626e-01, -3.35646616e-02,  2.83290009e+00,  6.36601135e-01,\n",
       "       -5.71694591e-01, -1.00478453e+00,  4.68483784e-01, -1.06864941e+00,\n",
       "       -6.86910080e-02, -2.38140855e+00, -7.77477778e-01,  6.16772876e-01,\n",
       "       -7.92253377e-01,  5.77739769e-01, -1.26081135e+00,  7.39385804e-01,\n",
       "       -5.70507266e-01,  1.00247510e-01, -1.63261433e-01,  1.23493365e+00,\n",
       "        1.39667895e+00, -5.14439147e-01,  5.79905582e-01,  1.42667989e-01,\n",
       "       -9.33281186e-01,  4.64663113e-02,  3.62889047e-01,  1.51605907e-01,\n",
       "       -3.04599266e-01, -3.53899633e-01,  9.03549297e-01, -6.93560295e-01,\n",
       "       -5.41760811e-01,  1.62434850e+00, -4.52764217e-01, -1.41032074e-01,\n",
       "       -1.02996241e+00,  2.46864321e-01, -3.46584393e-01,  2.95989108e+00,\n",
       "       -1.01184251e+00, -3.65307966e+00,  3.14041183e-01,  4.73561577e-01,\n",
       "       -6.67419360e-01, -1.36778932e+00,  7.89752125e-01,  9.85991076e-02,\n",
       "       -6.11331452e-01, -1.40227331e-01, -7.10618196e-01, -7.62801124e-01,\n",
       "        6.11785716e-01,  7.39926037e-01,  3.75728646e-01,  1.32365848e+00,\n",
       "       -4.71865759e-02, -1.28164890e+00, -5.68825261e-03, -4.12012589e-01,\n",
       "        2.44392047e-01, -2.70794268e+00, -6.69358657e-01, -1.84712556e+00,\n",
       "       -1.80912996e-01, -2.43959947e-01,  3.00768210e-01,  1.56107187e-01,\n",
       "       -3.02922623e-02, -4.72223152e-01,  1.12907110e+00, -8.05379913e-01,\n",
       "       -1.84892633e+00, -1.10796306e+00,  8.22028108e-02, -6.45368098e-01,\n",
       "       -5.84715587e-01,  2.58249987e+00,  1.58371680e-01,  1.89013776e+00,\n",
       "       -1.71892745e+00, -1.89829266e+00, -2.16770207e-01,  2.11043390e-01,\n",
       "        1.09262221e+00,  1.51371080e-01,  5.19778197e-01, -8.04898386e-01,\n",
       "       -1.39810568e+00,  9.76070317e-02,  7.34682678e-01,  7.17685463e-01,\n",
       "        1.22105118e+00, -2.55899158e-01, -7.54521635e-02, -6.02954216e-01,\n",
       "       -4.69657211e-01,  3.29775876e-01,  1.70392565e+00,  5.45783514e-01,\n",
       "        3.39951250e-01,  7.08605067e-01,  9.38545698e-01,  6.21638797e-01,\n",
       "        7.64200894e-01, -1.87004752e+00, -4.57638845e-01, -8.18961590e-01,\n",
       "        6.75597971e-02,  9.77102754e-01, -4.86431473e-01, -1.20474982e+00,\n",
       "        1.04789964e+00,  9.03561830e-01, -3.98153869e-01,  1.60186848e+00,\n",
       "       -2.21796009e+00, -5.45019359e-01, -6.12202157e-01, -1.85998705e-01,\n",
       "        2.21809668e+00, -6.14444882e-01, -2.76083681e-01,  3.12270090e-01,\n",
       "        1.12384687e+00, -3.19869583e-01, -7.45875148e-01,  1.21579121e-01,\n",
       "        7.01117664e-01, -1.23525748e+00,  1.06730964e-01, -2.25220003e-01,\n",
       "       -1.49646775e-01,  6.25924974e-01, -7.04648590e-01,  1.70565387e+00,\n",
       "        4.52059123e-01, -2.85872634e+00,  1.83687305e+00,  1.43031323e+00,\n",
       "       -1.14594307e-01, -1.18598230e-01,  3.71910737e-01,  1.03469856e+00,\n",
       "        1.24864659e+00, -1.12017272e+00,  5.10108755e-01,  1.07861309e+00,\n",
       "       -4.42685148e-01,  3.07721317e-01, -7.95300844e-01,  5.79797535e-01,\n",
       "        7.87141329e-01,  1.07251090e+00, -1.11362924e+00, -7.90023844e-01,\n",
       "       -2.41158639e+00,  5.28437753e-01, -1.82151892e+00,  1.91116001e+00,\n",
       "        6.27778586e-01, -9.89348108e-02, -2.03550128e-02,  2.16535967e+00,\n",
       "        5.06434644e-01,  7.19806034e-02, -8.64139301e-01,  1.51756841e+00,\n",
       "       -2.19362533e-01, -1.50561794e+00,  3.01180476e-01,  9.02408806e-01,\n",
       "       -3.05041215e-01, -1.97914289e+00,  7.63728602e-01,  1.09392035e+00,\n",
       "        3.22933587e-01, -1.37195815e+00,  6.06545985e-01, -6.36509336e-01,\n",
       "       -9.44356288e-01, -2.01532872e-01,  3.15393414e-01,  8.23919377e-01,\n",
       "        9.71334993e-01, -4.19374003e-01, -1.09050938e+00,  6.33568642e-01,\n",
       "       -2.78379175e-01,  1.45764149e+00, -9.74619880e-01, -7.62933049e-01,\n",
       "       -1.84257295e-01, -5.61740850e-01,  4.46699671e-01,  3.69433846e-01,\n",
       "       -1.11050261e+00, -7.87609617e-01,  5.98798268e-01, -6.25320901e-02,\n",
       "       -1.72459363e+00,  2.03216280e-01,  1.02454760e+00, -9.62528955e-01,\n",
       "        6.37438397e-01, -9.57370688e-01, -6.52518433e-01,  8.10437303e-01,\n",
       "       -3.54757145e-01, -6.56476182e-01,  7.82998102e-02,  4.34515739e-01,\n",
       "       -5.99306490e-01, -5.99602125e-02, -4.58747015e-01,  6.04658469e-01,\n",
       "       -2.14857295e-01,  1.63556212e+00, -1.53043963e+00, -7.37880494e-01,\n",
       "        1.32855289e+00,  2.01474751e+00, -1.60702089e-01,  5.03301426e-01,\n",
       "        9.35965122e-02, -1.22246735e+00,  6.98796444e-01,  5.21497180e-01,\n",
       "       -1.98986719e-01,  5.31777962e-01,  1.92383800e+00, -2.85861420e+00,\n",
       "        6.19533802e-01,  1.00915129e+00, -1.25983510e+00, -1.05866269e+00,\n",
       "        1.21560664e+00, -1.38170740e+00,  1.08873386e-03,  1.40388865e+00,\n",
       "       -2.04203813e+00,  8.64210586e-01,  4.22411622e-01,  3.37461166e-01,\n",
       "       -1.77841902e+00,  3.42929333e-02, -1.26065184e-01, -8.03321883e-01,\n",
       "       -1.11351710e+00, -6.78626387e-01,  9.69782896e-01,  9.12736553e-01,\n",
       "       -9.43162367e-01,  3.91496980e-01, -2.12193190e+00,  1.72226442e-01,\n",
       "       -9.37232339e-01,  1.15171603e+00, -1.78676868e-01, -1.78313534e+00,\n",
       "        5.11656895e-01, -1.07283803e+00, -3.82369045e-01,  4.00310105e-02,\n",
       "       -2.96795942e-03, -7.28269759e-01,  2.23286028e-01,  1.29440411e+00,\n",
       "        1.28497147e+00,  1.62441446e+00, -2.70429499e-02,  1.01324888e+00,\n",
       "        9.19376998e-01,  5.63294841e-01, -1.06223666e-01, -9.31935551e-01,\n",
       "        4.28660785e-02,  1.13900901e+00,  8.17859402e-01, -6.64087058e-02,\n",
       "       -1.23861497e+00,  5.89502465e-01, -4.30185255e-01,  8.25759730e-01,\n",
       "        6.44582597e-01, -1.36782893e-02, -3.11215304e-01, -7.20287102e-02,\n",
       "        1.35990486e+00,  2.25366366e+00,  8.74044934e-01,  5.07740702e-01,\n",
       "       -1.75306185e-01, -8.73934731e-01, -3.27851045e-01,  9.33544298e-02,\n",
       "        9.74685888e-01,  6.28869210e-01, -6.47610823e-01, -1.44303273e+00,\n",
       "        9.46684027e-02,  1.29936449e+00, -5.88145636e-01, -2.30243166e+00,\n",
       "        5.58415463e-01, -7.82015998e-01, -6.25487042e-03, -3.83734468e-01,\n",
       "       -1.75537053e-01, -1.20772473e+00,  1.04157186e+00,  4.74665129e-01,\n",
       "        3.22411823e-01,  3.03700903e-01, -1.80365508e-01, -1.58327439e-01,\n",
       "        2.89904847e-01, -4.44010994e-01,  4.69411217e-01, -1.72558307e+00,\n",
       "       -2.27825521e-01, -5.29623713e-01,  8.60211280e-01, -5.03588317e-01,\n",
       "        8.65444621e-02, -6.20683738e-02,  6.46244522e-01,  1.12387853e+00,\n",
       "       -4.77440785e-01, -4.39775006e-02, -2.12240023e+00, -1.76978453e+00,\n",
       "        1.09435702e+00,  1.72375397e+00, -7.06528521e-01, -7.31792156e-01,\n",
       "        1.90951214e-01, -5.83145679e-01, -1.12879282e-01,  1.07864739e+00,\n",
       "       -6.93533910e-01,  7.15705929e-01,  1.20983479e-01, -9.73617250e-01,\n",
       "        5.34372275e-02, -5.16055228e-01,  8.04831151e-01, -1.72250262e+00,\n",
       "       -3.67131709e-01, -2.84955636e-01, -6.38883985e-01, -1.27621899e-01,\n",
       "       -1.07798970e+00, -6.82023455e-01,  9.67906263e-01,  1.53988353e+00,\n",
       "        1.51444839e+00, -9.94309684e-01, -8.00960426e-01, -1.02707865e-01,\n",
       "        2.86287341e-02, -1.76348431e-03,  9.85262314e-01,  1.77558070e+00,\n",
       "       -1.90678203e+00, -5.35435008e-01,  1.01955819e+00, -1.56208843e+00,\n",
       "       -6.96871613e-01,  1.27338186e+00,  2.68701204e-01,  1.08705695e+00,\n",
       "       -1.01535172e+00, -3.43649062e-01,  1.20743916e+00,  6.71181906e-01,\n",
       "        2.73844959e-01,  3.67360645e-01, -6.46126667e-01,  8.57667107e-01,\n",
       "        1.26582916e+00,  5.46965628e-01,  3.44734190e-01, -1.86136686e+00,\n",
       "       -1.06833939e+00,  1.12281720e+00,  1.80886538e+00,  1.43795165e-02,\n",
       "        8.70304861e-01,  8.32487904e-01,  8.95859926e-02,  1.11372889e+00,\n",
       "        3.43131302e-01,  2.64224330e-01,  2.94601377e-01,  4.83090518e-01,\n",
       "        1.55748891e+00, -4.82843113e-01, -2.88016295e-01,  2.31377528e+00,\n",
       "       -2.74408353e+00, -2.51868850e-01, -1.15664338e+00, -5.30935171e-02,\n",
       "        8.36227318e-01,  9.01968053e-02,  4.49074980e-01,  1.93220860e-02,\n",
       "       -7.66699507e-01,  1.57585947e+00,  4.94292929e-01, -1.88722956e-01,\n",
       "        1.46504908e+00, -3.12118990e-01, -1.24941303e+00,  2.21778006e+00,\n",
       "        1.40413272e+00,  2.48609029e-01, -1.08535112e+00, -1.36291469e+00,\n",
       "        2.54348966e+00,  1.50946942e-01,  8.10327145e-01,  1.08413086e+00,\n",
       "        2.48743593e-01,  1.51595353e-01, -2.35325456e-01,  1.62495535e+00,\n",
       "        1.30129719e+00, -5.48350464e-01, -3.23411769e-01,  8.48934209e-02,\n",
       "        6.10730456e-02, -2.82108155e+00, -6.38923563e-01,  2.18611266e-01,\n",
       "        6.23883897e-01, -1.13077948e+00, -1.44396161e-01, -2.20305917e+00,\n",
       "       -1.45648248e+00,  5.03731502e-01,  1.57795048e+00,  2.84098169e-01,\n",
       "       -9.51697913e-01, -9.38617551e-01,  5.71556577e-01,  1.58568908e-01,\n",
       "        3.31609633e-01, -1.07950024e+00,  1.73709938e-01, -4.24974219e-01,\n",
       "        1.35882308e+00,  4.88974373e-01,  7.02337931e-03, -6.48124135e-02,\n",
       "       -2.65401834e+00,  1.54786499e+00, -7.93645185e-01, -5.83257815e-01,\n",
       "       -6.46013335e-02,  4.45573032e-01,  3.30423628e-01, -9.83465450e-01,\n",
       "        2.99896186e-01, -4.18081138e-01,  8.20652254e-01, -5.28198923e-01,\n",
       "        1.29683153e+00,  9.87044620e-01,  5.22106013e-01, -1.24794206e+00,\n",
       "        2.31149293e-02, -2.52666456e+00, -1.27153685e+00,  6.87430447e-01,\n",
       "        4.43900223e-01,  1.55227788e+00,  7.18782419e-01,  8.34062429e-01,\n",
       "       -1.42733366e+00, -1.66031858e-01, -1.38179975e+00, -7.90201943e-01,\n",
       "       -1.96795569e-02,  1.61471797e+00,  5.95730586e-02,  1.55852572e-01,\n",
       "       -2.85569087e-01,  5.48620825e-01, -1.76183486e-01, -1.73836660e+00,\n",
       "       -1.91368052e-01,  1.14219038e+00, -3.34262599e-01,  2.86770310e-01,\n",
       "        1.03044068e+00, -8.35030053e-01,  2.09799217e+00,  6.18568309e-01,\n",
       "        1.66904588e-01, -2.41341236e-01,  3.08006934e-01,  6.07439513e-01,\n",
       "        4.51297257e-01, -5.19683165e-01,  1.48208059e+00, -5.46173702e-01,\n",
       "       -9.83122445e-01,  6.14352053e-01,  2.48337144e+00, -2.01486698e-01,\n",
       "       -3.30574100e-02,  3.43090405e-01,  8.90734104e-01, -3.23649234e-01,\n",
       "        3.43570612e-01,  1.45180381e+00,  3.37048241e-01, -7.64351242e-01,\n",
       "       -4.51780180e-02, -1.66307041e+00, -3.90304333e-01, -6.22439536e-01,\n",
       "        1.54845205e+00, -1.40464835e-03,  8.51578109e-01, -6.11331452e-01,\n",
       "        2.07108607e+00, -2.38735717e-01, -2.62436041e-01,  5.53881333e-01,\n",
       "        1.86104950e-01,  7.02541135e-01, -4.84180956e-02,  1.40530145e-01,\n",
       "       -1.69013482e+00, -4.51022807e-01,  5.04394425e-01, -2.34512922e-02,\n",
       "       -3.12699460e-01, -4.99577798e-01, -3.70890375e-02, -2.70219615e-01,\n",
       "       -1.48780147e+00,  1.95388392e+00, -1.42097487e+00,  1.67620281e-01,\n",
       "       -1.88511876e-01,  4.02361539e-02, -7.27260533e-01,  1.84880027e-01,\n",
       "        4.42433877e-01,  1.08597702e-01, -1.70002800e-01, -7.39086803e-04,\n",
       "        1.13874780e+00,  1.78770461e+00, -1.35552689e+00, -1.98571156e-01,\n",
       "        3.98104443e-01, -6.69121192e-01, -6.41667603e-01,  2.15062484e-01,\n",
       "        7.68580144e-01, -1.37573780e+00, -9.69031661e-02,  1.15531824e+00,\n",
       "        3.92013467e-01, -1.18740828e+00,  7.87126158e-01, -7.59878985e-01,\n",
       "       -2.46235653e-01, -2.87210357e-02,  6.37158848e-01, -6.48717797e-02,\n",
       "        2.58774385e-02,  1.07081884e-01, -1.84634720e+00, -5.03495970e-01,\n",
       "       -1.67001507e-01,  3.62807254e-01, -1.35796750e+00, -1.07284463e+00,\n",
       "        1.33205550e+00, -5.23423239e-01, -8.20168703e-01, -1.20174853e+00,\n",
       "        5.59959126e-02, -1.09040265e-01, -9.20181034e-01,  2.39540506e-01,\n",
       "       -6.04867128e-01,  1.29519566e+00, -2.47337346e+00, -3.78760896e-01,\n",
       "        1.80916880e+00, -8.48506190e-01,  2.33853879e-01,  7.99640439e-02,\n",
       "       -2.34401982e-01, -1.67628270e+00, -1.06254788e+00,  5.24675789e-02,\n",
       "       -3.92527269e-01,  1.96884421e+00,  1.02731868e+00, -4.44894891e-01])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "train_pgs__ = ss.fit_transform(pd.read_csv(f\"./pgs_results_calculated/train_5_pgs.csv\").drop(columns=[\"FID\", \"IID\", \"y\"]).to_numpy())\n",
    "selector = SelectKBest(f_classif, k=19)\n",
    "train_pgs_ = selector.fit_transform(train_pgs, y_train)\n",
    "train_pgs_[:, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pgs__[0, 32] == train_pgs_[0, 9] #1 5 16 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PGS001780'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f\"./pgs_results_calculated/train_5_pgs.csv\").drop(columns=[\"FID\", \"IID\", \"y\"]).columns[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PGS003725</th>\n",
       "      <th>PGS000748</th>\n",
       "      <th>PGS000012</th>\n",
       "      <th>PGS003446</th>\n",
       "      <th>PGS004513</th>\n",
       "      <th>PGS000013</th>\n",
       "      <th>PGS005143</th>\n",
       "      <th>PGS003726</th>\n",
       "      <th>PGS002809</th>\n",
       "      <th>PGS000011</th>\n",
       "      <th>...</th>\n",
       "      <th>PGS004308</th>\n",
       "      <th>PGS000018</th>\n",
       "      <th>PGS004444</th>\n",
       "      <th>PGS000019</th>\n",
       "      <th>PGS000747</th>\n",
       "      <th>PGS000746</th>\n",
       "      <th>PGS004697</th>\n",
       "      <th>PGS004696</th>\n",
       "      <th>PGS004443</th>\n",
       "      <th>PGS000962</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>8.005584e-09</td>\n",
       "      <td>9.084808e-07</td>\n",
       "      <td>1.777764e-07</td>\n",
       "      <td>-6.012615e-07</td>\n",
       "      <td>0.026568</td>\n",
       "      <td>0.041486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-3.944674e-08</td>\n",
       "      <td>0.022992</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>-0.000962</td>\n",
       "      <td>7.630964e-08</td>\n",
       "      <td>-2.029301e-08</td>\n",
       "      <td>2.850699e-08</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-8.889825e-09</td>\n",
       "      <td>1.526839e-06</td>\n",
       "      <td>2.798525e-07</td>\n",
       "      <td>-1.002872e-06</td>\n",
       "      <td>0.039137</td>\n",
       "      <td>0.073953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>5.712632e-08</td>\n",
       "      <td>0.038436</td>\n",
       "      <td>-0.000372</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>2.776674e-08</td>\n",
       "      <td>-6.342878e-08</td>\n",
       "      <td>-1.692316e-07</td>\n",
       "      <td>0.000606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>-0.007964</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>-4.133983e-08</td>\n",
       "      <td>-1.360237e-06</td>\n",
       "      <td>-1.692639e-07</td>\n",
       "      <td>1.144774e-06</td>\n",
       "      <td>-0.039746</td>\n",
       "      <td>-0.056334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-1.123947e-07</td>\n",
       "      <td>-0.046830</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-0.001193</td>\n",
       "      <td>2.669667e-07</td>\n",
       "      <td>1.852695e-07</td>\n",
       "      <td>-1.090594e-07</td>\n",
       "      <td>-0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>0.023911</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>5.693390e-08</td>\n",
       "      <td>4.288501e-06</td>\n",
       "      <td>-4.875607e-07</td>\n",
       "      <td>-3.947093e-06</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>0.182713</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>7.797006e-07</td>\n",
       "      <td>0.113245</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>-1.983756e-07</td>\n",
       "      <td>-3.924250e-07</td>\n",
       "      <td>-1.108812e-07</td>\n",
       "      <td>0.000647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PGS003725  PGS000748  PGS000012  PGS003446     PGS004513     PGS000013  \\\n",
       "0  -0.000002  -0.000052   0.005138   0.000084  8.005584e-09  9.084808e-07   \n",
       "1  -0.000002  -0.000105   0.008560   0.000115 -8.889825e-09  1.526839e-06   \n",
       "2   0.000002   0.000114  -0.007964  -0.000145 -4.133983e-08 -1.360237e-06   \n",
       "3  -0.000009  -0.000283   0.023911   0.000436  5.693390e-08  4.288501e-06   \n",
       "\n",
       "      PGS005143     PGS003726  PGS002809  PGS000011  ...  PGS004308  \\\n",
       "0  1.777764e-07 -6.012615e-07   0.026568   0.041486  ...  -0.000346   \n",
       "1  2.798525e-07 -1.002872e-06   0.039137   0.073953  ...  -0.000167   \n",
       "2 -1.692639e-07  1.144774e-06  -0.039746  -0.056334  ...   0.000380   \n",
       "3 -4.875607e-07 -3.947093e-06   0.115361   0.182713  ...  -0.000510   \n",
       "\n",
       "   PGS000018     PGS004444  PGS000019  PGS000747  PGS000746     PGS004697  \\\n",
       "0   0.000020 -3.944674e-08   0.022992  -0.000179  -0.000962  7.630964e-08   \n",
       "1   0.000034  5.712632e-08   0.038436  -0.000372   0.001653  2.776674e-08   \n",
       "2  -0.000033 -1.123947e-07  -0.046830   0.000345  -0.001193  2.669667e-07   \n",
       "3   0.000097  7.797006e-07   0.113245  -0.000953   0.002220 -1.983756e-07   \n",
       "\n",
       "      PGS004696     PGS004443  PGS000962  \n",
       "0 -2.029301e-08  2.850699e-08   0.000128  \n",
       "1 -6.342878e-08 -1.692316e-07   0.000606  \n",
       "2  1.852695e-07 -1.090594e-07  -0.000284  \n",
       "3 -3.924250e-07 -1.108812e-07   0.000647  \n",
       "\n",
       "[4 rows x 73 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.read_csv(f\"./pgs_results_calculated/train_5_pgs.csv\").drop(columns=[\"FID\", \"IID\", \"y\"]).iloc[0:4, :] / np.array([[1.20057576e+00],  [7.29952508e-01], [-7.83539731e-01], [2.58283748e-01]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating feature importance using gradients...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABEQAAAMWCAYAAAD4ZFNRAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAA40NJREFUeJzs3XdUFNffBvBnWXrvRVQQEGkqdsWuKHaNXWMssXej0URjjSYmJjEaS4yxt2isSey9Y0UsFBUEVJTeO+zO+8csCyug+JO8Bvf5nMMRZmefvTOzu+7e+d47EkEQBBARERERERERqRGN990AIiIiIiIiIqL/b+wQISIiIiIiIiK1ww4RIiIiIiIiIlI77BAhIiIiIiIiIrXDDhEiIiIiIiIiUjvsECEiIiIiIiIitcMOESIiIiIiIiJSO+wQISIiIiIiIiK1ww4RIiIiIiIiIlI77BAhInqD4cOHw9DQsFzrSiQSLFy48N9tUBnatGmDNm3avJfHJqpoEyZMQIcOHd53M0p49XUWGRkJiUSCLVu2vLc2VVZbtmyBRCLBrVu3/vXHevW4BQcHQ1NTEw8ePPjXH5uIiP672CFCRP854eHhGDt2LJycnKCrqwtjY2M0b94cK1euRHZ29vtuXqXn6OgIiURS6k9OTs6/8pjffvstDh069K9kvytHR0d069btfTfjfxYcHIyFCxciMjLyfTelwkRERGDDhg2YM2fO+27Kf8batWsrbafLf7HtHh4e6Nq1K+bPn/++m0JERO+R5vtuABFRcUeOHEG/fv2go6ODoUOHwsvLC3l5ebh8+TJmzpyJoKAgrF+//n03s0zZ2dnQ1Pzvv7V6e3tjxowZJZZra2v/K4/37bffom/fvujVq9e/kq/OgoODsWjRIrRp0waOjo7vuzkVYuXKlahRowbatm37vpvyRg4ODsjOzoaWlta/+jhr166FpaUlhg8f/q8+zr/hv9r2cePGoUuXLggPD4ezs/P7bg4REb0H//1P7USkNiIiIjBw4EA4ODjg7NmzsLOzU942ceJEhIWF4ciRI++xhW+mq6v7vptQLvb29hgyZMj7bsY7kcvlyMvLqzT7vKLl5OT8ax1Y71N+fj527tyJcePGVWhuVlYW9PX1KzQTEIfJqetzsLLz9fWFmZkZtm7diq+//vp9N4eIiN4DDpkhov+MZcuWISMjAxs3blTpDCnk4uKCqVOnKv8uKCjA4sWL4ezsDB0dHTg6OmLOnDnIzc1VuV/hkIjz58+jYcOG0NPTQ+3atXH+/HkAwIEDB1C7dm3o6uqiQYMGuHPnTqnte/LkCfz8/GBgYIAqVarg66+/hiAIKuu8OofIwoULIZFIEBYWhuHDh8PU1BQmJiYYMWIEsrKySjzGjh070KBBA+jp6cHc3BwDBw7Es2fPSqy3fv16ODs7Q09PD40bN8alS5fK3K//i5SUFEybNg3VqlWDjo4OXFxc8P3330Mul6us9+OPP8LHxwcWFhbQ09NDgwYNsG/fPpV1JBIJMjMzsXXrVuXQnMIzxcOHDy+1qqFwv72aM2nSJOzcuROenp7Q0dHB8ePHAQDR0dH49NNPYWNjAx0dHXh6emLTpk3/07YXzgnx448/Ys2aNXBycoK+vj46duyIZ8+eQRAELF68GFWrVoWenh569uyJpKQklYzC59zJkyfh7e0NXV1deHh44MCBAyUe78mTJ+jXrx/Mzc2hr6+Ppk2bluj4O3/+PCQSCXbv3o25c+fC3t4e+vr6+OWXX9CvXz8AQNu2bZX7t/C5/ddff6Fr166oUqUKdHR04OzsjMWLF0Mmk6nkt2nTBl5eXggODkbbtm2hr68Pe3t7LFu2rER7c3JysHDhQri6ukJXVxd2dnbo3bs3wsPDlevI5XKsWLECnp6e0NXVhY2NDcaOHYvk5OQ37v/Lly8jISEBvr6+JW6LiopCjx49YGBgAGtra3z22Wc4ceKEyjYX357bt2+jVatW0NfXVw6/Ke8+Acr3OitrDpHQ0FD07dsX5ubm0NXVRcOGDfH333+rrFM4h8aVK1cwffp0WFlZwcDAAB999BHi4+OV6zk6OiIoKAgXLlxQHuPC+TDy8/OxaNEi1KxZE7q6urCwsECLFi1w6tSp1+7nwse+fPkypkyZAisrK5iammLs2LHIy8tDSkoKhg4dCjMzM5iZmWHWrFkl3u/Kc5xf1/ZCubm5r93+QmvXrlW+9qtUqYKJEyciJSWlxHrlfX/U0tJCmzZt8Ndff712XxER0YeLFSJE9J/xzz//wMnJCT4+PuVaf9SoUdi6dSv69u2LGTNm4Pr161i6dClCQkJw8OBBlXXDwsIwePBgjB07FkOGDMGPP/6I7t27Y926dZgzZw4mTJgAAFi6dCn69++Phw8fQkOjqM9YJpOhU6dOaNq0KZYtW4bjx49jwYIFKCgoKNeZxf79+6NGjRpYunQpAgICsGHDBlhbW+P7779XrvPNN99g3rx56N+/P0aNGoX4+HisWrUKrVq1wp07d2BqagoA2LhxI8aOHQsfHx9MmzYNT548QY8ePWBubo5q1aqVa9/l5+cjISFBZZm+vj709fWRlZWF1q1bIzo6GmPHjkX16tVx9epVzJ49Gy9fvsSKFSuU91m5ciV69OiBjz/+GHl5edi9ezf69euHw4cPo2vXrgCA7du3Y9SoUWjcuDHGjBkDAP9zefrZs2fx559/YtKkSbC0tISjoyNiY2PRtGlTZYeJlZUVjh07hpEjRyItLQ3Tpk37nx5r586dyMvLw+TJk5GUlIRly5ahf//+aNeuHc6fP48vvvgCYWFhWLVqFT7//PMSHTCPHz/GgAEDMG7cOAwbNgybN29Gv379cPz4ceVkobGxsfDx8UFWVhamTJkCCwsLbN26FT169MC+ffvw0UcfqWQuXrwY2tra+Pzzz5Gbm4uOHTtiypQp+OWXXzBnzhy4u7sDgPLfLVu2wNDQENOnT4ehoSHOnj2L+fPnIy0tDT/88INKdnJyMjp16oTevXujf//+2LdvH7744gvUrl0bnTt3BiC+Drp164YzZ85g4MCBmDp1KtLT03Hq1Ck8ePBAeVzHjh2LLVu2YMSIEZgyZQoiIiKwevVq3LlzB1euXHnt8JKrV69CIpGgXr16KsszMzPRrl07vHz5ElOnToWtrS127dqFc+fOlZqTmJiIzp07Y+DAgRgyZAhsbGzeap+8y+ssKCgIzZs3h729Pb788ksYGBjgzz//RK9evbB///4Sx3Xy5MkwMzPDggULEBkZiRUrVmDSpEnYs2cPAGDFihWYPHkyDA0N8dVXXwGAcnsWLlyIpUuXKl9jaWlpuHXrFgICAso1Ke3kyZNha2uLRYsW4dq1a1i/fj1MTU1x9epVVK9eHd9++y2OHj2KH374AV5eXhg6dKjyvuU5zq9re3m3v3A7Fy1aBF9fX4wfPx4PHz7Er7/+ips3b6o8p972uDVo0AB//fUX0tLSYGxs/Mb9RUREHxiBiOg/IDU1VQAg9OzZs1zrBwYGCgCEUaNGqSz//PPPBQDC2bNnlcscHBwEAMLVq1eVy06cOCEAEPT09ISoqCjl8t9++00AIJw7d065bNiwYQIAYfLkycplcrlc6Nq1q6CtrS3Ex8crlwMQFixYoPx7wYIFAgDh008/VWnnRx99JFhYWCj/joyMFKRSqfDNN9+orHf//n1BU1NTuTwvL0+wtrYWvL29hdzcXOV669evFwAIrVu3ft1uU9kfr/4Utnvx4sWCgYGB8OjRI5X7ffnll4JUKhWePn2qXJaVlaWyTl5enuDl5SW0a9dOZbmBgYEwbNiwEm0ZNmyY4ODgUGJ54X4rDoCgoaEhBAUFqSwfOXKkYGdnJyQkJKgsHzhwoGBiYlKija9ycHAQunbtqvw7IiJCACBYWVkJKSkpyuWzZ88WAAh169YV8vPzlcsHDRokaGtrCzk5OSqZAIT9+/crl6Wmpgp2dnZCvXr1lMumTZsmABAuXbqkXJaeni7UqFFDcHR0FGQymSAIgnDu3DkBgODk5FRie/bu3VviOVuotG0fO3asoK+vr9Le1q1bCwCEbdu2KZfl5uYKtra2Qp8+fZTLNm3aJAAQli9fXiJXLpcLgiAIly5dEgAIO3fuVLn9+PHjpS5/1ZAhQ1ReG4V++uknAYBw6NAh5bLs7GzBzc2txPYXbs+6detK5JRnn7zN66zw+bJ582blsvbt2wu1a9dW2cdyuVzw8fERatasqVy2efNmAYDg6+ur3H+CIAifffaZIJVKVZ5/np6epb6+69atq/L8La/Cx/bz81N57GbNmgkSiUQYN26ccllBQYFQtWpVlcd/m+NcVtvLu/1xcXGCtra20LFjR+VrQhAEYfXq1QIAYdOmTYIg/G/vj7t27RIACNevX3/DHiMiog8Rh8wQ0X9CWloaAMDIyKhc6x89ehQAMH36dJXlhROFvjrkwMPDA82aNVP+3aRJEwBAu3btUL169RLLnzx5UuIxJ02apPy9sBohLy8Pp0+ffmN7X50PoWXLlkhMTFRu94EDByCXy9G/f38kJCQof2xtbVGzZk3lWfBbt24hLi4O48aNU5k/Yvjw4TAxMXljO4pv56lTp1R+Cs/87t27Fy1btoSZmZlKW3x9fSGTyXDx4kVljp6envL35ORkpKamomXLlggICCh3W95G69at4eHhofxbEATs378f3bt3hyAIKu318/NDamrq/9yWfv36qezTwufGkCFDVCbObdKkCfLy8hAdHa1y/ypVqqhUAhgbG2Po0KG4c+cOYmJiAIjP48aNG6NFixbK9QwNDTFmzBhERkYiODhYJXPYsGEq+/xNiq+bnp6OhIQEtGzZEllZWQgNDVVZ19DQUGVeGW1tbTRu3FjltbB//35YWlpi8uTJJR6rcIjT3r17YWJigg4dOqgcjwYNGsDQ0LDMio5CiYmJMDMzK7H8+PHjsLe3R48ePZTLdHV1MXr06FJzdHR0MGLEiBLLy7NP3uV1lpSUhLNnz6J///7K/ISEBCQmJsLPzw+PHz8u8VwZM2aMyhCxli1bQiaTISoq6rWPBQCmpqYICgrC48eP37huaUaOHKny2E2aNIEgCBg5cqRymVQqRcOGDVWeC+96nIt70/afPn0aeXl5mDZtmkrl3ujRo2FsbKx8v/9fjlvhc+3VijkiIlIPHDJDRP8JhaXK6enp5Vo/KioKGhoacHFxUVlua2sLU1PTEl8kind6AFB+OH61hLpw+atzHWhoaMDJyUllmaurKwCU63Knrz5+4Yfw5ORkGBsb4/HjxxAEATVr1iz1/oXl4IXb9ep6WlpaJdr3OpaWlqXO0QCIQz3u3bsHKyurUm+Pi4tT/n748GEsWbIEgYGBKnO3vDr/R0WpUaOGyt/x8fFISUnB+vXry7z6UPH2vo13fc64uLiU2A/FnzO2traIiopSdrQUVzjkJSoqCl5eXsrlr27/mwQFBWHu3Lk4e/assvOtUGpqqsrfVatWLdFeMzMz3Lt3T/l3eHg4atWq9dorKT1+/BipqamwtrYu9fbyHA/hlbkqAHFfODs7l2jjq+8Bhezt7UuddLY8++RdXmdhYWEQBAHz5s3DvHnzSl0nLi4O9vb2yr9f9/7wJl9//TV69uwJV1dXeHl5oVOnTvjkk09Qp06dN963tMd+3fO8eHsq4jiX1YZXt7/weNSqVUtlPW1tbTg5OSlv/1+OW+Fz7d96zyIiov82dogQ0X+CsbExqlSpggcPHrzV/cr7IVYqlb7V8tK+kL2LNz2OXC6HRCLBsWPHSl3X0NCwQtvzOnK5HB06dMCsWbNKvb3wS/2lS5fQo0cPtGrVCmvXroWdnR20tLSwefNm7Nq1q1yPVdbxK22CSwAlqiMKJ3kdMmQIhg0bVup9yvvF8FXv+zlTmrepDklJSUHr1q1hbGyMr7/+Gs7OztDV1UVAQAC++OKLEhPkVtR2yeVyWFtbY+fOnaXeXlZHWyELC4tydQS8SWn76m33yf+iMOPzzz+Hn59fqeu82onzLvu+VatWCA8Px19//YWTJ09iw4YN+Pnnn7Fu3TqMGjXqjfd/m+d58fa863EuTxv+P15Thc81S0vLf/2xiIjov4cdIkT0n9GtWzesX78e/v7+KsNbSuPg4AC5XI7Hjx8rz6YD4iSVKSkpcHBwqNC2yeVyPHnyRNkZAACPHj0CgFKvkvK2nJ2dIQgCatSoofIYryrcrsePH6Ndu3bK5fn5+YiIiEDdunUrpC0ZGRllVpAU2r9/P3R1dXHixAno6Ogol2/evLnEumV1fJiZmZV6lYjyDBUAxC9dRkZGkMlkb2zv/7fCSoHi2/7qc8bBwQEPHz4scd/CoRvleR6XtW/Pnz+PxMREHDhwAK1atVIuj4iIKPc2vMrZ2RnXr19Hfn5+mROjOjs74/Tp02jevPlbdeAUcnNzw86dO5GamqoyzMHBwQHBwcEl9mlYWFi5s8u7T97ldVZYiaClpVWhz8nXdf6am5tjxIgRGDFiBDIyMtCqVSssXLiwXB0i/6u3Oc7vWn1ReDwePnyoUumRl5eHiIgI5X7+X45bREQENDQ0Xvu+S0REHy7OIUJE/xmzZs2CgYEBRo0ahdjY2BK3h4eHY+XKlQCALl26AIDKFU8AYPny5QCgvMJJRVq9erXyd0EQsHr1amhpaaF9+/bvnN27d29IpVIsWrSoxFlRQRCQmJgIAGjYsCGsrKywbt065OXlKdfZsmVLqR0L/4v+/fvD398fJ06cKHFbSkoKCgoKAIhndSUSiUo1R2RkJA4dOlTifgYGBqW2z9nZGampqSrDMl6+fFniKkFlkUql6NOnD/bv319qdVFpl+78//LixQuV7UhLS8O2bdvg7e0NW1tbAOLz+MaNG/D391eul5mZifXr18PR0VFlvpSyGBgYAECJ/Vt41r348ykvLw9r1679n7epT58+SEhIUHktFCp8nP79+0Mmk2Hx4sUl1ikoKHjj87RZs2YQBAG3b99WWe7n54fo6GiVS9fm5OTg999/L3f7y7tP3uV1Zm1tjTZt2uC3337Dy5cvS9z+vz4ny3oNFb43FDI0NISLi0uJy49XtLc5zmW1vbx8fX2hra2NX375ReXYbdy4Eampqcr3+//luN2+fRuenp5vNQcTERF9OFghQkT/Gc7Ozti1axcGDBgAd3d3DB06FF5eXsjLy8PVq1exd+9eDB8+HABQt25dDBs2DOvXr1eWwd+4cQNbt25Fr1690LZt2wptm66uLo4fP45hw4ahSZMmOHbsGI4cOYI5c+a8VWl4WZydnbFkyRLMnj0bkZGR6NWrF4yMjBAREYGDBw9izJgx+Pzzz6GlpYUlS5Zg7NixaNeuHQYMGICIiAhs3rz5reYQeZ2ZM2fi77//Rrdu3TB8+HA0aNAAmZmZuH//Pvbt24fIyEhYWlqia9euWL58OTp16oTBgwcjLi4Oa9asgYuLi0oHByBe2vL06dNYvnw5qlSpgho1aqBJkyYYOHAgvvjiC3z00UeYMmUKsrKy8Ouvv8LV1bXck6F+9913OHfuHJo0aYLRo0fDw8MDSUlJCAgIwOnTp5GUlFQh++Vtubq6YuTIkbh58yZsbGywadMmxMbGqlTQfPnll/jjjz/QuXNnTJkyBebm5ti6dSsiIiKwf/9+lQkky+Lt7Q2pVIrvv/8eqamp0NHRQbt27eDj4wMzMzMMGzYMU6ZMgUQiwfbt299pGMLQoUOxbds2TJ8+HTdu3EDLli2RmZmJ06dPY8KECejZsydat26NsWPHYunSpQgMDETHjh2hpaWFx48fY+/evVi5ciX69u1b5mO0aNECFhYWOH36tMpZ/rFjx2L16tUYNGgQpk6dCjs7O+zcuRO6uroAyleFUN598q6vszVr1qBFixaoXbs2Ro8eDScnJ8TGxsLf3x/Pnz/H3bt335jxqgYNGuDXX3/FkiVL4OLiAmtra7Rr1w4eHh5o06YNGjRoAHNzc9y6dQv79u1TmQT63/A2x7mstpeXlZUVZs+ejUWLFqFTp07o0aMHHj58iLVr16JRo0bKyYDf9rjl5+fjwoULysuuExGRGvp/upoNEVG5PXr0SBg9erTg6OgoaGtrC0ZGRkLz5s2FVatWqVzGMj8/X1i0aJFQo0YNQUtLS6hWrZowe/ZslXUEoeRlVQsBECZOnKiyrPASmj/88INy2bBhwwQDAwMhPDxc6Nixo6Cvry/Y2NgICxYsULkEZGFmaZfdLX5pXkEoutxkRESEyvL9+/cLLVq0EAwMDAQDAwPBzc1NmDhxovDw4UOV9dauXSvUqFFD0NHRERo2bChcvHhRaN26dbkvu/umy3Smp6cLs2fPFlxcXARtbW3B0tJS8PHxEX788UchLy9Pud7GjRuFmjVrCjo6OoKbm5uwefPmUi+ZGxoaKrRq1UrQ09MTAKhcgvfkyZOCl5eXoK2tLdSqVUvYsWNHmZfdffV4FYqNjRUmTpwoVKtWTdDS0hJsbW2F9u3bC+vXr3/r/VHac0AQii59u3fvXpXlhcfy5s2bJTJPnDgh1KlTR7l/Xr2vIAhCeHi40LdvX8HU1FTQ1dUVGjduLBw+fLhcj13o999/F5ycnASpVKpyCdorV64ITZs2FfT09IQqVaoIs2bNUl5y+tXL1Hp6epbILe2yyFlZWcJXX32lfN3Z2toKffv2FcLDw1XWW79+vdCgQQNBT09PMDIyEmrXri3MmjVLePHiRanbUNyUKVMEFxeXEsufPHkidO3aVdDT0xOsrKyEGTNmCPv37xcACNeuXXvj9rzNPhGE8r3OSrvsriCIx3Xo0KGCra2toKWlJdjb2wvdunUT9u3bp1yntOeOIBQd7+LtiYmJEbp27SoYGRmpXEJ2yZIlQuPGjQVTU1NBT09PcHNzE7755huV12lpynrsst6zCt8HX1We41xW299m+wVBvMyum5uboKWlJdjY2Ajjx48XkpOTS7SpvO+Px44dEwAIjx8/fu2+IiKiD5dEEP4fZqwiIiJSI46OjvDy8sLhw4ffd1MqpSdPnsDNzQ3Hjh1745C0FStW4LPPPsPz589VrtxC9Ca9evWCRCIp9xA9IiL68LBDhIiIqIKxQ+TdjR8/HmFhYTh16pRyWXZ2tsoEnjk5OahXrx5kMplywlqi8ggJCUHt2rURGBiocmlrIiJSL5xDhIiIiP5zfv311xLLevfujerVq8Pb2xupqanYsWMHQkNDy7z0K1FZ3N3dlRNEExGR+mKHCBEREVUKfn5+2LBhA3bu3AmZTAYPDw/s3r0bAwYMeN9NIyIiokqIQ2aIiIiIiIiISO28+Xp+REREREREREQfGHaIEBEREREREZHaYYcIEREREREREakdTqpKREREREREVEnIY1zfdxOgYfthXO7+g+gQqYgnhIbtI4y4OeKdczY32ozmp75455wrHb6H+/yf3zkn5OvPUHvGu+fc/+kz1B/37jkB6z5D6y7L3jkHAC4cnYU2nb5/55zzx7+osJy2fu+ec+7EF/Bt9c0755y++BU6+Cx555xTV+fCr9Gid845cXMB/BoufPecWwvhV2/Bu+fcWYROdee9c87xu4vRyfOrd88J+gadPea8cw4AHAv+Fp3dZ797TshSdHaZ+e45YT+gs+Nn754T+TM6V53y7jnPf0Fn+8nvnhO9Cp3tJr57zss16Gw74d1zYtZ+uDk24989J/bXCskpzOpkOeadc44nrK+4HPPR756T9Ds6mY1695zkDehk8um756Ruqrgc43f/jHc8bTP89D5555wT2dsrLkf343fPydlZITkVmVWROR21Br5zzsn83eggfferWZ2S7am4HI1+754j3/vB5hCVF4fMEBEREREREZHa+SAqRIiIiIiIiIjUgRzy992ED6ay4kPZDiIiIiIiIiKicmOHCBERERERERGpHQ6ZISIiIiIiIqokZML7HzLzoXQksEKEiIiIiIiIiNTOh9KxQ0RERERERPTBk0N43034YLBChIiIiIiIiIjUDjtEiIiIiIiIiEjtcMgMERERERERUSUhx/ufVPVDwQoRIiIiIiIiIlI7rBAhIiIiIiIiqiRkAidVrSisECEiIiIiIiIitcMOESIiIiIiIiJSOxwyQ0RERERERFRJyMEhMxWFFSJEREREREREpHbYIUJEREREREREaodDZoiIiIiIiIgqCRmHzFQYVogQERERERERkdphhQgRERERERFRJcFJVSsOK0SIiIiIiIiISO2wQ4SIiIiIiIiI1A6HzBARERERERFVEjKBQ2YqCitEiIiIiIiIiEjtsEOEiIiIiIiIiNQOh8wQERERERERVRLy992ADwgrRIiIiIiIiIjoX7VmzRo4OjpCV1cXTZo0wY0bN167/t69e+Hm5gZdXV3Url0bR48eVbl9+PDhkEgkKj+dOnV6qzaxQ4SIiIiIiIiokpBBeO8/b2vPnj2YPn06FixYgICAANStWxd+fn6Ii4srdf2rV69i0KBBGDlyJO7cuYNevXqhV69eePDggcp6nTp1wsuXL5U/f/zxx1u1ix0iRERERERERPSvWb58OUaPHo0RI0bAw8MD69atg76+PjZt2lTq+itXrkSnTp0wc+ZMuLu7Y/Hixahfvz5Wr16tsp6Ojg5sbW2VP2ZmZm/VLnaIEBEREREREdG/Ii8vD7dv34avr69ymYaGBnx9feHv71/qffz9/VXWBwA/P78S658/fx7W1taoVasWxo8fj8TExLdqGydVJSIiIiIiIqokZG8/YqXC5ebmIjc3V2WZjo4OdHR0SqybkJAAmUwGGxsbleU2NjYIDQ0tNT8mJqbU9WNiYpR/d+rUCb1790aNGjUQHh6OOXPmoHPnzvD394dUKi3XdrBChIiIiIiIiIjKbenSpTAxMVH5Wbp06f9rGwYOHIgePXqgdu3a6NWrFw4fPoybN2/i/Pnz5c5ghQgRERERERFRJfFfuOzu7NmzMX36dJVlpVWHAIClpSWkUiliY2NVlsfGxsLW1rbU+9ja2r7V+gDg5OQES0tLhIWFoX379uXZDFaIEBEREREREVH56ejowNjYWOWnrA4RbW1tNGjQAGfOnFEuk8vlOHPmDJo1a1bqfZo1a6ayPgCcOnWqzPUB4Pnz50hMTISdnV25t4MdIkRERERERET0r5k+fTp+//13bN26FSEhIRg/fjwyMzMxYsQIAMDQoUMxe/Zs5fpTp07F8ePH8dNPPyE0NBQLFy7ErVu3MGnSJABARkYGZs6ciWvXriEyMhJnzpxBz5494eLiAj8/v3K3i0NmiIiIiIiIiCoJGSTvuwlvbcCAAYiPj8f8+fMRExMDb29vHD9+XDlx6tOnT6GhUVSv4ePjg127dmHu3LmYM2cOatasiUOHDsHLywsAIJVKce/ePWzduhUpKSmoUqUKOnbsiMWLF5dZqVIadogQERERERER0b9q0qRJygqPV5U2EWq/fv3Qr1+/UtfX09PDiRMn3rlNHDJDRERERERERGqHFSJERERERERElYRceN8t+HCwQoSIiIiIiIiI1A4rRIiIiIiIiIgqico4qep/FStEiIiIiIiIiEjtsEOEiIiIiIiIiNQOh8wQERERERERVRIcMlNxWCFCRERERERERGqHHSJEREREREREpHY4ZIaIiIiIiIiokpALHDJTUVghQkRERERERERqhxUiRERERERERJUEJ1WtOKwQISIiIiIiIiK1ww4RIiIiIiIiIlI7HDJDREREREREVEnIWNdQYbgniYiIiIiIiEjtsEKEiIiIiIiIqJLgZXcrDitEiIiIiIiIiEjtsEOEiIiIiIiIiNQOh8wQERERERERVRIycMhMRWGFCBERERERERGpHXaIEBEREREREZHa4ZAZIiIiIiIiokpCJrCuoaJwTxIRERERERGR2mGFCBEREREREVElIWddQ4XhniQiIiIiIiIitcMOESIiIiIiIiJSOxwyQ0RERERERFRJyCB53034YLBChIiIiIiIiIjUDjtEiIiIiIiIiEjtcMgMERERERERUSUhE1jXUFG4J4mIiIiIiIhI7bBChIiIiIiIiKiSkHNS1QrDChEiIiIiIiIiUjvsECEiIiIiIiIitcMhM0RERERERESVhIx1DRWGe5KIiIiIiIiI1A4rRIiIiIiIiIgqCV52t+JwTxIRERERERGR2mGHCBERERERERGpHQ6ZISIiIiIiIqok5KxrqDDck0RERERERESkdtghQkRERERERERqh0NmiIiIiIiIiCoJmSB53034YLBChIiIiIiIiIjUDitEiIiIiIiIiCoJGesaKgz3JBERERERERGpHXaIEBEREREREZHa4ZAZIiIiIiIiokpCLrCuoaJwTxIRERERERGR2mGFCBEREREREVElwUlVKw73JBERERERERGpHXaIEBEREREREZHa4ZAZIiIiIiIiokpCJkjedxM+GKwQISIiIiIiIiK1ww4RIiIiIiIiIlI7HDJDREREREREVEnIWddQYbgniYiIiIiIiEjtsEKEiIiIiIiIqJKQCaxrqCjck0RERERERESkdtghQkRERERERERqh0NmiIiIiIiIiCoJOSTvuwkfDFaIEBEREREREZHaYYcIEREREREREakdDpkhIiIiIiIiqiR4lZmKwz1JRERERERERGqHFSJERERERERElYSMdQ0VhnuSiIiIiIiIiNQOO0SIiIiIiIiISO1wyAwRERERERFRJSEXJO+7CR8MVogQERERERERkdphhQgRERERERFRJcFJVSsO9yQRERERERERqR12iBARERERERGR2uGQGSIiIiIiIqJKQi6wrqGicE8SERERERERkdphhwgRERERERERqR0OmSEiIiIiIiKqJGSQvO8mfDBYIUJEREREREREaocVIkRERERERESVBCdVrTjck0RERERERESkdtghQkRERERERERqh0NmiIiIiIiIiCoJTqpacVghQkRERERERERqhx0iRERERERERKR2OGSGiIiIiIiIqJLgVWYqDvckEREREREREakdVogQERERERERVRIyVohUGO5JIiIiIiIiIlI77BAhIiIiIiIiIrXDITNERERERERElYQckvfdhA8GK0SIiIiIiIiISO2wQoSIiIiIiIiokuCkqhWHe5KIiIiIiIiI1A47RIiIiIiIiIhI7XDIDBEREREREVElIRc4qWpFYYUIEREREREREakddogQERERERERkdrhkBkiIiIiIiKiSkLGuoYKwz1JRERERERERGqHFSJERERERERElQQnVa04rBAhIiIiIiIiIrXDDhEiIiIiIiIiUjscMkNERERERERUSchZ11BhuCeJiIiIiIiISO2wQ4SIiIiIiIiI1A6HzBARERERERFVEjJeZabCsEKEiIiIiIiIiNQOK0SIiIiIiIiIKgk5K0QqDCtEiIiIiIiIiEjtsEOEiIiIiIiIiNQOh8wQERERERERVRJygXUNFYV7koiIiIiIiIjUDitEiIiIiIiIiCoJGTipakVhhQgRERERERERqR12iBARERERERGR2uGQGSIiIiIiIqJKQi5wyExFYYUIEREREREREakddogQERERERERkdrhkBkiIiIiIiKiSkIusK6honBPEhEREREREZHaYYUIERERERERUSUhBydVrSisECEiIiIiIiIitcMOESIiIiIiIiJSOxwyQ0RERERERFRJyAQOmakorBAhIiIiIiIiIrXDDhEiIiIiIiIiUjscMkNERERERERUScgF1jVUFO5JIiIiIiIiIvpXrVmzBo6OjtDV1UWTJk1w48aN166/d+9euLm5QVdXF7Vr18bRo0fLXHfcuHGQSCRYsWLFW7WJHSJERERERERElYRckLz3n7e1Z88eTJ8+HQsWLEBAQADq1q0LPz8/xMXFlbr+1atXMWjQIIwcORJ37txBr1690KtXLzx48KDEugcPHsS1a9dQpUqVt24XO0SIiIiIiIiI6F+zfPlyjB49GiNGjICHhwfWrVsHfX19bNq0qdT1V65ciU6dOmHmzJlwd3fH4sWLUb9+faxevVplvejoaEyePBk7d+6ElpbWW7eLHSJERERERERE9K/Iy8vD7du34evrq1ymoaEBX19f+Pv7l3off39/lfUBwM/PT2V9uVyOTz75BDNnzoSnp+f/1DZOqkpERERERERUScjx9kNWKlpubi5yc3NVluno6EBHR6fEugkJCZDJZLCxsVFZbmNjg9DQ0FLzY2JiSl0/JiZG+ff3338PTU1NTJky5X/dDFaIEBEREREREVH5LV26FCYmJio/S5cu/X97/Nu3b2PlypXYsmULJJL/vYOIFSJERERERERElcT/MqlpRZs9ezamT5+usqy06hAAsLS0hFQqRWxsrMry2NhY2NralnofW1vb165/6dIlxMXFoXr16srbZTIZZsyYgRUrViAyMrJc28EKESIiIiIiIiIqNx0dHRgbG6v8lNUhoq2tjQYNGuDMmTPKZXK5HGfOnEGzZs1KvU+zZs1U1geAU6dOKdf/5JNPcO/ePQQGBip/qlSpgpkzZ+LEiRPl3g5WiBARERERERHRv2b69OkYNmwYGjZsiMaNG2PFihXIzMzEiBEjAABDhw6Fvb29ctjN1KlT0bp1a/z000/o2rUrdu/ejVu3bmH9+vUAAAsLC1hYWKg8hpaWFmxtbVGrVq1yt4sdIkRERERERESVhFyofAM9BgwYgPj4eMyfPx8xMTHw9vbG8ePHlROnPn36FBoaRdvl4+ODXbt2Ye7cuZgzZw5q1qyJQ4cOwcvLq0LbxQ4RIiIiIiIiIvpXTZo0CZMmTSr1tvPnz5dY1q9fP/Tr16/c+eWdN6S4yte1RERERERERET0jlghQkRERERERFRJ/BeuMvOhYIUIEREREREREakdVogQERERERERVRJysEKkorBChIiIiIiIiIjUDjtEiIiIiIiIiEjtcMgMERERERERUSXBSVUrDitEiIiIiIiIiEjtsEOEiIiIiIiIiNQOh8wQERERERERVRIcMlNxWCFCRERERERERGqHFSJERERERERElQQrRCoOK0SIiIiIiIiISO2wQ4SIiIiIiIiI1A6HzBARERERERFVEhwyU3FYIUJEREREREREaocVIkRERERERESVhBysEKkorBAhIiIiIiIiIrXDDhEiIiIiIiIiUjscMkNERERERERUSXBS1YrDChEiIiIiIiIiUjvsECEiIiIiIiIitcMhM0RERERERESVBIfMVBxWiBARERERERGR2mGFCBEREREREVElwQqRisMKESIiIiIiIiJSO+wQISIiIiIiIiK1wyEzRERERERERJUEh8xUHFaIEBEREREREZHaYYUIERERERERUSUhsEKkwrBChIiIiIiIiIjUDjtEiIiIiIiIiEjtcMgMERERERERUSUhB4fMVBRWiBARERERERGR2mGHCBERERERERGpHQ6ZISIiIiIiIqok5LzKTIVhhQgRERERERERqR1WiBARERERERFVEgIrRCoMK0SIiIiIiIiISO2wQ4SIiIiIiIiI1A6HzBARERERERFVEpxUteKwQoSIiIiIiIiI1A47RIiIiIiIiIhI7XDIDBEREREREVElwavMVBxWiBARERERERGR2mGFCBEREREREVElwUlVKw4rRIiIiIiIiIhI7bBDhIiIiIiIiIjUDofMEBEREREREVUSgvC+W/DhYIUIEREREREREakdVogQERERERERVRJycFLVisIKESIiIiIiIiJSO+wQISIiIiIiIiK1wyEzRERERERERJWEIHDITEVhhQgRERERERERqR12iBARERERERGR2uGQGSIiIiIiIqJKQs4hMxWGFSJEREREREREpHZYIUJERERERERUSQjC+27Bh4MVIkRERERERESkdtghQkRERERERERqh0NmiIiIiIiIiCoJgZOqVhhWiBARERERERGR2mGHCBERERERERGpHQ6ZISIiIiIiIqokOGSm4rBChIiIiIiIiIjUDitEiIiIiIiIiCoJOStEKgwrRIiIiIiIiIhI7bBDhIiIiIiIiIjUDofMEBEREREREVUSgvC+W/DhYIUIEREREREREakdVogQERERERERVRK87G7FYYUIEREREREREakddogQERERERERkdrhkBkiIiIiIiKiSoJDZioOK0SIiIiIiIiISO2wQ4SIiIiIiIiI1A6HzBARERERERFVEsL7bsAHhBUiRERERERERKR2WCFCREREREREVElwUtWKwwoRIiIiIiIiIlI77BAhIiIiIiIiIrXDITNERERERERElQVnVa0wrBAhIiIiIiIiIrXDDhEiIiIiIiIiUjscMkNERERERERUSfAqMxWHFSJEREREREREpHZYIUJERERERERUSQicVLXCsEKEiIiIiIiIiNQOO0SIiIiIiIiISO1wyAwRERERERFRJcFJVSsOK0SIiIiIiIiISO2wQoSIiIiIiIiosmCFSIVhhQgRERERERERqR12iBARERERERGR2uGQGSIiIiIiIqJKQhDedws+HKwQISIiIiIiIiK1ww4RIiIiIiIiIlI7HDJDREREREREVFlwyEyFYYUIEREREREREakdVogQERERERERVRKCIHnfTfhgsEKEiIiIiIiIiNQOO0SIiIiIiIiISO1wyAwRERERERFRZcFJVSsMK0SIiIiIiIiISO2wQ4SIiIiIiIiI1A6HzBARERERERFVErzKTMVhhQgRERERERERqR1WiBARERERERFVFpxUtcKwQoSIiIiIiIiI1A47RIiIiIiIiIhI7XDIDBEREREREVGlwUlVKworRIiIiIiIiIhI7bBChIiIiIiIiKiy4KSqFYYVIkRERERERESkdtghQkRERERERERqh0NmiIiIiIiIiCoLDpmpMKwQISIiIiIiIiK1ww4RIiIiIiIiIlI7HDJDREREREREVFkIkvfdgg8GK0SIiIiIiIiISO2wQoSIiIiIiIiokhA4qWqFYYUIEREREREREakddogQERERERERkdrhkBkiIiIiIiKiyoJDZioMK0SIiIiIiIiISO2wQ4SIiIiIiIiI1A6HzBARERERERFVFoLkfbfgg8EKESIiIiIiIiL6V61ZswaOjo7Q1dVFkyZNcOPGjdeuv3fvXri5uUFXVxe1a9fG0aNHVW5fuHAh3NzcYGBgADMzM/j6+uL69etv1SZ2iBARERERERFVEhLh/f+8rT179mD69OlYsGABAgICULduXfj5+SEuLq7U9a9evYpBgwZh5MiRuHPnDnr16oVevXrhwYMHynVcXV2xevVq3L9/H5cvX4ajoyM6duyI+Pj4creLHSJERERERERE9K9Zvnw5Ro8ejREjRsDDwwPr1q2Dvr4+Nm3aVOr6K1euRKdOnTBz5ky4u7tj8eLFqF+/PlavXq1cZ/DgwfD19YWTkxM8PT2xfPlypKWl4d69e+VuFztEiIiIiIiIiOhfkZeXh9u3b8PX11e5TENDA76+vvD39y/1Pv7+/irrA4Cfn1+Z6+fl5WH9+vUwMTFB3bp1y902TqpKREREREREVFn8D0NWKlpubi5yc3NVluno6EBHR6fEugkJCZDJZLCxsVFZbmNjg9DQ0FLzY2JiSl0/JiZGZdnhw4cxcOBAZGVlwc7ODqdOnYKlpWW5t4MVIkRERERERERUbkuXLoWJiYnKz9KlS//f29G2bVsEBgbi6tWr6NSpE/r371/mvCSlYYcIERERERERUWUhSN77z+zZs5GamqryM3v27FKba2lpCalUitjYWJXlsbGxsLW1LfU+tra25VrfwMAALi4uaNq0KTZu3AhNTU1s3Lix3LuSHSJEREREREREVG46OjowNjZW+SltuAwAaGtro0GDBjhz5oxymVwux5kzZ9CsWbNS79OsWTOV9QHg1KlTZa5fPPfVoTyvwzlEiIiIiIiIiOhfM336dAwbNgwNGzZE48aNsWLFCmRmZmLEiBEAgKFDh8Le3l457Gbq1Klo3bo1fvrpJ3Tt2hW7d+/GrVu3sH79egBAZmYmvvnmG/To0QN2dnZISEjAmjVrEB0djX79+pW7XewQISIiIiIiIqos/gOTqr6tAQMGID4+HvPnz0dMTAy8vb1x/Phx5cSpT58+hYZG0QAWHx8f7Nq1C3PnzsWcOXNQs2ZNHDp0CF5eXgAAqVSK0NBQbN26FQkJCbCwsECjRo1w6dIleHp6lrtd7BAhIiIiIiIion/VpEmTMGnSpFJvO3/+fIll/fr1K7PaQ1dXFwcOHHjnNnEOESIiIiIiIiJSO6wQISIiIiIiIqosKuGQmf8qVogQERERERERkdphhQgRERERERFRZcEKkQrDChEiIiIiIiIiUjvsECEiIiIiIiIitcMhM0RERERERESVhSB53y34YLBChIiIiIiIiIjUDitEiIiIiIiIiCoJCSdVrTCsECEiIiIiIiIitcMOESIiIiIiIiJSOxwyQ0RERERERFRZcMhMhWGFCBERERERERGpnf98hcjOnTuxceNGxMfHw83NDfPmzUOdOnXKXP/4OeCXTUB0DOBgD8wYB7RuCuw8CGzaDcTEAXK56mWKWjQWsHG7+HtOfA6eH3qOpDtJKEgrAABoGmvCeaQzLBpYoJ11O3S27QwTLRM8zXqKnU934vSq04g9GwvHIY5Ao6LcrOMP0cbcE5MHjYS9vT2e5yXh17Bj8E94iN5Vm2GwYytY6ZhAJsghAMiT5+NhWjTWh51QZjRyrIptn/YrdVv7rduFBy9iMaSJN6a094GBjjYEQUBqVg4uhUXip1OXS71fZ+9aWDywI3S0NBEVn4zvD53HpdBIcVs1NDC5sw9auteAg6UZpNKifeXpaIOgyFjYWRhjdJcmaFSrGiyMDRCfmoFj10MREZOIMd2aoaqVibLXMvRZHJbtOYeHT+MxoaePeIwOTENmZh5uB0bit80XUdvDHp9+0gK2NiaIfpGMdZsu4PqtJ+jVrR4G9mkMSwtD5ObmAwJgaKiLkZO2IOxJnMo2rVg2CN51qqssu3YjHF/O34de3ethYN8msHglZ9SEzSVyAKB1y1oYObQlqtqbQUNDA9t2XsGm7Zf/p5xPh6nmbN4m5gzo2wQWlq/kjN+M8FJyWrVxw/CRrVG1mjk0NDSwfcslbN10ET0+aoD+A5vC0tIIObn5AMScsZ9uQHhYrErG1Fld4NPSFaZmBpBIgKysPKxffRpH/7qDHr0boN/HzWBpaYTc3HwIipxxw35H+OOiHCNjXXwypi2at3ODuYURJBIgLTUbvyw9jMtnQ9C9XyP0HeIDSytFjgAYGuli/Mfr8OSRans6f9QAvQY2QfUaltDQ0EDUkzj8vvIUbl55LOZ80rxkzuB1ePIoRjWndwP0GtwE1WtYiTnhcfh9xUncvPxYuU7zdu7o2rcharpXgbGpPhLj0mBkogcAcPWyx6MH0ejcpyHadq4DZ3c7GBjqIu5lCkzNDRAfmwZNqQbMLA0R/TQJm1acUM1u7wEAOHJvMaRSDURHJWLd0sO4eekRug9qgr4jWsLM0hBpKVnQ0taErp42gu9EYdXXf+PF00Rljot7FTHn/hJINCTISM3GigUHcfVUELoNaoohk9rDxMygxHMDAAa2+AapSZkAAGf3Kpj+bR8AwNHgb8Wc+QfEnMFN0ffTVjCzNERuTgH0DLQhlWqgIF+GSyfu44dZfyoznT2qYPq3fcWcx8vEnDl7cfXkA3Qb4oO+o1rDzMoIaclZ0NbVhJGJPiQSCSb1/BnhQS+UOfaOlpi5fLCYE7Ecudn52LXqJPb+egYA0O2T5pi4uG+Jbfrt64M4tOliUU4NK4yc013cR1ErAAkQ+zwJv87dh5tng9FtWEuM+LI7dA10IJEAMpkcsgIZgm9GYPWcP/EiIh4AULuZC5btnQIAOBa9SuUxp3b5Aa7eDug/qQOsqpiVaNM3Yzbi8pHAopx9U8Wcl2tUczp9j0d3n6J2s5r4aEw7eLdwha6BjnijAESERGPl57vwKDAKtZvVxLID08ScmLUqObHPEmFmZYwXkfFIjkuFqZUxHFztkJdbAA0NCdKSM8XnlL42gm8+weov/lDet7ZPTSw78FmJbShsn2s9B/Sd0AFmVsb/c05k6Av8/Nl2PLoTBQD4ZFY3dPq4OQyM9VRy1l+aD1sHS2hpl/5xIyUhHRKJROXxC49XcYeiVkJbRwtyuYCHdyIwo+uP6DaiNfpO6ABzWxMAgKamFJAAcc+TMHfgKjx/5X2wPDmCIEBTSxMSCZCenImfpmzFjVMPVDKGz+kJADgW/5uYExCB6Z2/R/dP22DIF91hYmFU6rYOcJuB1IR05d8j5n5UZk7fSR1hZm2CtOQMaOtowcjMQHyNtVuCsHtPVXKVOYnrxZzbEZje6TsAQN/Jfvjkyx7Q1tVSrp/wIhkLB69G+P1nKjmNO9QGABxN/F38fyI9B9+NWo+bp+6j+6i2GDG/N3QNdIteY/kyBF8Pw6oZO/Ci2P9dW++Kj308dZNy2cmdl7F8wiZ0H9UOfad0gkUVUwCAVFMKCMCLiDjM6/uzas69ZW/MMbcTcwqPfWpCOr4d/ivuXX5YMidtc1HOjktYPqEot0F7L0xbPQKWdmaA4mPPs0cv8eO4DXh0O0LMuf8DAOBE9nbl/c7svgLXejVg42CJ2KgEVKtVBa+SyeSQy+QQ5AKCrj7EL1O2qNy+NXQ5bB2sVJYJgoDnj2Pww8h1eHjriXL50Hm90WlEWxia6iPY/xEAYMPdH2DjYInosFiYWBnD3MZEJSszLQsFeQXQNdBFsP8j/DJ5E16El3xtbLj3A+xd7KChIcHqaVvwz7pT6D62A/pO7yruFwBSLcXxehKLuT2Xlchp2bsxAOBY1o5/JQcAuo/tgCFze8PEUvE6e01OocPp26Gtq4XosJdY+9lW3DweiO7jO+KTeX1hbGEECQC5XA5BEHDvYgh+mbQRL8JiSuRsCv4Z9jUV+2jyJvy19gR6jO+IgV/2glVVixLrL+7/My7uv1bunEGzP4K5rSkAQKIhAQQgJioeX3X7Ds9Co0vmhKyAfc0qipyN+GvNcfSY4IeP5/aBqZUJBAAaEgkECIgKfo5FvX9AdGnbVUZO/5k9YVnVAoJcDqmmFHK5gLvnHuCXCb+XOwcAtHS0MO3XMWjUuR5MrY3FwyYXEPHgKX4e8xse3gxTydHS1sSqa0vh7O2I9TO3o9PIdrB1tMKLsBgkvUyBma0pqrvb49rh21jY+wcMWzQAnUe1h6GpAYKuhOKXCb+XaBvR6/ynK0SOHj2KpUuXYuLEiTh48CDc3NwwcuRIJCYmlrr+nQfA54uBPl2AA78D7VsCk78CNv4BfL8GmDgMaOMD2FoJMDQQ8NcmARcPCPhxflFG9ots5KXkoSC9APbd7FFjaA3Ic+R4uOIh6sjrYGC1gfjrxV9YGLQQz7KeYbrTdGgmaELbTLtEe+pUc8UPX36NQ4Hn8NHAvrgUH4yldYdiYPWWmFyrGzY9OYPfwo7jdlIYCgQZvgzcipicZPxcf5QyI/DZC4zfcQgFcjnWnr+GIRv2IPhFHARBQG5BATp7uWKmXyvEpqVj2fGLOBn0GNpamnCxtsDawT1LtKmuox2+G9IZ0UlpAICbYc+xckQPuNiKb+S62ppwr2qNa4+fQiIBNpy5gbAYcX+vmdwbZkZ6qGFjBg2JBN/sPI1+X2/DT3svYEDbuvjm0y4IiYoFBOBqUCQAIDYpHWsm94atuRHcqlsDAEZP3oZ5Sw6iWlVz/Lx0AOZ90R1HT97H6MlbcMn/Mb6Z9xEG9G6EiaPbYuuuK9i0/RKiX6SIH3jKoK+vDblcwNadVzB5xk7sPXATDeo5YkCfRpgwuh227LiCTdsuITo6+bU5nu72mP9lDzyLTsK9B88BAIMHNnv7HA97zJvdA8+fq+b079MI48e0w9adV7B565tzPLzs8dX8jxD9LAn374kfXgcNaY5+A5pg3ERfbN9yCZs3XkD086TX5mRk5MDEVB97tl/B13P2IzkxA9NmdUG/wU0xdkoH7Nh0CVt+v4DoZ0nQlJb+tmBuZQRHZyuYmRti77Yr+OnrvyAB8NXSfugzpBnGTOuInRsuYOu6c2KOZtlvLw5OVqhewxK3roYDAG5cfowFPw5EnyE+GPOZH3b+fh5b151F9NPy5Fjh1lXxP9Mblx5jwfKBcHC2Vq6jq6eFoMCnuHQ6CABwZP8tTBz8GwDgm1+HwcTcADq6Wrh19TFuXBQ/RP+5+RKWLzgIu6pmMLUwxJdjtsD/XAjmrxgMB5eibKdatgCAq6eDAQB3bzzB/FUfo8/w5hg9qwt2rD2Lf/64BhMzA2jraGLeuC3Iyc7HN+uHK78gmlsZ4fstIwEA+7dcxtLpfyAnOw9f/TwIvYe3wJgvumDripM4suca8vMKkJOdh68nb0dyYgZyc/KRlZFblLN1FBxrim1a+pkiZ8Vg9B7REmO+6Iqda84gNPApDI11IZfJsWzmHgTfiUK9Zi6vtGd0Uc6U7WLO6k/Qe2QrjJnTHTtXncLhHVdhYm4AA0NdhAaKX4rnrRmm8sX3221j4OpVVbxt2G94GhaDEbO6onZTZ7Tq5o0xc3sBAHJz8nDPPwxZGTkIvPoIPUe0gpZOUc7CjaNgYmYIANj321lc+CsAVnammL9xFHqPbYcx8z/Cw8BI3L3yCIJcgIaGBPM+WYecrDws2TFemRVyKwILhovHftfPx/D5Rz8j7P4zCIIAr6YuGLPgI/y18TwAoCBfhpysXHw98nfcOheMkXN7quYMWyfmLD+Kz3suV+bk5oidkx6NnKBroAOppgbkMjlung0CJEAVJ2t8s3sSTCwMEXLrCQbXmQ0AGFz7Swyu/SX8j9+FIAj4Z/MFTOqwFDdO3Ufd5rXw/HEMIAGeh8Xg8JYLMLEwhLauFuYNXoOcrFws2T1Zub9Cbj7BgiFrISuQYddPR/F5j58Qdv+puJ3NXDBmYR/s/OnIW+VcPnwHBfkFiH2eCEEQ8OxxDJb8MRkmloboN6kDeoxsg1Wz/sC0Lj8gJysX3x8UO1JO/HEVU/y+w8HfzqAgvwA7fzyC/LwC3Lv6CBmpWTAw1ivx+MWP/YApfgCAm6eDMH/Qahzffhm1vB3Re7wvxizqgxN/XIWGhgQaGhrIzcnHurl7YWRmgBVHZ72S0+m1OX+uOgG5TA5NTSnycvLx05StyM8rwPyt46FroK2S01/RpnkDf8GxbZdQq54j+kzogNGL+2HLN4dwePMF8bWalYuvh61FcnwacnPykJWeXZQzrTP6T+1UZs6OHw7jn43nYGJhBANjPYTcEr+Uz9syTnW7iuf0/wXHtl1ErfqOcHCvglYfNcSwOb3w9OEL5GTl4cHVx8jNzoOhqT5+PKK6f5p3r48vfh8tvsZWHceCQatw53ww5u+YiD6TOmL0kv54eDsCdy+Fiq8xiQTz+q1ETlYuvtn/mUpW4XvAzu//woxOS3FgzQm07dcUfSb7YfS3A3Dln9uQaEggkUiQm52HzYv2wcreHD+f/ko1R+f1Of9sOAuJpPDY52HllK2QaEjwzYHpped89xdm+H2LA6tPoG3/ZnBwtwcA2DhYYtGf02BmZQy5XI4jG88hIzULVV1s8e3BGUVfvBUGOk7CQMdJmN/7J7Tp2xTHt17AhKbzEHBG7DhbPu53rJy0Cfm5+bh2JAA5mbm4dzEE+XkFKMiX4dt/ZuFVRzeeg1zRkfvHsr9xfMt52DvbYOmRL2FiJX6B7D+jK3pO6IhVUzZjaquF0FTs51M7LmFCk69w9Z9bMLM2xs2Td5Gfm49fP9+Gw+tPQ1tXG9q62pjb43vkZObi28NfQkunqIPMo2lNAEBqfBoeXAkFAIz7YQj6TOuCMcs+xpVDNyGRSiDREI/Xpnl7YGVvjhUXFpXImb1tEgD8KzkOHlXRum9TjPtxCIwtDJGfk48HVx4iNyev1Jzi2xYTKXa0BZ4PxsL9n6PvZ10x/qehMDIzwJ1z91FQIENBvgyZKVkwtTbB0iOzVdvUzFWxj1Lx4HKI2KblQ9F3ejeM/WkoDv5yDABQkF+AnMwcLOzzA26eCMSo7z9+q5wDvxxFwOl7kMvkyM3Kw+Z5u2FhZ4ZfLi8uIycNDy4V5gxD3+ndMfanYQi68hChN8MgyOTIzc7D32uOw9GzGpZf/Pqtcv5YehARD54CEgnkMjmCr4YiJzMXS4/PLVeOo2c1AIBUqoGqblVgYKoPQQCehkbj7oUg2NWwxtLjc2GqeI4XGr3sEyS+SAIAjFw6GMc3ncX4+rNw7UgAvNt54eJ+fwScvg8AGDCrJ3pN7oyV49djctPZyvYRvY3/dIfI5s2b0b9/f/Tp0wcuLi5YtGgRdHV1sX///lLX37YPaNEYGDkIcHYEpo4E3F3FypB+3YDeXQBjQ8DDFdDXAy5cA6wsAJNi/9eZ1TWDVFcKs7pmcBjoALuOdqjWuxokUgn8rP1wMf4iLidcxoucF/j9zu/ITMvEqIWjIJFKSrRn6MCPcT3pEXYGncKTiCf4PfwkHqW9wMc12uCf5zdw9MUt7Iq6iFmBW5FdkIvapo745eFhGGrpKjPyZXL0qOuOy48jseqsP+4+j4GNsSFi0zIwuIk3hvnUx97b99F99XZs9Q/AjH1HkZmbh8CnL+Flb1OiTdO6tEB2Xj4+2/oPAGD31bsIjo7DoObeAICMnDyM+e0A6jrYYd+1+1h93B8L/hR75fMKZOjp44WrwVFYuO0kroU8RXRCKi7ee4LYpHTk5hegmrUpDly+j89+/RuhT+OQkpmDnPwC+DZwxYSVBwAAz6KTEPzwJVauPQ2Haha4e/8pdu+/gahnSdi0/TIehcdiUN/GOHz8Ho6deoBde29g7LRtyMrOK/O5YmVphNi4VGzefhn3g55jzfqzeBwWi4F9m+DI8bs4fuo+/vjzOsZN3Yas7Nwyc/r0aoAHwdFwdbbF10v/BgC8fJnyP+fUdLHF198Wy+mnyDkp5oyfsg1ZWWXn9O7bGEFBz+HiaoslCw+KOS+S0X9wMxw9HIgTx+5hzy5/TBq7+bU5trYmuHktHJt+O4/LF0Lx9Vf7IZFIMOATHxz7+w5OHLmLPTuuYtKoTcjKKn0/R4XHIyU5E7euhmHTmjM4dfgufvnuCACg3yc+OH4oACf/CcSf265gyrDfy8wBAHMLQ9y8Eoa9268AAP7YdAlhoS/Rb2ixnK3lyLE0ws3Lj7F3iyJn40WEhbxEz4GNleucOXIPO9dfgFtt8Yu5//mHePpEPAOdm5MPv171cWinP/7cdAnObnYAgHNH76FZW3fcvPwY6WnZ8KrvgG1rziAs5CV6DGyizK7qaAkA2PCj+GHo8O7rCAt+gb6ftsLxfbdw6lAA2nb1xpaVp5CZngu3utXxw+y9sLA2gk97dwBAkzZu0NISO7M2/XQcl048wPxxW6GhoYEBo1vj2N6bOLb3Jpq188DWlSeRkZYNFw97GBrrQirVgI+iSqUw55aiU+fSifuYP3aLSo7/mSDUbuyEY3/eQFpKFqzsTPH1pO0wMNKFj2+xHO1iOcfuY/7IjWLOuHY4tuc6Tu2/hTbd6+HGuRDI5QIiFZU7ZlZG8OngCQAwNtOHdRUzhCg6S25ffIgvB62FRCJBn9Ft8dGoNji22x8AcPGfO/hy8FpkZeTgwY0nMLc2hk/H2oocA1R1skZenlixt/nbv7Hqyz3Q1NLEi8gE9B3fHsf+uIo5g9bCwdUWdy4/glwmwK2+I36cth0WNibw8ROrCgvyZWjXWyzj2/7jUYQGRMLSzhQJL1PQd4Ivju3yx6XDgQCAvzdfQEZqNqo622Dp+M0wt34lp4/4HNv+wxGEBkQoc7p/2hoAsOeXE3BwtUVKQgaObLuMBUN+RcD5EGhpa0IQBHQc1AwF+TIkx4ud08nxaUhLzkCDth6IDo/D/rWn8exxDDZ/8xceBUbBq1lNPA+PQ1x0Mtp81Ahbl/6NzLRsuDWogR8nb4VFsbPCBfkytOvXBLfOBWP7D4cV7TNTbGcHHNt5Bad2X3urHMsqpji+8wp0dLWR8DIFaUmZyM3OQ8eBPug1uh12rziOayfuITIkGj9O3gozxQfc/WtPIzLkBdYv2I+we8/QZVhLnNh1BdVd7aAh1Sj18X061QUAaEg1MOizzgCAb0aux61zwVj9xR94fPcp+k7sgGM7rkBbVwuCIGDzNweRkZoFHT0trJy+A/rGemjdq2FRzvTX5zy+GwUdPW3sWXkcGalZMLcxwZKR6yGVasBvcHOVnIhg8UztrTNBWD1zJx4FRqHvZD8c334Zx7Zdgk8Xb2z5VmyPS+3qMDTRF1+rXeoV5czoiojg52XmnPrjKtr2bYLrJ8UvR1GKs8NmNiavyXmA1TPEnB6j2qH3hA44tu0iLGxNseP7vzGrx4/ISMnCg6uPoWugA5+uRTnjlg7Ec8UZ300L9+PGiXtYMuxXhN2NQt8pnXB82yXM/mg5HGrZ4c6FEMjlcrg1csIP4zfBwtZUmQUA+kZiBd72b/9CkP9jrJ+zR8yZ2hnHt16EmY0JZPkybFq0DxkpWYBEgm3fHISxuSF8utUvd05MVDykmhrYrMgxtjDEmhk7oKmtiRY9GpaSc0iRsxthd6PQY0x7AEBNb0dINTWQFJuKI5vOY/X07Vg1VexcEQTA75OWKC45NhXJsaloP7g5bp28h30/H8Wzhy+wf6X4/0DDjnXhN6w1jm0+j5r1nbBr6SF81eMHZGdkI/RmOCwUVS3FuTaogaz0bBzZcBZbFuzFigmb8PD2E0ilEvgNawUA6DWxE/74/m/4Hw5AxINnSE0Uq41iIuPw7OELbFu0D/l5BfBs5opjm87h0OoTaNa9AbYs2IPM1Cy4NamJZSN/hYWdKXx6NFA+dq+JYoeasYURVk0Wq2iehb5Av+ndcHzTOZjbmqIgT4ZN83YjIzkTkABbv94HYwvDEjmP70QCwL+S03N8R/Se0hkxkfHIzy3A1kV7MbPDEmQkZyLwQnCJHAAYsXggAODr/ssBAP+sO4mwOxHo93kPxETE48qhm3D0qIbN83YjPSkDwdcewdjMEBZVzNC8Z9FzqNekzop9ZIyVEzYAEL/U9/+8B45tOIOL+8QqkL9WH0dGShaqutpjycAVsLAzRfNeRaXjH015fc7eH/9BjToO2Dj3D2SkZEIuF3B04xnom+iVkWOElYpqiKch0eg/syeObTiDr/v9BBsHK2ycuwsZKZlIeJGM2yfvwsTS+JWcrq/NObL+FMysTbBxzk7k5xbAyNwI3w9bLe6fcuT0nCQ+t3KycmHjYIXk2BQ8f/gCzx++wMLeP4qdeoIAv0/bqRy3Bh3q4LeZYiVW0NWH2Pvj33gaGo2Ns3fi4c0wWNiZITkmRXzsqV2x85v98P/7FiLuP1W2j+ht/Gc7RPLy8hAUFAQfHx/lMg0NDfj4+ODOnTul3uduENBM9b0QzeoDSSmqy2/eBVJSgV+3AQt/ApJTVe+THpYOE6+iD4WybBl0TXXhWt0VQWniWWZBLuDRuke49/Ie3Ku4l9oeTxMH3EpSLQO7mfgYZloGuJlUVHYvQMCtpDDUNnVAz6pNkJ6frXKfutXs4P9ELJFt6+YEU31dHA96BO9qdvC0s4F/eFH5rCAA/uFP4VHFGnK56mw7Fob6qFejCvb530eO4ssFAFx9GIW6jnbKvzWlGvCoaoNrj8VcI12x3Pvmw2eo42SH0lSxNEFqZg7cq9vgeoh4P//gKNRxssP1kKel3s/AQAeCIOBWQJTK8tt3ImFqoo/bgZEq23U/6Hmpjw0ABvo6MDXRx197JmPzuk8xekQrBN5/ClNTfdy+E/VKTsmyw0JeHvaoZm+GFWtOIilZHIYQ9iT2rXM8FTkr15xEcmFOuCIn4JWc4LJzPLyqomo1c6xacQLJimER4WFiToDijGFhzoP7Ze8fD6+qCLgprq+rqwW/rnWRnpYNY2O9EjlB956VFQP32tVw52ZR+a6BoQ7ycvNhamaAgBtFywUBCL77tLQIMadONdwptj4A3LkeLuZcL54jIDjwdTlVcee6as5t/3C416mmskxTUwpHl5IdhHeuFa2rqSmFvYOlahuvhausc/tqGNyLDc169XEA4I5/OEzNDXDHPwy2Vc1gbmWkyAmDe93qyMrIRei953CvK+ZoaUnFsvFichVDoIxM9RF4rTDHGHf8wxHoHw4fX0/kZucj9N4zuHkrcrQ1IdWU4o5/WLGcgqIc/zC07e4NiUSC+JhU6Opr4+OJ7TH16954EvoSbnVfl1OsPVcew7aaOcytjeHVqAaunwlGdcW+ffzgOdzqOQAA0pKzUJAvg0QidhZrSDXQZXAzZGfmwqaqOWp6VUXkw5cAgIZtPfDH7a+hpa2JZh288DAwCm71HRU5mXgWHotaivZpSDXQZUhzJMen4caZIJhaGCLw0kPYVreAuY0JYp4mIDszB+71ayArPUfMauBYdMyK/d60Y20YmRngytG7ypzC4TJtejWAsZkB+o5vj9pNXfDwTiTcGtQoPcevDozMDHD58B24K9YpbI+FnSkCL4lnOXUNdJAUm4rkuDS4N3Aq8dxp6lcHWtqaOH/wpupz6mIITC2NkBSbAh09bZjbmODOxVAEXgqFe0PFdiq+QBS1rwYCL4aqtO/KkTswtTRC4MWi/VWenHtXHqJmnerIysgRt/OfALg3rIHAS6Go17KWMqdQVnoOZAWyEttXuB2FOfqGuqU+vltDcd+41KkGHT2xOmP16TnYee87fL1rEsKDnovbcSkUphZG0NTSxJ0LoQi8GAr3hk5IS86ERCJBE0WnWnly8hWvFWMLQ9y9/BCejV3QumdD5GTlws7RSiUnSvG83RX0AxbvnoInD57B1NIIdy6EwNbBUtwf50Nw50IIfLrWQ252HkJvR8BduV3VoaunjajQN+fUblYT107cQ3VX8f/Qx4FRZecE/4DFf05B+L2ncG/shJp1HRAZHA1zW1PcOR8ivp/eCIdrfUekxKfDvZEip251WFUxU27nrpAfsXjvVDi4V8Gd88Fim84Hi22yNUVMZDyyM3Lg3sgJWWnZCL39BO6NnJXHubAi48+IX7D60gL0ndIJgReKcgzN9KGtq40754Jx53ww3Bs5IyNFPGYN2nmWOyclvnC4lQ4CLwTDy8cVLXo2REZKFmoVe60qcyJXYfWlheg7pRMCzgbBvbHY5pSENEgkEljam+HuhWDoG+spc5LjUuHe2EXlebz3+Vqs8V+MBr61EXg+uMTzvFm3+qjV0AkNfGvDws4UAWcfQBAE3DkbBJe6Dgi9+aTEfWrUrg4DE3008quLvp91gYZUA7dP3Ud+bgE8GrvA1tFKmVXItb64je5NaiqX5WXnQc9QF74ft8RvAd/Dws4MgeeDcefcA3g0qSker5vhKvfx9BHP7i/79FfkKk70hNwIg6mVMQLOPoChqQF09LQRcCZImaM8Xh3qqORUVVQWVnRO8LXHcG/qgpr1ayA7I0fMORsk7tdzD2BhZ1oix9TaGJ7NxO3MLXZiJeD0PZhaGSMtMR1SLSks7MwQcOY+7py9D6tqlrCsao4n96Lg3tRVeR+v5rUAAN8PW63MCrn+GKbWxgg4cx9W1cQq67YDm8PI3BD9P++Ouq09EHo9TFmlIua4vTbHtoY1LOzMcOf0fQScuY/67WujXlsvxD9LLD1n6CrkKk6GKXNO3yvKOXUfAafvwaOpK3QNdJH0MhkezWqV3K5y5CS9TIaRuSGy0rLE7XpDTrD/I+U+LMyxrGKOxJfJAKDMSY5NgYdiPVNrkxI5odeLvi8BwK2Td5W5Ovo6yv1VqDBXHUiE9//zofjPdogkJydDJpPBwkJ1TJ6FhQUSEhJKvU9CEmD5Sqegni4ASGChWN6iMfDdHKBre8DaErh1Fxg7C5DJij685afkQ8tYLAXLjsnGy5Mv4dDIAZpSTaTli2fzog9HQ6IhQb51Poy1VEu9lG3VMURSXrrKsmx5HiQSCZLyMpTLfCzd4GtbF80t3TGgegtMC9igch9LQwMkZGQBAPrW98KVsCg8TUyBtZEBNKUaSMzMUt132dmoZWuFI/dDVZYvGdgRABD0XHWMZWJ6JiyN9JV/mxnoibnpWdDWlOKzri0AAHEpGbAw1serqlmZwEBXGwFhz6Ep1UBSWpYy18JYH0npWSXup60lxdgRrSEIQKziDGmhnJx8SCQSJCerbldqmmpHUXFSqQYO/H0b0774Azv3XEPHdl5o2thZ3Ncpmao5qVllpACWFoaIepaIK9eK3kzz8mT/W87TRFwp9qUyT/HlMPltciwNERWZgKuXH5XMSVbNSUspO8fMwhBOLtb4+/Qs/HP2CzRq5oxj/wSKOUmvtOcNOcmJ4vrGJnoYPLIVQh9EQyKRIOVtc5IyVJYVHveUV5a/NseyZE5yYgbMLAxVlhmbiWdoX5WSmAEzS8NS1zGzNERKYobKOsV/L1znVbnZ4mtcXFcsP0tJKDvn7vUn0NAQOw00taQwNNbFp5+JZ1UkEgmSE4pykhMykJyYAbtq5jh/5C6S4tOVOYHXw6GhIUFNRSWMobEuPp3uV5STmIHqzmLHhW+v+gi48hgxz5NgZKqP6s7WsFCM61XmeNkrcvTw6cwuKjlWduKHlh2/nMLLZ0kwMhFf36mJmTCzUi0vN1Uci78fLsNHo9rg762XYGppBKmmFIKi03blF3vw1SfrEPUoBjXcq0DPUFclZ87Hv0JX8YX27/Cf8NHotpg3ZB3SFV98k+PTlRUJOVl5KCiQw8xasc+K3QZA5Xe/gc0QcD4EyfFpin2dBj3F8IgVM3bh0uE7yM8twPxNo6Eh1YCZdRk5g3wQcD4E0U/ilOsU/iuVaiA5Ph0tu9eHa93qiHr4EhKJRCVLmTPYR5w7IFx1LqGcLPE5lZeTD23Fl7vk+DRx2xQ5ya+8j5pZGyM5Pl2ZG3A+GMlxiu2MT4OZ4oNneXJys/Mh1ZTCq4kLAs4HIzoiXplfON791ftpapUcwle4HV5NXPDoTkSZj1/4u131og7KP34+hgVD1iIjNQvt+jRSbkdh5YRbwxpISUiHlb0ZBk8Xn68WirbZFZufoawcPUOxMrNBWw+07dMYjTt4oUFbD9y78gimiudiYU791uKXkfmDVyEjNRPt+jURX/PF2p4Sn46U+HTYOVrh3P4bSIpJhZmNYrsUHQ/127iXmWNlbw4A2LHsH8REJcBIMYdQakJ62TmDViEjJQvt+zeFhZ2ZOOZfMaHXkC+649Dz1WjVqyGkUg0EXXusfA4U5hQ+xvyBYs6yf2ZCEFC0bYrqoZzMXMVrTPw7Ja7o+VTcF92W4ejmCxgwoytq+9QSc+LSEKHovLd3tkFKfBpsqlui9yTxvaq0eRjKyinsdOs2ui3aDWiGxh3rwLKKGe5feahsq0pO1+9xdPN5DJjRDZ5NXJTryPLlAMSTbnO2TsCB52thaW+O+5dDIYFEub//UsxhMavTUhzdeA4GJvrwLtaBk52Zg0sHbyAnMxcSiQQvnoiftZxqi525yXFpMLM1RUqc6lm4v9aehCAXIJFIcOnADQyc2QOjvh2I5LhUaOlowczWVPk6K35fMxtxmbniXwAI8n8EiUSCVVM348axQABAl0/bITm26PilxKaq3KdwHpbHAUUnR/IK/z+OS8WT++JJHHsXG6TEpcHGwRJ9poqvMetix8vczhS3i30xrcictKQMmNuKz+koRUWUvYsNJBIJCvJkqOpapUTO57+PAyQlq7dzFe9D9y+FoGFHsQMlNS4N+Xky5Rww2Rm5yv1bfB89ul3UmZWfrfisGpuqfP/4afRvuLjvGvJz87HwwOfQ0NSAmW35cwqP82e/jUH7wS1Q37c27l8OReiNsHLk5JXISY5NQXJcKhw8qsK1kTMig56rbpfiBEB5cnKz86CtGCaTHJvyxpz0xKL/Hwr/lWpKkVes2js5NgWARLltMzdPLJGT9upnvNgUZV7h3Ehijuo6RG/jP9sh8m/p2h5o1xwwMxWHyvz6HXA/VIIbN26UWDc3KRchy0Jg0dgCBk5FExpmRGTg5YmXqDm2Zon7/C8CksJx9MVtRGbG4VriIyyu83Gp69kYG6K5iwP2BTwo9XZAnBS1XS0nSAAsOnxWuXxwC2/o62qXqBp5HamGBD8O7aqcYKw0VqYGWD25NwRBQGDYi7JXLJ4r1cDC2T0hkUggk8nL3Z7XkcsFhEfEIyIyAafPBePbHw/DydHqzXcsxqepCyQSCU6cLnv//n/mNGteExKJBKdO3H/zyuXw4N4zjB/+O6ZP2Ibop0lo28HzzXcqg76BNhavGIynEfEqFSP09qLC4yBXvA4O3V6IXRfnICY6CVmZOaWub2FtBB1dLZzYf0tl+dMwMadxK/FMza5LXyHmeTKyMopyCqs1tq88hdjoZGRn5uH7Gbuhq68DEwsD1RzFl75d1+Yj5lmSSk6XwWLl3pU3PDc1pBLl/ab2XAH/k/fR9WMfaLzyIfXRvWcID4rGw8CnSIpLQ1Una5XbJyzuo7y63NRuP8H/xD0s3DIGuoY6r33817G0M0X9Nu44oRi2UygzXWxv2IPnSIpLQ/yLZJw9cAtVnUtWGKnk/HG1zMdyqV0N01cMwcqZu5CVXvpxFXM8lJ1EFaUw98SusttXXrXq16iwnOsn3/z+KNEoep5cOXIHYfee4uep21TWeaio3Bs57yP0Ht8eTh5VcVMxl4MglD+nsIrg0Z0onNt3HU8fvURU6At4NnGBVENDJcf/2F0AQNjdp1g+eWuZ7bewNYGOnjZO7FSd4Lww5+rRwDJzug4Xh0lcOVx6RWyZOZO2QACgra3aIbX9u78wqe0SXPknAFo6WnDyKqpuK3xfKHwfCrsbheUTN0MQAEcP+zIfvyyFnzMigp7j6Kbz+P2rPXBvUlRB4n9U3KbP141Cn8l+cHCvggv7xc9ggiCUO6ewA+fSwVs4s9sfT0NfoCCvQFn58bqc2i1rofDDjZFZ0Qmbnyduwuedloo5TVQrQw6sOSnmPHiGIxvOQi6To6FvbeWcKWmJGQg8H6zsqLny120AQHfF0JyyHPjluHK7r/5zG+u/3IWe4ztA+pr5s8oSdEUc6vjySSz8/xH/j/Ab3lplgvziek7ww2s/5AG4djgAADBz43j0mdYFDh5VcX6vOESksN2FOf7/3P7Xcx4otnHmxvE4kr4V7Qc1V35pLp6jZ6SrfE6X5uo/t3DpgPi82/FkNdoPboE0xTAkFHse9prUCW/aR5mKE1thdyKQFJOCuGeJOLPzsrKjprw5hVZO2ICT2y4gOiwGTbrUU5ms921yAMC6miXsnGzw85h1yEorOsHUa3Lnt8opS0XmFA5vI/r/9p/tEDEzM4NUKi0xgWpiYiIsLS1LvY+lOZCQrLosOwcABCS+sjwxWVy/WhXAzERAVFTRMAYtUy3kxOQg6NsgGLkawXmkMxJjE1EgK4CxljHSHqYhPy0ft6beQu71XERej0RuQi4id0aiXbuicXCJuRkw11Y9W6qnIV4Jxly76Mxyjjwf2hqaeJ6VgO+C90EmqL6BJ2RkwtJQH73reSIlKwfnQp/AwtAAcemZKJDJYWEg/meuqaGBn/t3ham+Hm5GPkdmblEvbJOa1VDXwQ6aUg0sHdwJR2aPAADsnjYYfZvWQUJ60ZtkcmY2CmRyTO/eClXMjDHmN3HuD3MjfSQWezO1NDHA+s/64e6TF4hLyYCutiYKZHKYK6pBLIwMkJiWVeJ+i2b3gI21MWZ8tQdJyZkwM1WtHtFVjAk3M1NdbmJc9htlUnImzE2LOq1CFCXEgiCoLAcAE5OSVS4AUL+uWOo/67POOHNkJs4cmQkA6NDO861y6nkrcqZ3xumjM3H6qGqOWTlzvBVDBj6f1RUnzs7GibPi5Iu+HbwU+0c1x9i09BxArJrQ19dB9PNk3A98iq+/2gdTMwMxx/yV9rwhx9rWBN/8MgTZWXlYNHMPdHTE42X6ljlm5qrVFYXH3fSV5a/NSSiZI1axqJ5RSEvOKrXzzdTCEMkJGaWuk5yQAVMLQ5V1iv9euM6rdPTE17i4rvjhytTy9TmJijP5Q9p+j/4+S7BjzRno6olDyswsi3LMLA1Rq041ZKZnIyz4hbitr+TsXCNewaV/s8XYseY0dPUVORaGiHkmTlKWnpYFMwsjJCekIzU5EzKZDLKCom1PjCuW03ABdvxyUiWnRi2xfH/7pa/QZ1QrVFNMYtusgydsFGe2vZuJHYMXFFdmCQ96jjXz9kMuF1BQIIOsQKb8QmdmZaj41wjxL1Ogq6eNVMUx9PapicbtPJEYK54ZDX/wHGu+2ovcnDy413cU22RlpKxQ0NXXhqamBpLj0pWZxasXCn/vMKAJ0pMzce3kfegqjpmZpTGS49KU9yu878OASOgb6SpvU8kZ2FTMOXEPZlZF9y/8Vy6TY9SC3li/YD/O7L0BMysjCIKgkiXmNEN6ciYSY1NLVNno6ovt09bVQp5iaIeZlbHYPmV7VStOkuPSYGZlpMy9duKeMkdsZ2q5c3T0tCCXy5GTmavYTiNlfpJiHPer9yvILzlkpvDxczJzcUnx5ai0xy/8PemVfQQA+XkFyEzLLtoOxXGY2XM5Lh++g5tngnDt+D0AQPxz8fmeFJv6xpxaivfbP385AUEAXkTE4/vxm6BnoANdfR2VnNxiZzjz8wqQmSrmmBZru6mVEWrVr4GM1CyE3X0KU2tjJMemlTunhodY6bX97nfoM7EDqimGEDTr4g0bRXl+WTlZadnIycqHrEAGDcUXFYlEA88fxyArIwePA6NQxcka2YrOucKctGJVfvl5BYiJjIeJpWHRtinW0zXQUbzGxL9NrYueTwBUfgeAh7eeQCqVijnWRftoRsdvcfnv27h56j4eKq7kEhNZVAGcHPv6nAbtxSFRx7ZeAABEh8di2ZjfS1SrlMwJh1QqRYaiWrOBr5gjK5AhMy0bD64+wrLR62FmbQItXU3lcXtVanw6pJpS2BQbamlmbYKkmBTx/U3xHdG2ho3iNmMkx6QohwWotjEFcpkcptYmeHgzHJpamqha0w75uflIjklRvs6K37fwLHhSsbPhuoqhyKbWJsrlmlqasK1ho9wPpjZFt3m38VC282jGNmwOEufa6DG+Q4mc6W0X4vLBm7h54i4e3hQnRI+JjFfJmbVpPABUeM6Amd0h1dRQ+X9jetuF+MR1Ki4evIGE54klctyb1FRWqm0JXQEAWHPtW7Qe0Ex83VubYNuivQCAr7p/h0v7ryFB8Z6ho6+t3L/ebTyV++h47i5sfbRS3LaJfmKOjUnR+6CNCcxsTJAcm4LQ649hYKynnOvCu51XuXPkMrmiGuYZNs7ZBUfPasrjp5KTtxtbH4tXTOsxqVOJnMZd6qNln6aIuP8Up7dfhJmNadF2tS1/jpmNKXT0tJGnGD5bnpwBX/aCppbYWViYIyuQQVuvaJJqscpEQHJMCrzbesFdMTlr8ZxPlwxSVo4U3qcwLy8nv1gOVNZRC4Lk/f98IP6zHSLa2trw9PSEv3/R2Tu5XA5/f3/Uq1ev1PvU9QSuvdKpfP0OYG6qulwuB64FAN6e4mV4U9IAK6uiagKD6gaIPhINQ0dDuIxxgURDgsS7iXj09BE8jD1g1dwKdb+tC+9vvNHKrxVibGKgbaYN+6722LChaLhLUGoUGpirnqloYOGC5PxMNDQvOvMggQQNzF3wIFWcK0HjlZ7Wu89eoqlTdXxUzxN/3Q1GgVwOH+fqCHz2EkEvY9HUqZqyM8TBwhS5+QW4GaU6L8XSg+fR96cduPIwCgFPojFhgzhB58ztRyCTy3E38mXRygKQmZsHB0tTjF63H6lZ4oemxm7VcO+JuJ6VqQF+n94PIU9jsXDrSdx78hINXash5GksGruJZ56auFfHvScvlffTVJxls69ihulz9iAtPQdBoS/QQNGBUKh+XQekpGahQd2i5RKJOL9HWYJColG/WI6L4gtaenqOyvLX5ez68xpu3o7AvQfPMWrCZoyaIE7mFRuXirS07PLn7LmGm7cicO/+c4wavxmjxr+SU698Obt3XsWtG09w/94zjB25AWNHis+t2JgUMafYHAYSCeCluJpHaYIfPEe9hsXXl0AqlSArKw/1io21lkgAz1LmxSj0KDga/Yc1R36+DAum/4H8PBm8G9VASnIm6jVyUsnxeE1OyL1n8G5UQ2WZdyMnMadx8fZI4FH3dTnP4d1YdS6G+k2dEPLKPCgFBTJElnIJTu8mResWFMgQHVX0YTzk3jN4N3FSWad+U2eEFLvk5auPU5iZkpQJ76bOiHmejKT4dEWOM0LuPoW+gQ7c6lRFSLE5VkIU86SkJGYgJysPrTvXAQQBacmZ8G7qoshJQ8OWrrCrZoF7NyOgb6CDWnWqIjRQNce7qfieUzLHGf5nxfHuPr5e8G7qjJDAp7CyM4GmphQPi21LyN1Xcrp6F+X4uGDR2M1ITcrAwc2XkJqUicuKL6AF+TKc2CuecdPR04IgALVfOVuro6eN+BfJePzgORxd7ZAUlwZvH1dIJBJ4+9REblaeONeBYm6bwrkfHgaqzjUkyAVUcbBCSmIGvFu4IuZpIpJiU2Fb3QJ6BjoICYiAvqEuank7IPR2ZNG2KX7v0L8pzuy7AVmBHHVbuJbI8W5RC94tXBFyOxKudR0g1ZQi9HZEyZwBzXBm73XICuSo18oNIYVf7J4mIi05E5BI8DAgEsd2XBHbU88RplbGCLmtWlnVYaCYE3IrAt4t3VRuq9vCDSkJ6TC3MUFudp7Yvla14N2iFkJuRShziwu5LeYU5orbKeZ4t6xVtJ3lyKnjUwsF+TK8jEpQbKe72M4WtXDn0kMxp2XReHJ9Q90S8+IUbodcLuBlVAJePIkv8/FDFZcZDbv7tERHplRTA6aWRsjOyBW3IypBmePR0AlBN8LgO6ApBEHAtRN3y52Tm5UHuUyOui1d4d2yFkJuPYGOvg4kGhK8UFyhojCnto9rsRwpTK2MkJ2RA+9Wbsr2NPKtDbsa1rh/9RH0DXXhVr8GQgq3KzAKMpkcdV6Ts3DIGqQmpOPAutNITcjA5X/EDqSCfBlO7LzyxpznYS/x+G4UHNztkRSTAu/WbuJrrLU7ohWXJn0S9EyxXVHIy8lH3PNElRyb6pYwtzEVnzOt3cVti0mBraMV9Ax1EXLzCfSNdOHWwAkhii+2ABDyyvxQTrWrQxAEpCVmiDmR8UiKSUGd1u5wb+SM4OthaD/QB3K5HHcVV6gAoJJZWk5BXgEK8grg3cYD3q3dEXIzHDqKEvqokOiyc+qIOSE3xCGthTmJL1Pg3UacXFpHT8wxMjNUrveq2GcJEAQBKcU6XOu390LItcd4fCcSjp5VkZOVi/w8cUiEd1tPhAVGwq2RU4mskOthyErLRr22HnCq6wCZTA7XBk7Q1NZE8I0wxETGI/FlCuq1LarsLLwccEixORa823giJT4N9dp6IiYiXjExpxxujZwRfP0x9I304NbIWXmftTO24dYp8f17fOM5mNtLvLRwdFgM0hIzlDmJL5NRt40n3JvURJD/I/h+3AJyuRyB54NUcu4rrgrzb+TcOBaIxwERcPSoKua09kTSyxTUbeUBbV3tEjnjG81Wbtvc7t8DAL4ZvBKyfDlS4tPg3c4LMRFxSHyZjBq1q6NuG09o6mgi5EYYXOrVQMg1cajyms+24NZJ8b1kXP0v8FU38bLS0Y9jkJaYjnrtaitz6rWvjXrtvBDs/xi1GjlDqiVF8DVxX6+Zuhm3Trx9TuH7UOG8GCo59Wbiq67fKnJeijntxZy0xHRMWTMKORk5OLfninjsm7gg2P9hsZzAN+YkvkxGPV8vmNuZIT0p461yrh8Rv3wV5iS8SFJOKlyYY2ptguBrj7Bm6maM8/68RM7jOxHYPLfocvD1fesoj01uVq5if3kpby/MJXob/9kOEQAYMWIE/vzzTxw8eBDh4eFYuHAhsrOz0bt3bwDArFmz8NNPPynXH9oXuHwD2LwHeBIFrN4MBD0EPh0I7D0C7PkL+Oo7YMo8IDMLqGYPTPxKvOLM7dviizY3KReZkZmQ58qha6uLtEdpiNgZgYwnGTgRdwKtrVqjjWMbuNR0wfgW46GrpYsb+TcgkUowZ9gcODkV/Ue3+8EZNLWohY/rdESN6jUw3LIF3IzssTPsLLrbN0aPKo0xy/0jfFv3E+hLtfEw7Tlme/SFra7qRCjbrt1By5qOqGZugmtPnmFi26bwrGKDXdcDsfVqAPo1rI3dYwahbjU7PElIgp62Fi48fAJLQ/HM+tQuzRGTko6wmESsO3UN3jWqoKGT+OW5masDXO0s8ceVQABilcnyYd0gCAL0dbTRuV4t1Kshlurp6Wjh76tBsDI1wIEFw6Al1cDP+y/CzEgPR66HwMfTAVGxyejdog5+GtcdHg42MDHQhZ62Fo5eC8Gysd0AACEPX0Iq1YC5mQFOng1C4wY10P+jRqhe1RzDP26OWjVt8ce+G+jaqS782nvCvZYdFs7uCT3FF6NqVc2xdEFv5f6pYmeKzKxcNGnkhJHDWqJnt3r4dlEfyOUCdu7xR7fOdeHn6yXmzOmlkvPtoj7KnKTkTGzdeRVeHvZo1KCG8gO0lZUxdv15rdw5ycmZ2LbrKrw87dGoYQ3I5MVy9hTLcbPDgq96QV+RU72aOb4pnpOUie1bL8GzdlU0bOxU1B5rE+zecRVdutVDh0614e5RBfMW9S5qT3VzLP6uvzLHtoop0tOy0bipC4aNbo02vp74bdsYSCQS7N99DV161EOHznXg5lEFc5f0UeZUrW6BxT8MUOboG2ijqoMlDI10EXLvGVzc7DB6age4ulfBvu1X0blXffh2rQs3L3t8tbQf9PQV7XGwxKLlA1We02eO3UMjHxd06yvOUj52uh9cPavg7z030LlXA0VOVXz1XfEcCyz6eZBqzpG7aNTcBd36K3I+94Orpz1OH76rXMfIWA9Orra4qbg0b5fe9eHTVvzCqaunjZOHAmBmYYhFv3ysnFix77AWCA99icYtXWFsoo8Ht6MwZFxbuNWpCo1i84ycPCR+SRk4tg0AYNCYNnD1qooje66jc9+G8O1ZD2ePBGL41I4wNNZFSOBTfL60LwoK5HAp1hGWoDgDOeKzjhgyyReTF/SCAODPDRfRSZFz7vBdfDLZFxIJcOzPm5jxXT9FTlEpbWJsKhq2FL8cDZnsi8kLPyrK6dcI7nWrIzoyAZ37N4aRqT6SE9OxYs9ECIKgcrncxJhiOdM6YrJiyMqfv51DpwFN4NnAEacP3EaPoc2hq6eNIMUH84J8GewVV94JuROFrIwcNFB8UW7Qyg0/7ZsCbR1N/LnuLA5uOI8uHzdDwstkfPxZJ3y/eyKMzQxQu4kzMtKy0bi9J4bP6oqQgEhkpGbBSFEpNOLL7pj24yDYOVrB3MYE+349g06DfNBnXDsEXHoI7xa1oCHVQFpCOuZvGgWZTA6X2kWdan9tFM8m2zlYIvDyI3w8vTNq1qmOfWtPo9NgH0xZNhCP7z/D8C+7w9DUAHYOFvDt3xgF+QVwqVM853yxnIf4eEYX1KxbHf9sEvPr+NSEnoEO5AUyeDRywvA5PbBo+zgUFMigoSHBqd1iqfiMX4Yqc47vvIK/fj+HBm090Htce1R1scHHn3eFq7cDzu2/iapONqjqbIOAiyEYPrsnDEz0EXo7AjNWDUPBK5OY/vX7OTRs5yG271IoPv68K2rWrY59a0+h08fN4du/Cc4duIlhX/YoV462jhYcatlh3uYxqFm3OozM9KGjr4NTu/1x6PezGD6nJ+b8PgqOblUwY9UwZeXGq9shlWrAwdXutY/vopi4OCsjB1cUlSSTfxiMBu08seLYF5BqSrFvzUl0+rgFfPs3xfPwOAyf0wuGZgawr2GFvhM7IC8nH86K416eHB3Fpds/nfcRDE0NkBSXhl/PfQVAnFuieE4NxWu3YXtPrDz5JaSaUuxdfQKdP2kJ3wHNcHbfdXzyRQ9IJMDRbRfx+dpPS2zX5b9vo4Zn1TJzPJu44NQef/Qc3Q66BtoIUnyBLcgvQJUa1mXnnJoNqaYUmxYdxIG1p9BleCvERydjyBc9sOzvGTAy1UfLXg2Ql5MPt4ZOGDHvI2Sl5+DIlguwVlSefLqgN778fTR0DXRgZW+Ofb8cR+ehrdB3sh8CzgXDu7UbNKQaSE1Ix4KdkyArkMFFcQLDvZGTshJg+Pze6DPZD1NXDoMgF/DniqPoPKw1uo9qh8iQaIyY3wfGZoao6e2IVr0bIS8nv1iOM5JiUl+bU1BQAA1NDYxc2BdGZgZIT0rHjydmQy6Xw1DxfqGa0wd9pnTC1JXDIcgF7F91AgBw48Q9ca4HGxN0/bQtJv44BMtPz4VcJocgF3Byx2W4N3bGyvPzAQC2jlZoO9AHVV3sIAgC/Ia1RjVXO8zfMxW1Gjrh+vFAXNh7DV1HtYe2rhaMzQyx5NDn4he1xi5IfCnunxFf94d7Exd8NMkPN47dhZ6RHrqN8cXUVSMQHfYSNevXgFwu4OS2iwCApJhkDFvQF0271oOjZ1Xl5YBtqluhmqsdPvt1FGo1csbZP66g88h2mLxqBDS1xIoafWM9hFwPw8yN41CQL0PNeuKJh/hnidj1rXiCrGGHOpAr5tOzq2GNPT/+jc6ftkX3cb6ICnqOEV/3h7G5AVwb1ECrvk2Rl5NfIsdTcYb/38n5Bwd+OYbOn7ZD4otkDJnXGz+dnQ9Ta2M4elVDUkwKmnapjxGLByD+WSKigp8rt612K3Genfq+tVGjdnXs/fFvdBnZHp9vHI9bJ+7i0yUDYWZtAgf3qsjPyUNBvgwu9ZyUbdr5jVgp3bBjXWU1pZ2TNXZ//xe6jGqHab+NxuOAJ/h0yUAYmRuiipM1OgxtjYK8ApVt27Fk/2tzpq4dhUe3w8UcM0No62piws/DISuQwVnx2lDJ8SueY4Pd3x1Cl1HtMfLbwdAz0oWGVAOa2lI8e/gCc/d8BlmBDDXrF25XAnYs3vfanA5DW+PWiUB8+s1gaOloIj83H4sOzYJcJpQrZ8+yv1Do3B+XYWJpjKq1qqBGner47uQ8yArkkGho4MTmc4h/loD+M3sCACKDnuH5I/EErEtdR7QZ4INqtargkwX9UKuRMwJO3YORuSEMTPRx4c+rGDK/H5p1bwhHr+qYtXUSEl+8MiyA6A0037zK+9OlSxckJSXhl19+QXx8PNzd3bFhwwblkJmXL18qP6gAQD0v4Id5wMqNwM+/Aw5VgVXfAK2bAro6wLodQGw8UHiXH34FmjcEtLWApCSxTC71QSryksXy0+eHnuP5oaIrd9zTuIc9z/agl30vmGiZ4GnWUyx/tBxpBeIHPytj1Tkrrm87ihn/RGHatGmYtG8IIiMjMWHceAR6y5CvIccwp3aw1jVRDpGZ6zUAIanP8DjjBdyMi872Bz57ibvPXsKzig1WD+qOqMQUTP7jbzyOS8TjuEQ4WpphSjtxTL+fp/ifyN+Thirvb2VcNJThbuRLfLnjGKZ1EydKbepaHVM3/42wGPHMkLWJIdp6FZ3Rnf1RW+Xvqw9dQVJ6Fro384CBng4M9HRw4rsxKtvs5WgLDQ2ghVcNQALYmhth0qqDkGpqoE1dMberXx109SuaCXzzjsvo3rkuRg9viefRyfhq8UFcv/UEeXkF+PSTFrA0N4RmsbONC7/sofKY+fkyVLM3R05uPoYMbCYex7RsLPz2EC5efoS8PBlGfNIClhaqOQvm9MSrgkKisfj7fzByWEuMUozh3rXbH3v233y7nOBoLPnuH3z6Ss6f+28iL1+G4UNL5swvJSf4QTS+/foQRoxqg09HtwEA/LHjCvbuuS7mfNoaFpaqOXMX9lbJyM8rgI2tKbKzc/HxcPG4Z2bkYsX3R3D070CkpWRj2OhSchar5rjUsoOjovJm4IiWGDii6FKEl84EIy+3AEPHtoGFlZFKzpxv+5bYrpruVSDVlKK1Yh4Tvx5i1Vd8bBp+X3kSQ8e1LZmztF/JHA9FTkfx7IBfT/GSjfbVLRB8Vzz72bR1LXz+9UfK+3Qf0ATdB4iXzp07YRtSkjIxZFxbNGlddFZ+0OjWAMShPfm5Bfhuwwi8eJqIqLA4aBbrEDFXfCDtrOjYaemnOEshAL//eByfTGoPM0sjpCVnQktHE9+sH46ggCg8DY9TGWJkohj+1G9Ua0AAEuLSsGrhQdy8+Aj5eQUYMtkX5pZGEOQC8mUyzF05GEEBUXgWHgeTYjnGZgbIzS2AvqYUg8e1E3MWHMTNiw+Rn1uAIVPEnLzcfGjraGH6N32RmpSJiIcxKkOujM2L5UzwRUJcKlZ9tR83L4SK7ZnmB3MrI6Qmids1cpbY2fn8STxMFEOY0pKzMGfoekxd2hfO7vZYvHUMcnPysf3nY7iqqCjxauKMTgOaQlNLCq/GThAE4PmTOCweswmTv+0HWYEMacmZmDdsPYYpJnbtO6E9AAniXyRjzZw/cfNsMPJz8zFqXi/lhG8AMO0ncS6m8KDnMCk2yW5hBUdudh7mbxyF6Ih4LB75uyKnAENmdIaRYlibVFMKv0E+iAx9gbycfJhYFA1lCblVLGfTGDFnxHrlFUh8+zdV6WQaMFmcNDI7MwdzB61BimIYlLW92AEedCMczxVVTN9P2IRhX/TA8Nk9EB0Rj/SUTPQeJ85DUN3VFtVdxeETWRk5WPLHJATdCMezRzHKYR9i+54g5HYEatapjvmbxyra9xtungkSt3NWN5hbGSuPYXlyNDWlaOzrBUAC66rmmDdoNVIS0rF39Sl0HdYKjX290KRDbQTdCMeXvVdgw9WF6DykhXI7gm6EQ1NLiguHbr328U2KTVa8bOIWtOrZEH6DfdD5kxbIycrF6i/+wNGtl5CRmoUhs7rBSrEPNbWk6DDIBxFB0SjIL1A5XssmbH5tTp8JHQAIkMvEifpmrByKjJQsPH30UlmlVJijrauFpn51sXj3FDFn5k4c2XIRGSnZ+OTLHjCzNoYgCMjPK8C8zeMRdD0MTx++hKllsfaM3wRtPW006/T6nLSkDGhpa2HkAvF99Pnj2LJz/pwq5ny+EyE3wxFyE/Bo7IIuw1tBS1sTXj6ugADEPk/EkmG/Yszi/soJRTfM3wdZgQx9J/mh7+ROgAR4GRGPdbN34+ap+8jLzcfor/srJzEEgM9WDRdfY/efKtuUn1ugvEpQ/8+6QgLxKi7fjfoN144GIi8nH/2nd4GFneKYaUrRvEd9PL4TJQ6tKMzJy1dWUpSV03dKJ8hlAiAI0NHVxpSVw5GamIHI4Gjla1glZ3qxnJHrlFUkdy+G4PuRv2Hs0kEwszZBt9HtFPs65v/au/M4G8v/8ePvY88uYpCSfRtmbINs2RmETJY+WSpRkRKhRD4lX5GQfU/ZlZRClpJQEtqEhOzGFCbbGHPevz/8zvmcM+tZLuY+c17Px6PH9/s5c87bdV33dd33fa7zvu5LJvSbKxfPx0qhYgXk3jK3xt3sPf8nZ4+dl5Xvfi7njp+X/7zaSXqNjpJLMf9KzOkL8sqiW5NEMaf/kRw5s0ueArkkrHElUVXJkjWzvNp+vMz/ZbzcHZJf4uPipVFUHSlRrqjYExIkU6ZMkiNXdilRtpicPHxWxj81Sy7+/yVGV/+9Lif/OCMDpz4hufPnlN923PqVvEXPhvL4yEck5uQ/curwOWnZs5HYbDZp1aux8+GYWbNnlbc+e1l+23FIjh84Jflclrg5MhhaP/mQhJS8dY2fOeRD+WzmRom/Hi9dBrf//9uY2iRLFpEH29eSP/YeFVVNEuf/ek6TEUsGyptrhhqP89f+k/LX/pNS5P5C8vjIzpI1WxapVKesqF3lj71HZVyv6TJw+pNuk7qOuj3U5dY9cnjTUHn9kQnyw/p9kilLZukxKurWeVrFuczpZnyCHP/9lOR3efD1/p232rpNn6YS8v+fTzdz0CJZM32DxF+Pl8dHRUneu3OLikjmrCKtnmwiR385Ljeux3sXZ2RnyVMwj4ioZMmaRR5/LUpOHzknly9cSSFOc5c478uaaeslPi5enhz7mGTNdmusZs6SWUZ/fGvp9pXYq5L/nnwex+k5uosUvq+Q8zlDjkkQEfEozrHf/pd5Wr9ThHP5YbFSIVKs1K3xNKDOcOfDggvfl/SRCPNeWSJt+jSX3mO638pe+eeyjFw12Pn3sIdu3Xe9MKuv5M6fU3799oAMbz1GFh6ckiRWhpOBdnlJbzZ1fYJVgLKfLZf2m9KQKeSQ9P6ht99xFtRaIA9uHOp3nO3Nx0nFke/6Hef3/74ooS/5H+eXd16U6v38j7Nn5ovSqM3bfscREdn6xcvSuNU4v+N8vX6osTgPtfQ/zlcbhkqzhmP8jrPpm1eleb03/Y6zcccIaVlrtN9xNvwwSlrWfN3/OLtfl5bho/yPs3e0tKr2mt9x1v/0hrSq/Kr/cX4bI60rveJ3HBGRdfvfktYVh/sf5/ex0rrMEP/jHB4vrUu+6H+cY+9K63uf9z/OySnSuvgA/+Ocek9aF30u7TemFefMNGkd8qz/cc5Oz7hxijzjf5xzM4zEccRqVejptN+YhvUxs83FubuP/3H+mSOtCjzlf5wLc6VVvif8j3Npvrk4ef2/x1sfu0Ba3vW433E2XPvAXJwcyT+I36s41xcbiWMylsk4LbJ2TfuNafgyfpk0z9wl7TemYWPCcnNxMiX9ocjrOPaVGTZORldq0sT0LoIceWFQehfBCEtniAAAAAAAABcBn9JgHZZ+hggAAAAAAMDtwIQIAAAAAAAIOiyZAQAAAAAgQNhYMmMMGSIAAAAAACDokCECAAAAAECgIEPEGDJEAAAAAABA0GFCBAAAAAAABB2WzAAAAAAAEChYMmMMGSIAAAAAACDoMCECAAAAAACCDktmAAAAAAAIEDaWzBhDhggAAAAAAAg6ZIgAAAAAABAo1JbeJcgwyBABAAAAAABBhwkRAAAAAAAQdFgyAwAAAABAoOChqsaQIQIAAAAAAIIOEyIAAAAAACDosGQGAAAAAIAAYWPJjDFkiAAAAAAAgKBDhggAAAAAAIGCDBFjyBABAAAAAABBhwkRAAAAAAAQdFgyAwAAAABAgOChquaQIQIAAAAAAIIOGSIAAAAAAAQKMkSMIUMEAAAAAAAEHSZEAAAAAABA0GHJDAAAAAAAgYIlM8aQIQIAAAAAAIIOEyIAAAAAACDosGQGAAAAAIAAYWPJjDFkiAAAAAAAgKDDhAgAAAAAAAg6TIgAAAAAAICgw4QIAAAAAAAIOjxUFQAAAACAQMFDVY0hQwQAAAAAAAQdJkQAAAAAAEDQYckMAAAAAAABwsaSGWPIEAEAAAAAAEGHDBEAAAAAAAIFGSLGkCECAAAAAACCDhMiAAAAAAAg6LBkBgAAAACAQMGSGWPIEAEAAAAAAEGHDBEAAAAAAAIE2+6aQ4YIAAAAAAAIOkyIAAAAAACAoMOSGQAAAAAAAgVLZowhQwQAAAAAAAQdJkQAAAAAAEDQYckMAAAAAAABgl1mzCFDBAAAAAAABB0yRAAAAAAACBRkiBhDhggAAAAAAAg6TIgAAAAAAICgw5IZAAAAAAACBUtmjCFDBAAAAAAABB0mRAAAAAAAQNBhyQwAAAAAAAHCxpIZY8gQAQAAAAAAQYcMEQAAAAAAAgUZIsaQIQIAAAAAAIIOEyIAAAAAACDosGQGAAAAAIBAwZIZY8gQAQAAAAAAQYcMEQAAAAAAAgTb7ppDhggAAAAAAAg6TIgAAAAAAICgw5IZAAAAAAACBUtmjCFDBAAAAAAABB0mRAAAAAAAQNBhyQwAAAAAAAGCXWbMIUMEAAAAAAAEHTJEAAAAAAAIFGSIGEOGCAAAAAAACDpMiAAAAAAAgKDDkhkAAAAAAAIFS2aMIUMEAAAAAAAEHSZEAAAAAABA0GHJDAAAAAAAAcKW3gXIQMgQAQAAAAAAQYcMEQAAAAAAAgUPVTWGDBEAAAAAABB0mBABAAAAAABBhyUzAAAAAAAECBtLZowhQwQAAAAAAAQdMkQAAAAAAAgUZIgYQ4YIAAAAAAAIOkyIAAAAAACAoMOSGQAAAAAAAgVLZowhQwQAAAAAAAQdJkQAAAAAAEDQYckMAAAAAAABwsaSGWPIEAEAAAAAAEGHDBEAAAAAAAIFGSLGkCECAAAAAACCDhMiAAAAAAAg6LBkBgAAAACAAMFDVc0hQwQAAAAAAAQdMkQAAAAAAAgUZIgYQ4YIAAAAAAAIOkyIAAAAAACA22ratGlSsmRJyZEjh0RERMiuXbtSff/KlSulQoUKkiNHDgkNDZUvvvjC+bf4+HgZOnSohIaGSq5cuaRYsWLSo0cPOX36tFdlYkIEAAAAAIAAYdP0/89by5cvl0GDBsmoUaNkz549Uq1aNWnZsqVER0cn+/4dO3ZIt27d5Mknn5S9e/dKhw4dpEOHDvLrr7+KiMjVq1dlz5498tprr8mePXvk448/loMHD0r79u29KhcTIgAAAAAA4LaZOHGi9OnTR3r37i2VKlWSmTNnSs6cOWX+/PnJvn/y5MnSqlUrGTJkiFSsWFHeeOMNqV69ukydOlVERPLlyycbN26URx99VMqXLy916tSRqVOnyo8//ijHjx/3uFxMiAAAAAAAAI/FxcVJbGys239xcXHJvvfGjRvy448/SrNmzZyvZcqUSZo1ayY7d+5M9jM7d+50e7+ISMuWLVN8v4jIpUuXxGazSf78+T2uBxMiAAAAAAAECk3//8aOHSv58uVz+2/s2LHJFjcmJkYSEhKkSJEibq8XKVJEzp49m+xnzp4969X7r1+/LkOHDpVu3bpJ3rx5k31Pcth2FwAAAAAAeGz48OEyaNAgt9eyZ8+eLmWJj4+XRx99VFRVZsyY4dVnmRABAAAAACBQ+PBQU9OyZ8/u8QRIoUKFJHPmzHLu3Dm318+dOychISHJfiYkJMSj9zsmQ/766y/ZsmWLV9khIiyZAQAAAAAAt0m2bNmkRo0asnnzZudrdrtdNm/eLHXr1k32M3Xr1nV7v4jIxo0b3d7vmAz5448/ZNOmTVKwYEGvy0aGCAAAAAAAuG0GDRokPXv2lJo1a0rt2rVl0qRJcuXKFendu7eIiPTo0UOKFy/ufA7JwIEDpVGjRvLOO+9IZGSkLFu2THbv3i2zZ88WkVuTIZ07d5Y9e/bI2rVrJSEhwfl8kbvvvluyZcvmUbmYEAEAAAAAIEDYLLBkxltdunSR8+fPy8iRI+Xs2bMSFhYm69evdz449fjx45Ip0/8WsNSrV0+WLFkiI0aMkFdeeUXKli0rn3zyiVSpUkVERE6dOiWffvqpiIiEhYW5/VtfffWVNG7c2KNyMSECAAAAAABuq/79+0v//v2T/dvXX3+d5LWoqCiJiopK9v0lS5YUVf9nhniGCAAAAAAACDpkiAAAAAAAECgCcMmMVZEhAgAAAAAAgg4ZIgAAAAAABAibgWdn4BYyRAAAAAAAQNBhQgQAAAAAAAQdlswAAAAAABAoWDFjDBkiAAAAAAAg6JAhAgAAAABAgLCRIWIMGSIAAAAAACDoMCECAAAAAACCDktmAAAAAAAIFCyZMYYMEQAAAAAAEHSYEAEAAAAAAEGHJTMAAAAAAAQIdpkxhwwRAAAAAAAQdMgQAQAAAAAgUJAhYgwZIgAAAAAAIOgwIQIAAAAAAIIOS2YAAAAAAAgQPFTVHDJEAAAAAABA0GFCBAAAAAAABB2WzAAAAAAAEChYMmMMGSIAAAAAACDokCECAAAAAECA4KGq5pAhAgAAAAAAgg4TIgAAAAAAIOiwZAYAAAAAgEChrJkxhQwRAAAAAAAQdMgQAQAAAAAgQPBQVXPIEAEAAAAAAEGHCREAAAAAABB0WDIDAAAAAECgYMmMMWSIAAAAAACAoMOECAAAAAAACDosmQEAAAAAIEDY7OldgoyDDBEAAAAAABB0yBABAAAAACBQ8FBVY8gQAQAAAAAAQYcJEQAAAAAAEHRYMgMAAAAAQICwsWTGGDJEAAAAAABA0GFCBAAAAAAABB2WzAAAAAAAECiUNTOmkCECAAAAAACCDhkiAAAAAAAECB6qag4ZIgAAAAAAIOgwIQIAAAAAAIIOS2YAAAAAAAgULJkxhgwRAAAAAAAQdMgQAQAAAAAgQPBQVXPIEAEAAAAAAEGHCREAAAAAABB0WDIDAAAAAECgUNbMmEKGCAAAAAAACDpMiAAAAAAAgKDDkhkAAAAAAAIEu8yYQ4YIAAAAAAAIOmSIAAAAAAAQKMgQMYYMEQAAAAAAEHSYEAEAAAAAAEGHJTMAAAAAAAQIHqpqDhkiAAAAAAAg6DAhAgAAAAAAgg5LZgAAAAAACBR21syYQoYIAAAAAAAIOmSIAAAAAAAQKEgQMYYMEQAAAAAAEHSYEAEAAAAAAEGHJTMAAAAAAAQIG0tmjCFDBAAAAAAABB0yRAAAAAAACBRKiogpZIgAAAAAAICgw4QIAAAAAAAIOiyZAQAAAAAgQPBQVXPIEAEAAAAAAEGHCREAAAAAABB0WDIDAAAAAECgYMmMMWSIAAAAAACAoEOGCAAAAAAAAcKmpIiYQoYIAAAAAAAIOkyIAAAAAACAoMOSGQAAAAAAAoU9vQuQcZAhAgAAAAAAgg4TIgAAAAAAIOiwZAYAAAAAgADBLjPmkCECAAAAAACCDhkiAAAAAAAEChJEjCFDBAAAAAAABB0mRAAAAAAAQNBhyQwAAAAAAIGCh6oaQ4YIAAAAAAAIOmSIAAAAAAAQIGwkiBhDhggAAAAAAAg6TIgAAAAAAICgw5IZAAAAAAACBQ9VNYYMEQAAAAAAEHSYEAEAAAAAAEGHJTMAAAAAAAQImz29S5BxkCECAAAAAACCDhkiAAAAAAAECh6qagwZIgAAAAAAIOgwIQIAAAAAAIIOS2YAAAAAAAgUrJgxhgwRAAAAAAAQdMgQAQAAAAAgQNh4qKoxZIgAAAAAAICgw4QIAAAAAAAIOiyZAQAAAAAgULBkxhgyRAAAAAAAQNBhQgQAAAAAAAQdlswAAAAAABAo7OldgIyDDBEAAAAAABB0yBABAAAAACBA2HioqjFkiAAAAAAAgKDDhAgAAAAAAAg6LJkBAAAAACBQsGTGGDJEAAAAAABA0GFCBAAAAAAABB2WzAAAAAAAEChYMmMMGSIAAAAAACDokCECAAAAAECgsKd3ATIOMkQAAAAAAEDQYUIEAAAAAAAEHZbMAAAAAAAQIGw8VNUYMkQAAAAAAEDQIUMEAAAAAIBAQYaIMWSIAAAAAACAoMOECAAAAAAAuK2mTZsmJUuWlBw5ckhERITs2rUr1fevXLlSKlSoIDly5JDQ0FD54osv3P7+8ccfS4sWLaRgwYJis9lk3759XpeJCREAAAAAAAKFavr/56Xly5fLoEGDZNSoUbJnzx6pVq2atGzZUqKjo5N9/44dO6Rbt27y5JNPyt69e6VDhw7SoUMH+fXXX53vuXLlitSvX1/GjRvnc1MyIQIAAAAAAG6biRMnSp8+faR3795SqVIlmTlzpuTMmVPmz5+f7PsnT54srVq1kiFDhkjFihXljTfekOrVq8vUqVOd73n88cdl5MiR0qxZM5/LxYQIAAAAAADwWFxcnMTGxrr9FxcXl+x7b9y4IT/++KPbxEWmTJmkWbNmsnPnzmQ/s3PnziQTHS1btkzx/b5iQgQAAAAAgECR3stlVGXs2LGSL18+t//Gjh2bbHFjYmIkISFBihQp4vZ6kSJF5OzZs8l+5uzZs16931dsuwsAAAAAADw2fPhwGTRokNtr2bNnT6fS+I4JEQAAAAAAAoU9vQtwa/LD0wmQQoUKSebMmeXcuXNur587d05CQkKS/UxISIhX7/cVS2YAAAAAAMBtkS1bNqlRo4Zs3rzZ+ZrdbpfNmzdL3bp1k/1M3bp13d4vIrJx48YU3+8rMkQAAAAAAMBtM2jQIOnZs6fUrFlTateuLZMmTZIrV65I7969RUSkR48eUrx4cedzSAYOHCiNGjWSd955RyIjI2XZsmWye/dumT17tjPmP//8I8ePH5fTp0+LiMjBgwdF5FZ2iaeZJEyIAAAAAAAQIGyq6V0Er3Xp0kXOnz8vI0eOlLNnz0pYWJisX7/e+eDU48ePS6ZM/1vAUq9ePVmyZImMGDFCXnnlFSlbtqx88sknUqVKFed7Pv30U+eEiohI165dRURk1KhR8vrrr3tULiZEAAAAAADAbdW/f3/p379/sn/7+uuvk7wWFRUlUVFRKcbr1auX9OrVy68y8QwRAAAAAAAQdMgQAQAAAAAgUATgkhmrIkMEAAAAAAAEHTJEAAAAAAAIFHYyREwhQwQAAAAAAAQdJkQAAAAAAEDQYckMAAAAAACBgoeqGkOGCAAAAAAACDpkiAAAAAAAECjIEDGGDBEAAAAAABB0mBABAAAAAABBhyUzAAAAAAAECpbMGEOGCAAAAAAACDpMiAAAAAAAgKDDkhkAAAAAAAKFnSUzppAhAgAAAAAAgg4ZIgAAAAAABAq1p3cJMgwyRAAAAAAAQNBhQgQAAAAAAAQdlswAAAAAABAolIeqmkKGCAAAAAAACDpMiAAAAAAAgKDDkhkAAAAAAAKFnSUzppAhAgAAAAAAgg4ZIgAAAAAABAoeqmoMGSIAAAAAACDoMCECAAAAAACCDktmAAAAAAAIFCyZMYYMEQAAAAAAEHTIEAEAAAAAIFCQIWIMGSIAAAAAACDoMCECAAAAAACCDktmAAAAAAAIFHZ7epcgwyBDBAAAAAAABB0mRAAAAAAAQNBhyQwAAAAAAIGCXWaMIUMEAAAAAAAEHTJEAAAAAAAIFGSIGEOGCAAAAAAACDpMiAAAAAAAgKDDkhkAAAAAAAKFnSUzppAhAgAAAAAAgg4TIgAAAAAAIOiwZAYAAAAAgAChak/vImQYZIgAAAAAAICgQ4YIAAAAAACBgoeqGkOGCAAAAAAACDpMiAAAAAAAgKDDkhkAAAAAAAKFsmTGFDJEAAAAAABA0CFDBAAAAACAQGFn211TyBABAAAAAABBhwkRAAAAAAAQdFgyAwAAAABAoOChqsaQIQIAAAAAAIIOEyIAAAAAACDosGQGAAAAAIAAoewyYwwZIgAAAAAAIOiQIQIAAAAAQKDgoarGkCECAAAAAACCDhMiAAAAAAAg6LBkBgAAAACAQGFnyYwpZIgAAAAAAICgw4QIAAAAAAAIOiyZAQAAAAAgUKg9vUuQYZAhAgAAAAAAgg4ZIgAAAAAABAjloarGkCECAAAAAACCDhMiAAAAAAAg6LBkBgAAAACAQMFDVY0hQwQAAAAAAAQdMkQAAAAAAAgQPFTVHDJEAAAAAABA0GFCBAAAAAAABB2WzAAAAAAAECh4qKoxZIgAAAAAAICgw4QIAAAAAAAIPprBXb9+XUeNGqXXr18nTgDEsWKZiEOcjBTHimUiDnGsEMeKZSIOcTJSHCuWiTjBGQdwleEnRC5duqQiopcuXSJOAMSxYpmIQ5yMFMeKZSIOcawQx4plIg5xMlIcK5aJOMEZB3DFkhkAAAAAABB0mBABAAAAAABBhwkRAAAAAAAQdDL8hEj27Nll1KhRkj17duIEQBwrlok4xMlIcaxYJuIQxwpxrFgm4hAnI8WxYpmIE5xxAFc2VdX0LgQAAAAAAMCdlOEzRAAAAAAAABJjQgQAAAAAAAQdJkQAAAAAAEDQYUIEQFDhsUnBi2MfeDhmAADgdgrYCZGbN2+mdxHcmLxp4wYQGYUV+/L58+dFxEzZrHYeMsmKx85fFy5cSO8iuImPj0/vIlie1Y6Zg4nxkdHGmKM+puqVkJBgJI4V29lqbWQlGfm8aJW+aLIc169f9zuG6XMH4K2AnBBZv369rFmzRkSsczEwcUL48ccf5fr162Kz2fyOZbpd7Ha70Xi+ev/992XIkCHG4vl78r18+bKhktxisp39rdvff//tdxlM9GVX/tbpgw8+kHvvvVd+/vlnv8q2c+dOERHJkiWL32PNccz9rVt8fLxbDF/jrVmzRqKjo/0+drt27ZLff//drxjJ8bVey5cvl7p168rRo0cNl8g3X3zxhSxatEguXrxoLKap84dVzvemjtm1a9ckNjbW7/L8+eefcuDAATl48KDYbLZ0H2OOySKr/CBz9epVSUhIkBs3bvhVhp9++klERDJnzuzX+fXGjRuiqs529rVuN2/eNNbGBw4cEBH/r42m2siUjz76SHbt2uV3HFPnxZMnT8qZM2fkxIkTIuL7sd+3b5+cOXPGr7KImOuLply4cEGuXbvmbGd/zmXjx4+X6Ohov8pz5coVsdvtznNHercPgk/ATYgsWLBA2rRpI6NGjRKRWxcDX5kacPPnz5c+ffpIXFyczzEWLFggkZGRsmzZMr9vRtesWSMvvPCCtGnTRj7++GO5cuWKT3GOHj0qhw8fluPHj0umTL53Fcekgb/1mj9/vvTu3Vtmz57t14X30KFD8sMPP8j+/fv9uilZtmyZPP30084bHF+dPXtWzp49K3///bdf7fztt9/K0qVLZdq0aRITE+NX/160aJFERUXJb7/95vNxW79+vbzyyisyYsQIWbx4sc9l+eqrr+Trr78WEfHrS8jMmTOlV69ekjVrVueEhi83kmvXrpUHH3xQmjdvLiK3zkG+Zop8/vnn8v7778vly5f9qtuKFSukb9++0rhxYxk+fLjs2LHDp749Z84c6dixo999+v3335c6derI9u3bRcT3sf/tt9/K1KlT5d1335UtW7aIiG9fJGbOnCndunWTP//8U/744w8R8e3Yf/755zJs2DBp3769LFmyRE6fPu11DBGRefPmSVRUlMTHx8u1a9dExLfr0U8//SQbNmyQZcuWiapKpkyZfG7ro0ePyp9//imnT5/2+Ty0a9cu2bdvn0+fTczUMVuxYoVERUVJRESE9O3b1+f2WbRokbRt21batWsn1apVk08//TRdx9jChQulRIkSsnPnTr/OHVu3bpWZM2fK8OHDJSYmRmw2m09ttHLlSunVq5dERETI0KFDncfMW6tXr5bw8HDp3bu3iPj+hX/FihXy1FNPSaNGjeS///2v7N6926d2+uSTT+S5556TBg0ayNixY+XgwYNel8XB0af/+usvn2OImGujnTt3ypw5c2Tx4sV+9cfZs2dLVFSUz/eaDqbOix9++KE8/PDD0rhxY2natKls3brVp7E6depUadiwod8/fJnqi6bOr8uWLZOuXbtKrVq1pEePHrJnzx6f2mfevHnSvXt3KViwoF8TGUuWLJFu3bpJzZo1pU+fPrJlyxbjP6YBadIAMnPmTM2SJYsOGTJEK1WqpMuXL/c51vLly3XChAkaHx/vd5lsNpuuWbPG7XW73e5xjGXLluldd92lixcv1qtXr/pVnnnz5mmePHm0f//+2qhRIy1cuLD+9ttvPsUpU6aMVqtWTfPmzav9+vXTrVu3eh1n/vz5WrRoUWcZEhISvI6h+r9jP3bsWK1SpYpOmDDBp3gLFy7UsmXLarly5dRms+l7773ndVnsdrv+/fffWqpUKbXZbNqlSxc9fPiw8+/elGnx4sVap04dLVWqlIaEhOhnn33mdQxV1Tlz5mj+/Pk1PDxcixUrpiEhITp16lQ9ffq0V3FUVd9//33NmTOnvvfee3r+/HmvP6+qumDBAs2ZM6c+/PDDWq9ePc2ZM6dGRUXp0aNHvYqzfPlytdlsWrduXd28ebPzdW/Gl6rq7NmzNXPmzLpx40Z9/vnntXTp0l7HcFi7dq2Gh4dreHi4NmrUyOcy/fbbb2qz2bR69eq6aNEivXLlik/lcRyv8ePH6/PPP6+PPPKI3nXXXfrxxx97FWfWrFmaJUsWXbVqlU/lcJg5c6ZmzZpVq1evrpUqVdLo6Gif4sybN08LFy6szZo103LlymlYWJiuXLnS6zizZ8/WLFmy6KZNm7Rz585au3Ztn8ozf/58zZ8/vz799NPaqFEjLVeunE6cOFFVvTv2W7du1cKFC+vSpUtVVfXGjRuqqnrp0iWvYs2fP1/LlCmj5cuX1yJFimiNGjW8qY6befPm6f3336+lSpXS7Nmz60svvaQ7duzwKsaSJUs0c+bM2qVLF927d6/PZVE1d8wWLlyoefPm1REjRui4ceM0T548OnbsWK/jLF26VPPkyaNLlizRb775Rp977jmtXbu289h5esxMjTFV1UcffVRtNpvmz5/feW2+efOmVzHmzp2rRYsW1aZNm+q9996rpUuX1mvXrnldlnnz5mmuXLn0rbfe0gEDBmjNmjV18uTJqur9eXHOnDlaqVIlbdiwofbs2dP5ujfXxA8//FCzZ8+uw4cP165du2qTJk20YMGC+sknn3hVpgULFmiePHl0+PDhGhUVpfXq1dMBAwbo9evXvaqT6q1jb7PZkj2HpUcbzZ07VwsXLqwPPvigFihQQHv37q3//vuvV+VQ/d9YTalPe1o3U+fFDz/8UHPlyqULFizQpUuXapcuXbRLly4efdbVzJkzNVu2bM7yJOZNeUz0RVPnV8e92eTJk3Xs2LHavHlzHThwoNdxvvvuOy1WrJguXrxYVVWvXbumcXFxXt8zLlu2TLNnz65vv/22Dho0SKOiojRz5sw6bdo0r8sE+CNgJkRmzZqlWbNm1bVr16qqanh4uHbv3t2nWKtXr1abzaY2m03feustn7+kz5kzR7Nly+a8EFy9elXtdrtevnzZ4xjx8fHatWtX503an3/+qfPnz9eXXnpJt2zZoidPnvQ41g8//KD333+/fvrpp87XqlWrpmvWrHGrY1on4LVr12qBAgV08eLF+tdff+nHH3+shQsX1tDQUP3oo488Ls+XX36pISEhWrRoUb8mRd577z3Nli2brl69WlVVhw0bpvfcc4+eOnXKqzjvv/++5s6dWz/44AM9ceKEjhkzRvPmzauxsbFexXEYPny4/t///Z8WKlRIIyMj9cCBA159/oMPPtDcuXPr7NmzdfXq1Tpo0CDNnj27/vHHH17F+eWXX7REiRL60Ucf6aVLl9Rut+uAAQO0QoUKOmTIED1x4oTHsY4fP65Vq1bVGTNmqKpqTEyM/vjjj7p9+3aP2/vUqVNavnx5nT17tqreGhc7duzQokWLauPGjfXQoUMexdm1a5eGh4frY489pu3bt9dmzZrppk2bnH/39EZixowZarPZnH33l19+0ZIlS+rUqVM9+nxi69ev17CwMP3kk0+0QoUK+tBDDzn/5joxlpajR49qhQoVtG7dulqhQgV9//339eLFi16V5dSpU1qnTh1dtGiR87Vdu3Zp1qxZNVOmTM7X02qrpUuXqs1m040bN6qq6pEjR3ThwoX64osv6qpVq/TgwYMelccx8bR69WrdtWuXlipVyjkx482Xtc8++0wLFSqky5YtU1XVQ4cOadeuXfW5557zqD4Ojglrxzl6zZo1WqZMGefEo6dxNm7cqMWLF3f7MjNkyBAtXbq0xsXFeVwvVdUpU6Zohw4dVFV1//792q1bN61Xr55GRER4/EV51apVmidPHl2xYoUeO3ZM9+7dq5UrV9aRI0d6VRZV1c2bN2vu3Ll1wYIF+tNPP+m8efM0PDxcW7VqlWSiPyU7d+7UKlWqaIcOHbROnTras2dPn2/aTR2zw4cPa7ly5fTDDz90vta/f3+dOXOmV1/8Ll++rJGRkfrmm286X1u6dKn26NFDf/31V4/raWqMOa6fgwcP1qFDh+rLL7+sd911l3711VeqemuceTLWli9frnny5NHVq1frv//+q6dPn9Z7771X9+zZ41E5HNauXauFCxd2uzfo3r27jhs3TuPi4pxt7elxW7p0qUZEROjkyZM1NDTU7Qv/hQsX0vz8tWvXtFWrVjp69GjnawcOHNABAwa49au0yrN161a9//77necgVdVJkybpvffe6/WXvvfff19tNpt+8cUXqqp6/vx5/f3333Xr1q1enz9U/W+j9evX6913360rVqxQVdWPP/5Yc+bMmeRewdPrhuPYHz58WN99913t0aOHTpgwQX/88UeP4qiaOS/GxMRo48aN3X7oeuedd/S5557TU6dOeXxvNXfuXM2WLZvzfH/q1Cn98ssvdfny5frNN98435dWvUz1RVPn1/Xr12vRokXdrmODBw/WYcOGaWxsrJ47d86j8qiqLlq0SJs2baqqt37ciYyM1OrVq+v999+vkyZN8ui+OiEhQaOiovTFF190vnbx4kUdN26cZs6cWd99912PywP4KyAmRL744gu12WzOL8SqtyY1cufO7fYFyRN//fWXtmvXTl955RWdNm2aZsqUSf/73/96/SX9m2++UZvNpi+//LKq3jrJdevWTWvWrKkPPPCATp482aMvorGxsVqqVCldu3atnjp1SkuWLKktWrTQsmXLatmyZfU///mPxzdKa9eu1dDQUP3rr7+cr9WqVUsfe+wxrVmzpo4ePVp///33NOM888wz+uyzz6rq/05E/fv31wIFCmi9evV03bp1aca4cOGCvvDCC9qvXz/du3evtmvXTgsVKuT1pMjevXu1QIECzhO43W7X77//XsuWLavz58/3ONbu3bu1atWqumDBAudr+/bt044dO+qmTZt0+/btHk8cONrkP//5j86YMUOPHj2qefPm1U6dOunBgwe1V69e+ueff6Ya4+eff9awsDBnHVRv/RKSuIye+O677/Tee+9Nkgk0ZswYrVSpko4ZM8bj7IODBw9qWFiYXr9+Xffv36+VK1fW8PBwzZYtmzZp0sSjsp05c0ZLly7t/NXS0V7Hjx/XYsWKadu2bT0qy86dO7VDhw56+PBh/eqrr7Rt27ZeT4qcOHFC27Zt65YtERsbq02aNNH27dt7VI7ETp48qR07dtRr167pZ599ppUrV9YmTZpoaGioTpkyxaNfDx0Tp1FRURodHa09e/bUChUq6Mcff6yXLl1y3qim5ciRI1q0aFH98ssv3V7v2LGjRkVFafbs2XX79u2pxoiLi9OhQ4eqzWbT3377TU+dOqWlS5fWBg0aaOnSpbVy5cpav359/eGHH1KNM3nyZLXZbM5fvlRV69ev7zZh5IlLly5p79693W6SVFWnTZumpUqV8njC+dChQ1qjRg2368b58+e1QoUK+sQTT3hcnmvXrumoUaO0f//+Ghsb68wqPHjwoJYuXdrjLCxHX33++ee1X79+qqpavHhxHTBggI4ePVr79++vNptNZ86c6fb+xE6dOqXNmzd3Zsmp3ppY79Gjh3bt2tXjejmMHTtWmzVr5vba119/rW3bttWmTZt6dI1dt26dRkVF6enTp3X58uVao0YNn27aTR0z1Vvn99KlS7tNVNerV0+rVaumxYsX18jISOckQmr++ecfLVWqlDPjQVW1TZs2WqRIEa1YsaJmy5ZNhwwZkmq2qakx5mrp0qXatWtXvXjxonbp0kVz5cqlX3/9tT722GO6fv36VD977Ngxbdy4sXPiW/VWP69Vq5a+9tpr+uSTT+rmzZudv86n5Pr16zplyhQdPXq0W3Zrw4YNNSIiQsuXL69NmzZ1TgJ5Yvfu3dq1a1eNj4/XKVOmaI0aNbRXr14aGhqqS5YsSTOrNzY2VsuUKeM2PlRV//77b33hhRf0rrvucvtSmxzHv/3EE09oTEyMc4LpwoULWrp0af3pp588rs+BAwc0f/782qZNG1X9X9uXLl1a7777bi1Xrpx+9dVXXn3p87eNhgwZ4pY1cePGDW3WrJlOnjxZp06dmuR6khLHOf+zzz7T3377TUuWLKmtW7fW2rVr64MPPqj33nuvbtmyJdUYps6LqqqnT5/WIkWK6AcffOB8rWXLlnrfffdp2bJlNX/+/M4fQpKLY7fb9erVq1qoUCEtWbKk2u12/fnnnzU0NFTDw8O1YMGCWqhQIX3ppZc8ah8TfVHVzPk1ISFBFy9erK+++qrbhHCTJk20QoUKWqZMGS1dunSakzSO1ydMmKCdO3fW+Ph4vf/++/XFF1/U2bNn67hx49Rms+krr7ySahzVW+fFWrVq6bBhw5L87Z133kk2+x64XQJiQuT8+fO6c+dOVf3f4Dp69KjWrFnTOZA8/YJ94sQJffvtt51fEubNm6eZMmXSN954w6tJka1bt2qzZs20Y8eOOm3aNC1durQ++eSTOmbMGH311Vc1b968OnjwYGfWSErsdru2b99eZ8+erf369dMBAwY4Z1YXLFigdevWdWaPpHXBXLJkiRYsWFCXL1+uhw8f1g4dOuj999+v06ZN0wEDBmi9evX0+eefT3VZjt1u1zZt2ugzzzyjqv9LW3zllVc0KipKGzZsqH369NH4+Pg0y7NmzRrdtm2bqt66iW/btq3bpIgnNwCnTp1yZhS4vr9NmzYaERGR5ucd9uzZo+PGjXNL34+MjHQuMylSpIh27txZ9+/f73HMZcuW6aBBg1T11oU4X758mjt3bq1Tp06av/R/8803Wr169SRZJQ0bNtTXXntNVT2fFd+2bZsWLVrU+WuMa8rzsGHDNCQkRH/++WePYu7fv1/vv/9+3bZtmzZu3FhffPFFPXbsmG7dulX79u2r1atXT/MG5+LFi1qwYEG31HRHP/rll180d+7c+tZbb3lUt2PHjjn//40bNzonRVxvsB0TECnVzfWYO97z9ddfa9asWd2+eHnq2rVrWqVKFec5ZM2aNZorVy7NlSuX85dDT5fitW7d2vmrYffu3bVixYpavHhx51KctI7X0aNHtXbt2jpx4kTnL4MrVqzQggUL6tatW7V58+Y6YMCANGOdP39en3/+ebXZbFq4cGEdMWKEnjlzRlVv3Yw1b95ce/TokWo6/ZQpU5zLGB3137BhgxYvXtwtay0tly9f1gkTJiSZeN24caOWLl3aq6VFjslhu93uPL8vW7ZM8+XL5zw3eWL+/PlJ+sqRI0c0b968+uuvv6b62cTtPnv2bC1RooS+8cYbzi81DhMmTNCcOXOmeh6KjY3VZ5991pkt6TBjxgx98MEHVVW9+tV54sSJWrVqVf3777/dXnecA3r37u3MPEvJtWvX3M5lS5Yscd60u2YceLLExDHm/T1mJ06c0Bw5cmj//v11y5YtGhkZqaVLl9bFixfrli1bNCwsTB966CFnmVLz3HPPaZYsWfTll1/W+vXrO78Ux8TE6Oeff642my3NPh4TE+P3GHP1xRdfaI0aNfTmzZtqt9v18ccfV5vNphUrVvTo8ytWrHD7gaR169YaEhKivXr10mbNmmm+fPmc4zm14/XXX3/p8ePH3eI4MsMWLFigvXr10goVKridyx2Si3vx4kUNCwtzLq+cPHmy5s6dW/Pnz+88vybOgEkc58knn9SmTZvq2bNn3V4/fvy4du7cWbt06ZLm8uTPPvtMP//8c7fXzp8/r3fffbfXy4dfe+01ffDBB/WJJ57QYsWK6YsvvqgbN27U/fv3a7t27bRw4cLJ3uekxJc2cjVw4EBt2rSp88e2hx9+WAsWLKgPP/yw1q1bV6tUqeJxVobjC3CBAgV0xIgR+s8//6jqrR99unbtqg0bNkxybkmOv+dF1Vvnva5du2qpUqV04sSJ2rhxYy1Tpozu2rVLf/31V502bZpmyZIlzR8J/vzzTw0JCdFatWpp2bJl9cUXX9Q//vhDjxw5ovPmzdMsWbLoO++840Hr+N4XXfuBqfPrpUuX3Cbwu3TpoqVKldINGzbohg0bdMiQIZo7d+40r2mqt7KKcuTIoePHj9euXbu6/RC0YsUKzZIli3733Xdpxhk2bJiWKVNGjxw54lb2uLg4ffbZZ7VWrVo+L90GvGH5CZHULg7//e9/NW/evF4/JyHxyXnu3LnOTBHHvxcbG5tmav/WrVs1MjJSCxQooAMHDnQ7gS9cuFAzZcrk/JKamj59+ugDDzygDRs2dEvvVb114SpfvrxHN22qqp06ddKSJUtqkyZNNCQkxHmSUb3VXiEhIUlOzIm98cYbmidPHt2xY4dGR0frqlWrNEuWLPrLL7/omjVr9K677nKLm1hKE0snT550Too4Lmznzp3TdevWefyrr+Mi//3332uxYsX0/fff9+hzqu7H/fXXX9cSJUrojz/+qHa7Xbdt26aFCxfWhQsXehxv3bp1Gh4e7vzf5cuX16xZs2rLli09elbGrl27nP+/4wtM+/btdcyYMW7v8yTjwJFamtxnatWqpY8//niaMex2u54+fVojIiJ0+PDh2q5dO7cU0wMHDmidOnWS/NrhynHsx40bp6VLl3b7Eunowy+99JK2aNFCr127luz4Tu1GbtOmTRoZGanNmjXTzZs367Vr17RBgwbJXnhTGjN2u12jo6O1efPm2rdvX71582aqk6Gu5XG8r1mzZs6bqipVqmiVKlW0fPny2qJFixTjJBfziSee0OHDhztfz58/v+bOnVunTp3q8Tr1gQMHapUqVbRx48bas2dPtdlszkyel19+WatXr+7RZO/58+d16NCh+sgjj+jp06fdPjNq1CgtVqyYRze2rk6dOqUVK1Z0Znt4OsnnegPk+Myvv/6qlStXdksJT/yFJTmJ6/77779rpUqV9P/+7/9U1fvnLjjKc+bMGQ0JCXG7SZ84caLbl8PkOL4ElS1bVjt16uRWxoMHD+p9992nX3/9daoxYmJikrw2e/ZsrVOnjttrnjy/Zd26dZo7d25n2rtre6xevVqzZMmi33//fZpxEh/bpUuXOm/a9+3b58yI8uTX9cTHxNtj5mjPVatWadGiRbV79+56zz33uH152L9/v9psthS/3Lr+GydOnNA33nhD33rrLa1Vq1aS5/OEhoZ69GySmJgYY2Ps6tWrWr9+fWd9K1asqEWLFtWcOXM6n//i6fl19erV2qRJE7clf+3bt9datWp5lbkQFxenffr0ccuQ/PTTT7VAgQIeLcW5ceOG/vvvv1q1alXnZE3lypW1TJkyGhoaqn369PGoHO+//76GhYXp+PHjkywhmTRpkhYtWjTFL1nJTWY72uDKlStaokQJt1/1hw4dmmIWr2tbjxo1SosXL67PP/98kkmvypUr61NPPeVR3eLj4/1uoxUrVmjp0qU1NDRU69evr8WLF3fGOnHihLZr106feuopTUhI8KgPTZ48WSMjI/XYsWNufXrWrFlaoECBZCfDEvv999/9Pi+qqn777bfav39/HTJkiFauXNktCyw6OlofeOABnTt3boqfdxz/P//8UwsXLqzt27d3m7C4ceOG9uzZU9u0aZPiPYwrf/qiK3/Or8mN+Rs3buiIESPcjs3u3bu1UKFCKWYFusa5cuWKduvWTYsWLap169Z1/j0hIUEvXryo5cuXTzHT1TXO1q1btUGDBs5lTa51XblypRYuXDjV7xuAKZadEEkrq0L11ok7NDRUR40apXa73et1Zq7vd0yKvPnmm3rq1Clt0qSJM+Urtc9t3bpVhw4dmiTr4cqVK1qwYMEkExyun3Wc7OPi4rRRo0bOZ5q4fpFbvny5Nm/ePNlf/FxjuV7ET548qatWrdIGDRrolStXnPHWrVunNWvWTPFZEI54169fd/7aVL58ec2ZM6dzouDs2bNauHDhZB+451qelP5/xxKGwoUL6zfffKMRERHasmVLr49ddHS01qtXz7l21pvP37x5U/fu3etcL+kQFhamI0aMSPL+lFIr9+/frx06dNC4uDgNDw/X5s2b644dO7RgwYJar149j5//4vpLaKdOnZxZT3a7XR955JEkD2FzLY/jwrJv3z697777tHXr1s6/OWL27NlTn3zySY/Konrr1xjHM3YSTzRERUV5dOO2f/9+7dKli9avXz/JL6dvvfWW1q9fP9kvPYnr5eBa502bNmm7du20cePGWqlSJS1WrJjbmHGNk9pEwMSJE/Wuu+5KcfIqtThvvvmmjhw5UkNDQ7Vhw4Z66tQp57rs559/PsV/M7FFixbp0KFDVfXWl6pGjRppx44dNTQ0VGfMmJHkxnnbtm363nvv6cSJE93SmqdOnar9+vXTHj16uGXwjB492rku29UXX3yhAwcO1F69eun06dOdr0dHR7vV23FemTNnjjZu3Nirhz47jtmsWbM0T548Hk0Op+a7777TEiVKOMvQqlUrrVKlilvfcG0f14fwJjZ06FC95557kpwDkovjmo3k2g8uXLigZcuWdZ5PmzZtqtWrV3fru67t7Lo8YfLkyVqoUCEtUKCA21K3s2fPanh4eJI06tTSlx1/mzp1qtuESN26dfXRRx9NsQ1c9e/fX/Pmzeuc+HCtQ7ly5Zzp6g6ptbNrWZcuXaq1atXSrl27amhoqJYuXTrJF07XNkr877hK65il5OrVq7pv3z6tUaOG2y+o33//vVatWjXJr6HJ9X+Hixcv6gMPPOA2EffPP/9oWFhYksl01zZy/YJx7tw5I2Ps2rVrWrduXV23bp3WqlVLGzZsqL///rs+8cQTarPZdN++fW7vT+0aGRMT48xMdbTRyy+/rI888kiS96Z07BO3laMPbdu2TSMiIpIsI01pbKjemjRfsGCBVqtWTRs1aqRHjx7VGTNmaLFixZL8YJDSuez555/XsmXL6qRJk9x+BPrmm280PDw8yfU5tePuYLfbtVKlSs5zWfPmzbVSpUqpXq9c/7Zw4cIkz6CIi4vThx56SF944YUk/15q48ybNkrOli1bdMuWLdq7d+8k/3bfvn01MjIyyWdSu0a7Hl/H3z755BOtW7duki/8KY2NSZMmeXVeTOk8rfq/5TOuWWVnzpzRqlWrpvksPMfxP3funG7YsCHJ359++mnt2LFjktdTKs+AAQO86oupjQ1vzq8pHa/E9zOO/713716tVatWkkmVlOKsXLlSw8PDNXv27G6T5hcvXtTw8HDnc5+Si+NazvHjx2t4eLgOHDjQbfLD8SOILxtDAN6y5ISIpzvA2O127dGjh9asWdPIvzt//nzNli2bFipUSEuVKpVqVobrScmR9ur6+v79+7VatWpuJ+Pk6uU4Ee3Zs0dr166tISEhumrVKj1x4oRevnxZW7Vqley68ORiuZ6oFi9erOXLl3eWJz4+Xlu1aqUPP/ywx5MHGzZs0I0bN7rdMO7atUtDQ0OTLPXwZtee06dPa6tWrdRms2loaKjXT+p3+OijjzRLlixepVGn5NSpU1qvXj23B6ippl6v69eva506ddRms2n9+vWd/eDXX3/VFi1a+PSw3g4dOjifS9OmTRstWrRokgmy5MoTHx+va9as0XvvvVcbN26s0dHRGhsbqwkJCfrggw8meR5Dclzbf/To0Wqz2bRPnz7OXw0vX76sTZo00XHjxnlUl2+++UY7deqkYWFhOnv2bL1x44aeOXNGW7Zsqf/5z3/c3rtkyRLNmjWrc3JANfVJkVWrVqnNZtOIiAhnW8THx3sV59q1axoREaF9+/ZNMtbTivP222+rzWbTNm3aOL+g3bhxQ3fs2OH1w0NLlSql5cqV0/r16zuzQpo3b66PPfaYW52T23Ul8RPwXftFXFycNmzYMMkEzdy5c7VAgQLao0cP7dChg4aEhLjdICYehzdu3NCWLVtqr169PK6Xq4MHD2r16tWdN+m+PsR6y5Ytet999+mlS5e0ffv2bplzdrvdo11pHP/2oUOHtFq1ajp+/Pgk5fF0d5uTJ09q0aJFdd++fUnKk5CQkGw7u8Z59913tVSpUlq2bFlduXKlrl27ViMjI7V+/fpuZfL03DpnzhytV6+eqqq2aNFCK1SokObSGcexvnTpknbu3Fnz5cunX375pfPfj4mJ0QoVKrjt6OZNO6v+b3eNWrVqOdvHMUaSayPX7AvXyeLUjllajhw5ooULF3aW8++//9ZOnTpps2bN3GJ5cv547LHHtE2bNrpz50799ddftX379hoREeH2vuTaKLXnAnk7xhz/1uOPP66ZM2fWJk2aOLOGzp07p2+88YZbf/F2V72rV69qixYtkvwo5Mmxdz1/XL9+Xdu2basdO3ZM8gNUasfd8dyIFi1aOM+vsbGxumrVKrd2Ti6Oazv37dtXQ0NDtVevXrpt2zb96aeftEWLFtq0aVO38iR33JPrY5cuXdKSJUvqpk2btFOnTlquXLkkfTqte7PkYjZq1CjJQ77TauuBAwd61EaJJT6/v/jiizp48GDn/7569ao2a9bM7TVVz8aGq7i4OG3VqpU++uijaV7HXO+7Jk+erKVLl07zvJjWGLtx44ZGRkbqiy++qL/88oseP35c27Vrpw8++KBH1+iUzjGXL1/WZs2aJXmAdVrX52eeecajvujNOVE15fOrt/dUjrHapk2bNM+JrvdLK1as0PDwcM2RI4dOmTJF582bp5GRkUnOicnFcb0+vfXWW1q3bl1t0KCBrl27Vjdv3qwtW7ZMctyB28VyEyKe7gDjeP3YsWNqs9ncdlnw1cWLF/W+++7T+vXru33J8ta1a9c0MjJSmzdv7iynJ/U6fvy4NmvWTIsXL64hISFas2ZNDQsLSzJh4Ems2NhY5/ay3bp104YNG7rF8vYEEx8fr3///be2bt3arV6elsfV2bNntVq1alqnTh2/2jk6OlpLly7t0zaKDo6HaLVt21YbNmyYJF08pXrZ7Xa9ceOGvvbaa9qvXz/nrH/ienjazo7PdenSRUeOHKndunXTsmXLOo9XfHx8mu0cFxenW7du1SpVqmixYsU0PDxca9asqRUrVvS4fRNPiuTOnVvr16+vjz76qDZq1EirVq3q0USlw48//qhDhgzRbNmy6X333aflypXT8PBwtz791VdfaalSpfShhx7SqlWrui0hSe7GJSYmRhs2bKjVqlVz6z/exrHb7RoVFZVkS77U4rjWffr06W6Toa48nRT5+++/tV69evrwww8nWd7gOL52uz3NXVdc+8KNGzd048aN2qRJE61SpYpbmVeuXKn33HOP88bx7NmzWr9+/WQfwnjlyhX94YcftEWLFm5t7csT359//nnNmzevTzsqOPz6669aqVIlDQ8P19KlS7uNDW93pbHb7RoREaE9evRwe92bOI4JEUe/di2Pp+38ySefaPfu3fWuu+7SWrVqaYsWLdzO0d6cWz/88ENnxp3rhL6nYz8mJkafeOIJzZ49u/bu3VtfeuklbdasmVatWtXZn71pH8fStLp162rNmjWTnOu96YuOeMkds7TY7XaNjY3VAQMGaIECBbRq1apavXp1ty8QCQkJqY5713ZfvHixtmjRQm02m4aHh2vDhg3dvoh400ZXr171a4wtWbJEn3rqqRSXwXpy3XAVFxenZ86c0cjISA0LC3PrO97Wa/fu3dqqVSutWrWqWzt7etzHjx+fJIXe4ebNmx7HmThxorZu3VptNpuGhYVp3bp1PT7uic/jFy9e1JIlS2q+fPm0YsWKScZYWvcMidv67Nmz2rZtW61Zs6bbv5VWWzvKPmHCBOeS8eTayBPvvfee2mw2/b//+z+dNm2atm3b1u067+01+tq1a7p161Zt2rRpkj6dWr1cy79mzRp97LHHUjwvetI+qrceGB0REaE5cuTQGjVquB17b5dKxsXF6c8//+z12HCt17vvvptqX/TmnJja+dXb47Vt2zZt0aJFkrGaWhzXa/mePXv0pZde0uLFi+uDDz6oHTt2dGtnT+N89NFH2r17d82WLZtWr17d7RlPTIrgdrPUhIi3O8DY7Xb9+++/ddy4cV6f3BK7cuWKtmrVSkuUKOHzl/S4uDjng5yqVavmHMhHjx71ql7r1q3TxYsXu830O8riSRu5Linq0aOH9ujRQ1999VWf63Xz5k394osvNDIy0i2jIyEhwetjFhcXpy+//HKSLxC+WrRokc/HPi4uTidPnqzNmzd3+5J+8+ZNj+t16dIlrx7ymBLHMYuKinLeaLu2j7ftPH36dJ0wYYJOnjzZr0mnzz77TEeNGqWPP/64jho1yhkjrTZPvJzr0KFDunz5cv3888/d+vTNmzf11Vdf1ccff1x3796tY8aM0YoVK6Z6Ad+1a5fWr1/frX28jeO6PMzxut1u9yiOpw899NQPP/zgtrY4cWqrt7uuXLx4URcsWKCdOnVy69P//vuvdu3aVV9//XW399erV0/btm2rbdu21aFDhzrbZuPGjdq1a1dt2bKlzzeRrhlwnTt39us8vWvXLrXZbFq9enW3Y+9t+7hmP7iWx9s4p0+f1oIFC7p9IXas70+rnRP/+nr8+HG9cOGCW0aft2N+6tSparPZtE6dOn6dW+fOnavdu3fXli1bumVP/fPPP17v/rN169ZkJ2e87YuOzyc+Zt44efKkfvzxxzps2DCdM2eO1+ch119Fjx8/rl9++aV+//33zuPhS1/csmWLT2PM9fya2iSjN33I8YWsbt26Wq9ePbfyeFuvr7/+Wnv37q3t27f3e2wkx5M4rjuBXL9+Xfft26eHDx92O17eXjeuXLmi1apV0wYNGiS5rnrb1suWLdPw8HCNiIjwuq1NfzkcOXKk3nvvvVq7dm3t3r27W3m8baNdu3bps88+q+3atfP6PJ14Uie586K3cb7//ntdsWKFfvHFF0nupz2VkJCgX3zxhbZp08anseF6vOLj45Pti96eE1WTP796e7x2796tL730kkZFRbn1aU/iJD73nD9/XuPi4tyOly9xjhw5otHR0W7tA9xulpoQ8XcHGMcg92T/68TOnz+vs2bNcjux+BJn0aJF2rt3b7cTi6f1SulGKPHD3fxtI1/q9csvv+isWbOS3AT4Up5t27a5XZjOnDmj0dHRbr90pPULWeLYvtZr6dKl+uyzzxqpV+Iy+1Ke119/3e1XfW/Lk1Yf8rRMqfWlEydOeHW8kovlWs6YmBjnOuLo6Gh94403klwwU4rveqH0Nk5Ka2o9iZPWWPOknT39FdiXXVdcH/bm2kaHDx92W8fbqVMnLVq0qI4YMULHjh2rOXLk0Kefftr5971797rdlPjSp1VvfZl0lOfmzZs+jfkTJ07omDFjkowNX9onuXR2X+LMnj072QlHT9o5pYcfOtrb23PQH3/84dwBzLU8nh6zlMaGI5avu/8k1w9Vve+LicvnSx9KzNvzUEo35o7j4Usb7d69222MmaiXg7d96PTp0zpv3rwkXxx9qde+ffuS/ULj7XFPiSdxUnrelbfne9f2X716dbJfrL1t65MnT+r06dONnM8Sx/dlzJ88eVJjY2OTHa/eXhP/+OOPJMfel3old432dxcyf64/GzduNDI2XLm2my9jw8TxOnr0qM9xHLtcJY7p2p6exknus2SG4E6x1ISIqv87wKxdu1YHDx7s197V8fHxxuI4mNrZxptYiZ/zoWqufUyUJyEhQZcsWaL16tXTYsWKaVhYWJKHMKUk8cXrs88+S7d6JXfMfG1n14tL4udaeFqelJ5472uZXNt68eLFRo5XchdQh3Pnzumbb77pdsG8cOGCTpkyJcXn+ngbJ60vNp7GSW4CysQYS8zTXVcSb8Wa2k3e119/rR07dnTbWWLWrFl6zz33JHnQbEJCgpH+Y7fbfR7zicvjGtfUrjSexkn8oODUftVPrZ3/+uuvVI+Rp2PedTco1f+dy3w9Zind2Jrc/ceVt23kax9KPL59OQ+5Zt0lx9c+ZPJ66Pq/fe1Difu0p/VKXObUvtD4Mza8iZPW0mtXKR33d9991+19yY15T9r60qVLxto6uXHm7Zh3xE/pS6i3bZT4fG+qXqbimLj+JJ5AuR3nxbT6tGtmqytvjtekSZNSPF4m7oV8iUM2CNKL5SZEHBI/ZMiTHWDmzZunRYoU0SFDhujOnTs9/rcSD9g5c+b4FCfxCSG5E4Ev9UqJt7F8bR9P6uVLeWbOnKnZs2fXCRMm6MiRI7V58+aaJ0+eNB+S6vrvHDt2zHL1MtUPTZXHnzK5/lumjpcnzp49q2+++aZWrlxZX3jhBW3YsKEWLVrU618L7nQcE+2s6tmvIp7supKWxL9eTZ06VRs3bpwkhdVUvaZPn+5TH3Idq55saa1qpn3SiuNpLE/bOSVpjXnXX9oc7lRfNNXOnrZRIJ6HPGmj210vk/ce3tQrLf6ODdNxVP0/7unV1nfy+nMnx4apOL6OscTZFHeqXlbq01aNA5hi2QmRxNLaAWblypWaO3duXb58eYrb1qX0YEWH2bNn61tvvWUkjusWVP7UyxupxTLVPp7WK63yLFmyRG02m9s2at9++60WLlw4ydO7UyrPzJkztWrVqporVy7L1Mtq7WyqTE899ZSR49WiRQtnmmpanzl//rwOHz5cbTab1q5d2+uHa93pOHf62Ke164ondXJ937Vr17Rt27bat29ft/eaqtd///vfO9aHVP1rH1NxvGlnb9yp66EnfdHfdvamjUxdN+7keUg17Ta6k/VyMHHvYYWxYXqMmTzuDneire/kmL+TY8NUnDs9xqwwNhLHC7R7KuBOCpgJkZR2gLHb7c4Tzvjx490+c/bsWf3yyy91xYoVzgchppQKPGvWLBURrVWrll9xZs+erTabzW2bLF/q5YvkYt24ccNI+3hbr9Tqdu7cOeeWsq7rJVVVa9asmeKvJ4kvTI4nkFuhXlZsZ1NjY8KECSoiWqBAAZ+P16xZszRnzpxu27um5fLly1qjRg2tXr26X2Pjdscx1c7eHvvUdl3xhuvT80NDQ52fdzzQ1US9RESrV6/u15j3tg+Zap/b3c7e/hKqevvHvDd90VT7qKbeRiauG+l1HkqtjdKrXibuPaw2NkyOMVPXDdXb29bpee9xu8eGqTjpMcasNjZUA+eeCkgPATEhktYOMNeuXdOaNWu6rfF899139eGHH9ZMmTLpPffco/fdd59znV/iVOeZM2dq3rx5ddmyZUbieHpBMbGzjSexTLWPNxfKtOq2YcMG7dy5s4aHh+uOHTtU9dZ+5jabLdlUz+TKs3TpUkvVy4rtbKpMI0eO9Pt4eXOzbrfb9fXXX3fbKtqXsXGn4qTHsU9p1xVvJCQk6Pr167VTp07aqFGjJDtdmKyXiTHvTR8y0T6m4qTVzt64U2Pe075oqp09aaM73YdMnT/SaqM7XS9T9x5WGhsmx5ip4656Z9o6Pa4/d2psmIoTiNcfK/Zpq8UBTLnjEyKmdoBxdfHiRX3wwQe1devWOmfOHI2MjNSKFSvq4MGDdceOHfrbb79p5cqVtWfPnqrqPkM+a9YszZs3r65atcqvOJMnT3bG8bdeptvI3/bJkyePV/VKqTxffvmlTpkyxfmeTZs2aceOHTUiIkLHjBmj+fPn1zlz5iQpg6sZM2Zo/vz5/T5eJuvlYLXy+FumgQMHao4cOZxl8vV45c2bV+fNm+f1rgkXLlzwezei2xnHlb/HPnfu3F63UXK7rvhSt9OnT+vWrVuTrZu/9cqZM6c+8cQTztfuZB8y1T63s52tdj18++23NXfu3M5j4mv7qKqxNjJ13UjP81BybWSqXvny5TNy3bDa2EjPOKrJn+9NjVeTu2ypps/1R/X2jQ2rjbH0vP7czj5ttThAerqjEyImdzg5efKkHjhwwPkQsQMHDmi1atU0PDxc69Wrpzt37nQ+3dmx9u6ZZ55xizVp0iTNkyePTpkyxa84ffr00WzZsumwYcP8rpepNjLVPjlz5tT27dv7XZ5///1Xn3jiCa1QoYLOnDnT+TfHBSpz5sw6ZMgQVU26g4TDypUr9a677tJJkyZZpl5Wa2dVM2Nj3LhxmjVrVi1evLhfxyt79uxavnx5r5/onvji6OvuNrcrjt1uN3bs77rrLp/ayFVCQoLPdUtcrxMnThipV968ebVJkyZ+j3lf+5ArU+1jsp1N7oxloi8+/vjjmjlzZr377rv93v3H1E4OsbGxRq4b6X0ecpWQkGC0Xu3atfO7D5na+cnU2EjvOMmd703dm5lqa1PnaV+vP7drbFhxjFnl+mOyT1stji9LgACT7tiEiMmdN1auXKlt27bVRx55RBcuXOj826VLlzQmJiZJjH///VcfeughHTdunPO1c+fOaZUqVTQ8PNyvOO+++65my5ZN27Zt63e9TLXR8uXLjbRPhQoVNF++fMZ2S9m/f78+99xzGh4ertOnT3f+ffPmzdqxY0etUaOG84Feyc3W9+/fX+vUqWOZelmxnU2NjSZNmuj48eP9Ol69evXSrFmz+r1rgqndF0zu4mCqncuXL+9TGyXedcXU0/NN9p8lS5b4PeZ97UOm2ud2tbPVrofjx4/XTJky6WOPPeb37j+md3JIrz5k6vyR0g5J/tbrySef1AIFCvjdh0zt/GTquKd3nOTO96bGq6m2Tu/rz+0aG1YbY+l9/bldfdpqcQAruCMTIiaffj1v3jy9++67dcGCBbp3717n30+cOOGM4ziJJCQk6MmTJ7VNmzZao0YNtxnJOXPmaIECBfyK46jXvHnz/K6XqTZ69dVXjbTP8uXLb8sTy3/77Tft169fkguUY9a+Zs2abk8BdzB13E3Vy4rtbKqNEhIS9J9//lFV34+XqSe6h4aGWipOixYt9J133jHSzh9++KGl6la5cmW/z4mOvzn6jyp9KHEckztjmRjzjnb+/PPP/apXixYtdNq0abdlJ4eM0odM1ctqOz9ZbYyZPF6zZ8+2VFubOk9b7fpjtTFmtXNHRo3jzc5YwO10WydE7HazT7x/9dVXtUCBArp48WK3WF27dtVcuXLpDz/84HwtOjpahw0bpq1bt9Y6deq4PYzo888/9yuO3W7Xf/75x9juCx9++KGxWLlz5/arfeLj443uLPHcc8/p1q1b3eL8/vvv2rdvX61WrZpOnTrV+frmzZu1YcOG2rt3b7f3+3u8bke9rNTOpsbG6tWrdf78+X4fL1NPdL/rrruM7ExiKk7OnDn1lVdeMXIOslobZc+e3e8+ffPmTV2zZg19KIU4pnfGMjHmT58+bWz3hfnz5xuJlS1bNiPXDav1IRP1MnlPZWrnJyuNMdNxPvjgA0u1tanztNXGhpXGmKr1zh0ZNY63O2MBt9NtzxAx8fTrPHny6IoVK/Spp57SZ5991nkBUlXt3LmzlixZUtu0aaMhISHOC8KxY8e0e/fuOmLECOes+I0bN/TGjRt+x4mPjzf6VG9/Y82YMUPz5MmjzZo187tepo5Zrly51Gazqc1m0xw5cmjz5s21R48eun37dv377781JiZGn3nmGa1Xr57bBWr37t3OGwu73W7seJmolxXb2dTY+O677/w+Xq5MPdHdKnHy5Mmjy5cvN9YXrdJGJvv07t276UNpxDGxM5apMe/4vyZ3X/A3lonrhiurHHuT9bLizk8ZNY5V2tr0vYeqdcaGFcdYRmwfq8YBrOK2T4iY2gEmLi5OS5YsqaNGjXL+/aefftK+ffvq8ePH9cCBA/r444/r3Xff7Vym4XrRcKQ0mopjql6mYi1dutRIvUyUx7FbSu/evfW+++7T4cOH6+DBg/Xhhx/WokWLarFixXTw4MH6zDPP6GOPPaaVK1fWGTNmuPUbR0xTxysjtrOpsREXF6eq6vfxMvVE91y5chnZmcRUHMeuRib6otXaKH/+/Eb6tKNf04dSbmcTO2OZGvPr1q0ztuPXa6+9ZnS3lIzWh0zVy8EqOz9ZbYyZHquq1mlrU+dpq40Nq42xjNo+VovjOsYAq7gtEyKmdl/Ily+fcwbx33//1RIlSuhbb72lqv+bbXRd0/njjz9qsWLFdMyYMW6xXGcm/Ylj6qne+fLl09mzZxttI3/bx+RuKd27d3em0XXq1EkjIiL0gw8+UNVbqYtLly7V9u3ba/Xq1Z0z+g8//LAmxyr1slo7mxob69ev1zFjxvh9vEztIpQzZ0596KGHLBMnV65cunLlSr/b2W63W66NHHXzt14bNmygD6USx9TOWKbGvKndF3LlyqWLFi0ytpNDt27dMlwfMlUvU9cNUzs/WW2MmTwnzpw501Jtbeo8bbWxYbUxllHbx2pxXO+pACvJIoatWrVK3n//fcmePbu0a9dOevbsKeXLl5dvvvlG4uPjpWDBgm7vv3nzply5ckVKlizpfC06Olo+/fRTGThwoBw9elQmTJgg9erVk06dOsmcOXOkbdu2EhoaKiIi2bNnF7vdLpkyZZL8+fNLhQoVJCwszO3f2L59u3z//feiqj7HMVmvXr16yaeffiobNmzwK9aiRYukbdu2cuTIEfn55599bp+PPvrISN1mzpwpOXLkkHz58smFCxecsTt37ixvvvmmZMqUSTp06CAVKlSQ9u3bS7Zs2eTTTz+VM2fOSN++fUVERFWNHC+T9bJaO5saGwsWLJDXXntN2rdv79fxstlskjt3bhk8eLBMmzZNZs2aJXa7XZ555hlp2rSp2Gw2ERHZsmWL7Nq1S2rXri12u935usO1a9fk008/lWLFilkmzptvvil//fWX3+cgq7XRvn375D//+Y8cO3bMrz69cOFC+lAqcbZu3SrVqlWTbdu2Sf78+dN9zIuI5MmTx0g7r1mzRpo2bSo1a9b0K9aGDRskT548kj9//gzVh0zVy+R1Y+bMmRIWFmaJ9rFinJdeeknWrl0rGzdutERbmzpPW21sWG2MZdT2sWIcx3UDsByTsysmd7mYNGmS3nPPPVq9enXNnTu3VqxYUTt27KgVKlTQRx55RH/77Te3fzs2NlYjIyO1efPmbssS5syZ43cck/WaMmWKkVizZs3SQoUK+d0+puq2ePFizZkzpy5fvlwvXbrkfL9Dt27dtFy5crpo0SK9fPmyJic+Pt7I8TJZL6u1s6mxsXTpUiPHKzFfn+huxTim+qLV6maqXvShO7Mzlsnr4e1oH39iZdQ+ZKpet2PnMCu0jxXjWK2tM+r1x1ScjHruCJY4gNUYmxAxsROI4yQ+Z84czZYtm3Obsy1btmiTJk20VatW+vTTT2uBAgW0Vq1aumrVKt2zZ48uXbpUGzVqpJUrV3bGSkhIMBLns88+M1YvU21kqn1MlSc6OlobN27s9qAq1VspiNu3b9f9+/erqurTTz+t5cuX1w8//FCvXLmSpA9ZrV5WK4+pNjp79qyR42VqRxGrxTHVzgkJCZarm6l6mRrzVmsfU3GsNuZN7SBlso0yah8yVS9Tfchq7WO1OKrWa+uMev2x2hizWr0yahwgEPg9IWI3vBPIV199pTabTUePHu2Mr6r61ltv6f3336/Xr1/XmTNnaoMGDTRLliyaLVs2rVGjhnbr1s0tlr9x7Ha7Xr161Ui9TLaRifYxuduO6q2LU6VKlXT16tXOONOnT9fOnTurzWbTwoULa9u2bVVV9YknntCCBQvq+vXr3fqR1epltfKYaqP4+Hgjx8vUjiJWi2Oyna1WN1P1UjUz5q3WPibiWPF6aHIHKZPjLCP2IRP1MtmHrNY+VotjxbbOqNcfK40xK9Yro8YBAoXfzxCx2WyiqrJp0ybp2bOn5MiRQ0REfv75ZylYsKB88803cvXqVRkzZoy0bNlS1q1bJ7Vr15Z58+Y535uQkCBZstwqSvHixaV+/fqyZ88e+eabb6Rhw4YiIpI5c2ZRVbly5Yr07dtXHnnkETl+/LjExsZKqVKlpESJEmKz2eTmzZuSJUsWI3EyZ85srF6m2shEvbJmzSo3btwwVjcRkdjYWPn8888lb968Mn36dDl06JDUr19fNmzYIJcuXZJBgwbJe++9J/PmzZOQkBBp1qyZWz+yWr2sVh6TY8Pf45WQkCA1atSQXr16yebNm+Wxxx6T+Ph4+eOPP6Rz585is9mke/fuIiLywAMPyIwZMyRz5szSr18/qVGjhoiI2O12UVVLxcmUKZOxdrbZbJarm8n+Qx9KuZ2tdD2Mi4uTiIgII/Uydcwc4yyj9SFT9TJ1T2W1c5DV4mTKlMlybW3qPJ1Rj31GPXdk1DiuxwuwPBOzKqZ2gHE4dOiQtmrVSlu0aKGHDh3SzZs3a/bs2dPcszrxrKS/cUzWy2QsE+1j+pht2rRJ8+XLp6VKldJq1arp5s2bNSYmRlVV//nnHw0LC9NXXnnF7TOJ17larV5WK4+pMqn6frxM7ShitTgm29nKdTPVf1TpQ7drZ6zEfD1m69atM1av2zXOMkofMlUvB6vs/JRR47iySlu7ykjXH6uNMavVK6PGAQKNzxMi27Zt0wkTJuj48eN1+/btOnDgQH3ggQf0559/dr4nISHBeSP9559/apMmTfTzzz/3KP6hQ4e0devWWr16dc2aNat++OGHqpr0S7TpOCbrdTvbyJf2ud3HLDo6Wo8cOZLk9X/++UcbNGigs2bNUtXkb/qtWi+rlcfXMiXH2+M1f/58LV68uD7zzDO6Y8cO5/sfeeQRLV++vC5evNi5TvfKlSsaHx+vH330kU6dOtWZymu32y0XJyW+tHMg1M1U/1GlDzniWG3Mm+w/t3ucBXofMlUvU33Iau1jtThWbOvkZITrj9XGmNXqlVHjAIHIpwmR2/X068QOHTqkTZo00SpVquh3333nfN3bAedpHJP1uhNt5E373Kljllh0dLRGRkZqREREwNbLauXxtkzeSOl4mXqiu9XipMWbdg6kut2u/qMafH3IamPeZP+5U+MssUDpQ6bqZbWdnzJqHFXrtXVqAvn6Y7UxZrV6ZdQ4QKDyekLE1NOvPfXHH39oq1attFWrVvrtt996W1yP45is151sI0/a504fM1XV8+fP69ixYzUyMlJr1aqVZOeEQKuX1crjaZk8ldrxMvVEd6vF8ZQn7RyIdTPZf1SDsw9Zbcyb7D93epypBlYfMlUvq+38lFHjqFpvly1PBOL1x2pjzGr1yqhxgEDm1YSIyV0KvHHo0CGNjIzUmjVr6k8//eT159OKY7Je6dFGqbVPeh2zvXv3atu2bXXgwIEZpl5WK09aZfJGasfLxBPdrRjHG2m1c6DWzVT/UQ2+PmTFMW+y/6THOAukPmSiXlbb+Skjx7FiW3sq0K4/VhpjVqxXRo0DBDKvdpkxvUuBp8qWLSvjx4+XuXPnSpUqVbz+fFpxTNYrPdootfZJr2MWFhYmH3zwgeTLl09sNluSXWkCsV5WK09aZfJGWsfL312ErBrHU560cyDWzVT/EQm+PmTVMW+y/9zpcRZofcjfellp56fb0T5WimPVtvZEIF5/rDLGrFqvjBoHCFjezqCY3KXAV6ZiucYxWa/0biPTu+34y9RDlqxWL6uVx1Ss27WLkBXj+Mrkriu3K46pevkiWPqQFce8yf6Tnn0xEPqQiXpZYeenYIljxbb2RTAde18Ewrkjo8YBApVPD1U1uUuBlZisl9XayGrlMcVq9bJaeUwysYuQFeOYlJHrZoLV2ie9dsa63Uz2H6v1RSsde1PSc+enYItjxbY2xWptTfsEZxwgEPm87e7t3KUgPZmsl9XayGrlMcVq9bJaeW4nX3YRCoQ4JmXkuplgtfa53TtjpReT/cdqfdFqfcgX6bHzU7DGCYS2NiW92/p2xTHFavXKqHEAq7Opqvq63Obw4cMyYMAAEREZMWKEPPjgg8aW8qQnk/WyWhtZrTymWK1eViuPaTExMTJ37lz59ttvJTo6WrZv3y5Zs2aVhIQEyZw5c8DGMSkj180Eq7WPv3GsOuZN9h+r9UWrHHtTTPchq7WPleJYta1NsVJbm4xjitXqlVHjAIEikz8fLlOmjEyZMkUyZ84sL7zwgvz888+mypWuTNbLam1ktfKYYrV6Wa08pp08eVK2b98uZcqUkR07dkjWrFnl5s2bXl8orRbHpIxcNxOs1j7+xrHqmDfZf6zWF61y7E0x3Yes1j5WimPVtjbFSm1tMo4pVqtXRo0DBAq/MkQcfv/9d5k7d66MHz9eMmXya47FUkzWy2ptZLXymGK1elmtPCZdvHjR7Ynuvl4orRbHpIxcNxOs1j4m4lhxzJvsP1bri1Y69qaY7ENWax+rxbFiW5titbamfYIzDhAIjEyIuLLb7Za5CTTJZL2s1kZWK48pVquX1cpjiqqKzWbLcHFMysh1M8Fq7WMqjtXGvMn+Y7W+aLVjb4qpPmS19rFaHBHrtbUpVmtr2ic44wBWZnxCBAAAAAAAwOqs89MVAAAAAADAHcKECAAAAAAACDpMiAAAAAAAgKDDhAgAAAAAAAg6TIgAAAAAAICgw4QIAAAAAAAIOkyIAAAAAACAoMOECAAAt1mvXr3EZrMl+e/w4cN+x164cKHkz5/f/0ICAAAEmSzpXQAAAIJBq1atZMGCBW6v3XPPPelUmuTFx8dL1qxZ07sYAAAAdwQZIgAA3AHZs2eXkJAQt/8yZ84sa9askerVq0uOHDmkVKlSMnr0aLl586bzcxMnTpTQ0FDJlSuXlChRQp599lm5fPmyiIh8/fXX0rt3b7l06ZIz6+T1118XERGbzSaffPKJWxny588vCxcuFBGRY8eOic1mk+XLl0ujRo0kR44csnjxYhERmTt3rlSsWFFy5MghFSpUkOnTp9/29gEAALjTyBABACCdbNu2TXr06CFTpkyRBg0ayJ9//ilPP/20iIiMGjVKREQyZcokU6ZMkQceeECOHDkizz77rLz88ssyffp0qVevnkyaNElGjhwpBw8eFBGR3Llze1WGYcOGyTvvvCPh4eHOSZGRI0fK1KlTJTw8XPbu3St9+vSRXLlySc+ePc02AAAAQDpiQgQAgDtg7dq1bpMVrVu3lgsXLsiwYcOcEw2lSpWSN954Q15++WXnhMgLL7zg/EzJkiXlzTfflH79+sn06dMlW7Zski9fPrHZbBISEuJTuV544QXp1KmT83+PGjVK3nnnHedrDzzwgOzfv19mzZrFhAgAAMhQmBABAOAOeOihh2TGjBnO/50rVy6pWrWqbN++XcaMGeN8PSEhQa5fvy5Xr16VnDlzyqZNm2Ts2LFy4MABiY2NlZs3b7r93V81a9Z0/v9XrlyRP//8U5588knp06eP8/WbN29Kvnz5/P63AAAArIQJEQAA7oBcuXJJmTJl3F67fPmyjB492i1DwyFHjhxy7Ngxadu2rTzzzDMyZswYufvuu+Xbb7+VJ598Um7cuJHqhIjNZhNVdXstPj4+2XK5lkdEZM6cORIREeH2vsyZM6ddSQAAgADChAgAAOmkevXqcvDgwSQTJQ4//vij2O12eeeddyRTplvPQV+xYoXbe7JlyyYJCQlJPnvPPffImTNnnP/7jz/+kKtXr6ZaniJFikixYsXkyJEj8thjj3lbHQAAgIDChAgAAOlk5MiR0rZtW7nvvvukc+fOkilTJvnpp5/k119/lTfffFPKlCkj8fHx8t5770m7du1k+/btMnPmTLcYJUuWlMuXL8vmzZulWrVqkjNnTsmZM6c0adJEpk6dKnXr1pWEhAQZOnSoR1vqjh49Wp5//nnJly+ftGrVSuLi4mT37t1y4cIFGTRo0O1qCgAAgDuObXcBAEgnLVu2lLVr18qXX34ptWrVkjp16si7774r999/v4iIVKtWTSZOnCjjxo2TKlWqyOLFi2Xs2LFuMerVqyf9+vWTLl26yD333CNvv/22iIi88847UqJECWnQoIF0795dBg8e7NEzR5566imZO3euLFiwQEJDQ6VRo0aycOFCeeCBB8w3AAAAQDqyaeIFxgAAAAAAABkcGSIAAAAAACDoMCECAAAAAACCDhMiAAAAAAAg6DAhAgAAAAAAgg4TIgAAAAAAIOgwIQIAAAAAAIIOEyIAAAAAACDoMCECAAAAAACCDhMiAAAAAAAg6DAhAgAAAAAAgg4TIgAAAAAAIOgwIQIAAAAAAILO/wMiEvXIPQBwVAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "def calculate_feature_importance_gradients(model, X_snp, X_pgs, target_class=1):\n",
    "    \"\"\"\n",
    "    Рассчитывает важность признаков на основе градиентов\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_snp_tensor = torch.FloatTensor(X_snp).to(device).requires_grad_(True)\n",
    "    X_pgs_tensor = torch.FloatTensor(X_pgs).to(device).requires_grad_(True)\n",
    "    \n",
    "    output = model(X_snp_tensor, X_pgs_tensor)\n",
    "    \n",
    "    if output.dim() == 1:\n",
    "        target = torch.ones_like(output)\n",
    "    else:\n",
    "        target = torch.zeros_like(output)\n",
    "        target[:, 0] = 1.0\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    output.backward(gradient=target)\n",
    "    \n",
    "    snp_gradients = X_snp_tensor.grad.abs().mean(dim=0).cpu().numpy()\n",
    "    pgs_gradients = X_pgs_tensor.grad.abs().mean(dim=0).cpu().numpy()\n",
    "    \n",
    "    return snp_gradients, pgs_gradients\n",
    "\n",
    "def manual_permutation_importance(model, X_snp, X_pgs, y, n_repeats=10):\n",
    "    \"\"\"\n",
    "    Вручную реализованный метод пермутации для расчета важности признаков\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        X_snp_tensor = torch.FloatTensor(X_snp).to(device)\n",
    "        X_pgs_tensor = torch.FloatTensor(X_pgs).to(device)\n",
    "        baseline_preds = model(X_snp_tensor, X_pgs_tensor).cpu().numpy()\n",
    "        if baseline_preds.ndim > 1:\n",
    "            baseline_preds = baseline_preds[:, 0]\n",
    "        baseline_score = roc_auc_score(y, baseline_preds)\n",
    "    \n",
    "    snp_importance = np.zeros(X_snp.shape[1])\n",
    "    pgs_importance = np.zeros(X_pgs.shape[1])\n",
    "    \n",
    "    for i in tqdm(range(X_snp.shape[1]), desc=\"Calculating SNP importance\"):\n",
    "        importance = 0\n",
    "        for _ in range(n_repeats):\n",
    "            X_snp_permuted = X_snp.copy()\n",
    "            np.random.shuffle(X_snp_permuted[:, i])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                X_snp_tensor = torch.FloatTensor(X_snp_permuted).to(device)\n",
    "                X_pgs_tensor = torch.FloatTensor(X_pgs).to(device)\n",
    "                permuted_preds = model(X_snp_tensor, X_pgs_tensor).cpu().numpy()\n",
    "                if permuted_preds.ndim > 1:\n",
    "                    permuted_preds = permuted_preds[:, 0]\n",
    "                permuted_score = roc_auc_score(y, permuted_preds)\n",
    "            \n",
    "            importance += baseline_score - permuted_score\n",
    "        \n",
    "        snp_importance[i] = importance / n_repeats\n",
    "    \n",
    "    for i in tqdm(range(X_pgs.shape[1]), desc=\"Calculating PGS importance\"):\n",
    "        importance = 0\n",
    "        for _ in range(n_repeats):\n",
    "            X_pgs_permuted = X_pgs.copy()\n",
    "            np.random.shuffle(X_pgs_permuted[:, i])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                X_snp_tensor = torch.FloatTensor(X_snp).to(device)\n",
    "                X_pgs_tensor = torch.FloatTensor(X_pgs_permuted).to(device)\n",
    "                permuted_preds = model(X_snp_tensor, X_pgs_tensor).cpu().numpy()\n",
    "                if permuted_preds.ndim > 1:\n",
    "                    permuted_preds = permuted_preds[:, 0]\n",
    "                permuted_score = roc_auc_score(y, permuted_preds)\n",
    "            \n",
    "            importance += baseline_score - permuted_score\n",
    "        \n",
    "        pgs_importance[i] = importance / n_repeats\n",
    "    \n",
    "    return snp_importance, pgs_importance\n",
    "\n",
    "def plot_feature_importance_heatmap(importance_values, feature_names, title, figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Создает тепловую карту важности признаков\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance_values\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    top_n = min(50, len(importance_df))\n",
    "    importance_df = importance_df.head(top_n)\n",
    "    \n",
    "    heatmap_data = importance_df.set_index('Feature')['Importance'].to_frame().T\n",
    "    \n",
    "    ax = sns.heatmap(heatmap_data, annot=True, cmap='viridis', linewidths=.5)\n",
    "    \n",
    "    plt.yticks([])\n",
    "    plt.xticks(rotation=45, ha='right')  # Поворачиваем метки оси X\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{title.replace(' ', '_')}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def analyze_and_visualize_feature_importance(model, X_snp, X_pgs, y, \n",
    "                                            snp_feature_names=None, pgs_feature_names=None,\n",
    "                                            method='permutation'):\n",
    "    \"\"\"\n",
    "    Анализирует и визуализирует важность признаков\n",
    "    \"\"\"\n",
    "    if snp_feature_names is None:\n",
    "        snp_feature_names = [f'SNP_{i}' for i in range(X_snp.shape[1])]\n",
    "    if pgs_feature_names is None:\n",
    "        pgs_feature_names = [f'PGS_{i}' for i in range(X_pgs.shape[1])]\n",
    "    \n",
    "    if method == 'gradients':\n",
    "        print(\"Calculating feature importance using gradients...\")\n",
    "        snp_importance, pgs_importance = calculate_feature_importance_gradients(model, X_snp, X_pgs)\n",
    "    else:  # 'permutation'\n",
    "        print(\"Calculating feature importance using permutation method...\")\n",
    "        snp_importance, pgs_importance = manual_permutation_importance(model, X_snp, X_pgs, y)\n",
    "    \n",
    "    plot_feature_importance_heatmap(\n",
    "        snp_importance, snp_feature_names,\n",
    "        f'SNP Feature Importance ({method} method)'\n",
    "    )\n",
    "    \n",
    "    plot_feature_importance_heatmap(\n",
    "        pgs_importance, pgs_feature_names,\n",
    "        f'PGS Feature Importance ({method} method)'\n",
    "    )\n",
    "    \n",
    "    combined_importance = np.concatenate([snp_importance, pgs_importance])\n",
    "    combined_names = snp_feature_names + pgs_feature_names\n",
    "    \n",
    "    plot_feature_importance_heatmap(\n",
    "        combined_importance, combined_names,\n",
    "        f'Combined Feature Importance ({method} method)'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'snp_importance': dict(zip(snp_feature_names, snp_importance)),\n",
    "        'pgs_importance': dict(zip(pgs_feature_names, pgs_importance))\n",
    "    }\n",
    "\n",
    "importance_results_grad = analyze_and_visualize_feature_importance(\n",
    "    combined_model, X_val_all, X_val_pgs, y_val,\n",
    "    method='gradients'\n",
    ")\n",
    "\n",
    "snp_importance_df = pd.DataFrame({\n",
    "    'Feature': list(importance_results_grad['snp_importance'].keys()),\n",
    "    'Importance': list(importance_results_grad['snp_importance'].values())\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "pgs_importance_df = pd.DataFrame({\n",
    "    'Feature': list(importance_results_grad['pgs_importance'].keys()),\n",
    "    'Importance': list(importance_results_grad['pgs_importance'].values())\n",
    "}).sort_values('Importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_dipl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
