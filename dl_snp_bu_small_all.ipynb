{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_snp_all = pd.read_csv(\"./csv/all_train_snp_selected.csv\")\n",
    "validation_snp_all = pd.read_csv(\"./csv/validation_snp_selected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all_ = all_train_snp_all.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "X_val_all_ = validation_snp_all.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "y_all_train = all_train_snp_all[\"target\"] - 1\n",
    "y_val = validation_snp_all[\"target\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_pgs = pd.read_csv(\"./pgs_results_calculated/all_train_pgs.csv\").drop(columns=[\"FID\", \"IID\", \"y\"])\n",
    "validation_pgs = pd.read_csv(\"./pgs_results_calculated/validation_pgs.csv\").drop(columns=[\"FID\", \"IID\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pgs = all_train_pgs.to_numpy()\n",
    "X_val_pgs = validation_pgs.to_numpy()\n",
    "ss = StandardScaler()\n",
    "X_train_pgs = ss.fit_transform(X_train_pgs)\n",
    "X_val_pgs = ss.transform(X_val_pgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snps = []\n",
    "test_snps = []\n",
    "train_pgss = []\n",
    "test_pgss = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    train_snps.append(train_snp)\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "    test_snps.append(test_snp)\n",
    "    ss = StandardScaler()\n",
    "    train_pgs = ss.fit_transform(pd.read_csv(f\"./pgs_results_calculated/train_{i}_pgs.csv\").drop(columns=[\"FID\", \"IID\", \"y\"]).to_numpy())\n",
    "    train_pgss.append(train_pgs)\n",
    "    test_pgs = ss.transform(pd.read_csv(f\"./pgs_results_calculated/test_{i}_pgs.csv\").drop(columns=[\"FID\", \"IID\", \"y\"]).to_numpy())\n",
    "    test_pgss.append(test_pgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регрессия на всех SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC bigset: 0.7321\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(np.concatenate([X_train_all_, X_train_pgs], axis=1))\n",
    "X_val_all = ss.transform(np.concatenate([X_val_all_, X_val_pgs], axis=1))\n",
    "\n",
    "model_gb = LogisticRegression()\n",
    "model_gb.fit(X_train_all, y_all_train)\n",
    "\n",
    "y_pred_proba = model_gb.predict_proba(X_val_all)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.6885\n",
      "ROC-AUC: 0.7077\n",
      "ROC-AUC: 0.7030\n",
      "ROC-AUC: 0.6694\n",
      "ROC-AUC: 0.7541\n",
      "среднее 0.7045301483766652\n"
     ]
    }
   ],
   "source": [
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = np.concatenate([train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), train_pgs], axis=1)\n",
    "    X_val_ = np.concatenate([test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), test_pgs], axis=1)\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    model_gb = LogisticRegression()\n",
    "    model_gb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг на всех SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC bigset: 0.7188\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(np.concatenate([X_train_all_, X_train_pgs], axis=1))\n",
    "X_val_all = ss.transform(np.concatenate([X_val_all_, X_val_pgs], axis=1))\n",
    "\n",
    "model_gb = GradientBoostingClassifier()\n",
    "model_gb.fit(X_train_all, y_all_train)\n",
    "\n",
    "y_pred_proba = model_gb.predict_proba(X_val_all)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.7041\n",
      "ROC-AUC: 0.7433\n",
      "ROC-AUC: 0.7327\n",
      "ROC-AUC: 0.6941\n",
      "ROC-AUC: 0.7444\n",
      "среднее 0.7237413260365753\n"
     ]
    }
   ],
   "source": [
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = np.concatenate([train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), train_pgs], axis=1)\n",
    "    X_val_ = np.concatenate([test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), test_pgs], axis=1)\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    model_gb = GradientBoostingClassifier()\n",
    "    model_gb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC на всех SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC bigset: 0.7374\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(np.concatenate([X_train_all_, X_train_pgs], axis=1))\n",
    "X_val_all = ss.transform(np.concatenate([X_val_all_, X_val_pgs], axis=1))\n",
    "\n",
    "model_gb = SVC(probability=True)\n",
    "model_gb.fit(X_train_all, y_all_train)\n",
    "\n",
    "y_pred_proba = model_gb.predict_proba(X_val_all)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.7171\n",
      "ROC-AUC: 0.7331\n",
      "ROC-AUC: 0.7352\n",
      "ROC-AUC: 0.7106\n",
      "ROC-AUC: 0.7634\n",
      "среднее 0.7318608849429276\n"
     ]
    }
   ],
   "source": [
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = np.concatenate([train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), train_pgs], axis=1)\n",
    "    X_val_ = np.concatenate([test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), test_pgs], axis=1)\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    model_gb = SVC(probability=True)\n",
    "    model_gb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полносвязная сеть на всех snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7666\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(np.concatenate([X_train_all_, X_train_pgs], axis=1))\n",
    "X_val_all = ss.transform(np.concatenate([X_val_all_, X_val_pgs], axis=1))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train_all)\n",
    "y_train_tensor = torch.FloatTensor(y_all_train.values).reshape(-1, 1)\n",
    "\n",
    "model = Net(X_train_all.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_val_tensor = torch.FloatTensor(X_val_all)\n",
    "    y_pred_proba = model(X_val_tensor).numpy().flatten()\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7266\n",
      "ROC-AUC autoencoded: 0.7502\n",
      "ROC-AUC autoencoded: 0.7525\n",
      "ROC-AUC autoencoded: 0.6956\n",
      "ROC-AUC autoencoded: 0.7383\n",
      "среднее 0.7326409170129168\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = np.concatenate([train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), train_pgs], axis=1)\n",
    "    X_val_ = np.concatenate([test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy(), test_pgs], axis=1)\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "    \n",
    "    model = Net(X_train.shape[1])\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val_tensor = torch.FloatTensor(X_val)\n",
    "        y_pred_proba = model(X_val_tensor).numpy().flatten()\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок обучения с использованием классического автоэнкодера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С использованием логистической регрессии для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 20:16:05,668] A new study created in memory with name: no-name-ceeb740f-a317-4942-a61f-329dd8ea1193\n",
      "[I 2025-05-10 20:16:12,222] Trial 0 finished with value: 0.7621923165401425 and parameters: {'latent_dim': 37, 'hidden_dim': 178, 'lr': 0.009158291855730935, 'epochs': 46, 'C': 0.3182338683217116, 'dropout_rate': 0.483964389594041}. Best is trial 0 with value: 0.7621923165401425.\n",
      "[I 2025-05-10 20:16:14,651] Trial 1 finished with value: 0.7631700023004371 and parameters: {'latent_dim': 34, 'hidden_dim': 143, 'lr': 0.0019095555895441753, 'epochs': 19, 'C': 0.3113717523856937, 'dropout_rate': 0.14855696670680368}. Best is trial 1 with value: 0.7631700023004371.\n",
      "[I 2025-05-10 20:16:20,958] Trial 2 finished with value: 0.7661605705083967 and parameters: {'latent_dim': 34, 'hidden_dim': 164, 'lr': 0.0008534256270681129, 'epochs': 48, 'C': 0.0017160381632241107, 'dropout_rate': 0.32109264853624353}. Best is trial 2 with value: 0.7661605705083967.\n",
      "[I 2025-05-10 20:16:23,060] Trial 3 finished with value: 0.7789855072463768 and parameters: {'latent_dim': 64, 'hidden_dim': 212, 'lr': 0.0008396933673003034, 'epochs': 13, 'C': 0.0053857178227279265, 'dropout_rate': 0.179695742690425}. Best is trial 3 with value: 0.7789855072463768.\n",
      "[I 2025-05-10 20:16:28,750] Trial 4 finished with value: 0.7650103519668737 and parameters: {'latent_dim': 58, 'hidden_dim': 225, 'lr': 0.0019342983908909126, 'epochs': 40, 'C': 0.0011462884280708464, 'dropout_rate': 0.30121681830397296}. Best is trial 3 with value: 0.7789855072463768.\n",
      "[I 2025-05-10 20:16:30,165] Trial 5 finished with value: 0.7623648493213709 and parameters: {'latent_dim': 49, 'hidden_dim': 189, 'lr': 0.000884650422373095, 'epochs': 13, 'C': 0.03477913695869962, 'dropout_rate': 0.20056203189313107}. Best is trial 3 with value: 0.7789855072463768.\n",
      "[I 2025-05-10 20:16:31,580] Trial 6 finished with value: 0.7523004370830457 and parameters: {'latent_dim': 28, 'hidden_dim': 160, 'lr': 0.004345814870696957, 'epochs': 15, 'C': 1.173296484553324, 'dropout_rate': 0.4731223628913531}. Best is trial 3 with value: 0.7789855072463768.\n",
      "[I 2025-05-10 20:16:35,776] Trial 7 finished with value: 0.7548309178743962 and parameters: {'latent_dim': 87, 'hidden_dim': 136, 'lr': 0.0017105253621608647, 'epochs': 43, 'C': 0.18993338929020095, 'dropout_rate': 0.1535233116129828}. Best is trial 3 with value: 0.7789855072463768.\n",
      "[I 2025-05-10 20:16:39,076] Trial 8 finished with value: 0.764377731769036 and parameters: {'latent_dim': 95, 'hidden_dim': 208, 'lr': 0.00012181836285281196, 'epochs': 13, 'C': 3.6315101084891097, 'dropout_rate': 0.2785388364914696}. Best is trial 3 with value: 0.7789855072463768.\n",
      "[I 2025-05-10 20:16:42,383] Trial 9 finished with value: 0.7771451575799402 and parameters: {'latent_dim': 82, 'hidden_dim': 97, 'lr': 0.00235224587071387, 'epochs': 27, 'C': 0.005559760182943659, 'dropout_rate': 0.17370833067503794}. Best is trial 3 with value: 0.7789855072463768.\n",
      "[I 2025-05-10 20:16:46,885] Trial 10 finished with value: 0.7692661605705083 and parameters: {'latent_dim': 61, 'hidden_dim': 245, 'lr': 0.00025723548499645746, 'epochs': 27, 'C': 0.017772061360587822, 'dropout_rate': 0.3838584767066092}. Best is trial 3 with value: 0.7789855072463768.\n",
      "[I 2025-05-10 20:16:50,395] Trial 11 finished with value: 0.7780653324131585 and parameters: {'latent_dim': 78, 'hidden_dim': 70, 'lr': 0.000331092496332155, 'epochs': 26, 'C': 0.007488950260504438, 'dropout_rate': 0.2157769103724794}. Best is trial 3 with value: 0.7789855072463768.\n",
      "[I 2025-05-10 20:16:52,735] Trial 12 finished with value: 0.7816310098918795 and parameters: {'latent_dim': 73, 'hidden_dim': 66, 'lr': 0.00036296363705733587, 'epochs': 22, 'C': 0.010098480760178918, 'dropout_rate': 0.2289821605173353}. Best is trial 12 with value: 0.7816310098918795.\n",
      "[I 2025-05-10 20:16:55,990] Trial 13 finished with value: 0.7685760294455946 and parameters: {'latent_dim': 69, 'hidden_dim': 111, 'lr': 0.000444206072215578, 'epochs': 21, 'C': 0.03639031243423986, 'dropout_rate': 0.10197805583250841}. Best is trial 12 with value: 0.7816310098918795.\n",
      "[I 2025-05-10 20:16:57,529] Trial 14 finished with value: 0.7695537152058892 and parameters: {'latent_dim': 12, 'hidden_dim': 208, 'lr': 0.00014395026928503175, 'epochs': 10, 'C': 0.004673503559488223, 'dropout_rate': 0.2422594495519761}. Best is trial 12 with value: 0.7816310098918795.\n",
      "[I 2025-05-10 20:17:02,545] Trial 15 finished with value: 0.7757073844030364 and parameters: {'latent_dim': 71, 'hidden_dim': 255, 'lr': 0.0005369658121884386, 'epochs': 35, 'C': 0.06160052812217617, 'dropout_rate': 0.35168672385443134}. Best is trial 12 with value: 0.7816310098918795.\n",
      "[I 2025-05-10 20:17:04,945] Trial 16 finished with value: 0.7697837589141938 and parameters: {'latent_dim': 100, 'hidden_dim': 64, 'lr': 0.00022247159059815514, 'epochs': 20, 'C': 0.013418545441515191, 'dropout_rate': 0.24340528794251653}. Best is trial 12 with value: 0.7816310098918795.\n",
      "[I 2025-05-10 20:17:07,904] Trial 17 finished with value: 0.7685185185185185 and parameters: {'latent_dim': 49, 'hidden_dim': 109, 'lr': 0.0006028450847239024, 'epochs': 32, 'C': 0.003650812690220909, 'dropout_rate': 0.1144995632135039}. Best is trial 12 with value: 0.7816310098918795.\n",
      "[I 2025-05-10 20:17:10,193] Trial 18 finished with value: 0.769553715205889 and parameters: {'latent_dim': 66, 'hidden_dim': 228, 'lr': 0.0011015900495221747, 'epochs': 22, 'C': 0.002152032806572925, 'dropout_rate': 0.3991641982543077}. Best is trial 12 with value: 0.7816310098918795.\n",
      "[I 2025-05-10 20:17:11,700] Trial 19 finished with value: 0.7706464228203359 and parameters: {'latent_dim': 49, 'hidden_dim': 87, 'lr': 0.003981100628085377, 'epochs': 16, 'C': 0.01388737930896595, 'dropout_rate': 0.2569401458895653}. Best is trial 12 with value: 0.7816310098918795.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7731\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "    \n",
    "def train_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, _ in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _ = model(batch_x)\n",
    "            loss = criterion(reconstructed, batch_x)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    C = trial.suggest_float('C', 1e-3, 10.0, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "    autoencoder = train_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "    \n",
    "    X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "    X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "    \n",
    "    logreg = LogisticRegression(C=C, max_iter=1000)\n",
    "    logreg.fit(X_train_latent, y_train)\n",
    "    \n",
    "    y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(C=best_params['C'], max_iter=1000)\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latent_dim': 73,\n",
       " 'hidden_dim': 66,\n",
       " 'lr': 0.00036296363705733587,\n",
       " 'epochs': 22,\n",
       " 'C': 0.010098480760178918,\n",
       " 'dropout_rate': 0.2289821605173353}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7586\n",
      "ROC-AUC autoencoded: 0.7777\n",
      "ROC-AUC autoencoded: 0.7416\n",
      "ROC-AUC autoencoded: 0.7053\n",
      "ROC-AUC autoencoded: 0.7600\n",
      "среднее 0.7486588660295539\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "    autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "    \n",
    "    X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "    X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "    \n",
    "    logreg = LogisticRegression(C=best_params['C'], max_iter=1000)\n",
    "    logreg.fit(X_train_latent, y_train)\n",
    "    \n",
    "    y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "с градиентным бустингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 20:26:39,860] A new study created in memory with name: no-name-b9ad9930-e30e-41a4-9e81-900592c76f9a\n",
      "[I 2025-05-10 20:27:50,576] Trial 0 finished with value: 0.7423702170078981 and parameters: {'latent_dim': 90, 'hidden_dim': 170, 'lr': 0.00010981442731189312, 'epochs': 17, 'dropout_rate': 0.46939251449007113, 'n_estimators': 254, 'max_depth': 5, 'learning_rate': 0.017113280095762472, 'subsample': 0.7140088324766143, 'min_samples_split': 16, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7423702170078981.\n",
      "[I 2025-05-10 20:30:50,170] Trial 1 finished with value: 0.737941875623035 and parameters: {'latent_dim': 92, 'hidden_dim': 187, 'lr': 0.008093118002276292, 'epochs': 48, 'dropout_rate': 0.3681739947203867, 'n_estimators': 433, 'max_depth': 8, 'learning_rate': 0.011373414878795882, 'subsample': 0.8748184994158401, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7423702170078981.\n",
      "[I 2025-05-10 20:31:27,679] Trial 2 finished with value: 0.724369296833065 and parameters: {'latent_dim': 60, 'hidden_dim': 117, 'lr': 0.0012747557242261578, 'epochs': 49, 'dropout_rate': 0.3512457097032552, 'n_estimators': 90, 'max_depth': 8, 'learning_rate': 0.049105012046803745, 'subsample': 0.8408100805629977, 'min_samples_split': 16, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7423702170078981.\n",
      "[I 2025-05-10 20:31:58,441] Trial 3 finished with value: 0.7213020473890039 and parameters: {'latent_dim': 31, 'hidden_dim': 130, 'lr': 0.0005116734518851096, 'epochs': 44, 'dropout_rate': 0.19698007913044005, 'n_estimators': 110, 'max_depth': 6, 'learning_rate': 0.015416021215421898, 'subsample': 0.8667373756170982, 'min_samples_split': 20, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7423702170078981.\n",
      "[I 2025-05-10 20:32:41,091] Trial 4 finished with value: 0.7216279426424355 and parameters: {'latent_dim': 13, 'hidden_dim': 204, 'lr': 0.0023330520281301926, 'epochs': 13, 'dropout_rate': 0.354089452244855, 'n_estimators': 235, 'max_depth': 8, 'learning_rate': 0.09680364461005071, 'subsample': 0.7245008629403678, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7423702170078981.\n",
      "[I 2025-05-10 20:33:25,784] Trial 5 finished with value: 0.7236024844720497 and parameters: {'latent_dim': 14, 'hidden_dim': 182, 'lr': 0.0003354950275568624, 'epochs': 14, 'dropout_rate': 0.2971823724187075, 'n_estimators': 399, 'max_depth': 10, 'learning_rate': 0.2217468878590827, 'subsample': 0.834097267651562, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7423702170078981.\n",
      "[I 2025-05-10 20:35:10,141] Trial 6 finished with value: 0.7366382946093091 and parameters: {'latent_dim': 50, 'hidden_dim': 248, 'lr': 0.003339832516357732, 'epochs': 36, 'dropout_rate': 0.23557707455002147, 'n_estimators': 477, 'max_depth': 8, 'learning_rate': 0.04300359946823241, 'subsample': 0.625610052978886, 'min_samples_split': 19, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7423702170078981.\n",
      "[I 2025-05-10 20:35:26,208] Trial 7 finished with value: 0.7458975538685683 and parameters: {'latent_dim': 25, 'hidden_dim': 113, 'lr': 0.0008227275277591775, 'epochs': 23, 'dropout_rate': 0.19247230114006797, 'n_estimators': 98, 'max_depth': 4, 'learning_rate': 0.024339083454532836, 'subsample': 0.7357252695006755, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.7458975538685683.\n",
      "[I 2025-05-10 20:38:08,181] Trial 8 finished with value: 0.725174449812131 and parameters: {'latent_dim': 92, 'hidden_dim': 183, 'lr': 0.005203395170824042, 'epochs': 18, 'dropout_rate': 0.3235159897973596, 'n_estimators': 294, 'max_depth': 10, 'learning_rate': 0.14114485202872198, 'subsample': 0.9866336538646507, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.7458975538685683.\n",
      "[I 2025-05-10 20:38:24,948] Trial 9 finished with value: 0.7087263246683536 and parameters: {'latent_dim': 57, 'hidden_dim': 199, 'lr': 0.0006548442002824065, 'epochs': 17, 'dropout_rate': 0.3016887168842908, 'n_estimators': 60, 'max_depth': 9, 'learning_rate': 0.05475534864220809, 'subsample': 0.652774474710991, 'min_samples_split': 12, 'min_samples_leaf': 10}. Best is trial 7 with value: 0.7458975538685683.\n",
      "[I 2025-05-10 20:38:45,363] Trial 10 finished with value: 0.7409707844490453 and parameters: {'latent_dim': 35, 'hidden_dim': 67, 'lr': 0.00021191861976028564, 'epochs': 28, 'dropout_rate': 0.10979721758674836, 'n_estimators': 158, 'max_depth': 3, 'learning_rate': 0.025020803915026934, 'subsample': 0.7532247918118234, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 7 with value: 0.7458975538685683.\n",
      "[I 2025-05-10 20:39:25,784] Trial 11 finished with value: 0.7270147994785677 and parameters: {'latent_dim': 78, 'hidden_dim': 127, 'lr': 0.00012139686379418717, 'epochs': 24, 'dropout_rate': 0.4390995629070562, 'n_estimators': 234, 'max_depth': 4, 'learning_rate': 0.023934250932068645, 'subsample': 0.7059941655138089, 'min_samples_split': 15, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.7458975538685683.\n",
      "[I 2025-05-10 20:40:36,950] Trial 12 finished with value: 0.72663139329806 and parameters: {'latent_dim': 73, 'hidden_dim': 91, 'lr': 0.0013380678290104706, 'epochs': 23, 'dropout_rate': 0.4689929992443901, 'n_estimators': 328, 'max_depth': 5, 'learning_rate': 0.023460951429874546, 'subsample': 0.7739251875958725, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.7458975538685683.\n",
      "[I 2025-05-10 20:41:08,122] Trial 13 finished with value: 0.7443255885284871 and parameters: {'latent_dim': 35, 'hidden_dim': 151, 'lr': 0.00010398398905119486, 'epochs': 34, 'dropout_rate': 0.13220221617689487, 'n_estimators': 174, 'max_depth': 5, 'learning_rate': 0.011027339211270821, 'subsample': 0.6784893792672045, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.7458975538685683.\n",
      "[I 2025-05-10 20:41:30,348] Trial 14 finished with value: 0.7458017023234415 and parameters: {'latent_dim': 31, 'hidden_dim': 147, 'lr': 0.00023611935933271942, 'epochs': 36, 'dropout_rate': 0.12264919201636011, 'n_estimators': 163, 'max_depth': 3, 'learning_rate': 0.010545384341148772, 'subsample': 0.6689912236231212, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.7458975538685683.\n",
      "[I 2025-05-10 20:41:52,093] Trial 15 finished with value: 0.7375201288244767 and parameters: {'latent_dim': 26, 'hidden_dim': 99, 'lr': 0.00029637272355451387, 'epochs': 42, 'dropout_rate': 0.1833168400869779, 'n_estimators': 162, 'max_depth': 3, 'learning_rate': 0.03343915733149021, 'subsample': 0.6185025493713258, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.7458975538685683.\n",
      "[I 2025-05-10 20:42:18,640] Trial 16 finished with value: 0.7200176366843034 and parameters: {'latent_dim': 47, 'hidden_dim': 146, 'lr': 0.0005449525019841845, 'epochs': 33, 'dropout_rate': 0.17475438473966118, 'n_estimators': 131, 'max_depth': 4, 'learning_rate': 0.08666794706262, 'subsample': 0.7916353151089203, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.7458975538685683.\n",
      "[I 2025-05-10 20:42:33,254] Trial 17 finished with value: 0.7489839736216547 and parameters: {'latent_dim': 24, 'hidden_dim': 70, 'lr': 0.000895516101101449, 'epochs': 39, 'dropout_rate': 0.24420269002884082, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.015597295160939544, 'subsample': 0.9358877734795283, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 17 with value: 0.7489839736216547.\n",
      "[I 2025-05-10 20:42:50,361] Trial 18 finished with value: 0.7408749329039184 and parameters: {'latent_dim': 21, 'hidden_dim': 77, 'lr': 0.002015843345998459, 'epochs': 40, 'dropout_rate': 0.24984735674025071, 'n_estimators': 55, 'max_depth': 4, 'learning_rate': 0.017520490235573245, 'subsample': 0.9436957376694161, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 17 with value: 0.7489839736216547.\n",
      "[I 2025-05-10 20:43:41,467] Trial 19 finished with value: 0.7287209569818266 and parameters: {'latent_dim': 44, 'hidden_dim': 99, 'lr': 0.0008471969640035655, 'epochs': 28, 'dropout_rate': 0.24377920343848156, 'n_estimators': 209, 'max_depth': 6, 'learning_rate': 0.03372986489650831, 'subsample': 0.9072340626542017, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 17 with value: 0.7489839736216547.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7493\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры градиентного бустинга\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7387\n",
      "ROC-AUC autoencoded: 0.7492\n",
      "ROC-AUC autoencoded: 0.7468\n",
      "ROC-AUC autoencoded: 0.7401\n",
      "ROC-AUC autoencoded: 0.7440\n",
      "ROC-AUC autoencoded: 0.7441\n",
      "ROC-AUC autoencoded: 0.7375\n",
      "ROC-AUC autoencoded: 0.7411\n",
      "ROC-AUC autoencoded: 0.7239\n",
      "ROC-AUC autoencoded: 0.7376\n",
      "ROC-AUC autoencoded: 0.7373\n",
      "ROC-AUC autoencoded: 0.7369\n",
      "ROC-AUC autoencoded: 0.7414\n",
      "ROC-AUC autoencoded: 0.7349\n",
      "ROC-AUC autoencoded: 0.7366\n",
      "ROC-AUC autoencoded: 0.7129\n",
      "ROC-AUC autoencoded: 0.7136\n",
      "ROC-AUC autoencoded: 0.7172\n",
      "ROC-AUC autoencoded: 0.7167\n",
      "ROC-AUC autoencoded: 0.7226\n",
      "ROC-AUC autoencoded: 0.7455\n",
      "ROC-AUC autoencoded: 0.7495\n",
      "ROC-AUC autoencoded: 0.7479\n",
      "ROC-AUC autoencoded: 0.7468\n",
      "ROC-AUC autoencoded: 0.7535\n",
      "среднее 0.7366493156384593\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь с SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 20:45:25,253] A new study created in memory with name: no-name-31ec2f1c-0f36-4728-bccc-a51b3f27b8c2\n",
      "[I 2025-05-10 20:45:32,051] Trial 0 finished with value: 0.6033279656468062 and parameters: {'latent_dim': 24, 'hidden_dim': 66, 'lr': 0.0004236092982241249, 'epochs': 24, 'dropout_rate': 0.3034119355588364, 'C': 5.20596690472872, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 0 with value: 0.6033279656468062.\n",
      "[I 2025-05-10 20:45:48,373] Trial 1 finished with value: 0.741660915573959 and parameters: {'latent_dim': 65, 'hidden_dim': 248, 'lr': 0.0015545428444563034, 'epochs': 50, 'dropout_rate': 0.2682758189179693, 'C': 0.2469476376907018, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.741660915573959.\n",
      "[I 2025-05-10 20:45:59,654] Trial 2 finished with value: 0.6659957058507783 and parameters: {'latent_dim': 42, 'hidden_dim': 166, 'lr': 0.00013076216775538712, 'epochs': 36, 'dropout_rate': 0.3447443841718676, 'C': 0.45067734351800826, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 1 with value: 0.741660915573959.\n",
      "[I 2025-05-10 20:46:04,975] Trial 3 finished with value: 0.7256728778467908 and parameters: {'latent_dim': 51, 'hidden_dim': 128, 'lr': 0.0021701214378331665, 'epochs': 15, 'dropout_rate': 0.1365556778204522, 'C': 0.18813277743583393, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.741660915573959.\n",
      "[I 2025-05-10 20:46:12,727] Trial 4 finished with value: 0.684820949313703 and parameters: {'latent_dim': 52, 'hidden_dim': 118, 'lr': 0.00013952534894741907, 'epochs': 24, 'dropout_rate': 0.16306764683752606, 'C': 0.3055775135062633, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 1 with value: 0.741660915573959.\n",
      "[I 2025-05-10 20:46:19,215] Trial 5 finished with value: 0.7266409784525726 and parameters: {'latent_dim': 51, 'hidden_dim': 245, 'lr': 0.001724386229756503, 'epochs': 17, 'dropout_rate': 0.3274915646660579, 'C': 0.18654506961350745, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.741660915573959.\n",
      "[I 2025-05-10 20:46:30,365] Trial 6 finished with value: 0.739648033126294 and parameters: {'latent_dim': 87, 'hidden_dim': 150, 'lr': 0.0014863869369274069, 'epochs': 31, 'dropout_rate': 0.2493650277827323, 'C': 0.29784637066237235, 'kernel': 'linear'}. Best is trial 1 with value: 0.741660915573959.\n",
      "[I 2025-05-10 20:46:42,843] Trial 7 finished with value: 0.7229027681926232 and parameters: {'latent_dim': 73, 'hidden_dim': 177, 'lr': 0.0030613971658617722, 'epochs': 36, 'dropout_rate': 0.15294899719657581, 'C': 11.296010482607198, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.741660915573959.\n",
      "[I 2025-05-10 20:51:50,301] Trial 8 finished with value: 0.7556935817805384 and parameters: {'latent_dim': 78, 'hidden_dim': 203, 'lr': 0.00017166365117047392, 'epochs': 39, 'dropout_rate': 0.4049146822300851, 'C': 29.016705157856826, 'kernel': 'linear'}. Best is trial 8 with value: 0.7556935817805384.\n",
      "[I 2025-05-10 20:52:03,297] Trial 9 finished with value: 0.7584445211256806 and parameters: {'latent_dim': 26, 'hidden_dim': 128, 'lr': 0.0004575342509628243, 'epochs': 29, 'dropout_rate': 0.4928936680776078, 'C': 1.6575723772428663, 'kernel': 'linear'}. Best is trial 9 with value: 0.7584445211256806.\n",
      "[I 2025-05-10 20:52:10,569] Trial 10 finished with value: 0.7742887815351583 and parameters: {'latent_dim': 12, 'hidden_dim': 73, 'lr': 0.008783619230910956, 'epochs': 10, 'dropout_rate': 0.46163749117366804, 'C': 1.3993276634550393, 'kernel': 'linear'}. Best is trial 10 with value: 0.7742887815351583.\n",
      "[I 2025-05-10 20:52:18,289] Trial 11 finished with value: 0.7720650256882141 and parameters: {'latent_dim': 10, 'hidden_dim': 68, 'lr': 0.007621585962513926, 'epochs': 10, 'dropout_rate': 0.49416444258239295, 'C': 1.5665088964936993, 'kernel': 'linear'}. Best is trial 10 with value: 0.7742887815351583.\n",
      "[I 2025-05-10 20:52:25,557] Trial 12 finished with value: 0.7718829077524729 and parameters: {'latent_dim': 11, 'hidden_dim': 66, 'lr': 0.009371978568964393, 'epochs': 11, 'dropout_rate': 0.4984500546691867, 'C': 1.3477067161859033, 'kernel': 'linear'}. Best is trial 10 with value: 0.7742887815351583.\n",
      "[I 2025-05-10 20:52:32,433] Trial 13 finished with value: 0.7717103749712445 and parameters: {'latent_dim': 12, 'hidden_dim': 94, 'lr': 0.009010264415904917, 'epochs': 10, 'dropout_rate': 0.4181604762251701, 'C': 1.1151001493612789, 'kernel': 'linear'}. Best is trial 10 with value: 0.7742887815351583.\n",
      "[I 2025-05-10 20:52:38,203] Trial 14 finished with value: 0.6461352657004831 and parameters: {'latent_dim': 32, 'hidden_dim': 97, 'lr': 0.004518258750723694, 'epochs': 18, 'dropout_rate': 0.44725092870242233, 'C': 92.06411996274525, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 10 with value: 0.7742887815351583.\n",
      "[I 2025-05-10 20:52:57,968] Trial 15 finished with value: 0.7697645886051684 and parameters: {'latent_dim': 10, 'hidden_dim': 95, 'lr': 0.004816850248755415, 'epochs': 21, 'dropout_rate': 0.3809675413413696, 'C': 3.8947761290538003, 'kernel': 'linear'}. Best is trial 10 with value: 0.7742887815351583.\n",
      "[I 2025-05-10 20:53:04,366] Trial 16 finished with value: 0.7670040641055134 and parameters: {'latent_dim': 38, 'hidden_dim': 64, 'lr': 0.004591105358306941, 'epochs': 14, 'dropout_rate': 0.4549709965003054, 'C': 0.799826374699161, 'kernel': 'linear'}. Best is trial 10 with value: 0.7742887815351583.\n",
      "[I 2025-05-10 20:54:17,727] Trial 17 finished with value: 0.732919254658385 and parameters: {'latent_dim': 98, 'hidden_dim': 88, 'lr': 0.0007467106146529448, 'epochs': 10, 'dropout_rate': 0.45400618607562065, 'C': 10.028043621536996, 'kernel': 'linear'}. Best is trial 10 with value: 0.7742887815351583.\n",
      "[I 2025-05-10 20:54:23,769] Trial 18 finished with value: 0.6668487846024078 and parameters: {'latent_dim': 21, 'hidden_dim': 112, 'lr': 0.007322332852955265, 'epochs': 21, 'dropout_rate': 0.3664548352638919, 'C': 2.1659755951391895, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 10 with value: 0.7742887815351583.\n",
      "[I 2025-05-10 20:54:37,745] Trial 19 finished with value: 0.6171114178360556 and parameters: {'latent_dim': 19, 'hidden_dim': 211, 'lr': 0.006008922289834683, 'epochs': 50, 'dropout_rate': 0.1968917095065793, 'C': 0.613913738089889, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 10 with value: 0.7742887815351583.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7694\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры SVC\n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if best_params['kernel'] in ['rbf', 'poly', 'sigmoid'] else 'scale',\n",
    "    degree=best_params['degree'] if best_params['kernel'] == 'poly' else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7000\n",
      "ROC-AUC autoencoded: 0.7129\n",
      "ROC-AUC autoencoded: 0.7199\n",
      "ROC-AUC autoencoded: 0.7076\n",
      "ROC-AUC autoencoded: 0.7000\n",
      "ROC-AUC autoencoded: 0.7299\n",
      "ROC-AUC autoencoded: 0.7367\n",
      "ROC-AUC autoencoded: 0.7548\n",
      "ROC-AUC autoencoded: 0.7340\n",
      "ROC-AUC autoencoded: 0.7497\n",
      "ROC-AUC autoencoded: 0.7378\n",
      "ROC-AUC autoencoded: 0.7417\n",
      "ROC-AUC autoencoded: 0.7468\n",
      "ROC-AUC autoencoded: 0.7363\n",
      "ROC-AUC autoencoded: 0.7487\n",
      "ROC-AUC autoencoded: 0.6503\n",
      "ROC-AUC autoencoded: 0.6516\n",
      "ROC-AUC autoencoded: 0.6529\n",
      "ROC-AUC autoencoded: 0.6742\n",
      "ROC-AUC autoencoded: 0.6515\n",
      "ROC-AUC autoencoded: 0.7350\n",
      "ROC-AUC autoencoded: 0.7408\n",
      "ROC-AUC autoencoded: 0.7361\n",
      "ROC-AUC autoencoded: 0.7446\n",
      "ROC-AUC autoencoded: 0.7159\n",
      "среднее 0.7164051675909022\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if best_params['kernel'] in ['rbf', 'poly', 'sigmoid'] else 'scale',\n",
    "            degree=best_params['degree'] if best_params['kernel'] == 'poly' else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 21:07:17,646] A new study created in memory with name: no-name-0401ac9f-d6fc-4791-a14a-08be54858576\n",
      "[I 2025-05-10 21:07:33,032] Trial 0 finished with value: 0.7623840196303964 and parameters: {'latent_dim': 13, 'hidden_dim_ae': 83, 'lr_ae': 0.0016714360488584885, 'epochs_ae': 35, 'dropout_rate_ae': 0.4100147384409282, 'hidden_dim_mlp': 35, 'lr_mlp': 0.0010455354639130117, 'batch_size_mlp': 32, 'epochs_mlp': 15, 'dropout_rate_mlp': 0.38976174101096406}. Best is trial 0 with value: 0.7623840196303964.\n",
      "[I 2025-05-10 21:07:57,537] Trial 1 finished with value: 0.7208227896633693 and parameters: {'latent_dim': 90, 'hidden_dim_ae': 254, 'lr_ae': 0.0010433857832760631, 'epochs_ae': 47, 'dropout_rate_ae': 0.13995367502606093, 'hidden_dim_mlp': 72, 'lr_mlp': 0.0015551454924189955, 'batch_size_mlp': 64, 'epochs_mlp': 46, 'dropout_rate_mlp': 0.21759582506376032}. Best is trial 0 with value: 0.7623840196303964.\n",
      "[I 2025-05-10 21:08:08,345] Trial 2 finished with value: 0.7338777701096543 and parameters: {'latent_dim': 41, 'hidden_dim_ae': 163, 'lr_ae': 0.0017600038650889913, 'epochs_ae': 27, 'dropout_rate_ae': 0.10575099399680701, 'hidden_dim_mlp': 95, 'lr_mlp': 0.0008385085485054147, 'batch_size_mlp': 64, 'epochs_mlp': 32, 'dropout_rate_mlp': 0.33371017711945017}. Best is trial 0 with value: 0.7623840196303964.\n",
      "[I 2025-05-10 21:08:18,124] Trial 3 finished with value: 0.7531631009891879 and parameters: {'latent_dim': 18, 'hidden_dim_ae': 244, 'lr_ae': 0.00047288555585061357, 'epochs_ae': 27, 'dropout_rate_ae': 0.13478561343548862, 'hidden_dim_mlp': 39, 'lr_mlp': 0.0007393474183045843, 'batch_size_mlp': 64, 'epochs_mlp': 15, 'dropout_rate_mlp': 0.10270840711233441}. Best is trial 0 with value: 0.7623840196303964.\n",
      "[I 2025-05-10 21:08:35,163] Trial 4 finished with value: 0.7165094701326585 and parameters: {'latent_dim': 53, 'hidden_dim_ae': 147, 'lr_ae': 0.0010620811326405373, 'epochs_ae': 33, 'dropout_rate_ae': 0.46879846036412254, 'hidden_dim_mlp': 38, 'lr_mlp': 0.0014815711991406078, 'batch_size_mlp': 32, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.23425800542335448}. Best is trial 0 with value: 0.7623840196303964.\n",
      "[I 2025-05-10 21:08:44,861] Trial 5 finished with value: 0.7065984203665362 and parameters: {'latent_dim': 64, 'hidden_dim_ae': 75, 'lr_ae': 0.0007693250896647421, 'epochs_ae': 18, 'dropout_rate_ae': 0.35077019614179383, 'hidden_dim_mlp': 122, 'lr_mlp': 0.008489350656551691, 'batch_size_mlp': 64, 'epochs_mlp': 37, 'dropout_rate_mlp': 0.3388003314191097}. Best is trial 0 with value: 0.7623840196303964.\n",
      "[I 2025-05-10 21:09:13,827] Trial 6 finished with value: 0.7542558086036347 and parameters: {'latent_dim': 48, 'hidden_dim_ae': 220, 'lr_ae': 0.005735797584293273, 'epochs_ae': 48, 'dropout_rate_ae': 0.38841567354147244, 'hidden_dim_mlp': 44, 'lr_mlp': 0.0001370734763563655, 'batch_size_mlp': 16, 'epochs_mlp': 28, 'dropout_rate_mlp': 0.1706229401588776}. Best is trial 0 with value: 0.7623840196303964.\n",
      "[I 2025-05-10 21:09:37,858] Trial 7 finished with value: 0.7269764588605168 and parameters: {'latent_dim': 23, 'hidden_dim_ae': 148, 'lr_ae': 0.00018870996747308698, 'epochs_ae': 44, 'dropout_rate_ae': 0.4943388408532291, 'hidden_dim_mlp': 52, 'lr_mlp': 0.002621077131960874, 'batch_size_mlp': 32, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.3840723931334047}. Best is trial 0 with value: 0.7623840196303964.\n",
      "[I 2025-05-10 21:09:53,198] Trial 8 finished with value: 0.7537765508780002 and parameters: {'latent_dim': 67, 'hidden_dim_ae': 253, 'lr_ae': 0.00042676243725222284, 'epochs_ae': 42, 'dropout_rate_ae': 0.26921180142563644, 'hidden_dim_mlp': 53, 'lr_mlp': 0.0006011044931416185, 'batch_size_mlp': 64, 'epochs_mlp': 12, 'dropout_rate_mlp': 0.31291356914437257}. Best is trial 0 with value: 0.7623840196303964.\n",
      "[I 2025-05-10 21:10:12,144] Trial 9 finished with value: 0.7125795567824554 and parameters: {'latent_dim': 46, 'hidden_dim_ae': 238, 'lr_ae': 0.007965192250715833, 'epochs_ae': 22, 'dropout_rate_ae': 0.31394727243245857, 'hidden_dim_mlp': 121, 'lr_mlp': 0.00141432053201399, 'batch_size_mlp': 16, 'epochs_mlp': 29, 'dropout_rate_mlp': 0.393521975788223}. Best is trial 0 with value: 0.7623840196303964.\n",
      "[I 2025-05-10 21:10:20,068] Trial 10 finished with value: 0.7679817498658078 and parameters: {'latent_dim': 13, 'hidden_dim_ae': 78, 'lr_ae': 0.0030702797730008846, 'epochs_ae': 11, 'dropout_rate_ae': 0.40847554784558665, 'hidden_dim_mlp': 77, 'lr_mlp': 0.00022144661752389336, 'batch_size_mlp': 32, 'epochs_mlp': 21, 'dropout_rate_mlp': 0.4899716849527423}. Best is trial 10 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 21:10:32,242] Trial 11 finished with value: 0.7642627099148838 and parameters: {'latent_dim': 11, 'hidden_dim_ae': 72, 'lr_ae': 0.003055421595186818, 'epochs_ae': 35, 'dropout_rate_ae': 0.4200956214376832, 'hidden_dim_mlp': 77, 'lr_mlp': 0.00021255142082046032, 'batch_size_mlp': 32, 'epochs_mlp': 19, 'dropout_rate_mlp': 0.49629221766008214}. Best is trial 10 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 21:10:38,259] Trial 12 finished with value: 0.7638601334253506 and parameters: {'latent_dim': 30, 'hidden_dim_ae': 110, 'lr_ae': 0.003970230902563204, 'epochs_ae': 10, 'dropout_rate_ae': 0.2652063253829721, 'hidden_dim_mlp': 82, 'lr_mlp': 0.00014278040368166512, 'batch_size_mlp': 32, 'epochs_mlp': 21, 'dropout_rate_mlp': 0.4999319952210697}. Best is trial 10 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 21:10:45,007] Trial 13 finished with value: 0.758243232880914 and parameters: {'latent_dim': 32, 'hidden_dim_ae': 106, 'lr_ae': 0.0033364471818515496, 'epochs_ae': 13, 'dropout_rate_ae': 0.42293017680366285, 'hidden_dim_mlp': 72, 'lr_mlp': 0.00029073669097609805, 'batch_size_mlp': 32, 'epochs_mlp': 21, 'dropout_rate_mlp': 0.49467213192285153}. Best is trial 10 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 21:11:03,424] Trial 14 finished with value: 0.7649336707307722 and parameters: {'latent_dim': 11, 'hidden_dim_ae': 108, 'lr_ae': 0.0028044870816292264, 'epochs_ae': 37, 'dropout_rate_ae': 0.4358839596696533, 'hidden_dim_mlp': 98, 'lr_mlp': 0.0002839113954804675, 'batch_size_mlp': 32, 'epochs_mlp': 22, 'dropout_rate_mlp': 0.46870287655353887}. Best is trial 10 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 21:11:25,924] Trial 15 finished with value: 0.7475845410628018 and parameters: {'latent_dim': 93, 'hidden_dim_ae': 114, 'lr_ae': 0.0021254653012854918, 'epochs_ae': 39, 'dropout_rate_ae': 0.20564422169224467, 'hidden_dim_mlp': 100, 'lr_mlp': 0.0003451301927754744, 'batch_size_mlp': 32, 'epochs_mlp': 25, 'dropout_rate_mlp': 0.43760622960744344}. Best is trial 10 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 21:11:39,750] Trial 16 finished with value: 0.7688060731538991 and parameters: {'latent_dim': 31, 'hidden_dim_ae': 130, 'lr_ae': 0.009891180782161316, 'epochs_ae': 18, 'dropout_rate_ae': 0.35583887323537855, 'hidden_dim_mlp': 104, 'lr_mlp': 0.00010294369958555136, 'batch_size_mlp': 32, 'epochs_mlp': 38, 'dropout_rate_mlp': 0.44163381505413446}. Best is trial 16 with value: 0.7688060731538991.\n",
      "[I 2025-05-10 21:12:01,453] Trial 17 finished with value: 0.7643969020780615 and parameters: {'latent_dim': 33, 'hidden_dim_ae': 188, 'lr_ae': 0.008795696779911, 'epochs_ae': 17, 'dropout_rate_ae': 0.36385816557776796, 'hidden_dim_mlp': 111, 'lr_mlp': 0.0001317328416254773, 'batch_size_mlp': 16, 'epochs_mlp': 38, 'dropout_rate_mlp': 0.43229646877202554}. Best is trial 16 with value: 0.7688060731538991.\n",
      "[I 2025-05-10 21:12:15,179] Trial 18 finished with value: 0.7652212253661529 and parameters: {'latent_dim': 24, 'hidden_dim_ae': 131, 'lr_ae': 0.005438681120487769, 'epochs_ae': 20, 'dropout_rate_ae': 0.3269258640307073, 'hidden_dim_mlp': 88, 'lr_mlp': 0.0001037058333342437, 'batch_size_mlp': 32, 'epochs_mlp': 37, 'dropout_rate_mlp': 0.4411250278159438}. Best is trial 16 with value: 0.7688060731538991.\n",
      "[I 2025-05-10 21:12:25,536] Trial 19 finished with value: 0.7258454106280193 and parameters: {'latent_dim': 79, 'hidden_dim_ae': 192, 'lr_ae': 0.00011719210599182788, 'epochs_ae': 10, 'dropout_rate_ae': 0.2721052671593235, 'hidden_dim_mlp': 62, 'lr_mlp': 0.0004722496294327302, 'batch_size_mlp': 32, 'epochs_mlp': 43, 'dropout_rate_mlp': 0.3643097548925297}. Best is trial 16 with value: 0.7688060731538991.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7754\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры MLP\n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    batch_size_mlp = trial.suggest_categorical('batch_size_mlp', [16, 32, 64])\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size_mlp, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], best_params['batch_size_mlp'], best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7458\n",
      "ROC-AUC autoencoded: 0.7454\n",
      "ROC-AUC autoencoded: 0.7434\n",
      "ROC-AUC autoencoded: 0.7462\n",
      "ROC-AUC autoencoded: 0.7522\n",
      "ROC-AUC autoencoded: 0.7556\n",
      "ROC-AUC autoencoded: 0.7658\n",
      "ROC-AUC autoencoded: 0.7728\n",
      "ROC-AUC autoencoded: 0.7601\n",
      "ROC-AUC autoencoded: 0.7641\n",
      "ROC-AUC autoencoded: 0.7344\n",
      "ROC-AUC autoencoded: 0.7297\n",
      "ROC-AUC autoencoded: 0.7332\n",
      "ROC-AUC autoencoded: 0.7266\n",
      "ROC-AUC autoencoded: 0.7490\n",
      "ROC-AUC autoencoded: 0.7106\n",
      "ROC-AUC autoencoded: 0.7196\n",
      "ROC-AUC autoencoded: 0.7102\n",
      "ROC-AUC autoencoded: 0.6862\n",
      "ROC-AUC autoencoded: 0.7038\n",
      "ROC-AUC autoencoded: 0.7548\n",
      "ROC-AUC autoencoded: 0.7600\n",
      "ROC-AUC autoencoded: 0.7597\n",
      "ROC-AUC autoencoded: 0.7496\n",
      "ROC-AUC autoencoded: 0.7533\n",
      "среднее 0.7412807902350896\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], best_params['batch_size_mlp'], best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок с классическим автоэнкодером с второй классифицирующей головой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "логситическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 21:15:02,141] A new study created in memory with name: no-name-1fbe59d4-ba18-4392-ad8b-70f945632178\n",
      "[I 2025-05-10 21:15:11,972] Trial 0 finished with value: 0.5823364772640135 and parameters: {'latent_dim': 85, 'hidden_dim': 144, 'lr': 0.0008863120405804203, 'epochs': 27, 'dropout_rate': 0.2927137755142506, 'recon_weight': 0.17832524088973134, 'C': 0.08417701865571019}. Best is trial 0 with value: 0.5823364772640135.\n",
      "[I 2025-05-10 21:15:21,225] Trial 1 finished with value: 0.6388697185798635 and parameters: {'latent_dim': 35, 'hidden_dim': 245, 'lr': 0.003936583874037625, 'epochs': 23, 'dropout_rate': 0.22834626110558812, 'recon_weight': 0.33331948767221525, 'C': 0.014186192824981014}. Best is trial 1 with value: 0.6388697185798635.\n",
      "[I 2025-05-10 21:15:38,408] Trial 2 finished with value: 0.5821064335557089 and parameters: {'latent_dim': 95, 'hidden_dim': 171, 'lr': 0.0009131576242124419, 'epochs': 46, 'dropout_rate': 0.32324701685855695, 'recon_weight': 0.6768235888431784, 'C': 14.177387384788867}. Best is trial 1 with value: 0.6388697185798635.\n",
      "[I 2025-05-10 21:15:43,242] Trial 3 finished with value: 0.5930718503182271 and parameters: {'latent_dim': 11, 'hidden_dim': 161, 'lr': 0.0033185650157129642, 'epochs': 13, 'dropout_rate': 0.13666959346099805, 'recon_weight': 0.5061681418879473, 'C': 0.2503860762971641}. Best is trial 1 with value: 0.6388697185798635.\n",
      "[I 2025-05-10 21:15:47,629] Trial 4 finished with value: 0.6345563990491526 and parameters: {'latent_dim': 79, 'hidden_dim': 206, 'lr': 0.003369851455712625, 'epochs': 11, 'dropout_rate': 0.46640527247228425, 'recon_weight': 0.46209511370994283, 'C': 15.847381957147922}. Best is trial 1 with value: 0.6388697185798635.\n",
      "[I 2025-05-10 21:16:04,058] Trial 5 finished with value: 0.5865731155586228 and parameters: {'latent_dim': 73, 'hidden_dim': 105, 'lr': 0.0011422252239847346, 'epochs': 45, 'dropout_rate': 0.10276213945389388, 'recon_weight': 0.13473004859638174, 'C': 0.07371246681255507}. Best is trial 1 with value: 0.6388697185798635.\n",
      "[I 2025-05-10 21:16:11,729] Trial 6 finished with value: 0.7192316540142626 and parameters: {'latent_dim': 79, 'hidden_dim': 232, 'lr': 0.00012530644399672206, 'epochs': 20, 'dropout_rate': 0.1981512868570457, 'recon_weight': 0.11856231251070454, 'C': 0.014799083620929456}. Best is trial 6 with value: 0.7192316540142626.\n",
      "[I 2025-05-10 21:16:23,393] Trial 7 finished with value: 0.5555747258645809 and parameters: {'latent_dim': 80, 'hidden_dim': 139, 'lr': 0.0041034125673916405, 'epochs': 33, 'dropout_rate': 0.11202577568298233, 'recon_weight': 0.19963465813552955, 'C': 20.95110360819264}. Best is trial 6 with value: 0.7192316540142626.\n",
      "[I 2025-05-10 21:16:41,552] Trial 8 finished with value: 0.606280193236715 and parameters: {'latent_dim': 21, 'hidden_dim': 78, 'lr': 0.0051079458138197364, 'epochs': 38, 'dropout_rate': 0.3835780983621231, 'recon_weight': 0.732433507569045, 'C': 2.679826657709378}. Best is trial 6 with value: 0.7192316540142626.\n",
      "[I 2025-05-10 21:16:58,660] Trial 9 finished with value: 0.5564182194616977 and parameters: {'latent_dim': 68, 'hidden_dim': 255, 'lr': 0.0015507614712414765, 'epochs': 38, 'dropout_rate': 0.3603048526250908, 'recon_weight': 0.4129772609024237, 'C': 16.25503808592434}. Best is trial 6 with value: 0.7192316540142626.\n",
      "[I 2025-05-10 21:17:06,310] Trial 10 finished with value: 0.7704163791120312 and parameters: {'latent_dim': 50, 'hidden_dim': 211, 'lr': 0.00011269118764370099, 'epochs': 20, 'dropout_rate': 0.2102492768869898, 'recon_weight': 0.8360429782321463, 'C': 0.014169209258410226}. Best is trial 10 with value: 0.7704163791120312.\n",
      "[I 2025-05-10 21:17:13,432] Trial 11 finished with value: 0.771470746108427 and parameters: {'latent_dim': 50, 'hidden_dim': 220, 'lr': 0.0001139705545545556, 'epochs': 19, 'dropout_rate': 0.21926008211780035, 'recon_weight': 0.8684473430629742, 'C': 0.01664635833150399}. Best is trial 11 with value: 0.771470746108427.\n",
      "[I 2025-05-10 21:17:20,228] Trial 12 finished with value: 0.7410858063031975 and parameters: {'latent_dim': 50, 'hidden_dim': 199, 'lr': 0.00014842440047250607, 'epochs': 18, 'dropout_rate': 0.21844548749279827, 'recon_weight': 0.8886593635445329, 'C': 0.840528259032669}. Best is trial 11 with value: 0.771470746108427.\n",
      "[I 2025-05-10 21:17:26,224] Trial 13 finished with value: 0.7728701786672801 and parameters: {'latent_dim': 55, 'hidden_dim': 213, 'lr': 0.0002842310382532147, 'epochs': 16, 'dropout_rate': 0.2654641135962812, 'recon_weight': 0.8728854165691271, 'C': 0.010483657328154636}. Best is trial 13 with value: 0.7728701786672801.\n",
      "[I 2025-05-10 21:17:32,826] Trial 14 finished with value: 0.7109692508243234 and parameters: {'latent_dim': 60, 'hidden_dim': 186, 'lr': 0.0003110746862525097, 'epochs': 15, 'dropout_rate': 0.27722418756997846, 'recon_weight': 0.6395954076995373, 'C': 0.06622058135094186}. Best is trial 13 with value: 0.7728701786672801.\n",
      "[I 2025-05-10 21:17:43,546] Trial 15 finished with value: 0.6224024231270607 and parameters: {'latent_dim': 39, 'hidden_dim': 219, 'lr': 0.0003151604249567438, 'epochs': 27, 'dropout_rate': 0.16379948937012978, 'recon_weight': 0.7712761860718056, 'C': 0.28307945213645924}. Best is trial 13 with value: 0.7728701786672801.\n",
      "[I 2025-05-10 21:17:52,749] Trial 16 finished with value: 0.62261329652634 and parameters: {'latent_dim': 38, 'hidden_dim': 181, 'lr': 0.00028206148988356916, 'epochs': 25, 'dropout_rate': 0.2450851978886044, 'recon_weight': 0.6075884202181621, 'C': 73.57088830980211}. Best is trial 13 with value: 0.7728701786672801.\n",
      "[I 2025-05-10 21:17:56,644] Trial 17 finished with value: 0.7729468599033816 and parameters: {'latent_dim': 60, 'hidden_dim': 231, 'lr': 0.0005288159392883912, 'epochs': 10, 'dropout_rate': 0.4308259813006151, 'recon_weight': 0.886798862183724, 'C': 0.032161845658930606}. Best is trial 17 with value: 0.7729468599033816.\n",
      "[I 2025-05-10 21:18:00,959] Trial 18 finished with value: 0.7650678628939499 and parameters: {'latent_dim': 62, 'hidden_dim': 236, 'lr': 0.00043838836646696415, 'epochs': 10, 'dropout_rate': 0.4855312814494102, 'recon_weight': 0.7781758201641347, 'C': 0.05643067993415879}. Best is trial 17 with value: 0.7729468599033816.\n",
      "[I 2025-05-10 21:18:06,274] Trial 19 finished with value: 0.6502760524499654 and parameters: {'latent_dim': 29, 'hidden_dim': 120, 'lr': 0.009928502839737542, 'epochs': 15, 'dropout_rate': 0.41434490841180094, 'recon_weight': 0.7085792656799413, 'C': 0.22372070700470564}. Best is trial 17 with value: 0.7729468599033816.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7737\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(ClassifyingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "\n",
    "def train_classifying_autoencoder(model, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    class_criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _, classification = model(batch_x)\n",
    "            \n",
    "            recon_loss = recon_criterion(reconstructed, batch_x)\n",
    "            class_loss = class_criterion(classification, batch_y)\n",
    "            \n",
    "            loss = recon_weight * recon_loss + class_weight * class_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent, _ = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Веса для объединенной функции потерь\n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    # Параметры логистической регрессии\n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(C=C, max_iter=1000, random_state=42)\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(C=best_params['C'], max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7347\n",
      "ROC-AUC autoencoded: 0.7184\n",
      "ROC-AUC autoencoded: 0.7471\n",
      "ROC-AUC autoencoded: 0.7488\n",
      "ROC-AUC autoencoded: 0.7311\n",
      "ROC-AUC autoencoded: 0.7357\n",
      "ROC-AUC autoencoded: 0.7563\n",
      "ROC-AUC autoencoded: 0.7718\n",
      "ROC-AUC autoencoded: 0.7609\n",
      "ROC-AUC autoencoded: 0.7791\n",
      "ROC-AUC autoencoded: 0.7411\n",
      "ROC-AUC autoencoded: 0.7303\n",
      "ROC-AUC autoencoded: 0.7423\n",
      "ROC-AUC autoencoded: 0.7305\n",
      "ROC-AUC autoencoded: 0.7375\n",
      "ROC-AUC autoencoded: 0.6755\n",
      "ROC-AUC autoencoded: 0.6801\n",
      "ROC-AUC autoencoded: 0.6968\n",
      "ROC-AUC autoencoded: 0.6970\n",
      "ROC-AUC autoencoded: 0.6938\n",
      "ROC-AUC autoencoded: 0.7461\n",
      "ROC-AUC autoencoded: 0.7597\n",
      "ROC-AUC autoencoded: 0.7546\n",
      "ROC-AUC autoencoded: 0.7575\n",
      "ROC-AUC autoencoded: 0.7557\n",
      "среднее 0.7352955008279881\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(C=best_params['C'], max_iter=1000, random_state=42)\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 21:20:02,907] A new study created in memory with name: no-name-873325c3-fdc9-4ca8-944d-e7093de95b80\n",
      "[I 2025-05-10 21:20:52,520] Trial 0 finished with value: 0.6894793344068706 and parameters: {'latent_dim': 69, 'hidden_dim': 66, 'lr': 0.0003592453319438576, 'epochs': 47, 'dropout_rate': 0.33676841219726805, 'recon_weight': 0.6930921587379049, 'n_estimators': 117, 'max_depth': 4, 'learning_rate': 0.07954057275621372, 'subsample': 0.9665096632357344, 'min_samples_split': 19, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.6894793344068706.\n",
      "[I 2025-05-10 21:21:47,031] Trial 1 finished with value: 0.5653899240855762 and parameters: {'latent_dim': 41, 'hidden_dim': 120, 'lr': 0.006032840348185214, 'epochs': 46, 'dropout_rate': 0.25689892335937814, 'recon_weight': 0.7083611486364733, 'n_estimators': 266, 'max_depth': 5, 'learning_rate': 0.09376732490536899, 'subsample': 0.6137562140870056, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.6894793344068706.\n",
      "[I 2025-05-10 21:22:37,959] Trial 2 finished with value: 0.5724445978069167 and parameters: {'latent_dim': 80, 'hidden_dim': 92, 'lr': 0.003934710417251735, 'epochs': 29, 'dropout_rate': 0.1608813228602347, 'recon_weight': 0.36393715601944254, 'n_estimators': 85, 'max_depth': 8, 'learning_rate': 0.01841736962955337, 'subsample': 0.9067506179731455, 'min_samples_split': 15, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.6894793344068706.\n",
      "[I 2025-05-10 21:23:15,946] Trial 3 finished with value: 0.5573192239858907 and parameters: {'latent_dim': 51, 'hidden_dim': 227, 'lr': 0.008030291619556382, 'epochs': 30, 'dropout_rate': 0.28721265817990593, 'recon_weight': 0.3390875696137215, 'n_estimators': 205, 'max_depth': 3, 'learning_rate': 0.17155080637228712, 'subsample': 0.9332141020146953, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.6894793344068706.\n",
      "[I 2025-05-10 21:24:25,022] Trial 4 finished with value: 0.7007131354957442 and parameters: {'latent_dim': 49, 'hidden_dim': 254, 'lr': 0.00013813183549706798, 'epochs': 28, 'dropout_rate': 0.2888932115219971, 'recon_weight': 0.6595487773423294, 'n_estimators': 456, 'max_depth': 9, 'learning_rate': 0.17610023986543566, 'subsample': 0.8154146945571953, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 4 with value: 0.7007131354957442.\n",
      "[I 2025-05-10 21:24:51,534] Trial 5 finished with value: 0.6492025151445441 and parameters: {'latent_dim': 95, 'hidden_dim': 166, 'lr': 0.0005505525366674189, 'epochs': 16, 'dropout_rate': 0.30083848941084135, 'recon_weight': 0.20684979811141357, 'n_estimators': 79, 'max_depth': 8, 'learning_rate': 0.034089981392674155, 'subsample': 0.7273992630355692, 'min_samples_split': 14, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.7007131354957442.\n",
      "[I 2025-05-10 21:25:45,194] Trial 6 finished with value: 0.6806801625642205 and parameters: {'latent_dim': 50, 'hidden_dim': 225, 'lr': 0.0005447955243304799, 'epochs': 11, 'dropout_rate': 0.3969514610099204, 'recon_weight': 0.1442894547277332, 'n_estimators': 260, 'max_depth': 7, 'learning_rate': 0.022539212160712994, 'subsample': 0.7380331104122371, 'min_samples_split': 15, 'min_samples_leaf': 8}. Best is trial 4 with value: 0.7007131354957442.\n",
      "[I 2025-05-10 21:27:00,342] Trial 7 finished with value: 0.5752051223065716 and parameters: {'latent_dim': 82, 'hidden_dim': 152, 'lr': 0.003930632329140665, 'epochs': 17, 'dropout_rate': 0.21966166739286241, 'recon_weight': 0.34270431108098387, 'n_estimators': 244, 'max_depth': 10, 'learning_rate': 0.012311024628855928, 'subsample': 0.6970382940370465, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.7007131354957442.\n",
      "[I 2025-05-10 21:27:46,978] Trial 8 finished with value: 0.7151100375738056 and parameters: {'latent_dim': 11, 'hidden_dim': 142, 'lr': 0.0002024124708149623, 'epochs': 47, 'dropout_rate': 0.2642656500257049, 'recon_weight': 0.8608142346252345, 'n_estimators': 186, 'max_depth': 9, 'learning_rate': 0.28033070146848293, 'subsample': 0.8221814882463596, 'min_samples_split': 13, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.7151100375738056.\n",
      "[I 2025-05-10 21:28:50,704] Trial 9 finished with value: 0.5978931830381106 and parameters: {'latent_dim': 28, 'hidden_dim': 149, 'lr': 0.008437409890180075, 'epochs': 48, 'dropout_rate': 0.4794680715539179, 'recon_weight': 0.7357716972554875, 'n_estimators': 354, 'max_depth': 5, 'learning_rate': 0.012424802960578105, 'subsample': 0.8141896589887699, 'min_samples_split': 11, 'min_samples_leaf': 9}. Best is trial 8 with value: 0.7151100375738056.\n",
      "[I 2025-05-10 21:29:39,364] Trial 10 finished with value: 0.7176980292922321 and parameters: {'latent_dim': 11, 'hidden_dim': 191, 'lr': 0.00013552916035860805, 'epochs': 39, 'dropout_rate': 0.11574377956144552, 'recon_weight': 0.8858726896798335, 'n_estimators': 356, 'max_depth': 10, 'learning_rate': 0.29324094198877565, 'subsample': 0.8698685691429237, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.7176980292922321.\n",
      "[I 2025-05-10 21:30:27,997] Trial 11 finished with value: 0.7268997776244154 and parameters: {'latent_dim': 10, 'hidden_dim': 185, 'lr': 0.00011038371935862775, 'epochs': 40, 'dropout_rate': 0.10973554737901568, 'recon_weight': 0.8886933303641942, 'n_estimators': 379, 'max_depth': 10, 'learning_rate': 0.29285753840958334, 'subsample': 0.878167517916627, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.7268997776244154.\n",
      "[I 2025-05-10 21:31:18,958] Trial 12 finished with value: 0.7061766735679779 and parameters: {'latent_dim': 12, 'hidden_dim': 182, 'lr': 0.00010549938964347699, 'epochs': 39, 'dropout_rate': 0.10148306491814983, 'recon_weight': 0.883090742274706, 'n_estimators': 374, 'max_depth': 10, 'learning_rate': 0.2938130262908051, 'subsample': 0.881851144914246, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.7268997776244154.\n",
      "[I 2025-05-10 21:32:07,591] Trial 13 finished with value: 0.5779752319607393 and parameters: {'latent_dim': 28, 'hidden_dim': 196, 'lr': 0.0016467848833091776, 'epochs': 38, 'dropout_rate': 0.10004515655365036, 'recon_weight': 0.4988743264885298, 'n_estimators': 359, 'max_depth': 10, 'learning_rate': 0.14892818459289212, 'subsample': 0.9989018248091395, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.7268997776244154.\n",
      "[I 2025-05-10 21:33:55,714] Trial 14 finished with value: 0.6926232650870331 and parameters: {'latent_dim': 22, 'hidden_dim': 205, 'lr': 0.0002453243664707999, 'epochs': 38, 'dropout_rate': 0.1804078973456549, 'recon_weight': 0.805693468200846, 'n_estimators': 497, 'max_depth': 7, 'learning_rate': 0.0527610612376032, 'subsample': 0.8725896280126354, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.7268997776244154.\n",
      "[I 2025-05-10 21:35:03,521] Trial 15 finished with value: 0.5785215857679625 and parameters: {'latent_dim': 36, 'hidden_dim': 180, 'lr': 0.0010872969779229492, 'epochs': 41, 'dropout_rate': 0.1561305467610553, 'recon_weight': 0.5576811450741912, 'n_estimators': 418, 'max_depth': 9, 'learning_rate': 0.1079480744921612, 'subsample': 0.8732385354798347, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.7268997776244154.\n",
      "[I 2025-05-10 21:36:03,313] Trial 16 finished with value: 0.6862203818725559 and parameters: {'latent_dim': 20, 'hidden_dim': 120, 'lr': 0.00010390046216072639, 'epochs': 35, 'dropout_rate': 0.1950733421415558, 'recon_weight': 0.5487173328766131, 'n_estimators': 335, 'max_depth': 8, 'learning_rate': 0.20467164717949585, 'subsample': 0.7783393870265647, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.7268997776244154.\n",
      "[I 2025-05-10 21:37:01,817] Trial 17 finished with value: 0.6917606011808911 and parameters: {'latent_dim': 10, 'hidden_dim': 216, 'lr': 0.00019980811360466983, 'epochs': 23, 'dropout_rate': 0.13370386892401037, 'recon_weight': 0.7870279384714052, 'n_estimators': 323, 'max_depth': 6, 'learning_rate': 0.06275915697888239, 'subsample': 0.9355294693719451, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.7268997776244154.\n",
      "[I 2025-05-10 21:38:22,809] Trial 18 finished with value: 0.6054558699486235 and parameters: {'latent_dim': 62, 'hidden_dim': 241, 'lr': 0.00033357681618109204, 'epochs': 33, 'dropout_rate': 0.23283674509287172, 'recon_weight': 0.6165375828189164, 'n_estimators': 412, 'max_depth': 10, 'learning_rate': 0.1273276384762698, 'subsample': 0.8560795304602864, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.7268997776244154.\n",
      "[I 2025-05-10 21:39:21,188] Trial 19 finished with value: 0.649950157196534 and parameters: {'latent_dim': 34, 'hidden_dim': 190, 'lr': 0.0006443851693652122, 'epochs': 43, 'dropout_rate': 0.40410272999884667, 'recon_weight': 0.8096429214862318, 'n_estimators': 311, 'max_depth': 9, 'learning_rate': 0.23066261917975175, 'subsample': 0.7614606633676428, 'min_samples_split': 12, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.7268997776244154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7109\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Веса для объединенной функции потерь\n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    # Параметры градиентного бустинга\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7130\n",
      "ROC-AUC autoencoded: 0.7308\n",
      "ROC-AUC autoencoded: 0.7045\n",
      "ROC-AUC autoencoded: 0.7254\n",
      "ROC-AUC autoencoded: 0.7050\n",
      "ROC-AUC autoencoded: 0.6957\n",
      "ROC-AUC autoencoded: 0.7331\n",
      "ROC-AUC autoencoded: 0.7162\n",
      "ROC-AUC autoencoded: 0.6838\n",
      "ROC-AUC autoencoded: 0.6922\n",
      "ROC-AUC autoencoded: 0.7270\n",
      "ROC-AUC autoencoded: 0.7544\n",
      "ROC-AUC autoencoded: 0.7289\n",
      "ROC-AUC autoencoded: 0.7229\n",
      "ROC-AUC autoencoded: 0.7488\n",
      "ROC-AUC autoencoded: 0.6799\n",
      "ROC-AUC autoencoded: 0.6886\n",
      "ROC-AUC autoencoded: 0.6977\n",
      "ROC-AUC autoencoded: 0.6932\n",
      "ROC-AUC autoencoded: 0.7109\n",
      "ROC-AUC autoencoded: 0.7271\n",
      "ROC-AUC autoencoded: 0.7413\n",
      "ROC-AUC autoencoded: 0.7204\n",
      "ROC-AUC autoencoded: 0.7452\n",
      "ROC-AUC autoencoded: 0.7267\n",
      "среднее 0.7165108476697865\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 21:44:58,121] A new study created in memory with name: no-name-33035a43-041b-445a-bfd0-f0ace4206c7f\n",
      "[I 2025-05-10 21:45:03,912] Trial 0 finished with value: 0.7150046008741661 and parameters: {'latent_dim': 92, 'hidden_dim': 174, 'lr': 0.00040293924170599306, 'epochs': 12, 'dropout_rate': 0.21647311795149698, 'recon_weight': 0.7822068721387879, 'C': 0.11899817977582994, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.7150046008741661.\n",
      "[I 2025-05-10 21:45:08,525] Trial 1 finished with value: 0.6729545280269917 and parameters: {'latent_dim': 89, 'hidden_dim': 79, 'lr': 0.0031839583742939775, 'epochs': 11, 'dropout_rate': 0.19706146089054083, 'recon_weight': 0.7220418494244706, 'C': 1.1556672891774213, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.7150046008741661.\n",
      "[I 2025-05-10 21:45:17,007] Trial 2 finished with value: 0.608695652173913 and parameters: {'latent_dim': 65, 'hidden_dim': 221, 'lr': 0.00559228779234471, 'epochs': 20, 'dropout_rate': 0.23832381946252026, 'recon_weight': 0.22949596404695144, 'C': 10.041951397405454, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 0 with value: 0.7150046008741661.\n",
      "[I 2025-05-10 21:45:22,937] Trial 3 finished with value: 0.6032608695652174 and parameters: {'latent_dim': 85, 'hidden_dim': 216, 'lr': 0.0015753690326508378, 'epochs': 13, 'dropout_rate': 0.2689428948622417, 'recon_weight': 0.3860072130469321, 'C': 9.084294634337686, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 0 with value: 0.7150046008741661.\n",
      "[I 2025-05-10 21:45:31,884] Trial 4 finished with value: 0.7111226132965264 and parameters: {'latent_dim': 39, 'hidden_dim': 124, 'lr': 0.0005758933632759701, 'epochs': 23, 'dropout_rate': 0.31855925111070493, 'recon_weight': 0.7032288027752975, 'C': 0.25471603947963967, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 0 with value: 0.7150046008741661.\n",
      "[I 2025-05-10 21:46:04,458] Trial 5 finished with value: 0.6312207652787362 and parameters: {'latent_dim': 40, 'hidden_dim': 240, 'lr': 0.0002639158355805214, 'epochs': 37, 'dropout_rate': 0.2891589943230677, 'recon_weight': 0.7367761587138427, 'C': 15.833364117509051, 'kernel': 'linear'}. Best is trial 0 with value: 0.7150046008741661.\n",
      "[I 2025-05-10 21:46:12,465] Trial 6 finished with value: 0.6447454182961428 and parameters: {'latent_dim': 38, 'hidden_dim': 210, 'lr': 0.004359707705477767, 'epochs': 19, 'dropout_rate': 0.13235544636608645, 'recon_weight': 0.520253667897881, 'C': 0.11286535294055292, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.7150046008741661.\n",
      "[I 2025-05-10 21:46:29,015] Trial 7 finished with value: 0.6027624415305576 and parameters: {'latent_dim': 24, 'hidden_dim': 157, 'lr': 0.0004387950938492398, 'epochs': 43, 'dropout_rate': 0.21295724126908852, 'recon_weight': 0.3781507871394182, 'C': 60.01499353674759, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 0 with value: 0.7150046008741661.\n",
      "[I 2025-05-10 21:46:34,093] Trial 8 finished with value: 0.6743827160493826 and parameters: {'latent_dim': 57, 'hidden_dim': 134, 'lr': 0.009064555451437, 'epochs': 12, 'dropout_rate': 0.4758000791863445, 'recon_weight': 0.2938016466755865, 'C': 0.17449342317751812, 'kernel': 'linear'}. Best is trial 0 with value: 0.7150046008741661.\n",
      "[I 2025-05-10 21:46:47,674] Trial 9 finished with value: 0.5865539452495975 and parameters: {'latent_dim': 66, 'hidden_dim': 196, 'lr': 0.008308344214922036, 'epochs': 35, 'dropout_rate': 0.16355195198311046, 'recon_weight': 0.7575044549875197, 'C': 4.3169420428508545, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 0 with value: 0.7150046008741661.\n",
      "[I 2025-05-10 21:47:06,267] Trial 10 finished with value: 0.7347404340157961 and parameters: {'latent_dim': 98, 'hidden_dim': 66, 'lr': 0.00012189445878651176, 'epochs': 50, 'dropout_rate': 0.41179988849595484, 'recon_weight': 0.897240760738758, 'C': 0.8903482190324105, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 10 with value: 0.7347404340157961.\n",
      "[I 2025-05-10 21:47:23,634] Trial 11 finished with value: 0.7383348669580553 and parameters: {'latent_dim': 100, 'hidden_dim': 67, 'lr': 0.00010340258647550139, 'epochs': 46, 'dropout_rate': 0.39747124410633, 'recon_weight': 0.896523138190112, 'C': 0.7947014363322796, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.7383348669580553.\n",
      "[I 2025-05-10 21:47:42,480] Trial 12 finished with value: 0.7242446898243999 and parameters: {'latent_dim': 77, 'hidden_dim': 67, 'lr': 0.00011865526598757397, 'epochs': 50, 'dropout_rate': 0.41196424808401544, 'recon_weight': 0.8932420760951733, 'C': 0.9066332231503385, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.7383348669580553.\n",
      "[I 2025-05-10 21:48:01,852] Trial 13 finished with value: 0.7358714822482938 and parameters: {'latent_dim': 99, 'hidden_dim': 99, 'lr': 0.00010351279516587383, 'epochs': 50, 'dropout_rate': 0.36514391548088726, 'recon_weight': 0.8952957964394301, 'C': 1.4237526453609595, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.7383348669580553.\n",
      "[I 2025-05-10 21:48:18,286] Trial 14 finished with value: 0.7270914807146691 and parameters: {'latent_dim': 76, 'hidden_dim': 101, 'lr': 0.00019084591434816986, 'epochs': 42, 'dropout_rate': 0.35355627343836254, 'recon_weight': 0.5671283170037944, 'C': 0.4564440537101007, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.7383348669580553.\n",
      "[I 2025-05-10 21:48:35,735] Trial 15 finished with value: 0.6857219538378958 and parameters: {'latent_dim': 97, 'hidden_dim': 100, 'lr': 0.0009168396265608352, 'epochs': 46, 'dropout_rate': 0.38020546717228343, 'recon_weight': 0.8474249098414821, 'C': 2.683266659275647, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.7383348669580553.\n",
      "[I 2025-05-10 21:48:48,657] Trial 16 finished with value: 0.7118223295759528 and parameters: {'latent_dim': 80, 'hidden_dim': 97, 'lr': 0.00020623511322057447, 'epochs': 33, 'dropout_rate': 0.4991930440930477, 'recon_weight': 0.6177998076341557, 'C': 2.3926100867617683, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.7383348669580553.\n",
      "[I 2025-05-10 21:48:59,953] Trial 17 finished with value: 0.7380568974771874 and parameters: {'latent_dim': 100, 'hidden_dim': 130, 'lr': 0.0001046204797985501, 'epochs': 27, 'dropout_rate': 0.4295460271405178, 'recon_weight': 0.628622831072617, 'C': 0.436994564964828, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.7383348669580553.\n",
      "[I 2025-05-10 21:49:10,969] Trial 18 finished with value: 0.6288628172686144 and parameters: {'latent_dim': 11, 'hidden_dim': 133, 'lr': 0.001786768498826482, 'epochs': 28, 'dropout_rate': 0.466429622852347, 'recon_weight': 0.6481840386285842, 'C': 0.35702302280003584, 'kernel': 'linear'}. Best is trial 11 with value: 0.7383348669580553.\n",
      "[I 2025-05-10 21:49:22,676] Trial 19 finished with value: 0.7259508473276589 and parameters: {'latent_dim': 72, 'hidden_dim': 159, 'lr': 0.0002329945303600146, 'epochs': 28, 'dropout_rate': 0.4144639536863421, 'recon_weight': 0.4391948397632365, 'C': 0.4464397760750787, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 11 with value: 0.7383348669580553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7262\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7171\n",
      "ROC-AUC autoencoded: 0.7040\n",
      "ROC-AUC autoencoded: 0.7093\n",
      "ROC-AUC autoencoded: 0.6979\n",
      "ROC-AUC autoencoded: 0.7169\n",
      "ROC-AUC autoencoded: 0.7319\n",
      "ROC-AUC autoencoded: 0.7223\n",
      "ROC-AUC autoencoded: 0.7173\n",
      "ROC-AUC autoencoded: 0.7348\n",
      "ROC-AUC autoencoded: 0.7126\n",
      "ROC-AUC autoencoded: 0.7036\n",
      "ROC-AUC autoencoded: 0.7094\n",
      "ROC-AUC autoencoded: 0.7252\n",
      "ROC-AUC autoencoded: 0.7168\n",
      "ROC-AUC autoencoded: 0.7078\n",
      "ROC-AUC autoencoded: 0.6963\n",
      "ROC-AUC autoencoded: 0.7094\n",
      "ROC-AUC autoencoded: 0.6949\n",
      "ROC-AUC autoencoded: 0.7088\n",
      "ROC-AUC autoencoded: 0.6979\n",
      "ROC-AUC autoencoded: 0.7568\n",
      "ROC-AUC autoencoded: 0.7491\n",
      "ROC-AUC autoencoded: 0.7182\n",
      "ROC-AUC autoencoded: 0.7531\n",
      "ROC-AUC autoencoded: 0.7357\n",
      "среднее 0.7178787651477744\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 22:16:05,418] A new study created in memory with name: no-name-1937c797-2563-4cf4-bdc8-ffa00fdd5f6f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 22:16:19,482] Trial 0 finished with value: 0.7630741507553102 and parameters: {'latent_dim': 39, 'hidden_dim_ae': 144, 'hidden_dim_combined': 33, 'lr_ae': 0.00022500979189260536, 'lr_combined': 0.0005796070741164595, 'epochs_ae': 15, 'epochs_freeze': 7, 'epochs_unfreeze': 18, 'dropout_rate_ae': 0.4916343137842111, 'dropout_rate_combined': 0.15687399844709649, 'recon_weight': 0.72013168762003}. Best is trial 0 with value: 0.7630741507553102.\n",
      "[I 2025-05-10 22:16:34,776] Trial 1 finished with value: 0.6350356567747871 and parameters: {'latent_dim': 52, 'hidden_dim_ae': 182, 'hidden_dim_combined': 128, 'lr_ae': 0.003150179173782054, 'lr_combined': 0.00024094452968125498, 'epochs_ae': 28, 'epochs_freeze': 16, 'epochs_unfreeze': 7, 'dropout_rate_ae': 0.39756023309427324, 'dropout_rate_combined': 0.25855779849775384, 'recon_weight': 0.29944487925592245}. Best is trial 0 with value: 0.7630741507553102.\n",
      "[I 2025-05-10 22:16:46,810] Trial 2 finished with value: 0.7431561996779387 and parameters: {'latent_dim': 36, 'hidden_dim_ae': 205, 'hidden_dim_combined': 76, 'lr_ae': 0.0001687085813852501, 'lr_combined': 0.0007119692369125306, 'epochs_ae': 20, 'epochs_freeze': 11, 'epochs_unfreeze': 8, 'dropout_rate_ae': 0.3216545842859653, 'dropout_rate_combined': 0.46145601450794294, 'recon_weight': 0.3479414211307722}. Best is trial 0 with value: 0.7630741507553102.\n",
      "[I 2025-05-10 22:17:01,282] Trial 3 finished with value: 0.7647227973314928 and parameters: {'latent_dim': 100, 'hidden_dim_ae': 70, 'hidden_dim_combined': 69, 'lr_ae': 0.00020583406985291895, 'lr_combined': 0.0002626202822532929, 'epochs_ae': 25, 'epochs_freeze': 15, 'epochs_unfreeze': 10, 'dropout_rate_ae': 0.49286075789896033, 'dropout_rate_combined': 0.27389804070690793, 'recon_weight': 0.5840027881904856}. Best is trial 3 with value: 0.7647227973314928.\n",
      "[I 2025-05-10 22:17:17,714] Trial 4 finished with value: 0.6545702016716509 and parameters: {'latent_dim': 75, 'hidden_dim_ae': 116, 'hidden_dim_combined': 35, 'lr_ae': 0.00027187665815721324, 'lr_combined': 0.00941421113742875, 'epochs_ae': 40, 'epochs_freeze': 8, 'epochs_unfreeze': 6, 'dropout_rate_ae': 0.22174083438974887, 'dropout_rate_combined': 0.2546546375942183, 'recon_weight': 0.14348442425843866}. Best is trial 3 with value: 0.7647227973314928.\n",
      "[I 2025-05-10 22:17:39,285] Trial 5 finished with value: 0.6044877693428418 and parameters: {'latent_dim': 77, 'hidden_dim_ae': 224, 'hidden_dim_combined': 88, 'lr_ae': 0.004163374036861181, 'lr_combined': 0.0012005462655142287, 'epochs_ae': 25, 'epochs_freeze': 14, 'epochs_unfreeze': 14, 'dropout_rate_ae': 0.2643805559325433, 'dropout_rate_combined': 0.34386054111119846, 'recon_weight': 0.6054778989393805}. Best is trial 3 with value: 0.7647227973314928.\n",
      "[I 2025-05-10 22:17:58,876] Trial 6 finished with value: 0.6973775017253278 and parameters: {'latent_dim': 94, 'hidden_dim_ae': 206, 'hidden_dim_combined': 60, 'lr_ae': 0.0002137847891727812, 'lr_combined': 0.0009551340015831482, 'epochs_ae': 36, 'epochs_freeze': 14, 'epochs_unfreeze': 6, 'dropout_rate_ae': 0.30898397364003005, 'dropout_rate_combined': 0.15241984023414848, 'recon_weight': 0.5306612262615356}. Best is trial 3 with value: 0.7647227973314928.\n",
      "[I 2025-05-10 22:18:16,852] Trial 7 finished with value: 0.637642818802239 and parameters: {'latent_dim': 36, 'hidden_dim_ae': 145, 'hidden_dim_combined': 39, 'lr_ae': 0.0096555834569484, 'lr_combined': 0.00034785886287061566, 'epochs_ae': 34, 'epochs_freeze': 7, 'epochs_unfreeze': 13, 'dropout_rate_ae': 0.4289614256557681, 'dropout_rate_combined': 0.13436011091768824, 'recon_weight': 0.1257103157817901}. Best is trial 3 with value: 0.7647227973314928.\n",
      "[I 2025-05-10 22:18:36,791] Trial 8 finished with value: 0.5868031592669274 and parameters: {'latent_dim': 40, 'hidden_dim_ae': 251, 'hidden_dim_combined': 116, 'lr_ae': 0.0005113889701001634, 'lr_combined': 0.0021280926762909827, 'epochs_ae': 40, 'epochs_freeze': 5, 'epochs_unfreeze': 8, 'dropout_rate_ae': 0.12007372673528023, 'dropout_rate_combined': 0.34959559259235806, 'recon_weight': 0.720881034665565}. Best is trial 3 with value: 0.7647227973314928.\n",
      "[I 2025-05-10 22:19:03,893] Trial 9 finished with value: 0.6377195000383405 and parameters: {'latent_dim': 97, 'hidden_dim_ae': 151, 'hidden_dim_combined': 92, 'lr_ae': 0.003801467236615512, 'lr_combined': 0.005881167675481221, 'epochs_ae': 40, 'epochs_freeze': 18, 'epochs_unfreeze': 19, 'dropout_rate_ae': 0.4259638056309639, 'dropout_rate_combined': 0.17741606345331948, 'recon_weight': 0.5788224031645474}. Best is trial 3 with value: 0.7647227973314928.\n",
      "[I 2025-05-10 22:19:16,093] Trial 10 finished with value: 0.7494632313472893 and parameters: {'latent_dim': 12, 'hidden_dim_ae': 77, 'hidden_dim_combined': 61, 'lr_ae': 0.0005680320419327769, 'lr_combined': 0.00010582559971990775, 'epochs_ae': 10, 'epochs_freeze': 20, 'epochs_unfreeze': 11, 'dropout_rate_ae': 0.49869652003289977, 'dropout_rate_combined': 0.45016408283266157, 'recon_weight': 0.8275052893435673}. Best is trial 3 with value: 0.7647227973314928.\n",
      "[I 2025-05-10 22:19:30,325] Trial 11 finished with value: 0.7679817498658078 and parameters: {'latent_dim': 16, 'hidden_dim_ae': 68, 'hidden_dim_combined': 51, 'lr_ae': 0.00010481019634413081, 'lr_combined': 0.0002837235439594661, 'epochs_ae': 15, 'epochs_freeze': 11, 'epochs_unfreeze': 19, 'dropout_rate_ae': 0.4843560369828743, 'dropout_rate_combined': 0.21592960639107298, 'recon_weight': 0.8477138015644216}. Best is trial 11 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 22:19:54,308] Trial 12 finished with value: 0.7462426194310252 and parameters: {'latent_dim': 10, 'hidden_dim_ae': 65, 'hidden_dim_combined': 59, 'lr_ae': 0.00010903155090607658, 'lr_combined': 0.00012719996948618956, 'epochs_ae': 49, 'epochs_freeze': 11, 'epochs_unfreeze': 16, 'dropout_rate_ae': 0.37846401516705996, 'dropout_rate_combined': 0.2401275117026608, 'recon_weight': 0.8932772989135247}. Best is trial 11 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 22:20:11,853] Trial 13 finished with value: 0.7611954604708228 and parameters: {'latent_dim': 70, 'hidden_dim_ae': 106, 'hidden_dim_combined': 74, 'lr_ae': 0.00010612808205475295, 'lr_combined': 0.0002296128175357059, 'epochs_ae': 20, 'epochs_freeze': 12, 'epochs_unfreeze': 20, 'dropout_rate_ae': 0.4649591316809681, 'dropout_rate_combined': 0.3042295023576576, 'recon_weight': 0.3635044601105849}. Best is trial 11 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 22:20:27,487] Trial 14 finished with value: 0.7438079901848017 and parameters: {'latent_dim': 23, 'hidden_dim_ae': 97, 'hidden_dim_combined': 50, 'lr_ae': 0.0008765601766545925, 'lr_combined': 0.0003506050505126711, 'epochs_ae': 20, 'epochs_freeze': 16, 'epochs_unfreeze': 11, 'dropout_rate_ae': 0.3684137814695608, 'dropout_rate_combined': 0.21405991938974767, 'recon_weight': 0.7018448880692565}. Best is trial 11 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 22:20:40,378] Trial 15 finished with value: 0.7240625718886587 and parameters: {'latent_dim': 60, 'hidden_dim_ae': 93, 'hidden_dim_combined': 49, 'lr_ae': 0.0003912632480057573, 'lr_combined': 0.0017677297426351298, 'epochs_ae': 10, 'epochs_freeze': 15, 'epochs_unfreeze': 16, 'dropout_rate_ae': 0.175165563092344, 'dropout_rate_combined': 0.3749768399537494, 'recon_weight': 0.45328579482332576}. Best is trial 11 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 22:20:55,870] Trial 16 finished with value: 0.7437121386396748 and parameters: {'latent_dim': 90, 'hidden_dim_ae': 125, 'hidden_dim_combined': 99, 'lr_ae': 0.001711706178580487, 'lr_combined': 0.00016166621717545859, 'epochs_ae': 25, 'epochs_freeze': 11, 'epochs_unfreeze': 10, 'dropout_rate_ae': 0.43920493585299947, 'dropout_rate_combined': 0.29346100273266734, 'recon_weight': 0.812297893696734}. Best is trial 11 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 22:21:09,124] Trial 17 finished with value: 0.767885898320681 and parameters: {'latent_dim': 55, 'hidden_dim_ae': 77, 'hidden_dim_combined': 68, 'lr_ae': 0.00013768767235172255, 'lr_combined': 0.0004529255170106308, 'epochs_ae': 15, 'epochs_freeze': 9, 'epochs_unfreeze': 15, 'dropout_rate_ae': 0.348789630340205, 'dropout_rate_combined': 0.1938423632407279, 'recon_weight': 0.6719785674940065}. Best is trial 11 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 22:21:22,683] Trial 18 finished with value: 0.7544666820029139 and parameters: {'latent_dim': 26, 'hidden_dim_ae': 86, 'hidden_dim_combined': 46, 'lr_ae': 0.00010076497691393747, 'lr_combined': 0.00040938146951438327, 'epochs_ae': 16, 'epochs_freeze': 9, 'epochs_unfreeze': 17, 'dropout_rate_ae': 0.33675979320336447, 'dropout_rate_combined': 0.11200202824199532, 'recon_weight': 0.8096304400550612}. Best is trial 11 with value: 0.7679817498658078.\n",
      "[I 2025-05-10 22:21:34,996] Trial 19 finished with value: 0.6619891112644737 and parameters: {'latent_dim': 52, 'hidden_dim_ae': 122, 'hidden_dim_combined': 66, 'lr_ae': 0.0010487304316813702, 'lr_combined': 0.0030402230136142828, 'epochs_ae': 15, 'epochs_freeze': 5, 'epochs_unfreeze': 16, 'dropout_rate_ae': 0.268541530740091, 'dropout_rate_combined': 0.19954275610937064, 'recon_weight': 0.6700848445509563}. Best is trial 11 with value: 0.7679817498658078.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7650\n"
     ]
    }
   ],
   "source": [
    "class CombinedClassifier(nn.Module):\n",
    "    def __init__(self, autoencoder, pgs_input_dim, hidden_dim=64, dropout_rate=0.2):\n",
    "        super(CombinedClassifier, self).__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "        self.pgs_branch = nn.Sequential(\n",
    "            nn.Linear(pgs_input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        latent_dim = list(autoencoder.classifier[0].parameters())[0].shape[1]\n",
    "        self.combined_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim // 2 + latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_snp, x_pgs):\n",
    "        _, latent, _ = self.autoencoder(x_snp)\n",
    "        pgs_features = self.pgs_branch(x_pgs)\n",
    "        combined = torch.cat([latent, pgs_features], dim=1)\n",
    "        output = self.combined_classifier(combined)\n",
    "        return output\n",
    "\n",
    "def train_combined_classifier(model, X_train_snp, X_train_pgs, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_snp_tensor = torch.FloatTensor(X_train_snp).to(device)\n",
    "    X_train_pgs_tensor = torch.FloatTensor(X_train_pgs).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_snp_tensor, X_train_pgs_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Этап 1: Заморозить автоэнкодер и его голову\n",
    "    for param in model.autoencoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs_freeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Этап 2: Разморозить всё и обучать вместе\n",
    "    for param in model.autoencoder.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr/10)  # Уменьшаем скорость обучения для всей сети\n",
    "    \n",
    "    for epoch in range(epochs_unfreeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_combined(model, X_snp, X_pgs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_snp_tensor = torch.FloatTensor(X_snp).to(device)\n",
    "    X_pgs_tensor = torch.FloatTensor(X_pgs).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_snp_tensor, X_pgs_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    hidden_dim_combined = trial.suggest_int('hidden_dim_combined', 32, 128)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    lr_combined = trial.suggest_float('lr_combined', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    epochs_freeze = trial.suggest_int('epochs_freeze', 5, 20)\n",
    "    epochs_unfreeze = trial.suggest_int('epochs_unfreeze', 5, 20)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    dropout_rate_combined = trial.suggest_float('dropout_rate_combined', 0.1, 0.5)\n",
    "    \n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs_ae, batch_size, lr_ae, recon_weight, class_weight)\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, X_pgs_train.shape[1], hidden_dim_combined, dropout_rate_combined)\n",
    "        combined_model = train_combined_classifier(combined_model, X_train, X_pgs_train, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr_combined)\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, X_pgs_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs_ae'], 32, \n",
    "    best_params['lr_ae'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "combined_model = CombinedClassifier(autoencoder, X_train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "combined_model = train_combined_classifier(\n",
    "    combined_model, X_train_all, X_train_pgs, y_all_train, \n",
    "    best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    ")\n",
    "\n",
    "y_pred_proba = predict_combined(combined_model, X_val_all, X_val_pgs)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7464\n",
      "ROC-AUC autoencoded: 0.7405\n",
      "ROC-AUC autoencoded: 0.7531\n",
      "ROC-AUC autoencoded: 0.7479\n",
      "ROC-AUC autoencoded: 0.7465\n",
      "ROC-AUC autoencoded: 0.7647\n",
      "ROC-AUC autoencoded: 0.7680\n",
      "ROC-AUC autoencoded: 0.7794\n",
      "ROC-AUC autoencoded: 0.7481\n",
      "ROC-AUC autoencoded: 0.7682\n",
      "ROC-AUC autoencoded: 0.7244\n",
      "ROC-AUC autoencoded: 0.7250\n",
      "ROC-AUC autoencoded: 0.7248\n",
      "ROC-AUC autoencoded: 0.7316\n",
      "ROC-AUC autoencoded: 0.7314\n",
      "ROC-AUC autoencoded: 0.7028\n",
      "ROC-AUC autoencoded: 0.6912\n",
      "ROC-AUC autoencoded: 0.7136\n",
      "ROC-AUC autoencoded: 0.7125\n",
      "ROC-AUC autoencoded: 0.7048\n",
      "ROC-AUC autoencoded: 0.7546\n",
      "ROC-AUC autoencoded: 0.7781\n",
      "ROC-AUC autoencoded: 0.7485\n",
      "ROC-AUC autoencoded: 0.7558\n",
      "ROC-AUC autoencoded: 0.7627\n",
      "среднее 0.7409831682295444\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs_ae'], 32, \n",
    "            best_params['lr_ae'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "        combined_model = train_combined_classifier(\n",
    "            combined_model, X_train, train_pgs, y_train, \n",
    "            best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, test_pgs)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше идет блок со sparse автоэнкодером без классифицирующей головы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 22:24:29,551] A new study created in memory with name: no-name-53ed7951-e0a0-48aa-b241-b0f2db5b9f42\n",
      "[I 2025-05-10 22:24:40,819] Trial 0 finished with value: 0.7609654167625183 and parameters: {'latent_dim': 32, 'hidden_dim': 193, 'lr': 0.000439054835052641, 'epochs': 37, 'dropout_rate': 0.26356971038867627, 'sparsity_weight': 0.0037130881811672936, 'C': 0.2273128169568188, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7609654167625183.\n",
      "[I 2025-05-10 22:24:46,217] Trial 1 finished with value: 0.7731577333026607 and parameters: {'latent_dim': 21, 'hidden_dim': 148, 'lr': 0.0002852222563059938, 'epochs': 20, 'dropout_rate': 0.14634224735361331, 'sparsity_weight': 0.06874570719718005, 'C': 0.38489667229645136, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7731577333026607.\n",
      "[I 2025-05-10 22:24:55,706] Trial 2 finished with value: 0.7632850241545893 and parameters: {'latent_dim': 75, 'hidden_dim': 94, 'lr': 0.00043951678703255435, 'epochs': 37, 'dropout_rate': 0.17163667774406166, 'sparsity_weight': 0.0011998362280885308, 'C': 0.03782961130145265, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7731577333026607.\n",
      "[I 2025-05-10 22:25:10,978] Trial 3 finished with value: 0.7316348439536845 and parameters: {'latent_dim': 97, 'hidden_dim': 180, 'lr': 0.009769093055241974, 'epochs': 38, 'dropout_rate': 0.41244952089722275, 'sparsity_weight': 0.0001881847491171645, 'C': 35.3557920797564, 'solver': 'saga'}. Best is trial 1 with value: 0.7731577333026607.\n",
      "[I 2025-05-10 22:25:20,906] Trial 4 finished with value: 0.7266505636070854 and parameters: {'latent_dim': 73, 'hidden_dim': 121, 'lr': 0.005344208239336948, 'epochs': 37, 'dropout_rate': 0.32615311876804154, 'sparsity_weight': 0.00013768902078588978, 'C': 40.67687031805184, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7731577333026607.\n",
      "[I 2025-05-10 22:25:29,433] Trial 5 finished with value: 0.7658155049459398 and parameters: {'latent_dim': 36, 'hidden_dim': 150, 'lr': 0.0007771181734878068, 'epochs': 25, 'dropout_rate': 0.489005344522078, 'sparsity_weight': 0.0005785996672110799, 'C': 0.18268985096750823, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7731577333026607.\n",
      "[I 2025-05-10 22:25:39,932] Trial 6 finished with value: 0.766889042251361 and parameters: {'latent_dim': 87, 'hidden_dim': 249, 'lr': 0.00136851452546643, 'epochs': 26, 'dropout_rate': 0.44489424829568613, 'sparsity_weight': 0.009901406605173165, 'C': 0.08141829766427558, 'solver': 'liblinear'}. Best is trial 1 with value: 0.7731577333026607.\n",
      "[I 2025-05-10 22:25:53,116] Trial 7 finished with value: 0.7743462924622344 and parameters: {'latent_dim': 75, 'hidden_dim': 230, 'lr': 0.0005133791040563742, 'epochs': 29, 'dropout_rate': 0.30906924014866366, 'sparsity_weight': 0.05686699996359998, 'C': 0.05679570161026221, 'solver': 'saga'}. Best is trial 7 with value: 0.7743462924622344.\n",
      "[I 2025-05-10 22:25:58,613] Trial 8 finished with value: 0.747642051989878 and parameters: {'latent_dim': 41, 'hidden_dim': 180, 'lr': 0.0004385587534770171, 'epochs': 18, 'dropout_rate': 0.26922761082526875, 'sparsity_weight': 0.0014357729933746897, 'C': 49.07104098825436, 'solver': 'liblinear'}. Best is trial 7 with value: 0.7743462924622344.\n",
      "[I 2025-05-10 22:26:08,260] Trial 9 finished with value: 0.7372517444981211 and parameters: {'latent_dim': 93, 'hidden_dim': 116, 'lr': 0.0001369322366570214, 'epochs': 33, 'dropout_rate': 0.4865492071651306, 'sparsity_weight': 0.0012274677603585364, 'C': 55.687066251094436, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.7743462924622344.\n",
      "[I 2025-05-10 22:26:26,748] Trial 10 finished with value: 0.7452457633617054 and parameters: {'latent_dim': 65, 'hidden_dim': 256, 'lr': 0.001872776712000822, 'epochs': 48, 'dropout_rate': 0.341034306152114, 'sparsity_weight': 0.09391698209845688, 'C': 3.2909194594327498, 'solver': 'saga'}. Best is trial 7 with value: 0.7743462924622344.\n",
      "[I 2025-05-10 22:26:31,771] Trial 11 finished with value: 0.7806341538225596 and parameters: {'latent_dim': 53, 'hidden_dim': 218, 'lr': 0.00011548900992531349, 'epochs': 15, 'dropout_rate': 0.10081211023000487, 'sparsity_weight': 0.08887325224100896, 'C': 0.014198731483534777, 'solver': 'saga'}. Best is trial 11 with value: 0.7806341538225596.\n",
      "[I 2025-05-10 22:26:35,215] Trial 12 finished with value: 0.7747296986427421 and parameters: {'latent_dim': 52, 'hidden_dim': 221, 'lr': 0.00011425858265569652, 'epochs': 10, 'dropout_rate': 0.2003190487980802, 'sparsity_weight': 0.024139061703112315, 'C': 0.011623999894181435, 'solver': 'saga'}. Best is trial 11 with value: 0.7806341538225596.\n",
      "[I 2025-05-10 22:26:38,788] Trial 13 finished with value: 0.7727168161950769 and parameters: {'latent_dim': 51, 'hidden_dim': 214, 'lr': 0.0001029925924021825, 'epochs': 10, 'dropout_rate': 0.10078322410242666, 'sparsity_weight': 0.023681014450903724, 'C': 0.01264448087104702, 'solver': 'saga'}. Best is trial 11 with value: 0.7806341538225596.\n",
      "[I 2025-05-10 22:26:43,436] Trial 14 finished with value: 0.7774518825243463 and parameters: {'latent_dim': 57, 'hidden_dim': 214, 'lr': 0.00019216155105485904, 'epochs': 10, 'dropout_rate': 0.19540152707992287, 'sparsity_weight': 0.0194167203669604, 'C': 0.010752302891818213, 'solver': 'saga'}. Best is trial 11 with value: 0.7806341538225596.\n",
      "[I 2025-05-10 22:26:48,498] Trial 15 finished with value: 0.7465876849934822 and parameters: {'latent_dim': 58, 'hidden_dim': 198, 'lr': 0.00020168906438156514, 'epochs': 16, 'dropout_rate': 0.21365599564663817, 'sparsity_weight': 0.011582997148256766, 'C': 3.0608324642876883, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.7806341538225596.\n",
      "[I 2025-05-10 22:26:53,955] Trial 16 finished with value: 0.777432712215321 and parameters: {'latent_dim': 45, 'hidden_dim': 227, 'lr': 0.00023435350922982603, 'epochs': 15, 'dropout_rate': 0.10637135503581432, 'sparsity_weight': 0.030097187624465383, 'C': 0.03082807570620801, 'solver': 'saga'}. Best is trial 11 with value: 0.7806341538225596.\n",
      "[I 2025-05-10 22:27:01,538] Trial 17 finished with value: 0.75954681389464 and parameters: {'latent_dim': 12, 'hidden_dim': 166, 'lr': 0.0025306019615339626, 'epochs': 22, 'dropout_rate': 0.141845853414522, 'sparsity_weight': 0.0076311188056097864, 'C': 1.3578848414100524, 'solver': 'saga'}. Best is trial 11 with value: 0.7806341538225596.\n",
      "[I 2025-05-10 22:27:06,138] Trial 18 finished with value: 0.7757648953301127 and parameters: {'latent_dim': 62, 'hidden_dim': 205, 'lr': 0.0001686580587384989, 'epochs': 13, 'dropout_rate': 0.2395902663287659, 'sparsity_weight': 0.042161452304945085, 'C': 0.013790626578129779, 'solver': 'saga'}. Best is trial 11 with value: 0.7806341538225596.\n",
      "[I 2025-05-10 22:27:19,147] Trial 19 finished with value: 0.7635534084809447 and parameters: {'latent_dim': 29, 'hidden_dim': 66, 'lr': 0.0007649357495263346, 'epochs': 47, 'dropout_rate': 0.17361492955412294, 'sparsity_weight': 0.004959345279219581, 'C': 0.09769311929053835, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.7806341538225596.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7768\n"
     ]
    }
   ],
   "source": [
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "    \n",
    "def train_sparse_autoencoder(model, X_train, epochs, batch_size, lr, sparsity_weight):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, _ in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, latent = model(batch_x)\n",
    "            \n",
    "            recon_loss = criterion(reconstructed, batch_x)\n",
    "            \n",
    "            sparsity_loss = torch.mean(torch.abs(latent))\n",
    "            \n",
    "            loss = recon_loss + sparsity_weight * sparsity_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs, batch_size, lr, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7551\n",
      "ROC-AUC autoencoded: 0.7581\n",
      "ROC-AUC autoencoded: 0.7639\n",
      "ROC-AUC autoencoded: 0.7451\n",
      "ROC-AUC autoencoded: 0.7541\n",
      "ROC-AUC autoencoded: 0.7614\n",
      "ROC-AUC autoencoded: 0.7625\n",
      "ROC-AUC autoencoded: 0.7762\n",
      "ROC-AUC autoencoded: 0.7789\n",
      "ROC-AUC autoencoded: 0.7806\n",
      "ROC-AUC autoencoded: 0.7348\n",
      "ROC-AUC autoencoded: 0.7506\n",
      "ROC-AUC autoencoded: 0.7358\n",
      "ROC-AUC autoencoded: 0.7495\n",
      "ROC-AUC autoencoded: 0.7419\n",
      "ROC-AUC autoencoded: 0.7125\n",
      "ROC-AUC autoencoded: 0.7123\n",
      "ROC-AUC autoencoded: 0.7104\n",
      "ROC-AUC autoencoded: 0.7003\n",
      "ROC-AUC autoencoded: 0.7104\n",
      "ROC-AUC autoencoded: 0.7577\n",
      "ROC-AUC autoencoded: 0.7610\n",
      "ROC-AUC autoencoded: 0.7688\n",
      "ROC-AUC autoencoded: 0.7509\n",
      "ROC-AUC autoencoded: 0.7609\n",
      "среднее 0.7477580528475479\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 22:28:54,784] A new study created in memory with name: no-name-7414702f-52c0-4757-9709-0910321f91f8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 22:30:31,745] Trial 0 finished with value: 0.7316156736446592 and parameters: {'latent_dim': 26, 'hidden_dim': 64, 'lr': 0.0006469295284087385, 'epochs': 24, 'dropout_rate': 0.44588186205422464, 'sparsity_weight': 0.0023930896689645987, 'n_estimators': 425, 'max_depth': 6, 'learning_rate': 0.041580179378465205, 'subsample': 0.8300983689591996, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7316156736446592.\n",
      "[I 2025-05-10 22:31:47,227] Trial 1 finished with value: 0.7169120466221915 and parameters: {'latent_dim': 28, 'hidden_dim': 256, 'lr': 0.006038845936678987, 'epochs': 48, 'dropout_rate': 0.18524211155355952, 'sparsity_weight': 0.02546856117329749, 'n_estimators': 293, 'max_depth': 5, 'learning_rate': 0.16778073282756392, 'subsample': 0.9541033040936405, 'min_samples_split': 16, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7316156736446592.\n",
      "[I 2025-05-10 22:32:20,498] Trial 2 finished with value: 0.7447473353270455 and parameters: {'latent_dim': 58, 'hidden_dim': 145, 'lr': 0.0009473271845632404, 'epochs': 39, 'dropout_rate': 0.11775205227176536, 'sparsity_weight': 0.0738585917773478, 'n_estimators': 157, 'max_depth': 3, 'learning_rate': 0.08956999317407194, 'subsample': 0.945355596022333, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.7447473353270455.\n",
      "[I 2025-05-10 22:33:25,668] Trial 3 finished with value: 0.7163177670424047 and parameters: {'latent_dim': 13, 'hidden_dim': 171, 'lr': 0.0005997716891071644, 'epochs': 49, 'dropout_rate': 0.21445865176494172, 'sparsity_weight': 0.012253904483141672, 'n_estimators': 467, 'max_depth': 10, 'learning_rate': 0.20747157859781382, 'subsample': 0.7568478607625901, 'min_samples_split': 16, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.7447473353270455.\n",
      "[I 2025-05-10 22:33:54,132] Trial 4 finished with value: 0.7442680776014109 and parameters: {'latent_dim': 97, 'hidden_dim': 138, 'lr': 0.00010823362952252499, 'epochs': 30, 'dropout_rate': 0.22446062637062109, 'sparsity_weight': 0.0001294460854469908, 'n_estimators': 120, 'max_depth': 4, 'learning_rate': 0.015785003722836134, 'subsample': 0.678706207976857, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.7447473353270455.\n",
      "[I 2025-05-10 22:34:27,049] Trial 5 finished with value: 0.7052373284257342 and parameters: {'latent_dim': 29, 'hidden_dim': 250, 'lr': 0.00011448867107290874, 'epochs': 15, 'dropout_rate': 0.30807930455630295, 'sparsity_weight': 0.00033281796119022914, 'n_estimators': 321, 'max_depth': 3, 'learning_rate': 0.0846998064138745, 'subsample': 0.7258465761615389, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7447473353270455.\n",
      "[I 2025-05-10 22:35:46,064] Trial 6 finished with value: 0.7083812591058969 and parameters: {'latent_dim': 52, 'hidden_dim': 76, 'lr': 0.009947008043663488, 'epochs': 13, 'dropout_rate': 0.1463553337768817, 'sparsity_weight': 0.08297550576065743, 'n_estimators': 215, 'max_depth': 10, 'learning_rate': 0.06711164212524069, 'subsample': 0.9161990676429679, 'min_samples_split': 14, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.7447473353270455.\n",
      "[I 2025-05-10 22:37:09,180] Trial 7 finished with value: 0.7176596886741814 and parameters: {'latent_dim': 39, 'hidden_dim': 187, 'lr': 0.000923997110563554, 'epochs': 34, 'dropout_rate': 0.30816679342399467, 'sparsity_weight': 0.00016403477188365494, 'n_estimators': 364, 'max_depth': 9, 'learning_rate': 0.16655351735006874, 'subsample': 0.822319274832866, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.7447473353270455.\n",
      "[I 2025-05-10 22:38:30,399] Trial 8 finished with value: 0.7125028755463537 and parameters: {'latent_dim': 79, 'hidden_dim': 199, 'lr': 0.0022138270757033536, 'epochs': 33, 'dropout_rate': 0.4847992369129567, 'sparsity_weight': 0.0074561818029933065, 'n_estimators': 314, 'max_depth': 6, 'learning_rate': 0.04358619468760567, 'subsample': 0.8160180119711361, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.7447473353270455.\n",
      "[I 2025-05-10 22:41:21,258] Trial 9 finished with value: 0.7259796027911971 and parameters: {'latent_dim': 91, 'hidden_dim': 224, 'lr': 0.006331114539363385, 'epochs': 23, 'dropout_rate': 0.4384966635080979, 'sparsity_weight': 0.0017456173560529262, 'n_estimators': 479, 'max_depth': 7, 'learning_rate': 0.013412355396109231, 'subsample': 0.946025290520316, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.7447473353270455.\n",
      "[I 2025-05-10 22:41:47,451] Trial 10 finished with value: 0.7451307415075531 and parameters: {'latent_dim': 68, 'hidden_dim': 120, 'lr': 0.000286198014859255, 'epochs': 42, 'dropout_rate': 0.10821545313816033, 'sparsity_weight': 0.08929901783151792, 'n_estimators': 60, 'max_depth': 3, 'learning_rate': 0.023276575310191096, 'subsample': 0.8856782878606454, 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.7451307415075531.\n",
      "[I 2025-05-10 22:42:14,641] Trial 11 finished with value: 0.7516678168852082 and parameters: {'latent_dim': 72, 'hidden_dim': 119, 'lr': 0.00025761791280123724, 'epochs': 41, 'dropout_rate': 0.11291953130065514, 'sparsity_weight': 0.08951791902363053, 'n_estimators': 83, 'max_depth': 3, 'learning_rate': 0.02561305358102531, 'subsample': 0.8845037629963304, 'min_samples_split': 19, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.7516678168852082.\n",
      "[I 2025-05-10 22:42:44,713] Trial 12 finished with value: 0.7484280346599186 and parameters: {'latent_dim': 71, 'hidden_dim': 107, 'lr': 0.0002868948015094119, 'epochs': 42, 'dropout_rate': 0.11410989059071003, 'sparsity_weight': 0.0329561472237854, 'n_estimators': 68, 'max_depth': 4, 'learning_rate': 0.023876334190242328, 'subsample': 0.8933133245805558, 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.7516678168852082.\n",
      "[I 2025-05-10 22:43:14,780] Trial 13 finished with value: 0.7377118319147304 and parameters: {'latent_dim': 77, 'hidden_dim': 108, 'lr': 0.0003570337384027815, 'epochs': 43, 'dropout_rate': 0.25833109370543456, 'sparsity_weight': 0.025447346760924534, 'n_estimators': 83, 'max_depth': 5, 'learning_rate': 0.026067848207769997, 'subsample': 0.607428033738185, 'min_samples_split': 20, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.7516678168852082.\n",
      "[I 2025-05-10 22:44:10,649] Trial 14 finished with value: 0.7402423127060809 and parameters: {'latent_dim': 60, 'hidden_dim': 102, 'lr': 0.00023480291695158882, 'epochs': 38, 'dropout_rate': 0.16829463277716977, 'sparsity_weight': 0.028362888865801444, 'n_estimators': 211, 'max_depth': 4, 'learning_rate': 0.010181500889736437, 'subsample': 0.876064050550727, 'min_samples_split': 18, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.7516678168852082.\n",
      "[I 2025-05-10 22:45:42,720] Trial 15 finished with value: 0.7273598650410245 and parameters: {'latent_dim': 80, 'hidden_dim': 86, 'lr': 0.0020011234173365803, 'epochs': 45, 'dropout_rate': 0.38539891874360965, 'sparsity_weight': 0.005669855796909229, 'n_estimators': 174, 'max_depth': 8, 'learning_rate': 0.022512880797753817, 'subsample': 0.8731129046947365, 'min_samples_split': 12, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.7516678168852082.\n",
      "[I 2025-05-10 22:46:14,173] Trial 16 finished with value: 0.733072617130588 and parameters: {'latent_dim': 47, 'hidden_dim': 138, 'lr': 0.00020710501430688054, 'epochs': 26, 'dropout_rate': 0.1025192292005347, 'sparsity_weight': 0.000852575130170929, 'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.030964236157618657, 'subsample': 0.9997309907272234, 'min_samples_split': 20, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.7516678168852082.\n",
      "[I 2025-05-10 22:47:24,095] Trial 17 finished with value: 0.7335902154742734 and parameters: {'latent_dim': 71, 'hidden_dim': 119, 'lr': 0.0004248116030729546, 'epochs': 36, 'dropout_rate': 0.3600184759423428, 'sparsity_weight': 0.03990953626991121, 'n_estimators': 233, 'max_depth': 5, 'learning_rate': 0.01634197807615712, 'subsample': 0.7819171324735504, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.7516678168852082.\n",
      "[I 2025-05-10 22:48:09,010] Trial 18 finished with value: 0.7471244536461926 and parameters: {'latent_dim': 88, 'hidden_dim': 164, 'lr': 0.00015452189927049492, 'epochs': 40, 'dropout_rate': 0.2593697819456675, 'sparsity_weight': 0.013536794958252302, 'n_estimators': 132, 'max_depth': 4, 'learning_rate': 0.041294352288520866, 'subsample': 0.8563518480442561, 'min_samples_split': 18, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.7516678168852082.\n",
      "[I 2025-05-10 22:48:43,431] Trial 19 finished with value: 0.7218771566597654 and parameters: {'latent_dim': 66, 'hidden_dim': 91, 'lr': 0.0016540085688198142, 'epochs': 50, 'dropout_rate': 0.1493408155096825, 'sparsity_weight': 0.0474009058815809, 'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.05877307164225123, 'subsample': 0.9153444309845997, 'min_samples_split': 11, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.7516678168852082.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7588\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs, batch_size, lr, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7501\n",
      "ROC-AUC autoencoded: 0.7396\n",
      "ROC-AUC autoencoded: 0.7440\n",
      "ROC-AUC autoencoded: 0.7371\n",
      "ROC-AUC autoencoded: 0.7356\n",
      "ROC-AUC autoencoded: 0.7367\n",
      "ROC-AUC autoencoded: 0.7349\n",
      "ROC-AUC autoencoded: 0.7368\n",
      "ROC-AUC autoencoded: 0.7281\n",
      "ROC-AUC autoencoded: 0.7318\n",
      "ROC-AUC autoencoded: 0.7510\n",
      "ROC-AUC autoencoded: 0.7338\n",
      "ROC-AUC autoencoded: 0.7361\n",
      "ROC-AUC autoencoded: 0.7333\n",
      "ROC-AUC autoencoded: 0.7384\n",
      "ROC-AUC autoencoded: 0.7252\n",
      "ROC-AUC autoencoded: 0.7331\n",
      "ROC-AUC autoencoded: 0.7209\n",
      "ROC-AUC autoencoded: 0.7206\n",
      "ROC-AUC autoencoded: 0.7254\n",
      "ROC-AUC autoencoded: 0.7582\n",
      "ROC-AUC autoencoded: 0.7544\n",
      "ROC-AUC autoencoded: 0.7560\n",
      "ROC-AUC autoencoded: 0.7618\n",
      "ROC-AUC autoencoded: 0.7588\n",
      "среднее 0.7392669053725274\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 22:51:33,176] A new study created in memory with name: no-name-f83d3b13-7cfc-4b47-9bdc-bb9a4410ba41\n",
      "[I 2025-05-10 22:51:43,557] Trial 0 finished with value: 0.6364542596426654 and parameters: {'latent_dim': 66, 'hidden_dim': 163, 'lr': 0.006176910533801481, 'epochs': 21, 'dropout_rate': 0.4414074977951513, 'sparsity_weight': 0.005262446367759267, 'C': 1.0649836963445984, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.6364542596426654.\n",
      "[I 2025-05-10 22:51:54,819] Trial 1 finished with value: 0.7312130971551262 and parameters: {'latent_dim': 56, 'hidden_dim': 200, 'lr': 0.00019401128345167122, 'epochs': 24, 'dropout_rate': 0.18963744770433127, 'sparsity_weight': 0.0010726501375091877, 'C': 0.25770499698101157, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.7312130971551262.\n",
      "[I 2025-05-10 22:51:59,678] Trial 2 finished with value: 0.6630626485698948 and parameters: {'latent_dim': 15, 'hidden_dim': 98, 'lr': 0.007511135867907253, 'epochs': 11, 'dropout_rate': 0.21028612908561659, 'sparsity_weight': 0.001963812251617756, 'C': 0.19271202406984084, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 1 with value: 0.7312130971551262.\n",
      "[I 2025-05-10 22:52:04,359] Trial 3 finished with value: 0.6726478030825858 and parameters: {'latent_dim': 34, 'hidden_dim': 130, 'lr': 0.005836252065018404, 'epochs': 10, 'dropout_rate': 0.22682010688102516, 'sparsity_weight': 0.033207923077061774, 'C': 2.048779161448779, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.7312130971551262.\n",
      "[I 2025-05-10 22:52:14,842] Trial 4 finished with value: 0.7449006977992486 and parameters: {'latent_dim': 81, 'hidden_dim': 103, 'lr': 0.0006475593941509001, 'epochs': 24, 'dropout_rate': 0.1749768836703136, 'sparsity_weight': 0.014088160238241387, 'C': 0.5345338641101341, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 4 with value: 0.7449006977992486.\n",
      "[I 2025-05-10 22:52:29,429] Trial 5 finished with value: 0.6871309715512615 and parameters: {'latent_dim': 39, 'hidden_dim': 70, 'lr': 0.00011451876458592447, 'epochs': 39, 'dropout_rate': 0.13078675678754534, 'sparsity_weight': 0.06820450822806837, 'C': 0.18369059022891202, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.7449006977992486.\n",
      "[I 2025-05-10 22:52:39,612] Trial 6 finished with value: 0.7233341001456943 and parameters: {'latent_dim': 36, 'hidden_dim': 115, 'lr': 0.0027063311146492586, 'epochs': 23, 'dropout_rate': 0.39018778881652194, 'sparsity_weight': 0.013200425220164267, 'C': 0.1547199680007242, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 4 with value: 0.7449006977992486.\n",
      "[I 2025-05-10 22:52:58,969] Trial 7 finished with value: 0.7595563990491527 and parameters: {'latent_dim': 43, 'hidden_dim': 245, 'lr': 0.0015382709728463588, 'epochs': 27, 'dropout_rate': 0.4674655748892115, 'sparsity_weight': 0.0006624654324064085, 'C': 1.0720040840188771, 'kernel': 'linear'}. Best is trial 7 with value: 0.7595563990491527.\n",
      "[I 2025-05-10 22:53:20,448] Trial 8 finished with value: 0.7113143163867802 and parameters: {'latent_dim': 67, 'hidden_dim': 225, 'lr': 0.0002738266641674685, 'epochs': 36, 'dropout_rate': 0.4839147709109236, 'sparsity_weight': 0.005714412991670216, 'C': 1.6597688257855037, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 7 with value: 0.7595563990491527.\n",
      "[I 2025-05-10 22:53:40,716] Trial 9 finished with value: 0.7270723104056437 and parameters: {'latent_dim': 59, 'hidden_dim': 229, 'lr': 0.000759565177022565, 'epochs': 45, 'dropout_rate': 0.29655538468812725, 'sparsity_weight': 0.019166202252586247, 'C': 1.8988496930862977, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 7 with value: 0.7595563990491527.\n",
      "[I 2025-05-10 23:00:35,329] Trial 10 finished with value: 0.7332834905298674 and parameters: {'latent_dim': 96, 'hidden_dim': 251, 'lr': 0.0017796172994801773, 'epochs': 32, 'dropout_rate': 0.3604408293144815, 'sparsity_weight': 0.00010625224955857915, 'C': 28.113955741247842, 'kernel': 'linear'}. Best is trial 7 with value: 0.7595563990491527.\n",
      "[I 2025-05-10 23:02:23,497] Trial 11 finished with value: 0.7298328349052986 and parameters: {'latent_dim': 93, 'hidden_dim': 165, 'lr': 0.0006409796405057848, 'epochs': 26, 'dropout_rate': 0.3035735456691677, 'sparsity_weight': 0.0006875785656637849, 'C': 7.974964515178785, 'kernel': 'linear'}. Best is trial 7 with value: 0.7595563990491527.\n",
      "[I 2025-05-10 23:02:31,166] Trial 12 finished with value: 0.7370696265623802 and parameters: {'latent_dim': 80, 'hidden_dim': 67, 'lr': 0.0014779917190248374, 'epochs': 16, 'dropout_rate': 0.10352719214906456, 'sparsity_weight': 0.00020526662112018522, 'C': 0.599858470007196, 'kernel': 'linear'}. Best is trial 7 with value: 0.7595563990491527.\n",
      "[I 2025-05-10 23:02:41,867] Trial 13 finished with value: 0.7158576796257955 and parameters: {'latent_dim': 83, 'hidden_dim': 137, 'lr': 0.0004209659157085075, 'epochs': 30, 'dropout_rate': 0.2874027439239456, 'sparsity_weight': 0.00048500032560650706, 'C': 9.495600662392297, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 7 with value: 0.7595563990491527.\n",
      "[I 2025-05-10 23:02:51,024] Trial 14 finished with value: 0.7460700866497968 and parameters: {'latent_dim': 45, 'hidden_dim': 191, 'lr': 0.002945641811578839, 'epochs': 17, 'dropout_rate': 0.381596869608972, 'sparsity_weight': 0.003486325911648986, 'C': 0.6017601186634806, 'kernel': 'linear'}. Best is trial 7 with value: 0.7595563990491527.\n",
      "[I 2025-05-10 23:03:54,306] Trial 15 finished with value: 0.7637930373437619 and parameters: {'latent_dim': 23, 'hidden_dim': 197, 'lr': 0.0035498004654419264, 'epochs': 17, 'dropout_rate': 0.49979653917951206, 'sparsity_weight': 0.0022241128973952765, 'C': 9.133773433818549, 'kernel': 'linear'}. Best is trial 15 with value: 0.7637930373437619.\n",
      "[I 2025-05-10 23:10:23,804] Trial 16 finished with value: 0.7581473813357871 and parameters: {'latent_dim': 17, 'hidden_dim': 250, 'lr': 0.0032713958297316287, 'epochs': 17, 'dropout_rate': 0.4930113062809121, 'sparsity_weight': 0.00035563565111027646, 'C': 64.18434885776884, 'kernel': 'linear'}. Best is trial 15 with value: 0.7637930373437619.\n",
      "[I 2025-05-10 23:10:56,326] Trial 17 finished with value: 0.7520032972931524 and parameters: {'latent_dim': 29, 'hidden_dim': 197, 'lr': 0.00127974629097263, 'epochs': 30, 'dropout_rate': 0.4342185939596065, 'sparsity_weight': 0.0015881921739987397, 'C': 5.029968607553215, 'kernel': 'linear'}. Best is trial 15 with value: 0.7637930373437619.\n",
      "[I 2025-05-10 23:13:01,222] Trial 18 finished with value: 0.7561249137336095 and parameters: {'latent_dim': 24, 'hidden_dim': 222, 'lr': 0.004097906855821688, 'epochs': 49, 'dropout_rate': 0.4497560965171345, 'sparsity_weight': 0.0008421297903258636, 'C': 22.30936350223364, 'kernel': 'linear'}. Best is trial 15 with value: 0.7637930373437619.\n",
      "[I 2025-05-10 23:13:32,200] Trial 19 finished with value: 0.7454182961429338 and parameters: {'latent_dim': 49, 'hidden_dim': 180, 'lr': 0.002044679836037488, 'epochs': 15, 'dropout_rate': 0.424819282092462, 'sparsity_weight': 0.00026606685849248475, 'C': 4.2310962894863815, 'kernel': 'linear'}. Best is trial 15 with value: 0.7637930373437619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7576\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs, batch_size, lr, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7234\n",
      "ROC-AUC autoencoded: 0.7188\n",
      "ROC-AUC autoencoded: 0.7034\n",
      "ROC-AUC autoencoded: 0.7399\n",
      "ROC-AUC autoencoded: 0.7131\n",
      "ROC-AUC autoencoded: 0.7587\n",
      "ROC-AUC autoencoded: 0.7331\n",
      "ROC-AUC autoencoded: 0.7506\n",
      "ROC-AUC autoencoded: 0.7545\n",
      "ROC-AUC autoencoded: 0.7273\n",
      "ROC-AUC autoencoded: 0.7297\n",
      "ROC-AUC autoencoded: 0.7037\n",
      "ROC-AUC autoencoded: 0.7378\n",
      "ROC-AUC autoencoded: 0.7366\n",
      "ROC-AUC autoencoded: 0.7437\n",
      "ROC-AUC autoencoded: 0.6256\n",
      "ROC-AUC autoencoded: 0.6859\n",
      "ROC-AUC autoencoded: 0.6161\n",
      "ROC-AUC autoencoded: 0.6450\n",
      "ROC-AUC autoencoded: 0.6193\n",
      "ROC-AUC autoencoded: 0.7341\n",
      "ROC-AUC autoencoded: 0.7149\n",
      "ROC-AUC autoencoded: 0.7087\n",
      "ROC-AUC autoencoded: 0.7332\n",
      "ROC-AUC autoencoded: 0.7291\n",
      "среднее 0.7114574902519419\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 23:18:45,446] A new study created in memory with name: no-name-b8ba6cbe-46ee-4cf1-81d7-b8eefd91c8d1\n",
      "[I 2025-05-10 23:19:03,108] Trial 0 finished with value: 0.6973966720343533 and parameters: {'latent_dim': 90, 'hidden_dim_ae': 120, 'lr_ae': 0.00037056821636439563, 'epochs_ae': 43, 'dropout_rate_ae': 0.24079394383062028, 'sparsity_weight': 0.009851395724032133, 'hidden_dim_mlp': 72, 'lr_mlp': 0.0015644814119993757, 'epochs_mlp': 42, 'dropout_rate_mlp': 0.36742416059859173}. Best is trial 0 with value: 0.6973966720343533.\n",
      "[I 2025-05-10 23:19:16,952] Trial 1 finished with value: 0.7408365922858676 and parameters: {'latent_dim': 61, 'hidden_dim_ae': 95, 'lr_ae': 0.0019619413006113705, 'epochs_ae': 41, 'dropout_rate_ae': 0.18593520624481258, 'sparsity_weight': 0.0001204419304255439, 'hidden_dim_mlp': 119, 'lr_mlp': 0.0007261093340923912, 'epochs_mlp': 23, 'dropout_rate_mlp': 0.48146076073704247}. Best is trial 1 with value: 0.7408365922858676.\n",
      "[I 2025-05-10 23:19:30,139] Trial 2 finished with value: 0.7477570738440305 and parameters: {'latent_dim': 38, 'hidden_dim_ae': 81, 'lr_ae': 0.0003133459661411588, 'epochs_ae': 18, 'dropout_rate_ae': 0.4964321834990638, 'sparsity_weight': 0.06089918336178809, 'hidden_dim_mlp': 50, 'lr_mlp': 0.0001967655392501044, 'epochs_mlp': 37, 'dropout_rate_mlp': 0.14953779735894887}. Best is trial 2 with value: 0.7477570738440305.\n",
      "[I 2025-05-10 23:19:47,226] Trial 3 finished with value: 0.7274173759681005 and parameters: {'latent_dim': 66, 'hidden_dim_ae': 184, 'lr_ae': 0.003027969790080399, 'epochs_ae': 36, 'dropout_rate_ae': 0.22537833594140833, 'sparsity_weight': 0.045922702110130255, 'hidden_dim_mlp': 80, 'lr_mlp': 0.001046069681189444, 'epochs_mlp': 26, 'dropout_rate_mlp': 0.3586751953260917}. Best is trial 2 with value: 0.7477570738440305.\n",
      "[I 2025-05-10 23:20:00,485] Trial 4 finished with value: 0.7562878613603251 and parameters: {'latent_dim': 57, 'hidden_dim_ae': 130, 'lr_ae': 0.006440603326584487, 'epochs_ae': 18, 'dropout_rate_ae': 0.17034822411312095, 'sparsity_weight': 0.0027637632417012855, 'hidden_dim_mlp': 111, 'lr_mlp': 0.00015967934496499684, 'epochs_mlp': 49, 'dropout_rate_mlp': 0.4479534321713987}. Best is trial 4 with value: 0.7562878613603251.\n",
      "[I 2025-05-10 23:20:16,996] Trial 5 finished with value: 0.7466643662295835 and parameters: {'latent_dim': 96, 'hidden_dim_ae': 186, 'lr_ae': 0.000777813930454167, 'epochs_ae': 35, 'dropout_rate_ae': 0.4392602063207386, 'sparsity_weight': 0.033646861640600594, 'hidden_dim_mlp': 43, 'lr_mlp': 0.0003711391881003976, 'epochs_mlp': 37, 'dropout_rate_mlp': 0.30340468380318897}. Best is trial 4 with value: 0.7562878613603251.\n",
      "[I 2025-05-10 23:20:26,945] Trial 6 finished with value: 0.705179817498658 and parameters: {'latent_dim': 45, 'hidden_dim_ae': 171, 'lr_ae': 0.00028955593365804187, 'epochs_ae': 17, 'dropout_rate_ae': 0.15459641321426534, 'sparsity_weight': 0.001120107527050903, 'hidden_dim_mlp': 98, 'lr_mlp': 0.0041842983276385, 'epochs_mlp': 28, 'dropout_rate_mlp': 0.3599106102339543}. Best is trial 4 with value: 0.7562878613603251.\n",
      "[I 2025-05-10 23:20:35,804] Trial 7 finished with value: 0.750805152979066 and parameters: {'latent_dim': 26, 'hidden_dim_ae': 236, 'lr_ae': 0.003100271440587517, 'epochs_ae': 23, 'dropout_rate_ae': 0.2993779640361742, 'sparsity_weight': 0.04106556337996243, 'hidden_dim_mlp': 72, 'lr_mlp': 0.0007041560632307436, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.2622941324750279}. Best is trial 4 with value: 0.7562878613603251.\n",
      "[I 2025-05-10 23:20:54,588] Trial 8 finished with value: 0.7186565447435012 and parameters: {'latent_dim': 97, 'hidden_dim_ae': 225, 'lr_ae': 0.0007777938546644096, 'epochs_ae': 38, 'dropout_rate_ae': 0.3446860521388915, 'sparsity_weight': 0.040601789989563965, 'hidden_dim_mlp': 93, 'lr_mlp': 0.00018391334507436146, 'epochs_mlp': 41, 'dropout_rate_mlp': 0.12342291073552386}. Best is trial 4 with value: 0.7562878613603251.\n",
      "[I 2025-05-10 23:21:08,390] Trial 9 finished with value: 0.7116210413311862 and parameters: {'latent_dim': 38, 'hidden_dim_ae': 224, 'lr_ae': 0.0007361212920377486, 'epochs_ae': 17, 'dropout_rate_ae': 0.3016107333144496, 'sparsity_weight': 0.0031485357807897497, 'hidden_dim_mlp': 94, 'lr_mlp': 0.0005794398256106865, 'epochs_mlp': 49, 'dropout_rate_mlp': 0.3136163241385289}. Best is trial 4 with value: 0.7562878613603251.\n",
      "[I 2025-05-10 23:21:23,996] Trial 10 finished with value: 0.729449428724791 and parameters: {'latent_dim': 12, 'hidden_dim_ae': 133, 'lr_ae': 0.008875941748366525, 'epochs_ae': 27, 'dropout_rate_ae': 0.10213202562204748, 'sparsity_weight': 0.0005086220440031324, 'hidden_dim_mlp': 128, 'lr_mlp': 0.007168970245970232, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.49241353139613464}. Best is trial 4 with value: 0.7562878613603251.\n",
      "[I 2025-05-10 23:21:37,037] Trial 11 finished with value: 0.7561536691971474 and parameters: {'latent_dim': 15, 'hidden_dim_ae': 243, 'lr_ae': 0.008468332139210883, 'epochs_ae': 25, 'dropout_rate_ae': 0.36597590564396676, 'sparsity_weight': 0.0038671157119611636, 'hidden_dim_mlp': 63, 'lr_mlp': 0.0001156220877757321, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.20582337752521127}. Best is trial 4 with value: 0.7562878613603251.\n",
      "[I 2025-05-10 23:21:53,678] Trial 12 finished with value: 0.7515336247220304 and parameters: {'latent_dim': 72, 'hidden_dim_ae': 140, 'lr_ae': 0.008503807535950142, 'epochs_ae': 50, 'dropout_rate_ae': 0.38229394664014876, 'sparsity_weight': 0.005985561751606077, 'hidden_dim_mlp': 61, 'lr_mlp': 0.0001043911749758525, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.2148491230870937}. Best is trial 4 with value: 0.7562878613603251.\n",
      "[I 2025-05-10 23:22:00,040] Trial 13 finished with value: 0.7538915727321526 and parameters: {'latent_dim': 10, 'hidden_dim_ae': 254, 'lr_ae': 0.004876482364753136, 'epochs_ae': 10, 'dropout_rate_ae': 0.39088069819461824, 'sparsity_weight': 0.001610465633358894, 'hidden_dim_mlp': 110, 'lr_mlp': 0.00010145075667085495, 'epochs_mlp': 19, 'dropout_rate_mlp': 0.4281531981709075}. Best is trial 4 with value: 0.7562878613603251.\n",
      "[I 2025-05-10 23:22:11,030] Trial 14 finished with value: 0.7620964649950158 and parameters: {'latent_dim': 76, 'hidden_dim_ae': 106, 'lr_ae': 0.0015819482453729129, 'epochs_ae': 27, 'dropout_rate_ae': 0.2828385663656923, 'sparsity_weight': 0.009450441723096725, 'hidden_dim_mlp': 35, 'lr_mlp': 0.00031929849349724364, 'epochs_mlp': 19, 'dropout_rate_mlp': 0.1973642571416096}. Best is trial 14 with value: 0.7620964649950158.\n",
      "[I 2025-05-10 23:22:21,989] Trial 15 finished with value: 0.7656813127827621 and parameters: {'latent_dim': 79, 'hidden_dim_ae': 66, 'lr_ae': 0.0001281014167640408, 'epochs_ae': 30, 'dropout_rate_ae': 0.26736669931075, 'sparsity_weight': 0.013891320199293185, 'hidden_dim_mlp': 33, 'lr_mlp': 0.00028224662287147553, 'epochs_mlp': 18, 'dropout_rate_mlp': 0.2055851028576863}. Best is trial 15 with value: 0.7656813127827621.\n",
      "[I 2025-05-10 23:22:36,881] Trial 16 finished with value: 0.749348209493137 and parameters: {'latent_dim': 78, 'hidden_dim_ae': 64, 'lr_ae': 0.00010082436766460542, 'epochs_ae': 31, 'dropout_rate_ae': 0.27295508428201454, 'sparsity_weight': 0.013421664423831806, 'hidden_dim_mlp': 32, 'lr_mlp': 0.00031328755281088456, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.18842983070217303}. Best is trial 15 with value: 0.7656813127827621.\n",
      "[I 2025-05-10 23:22:56,388] Trial 17 finished with value: 0.756728778467909 and parameters: {'latent_dim': 82, 'hidden_dim_ae': 101, 'lr_ae': 0.0001028766717501346, 'epochs_ae': 31, 'dropout_rate_ae': 0.23369792959262148, 'sparsity_weight': 0.01506441132593596, 'hidden_dim_mlp': 33, 'lr_mlp': 0.0003486547633982612, 'epochs_mlp': 16, 'dropout_rate_mlp': 0.2491753933599976}. Best is trial 15 with value: 0.7656813127827621.\n",
      "[I 2025-05-10 23:23:15,776] Trial 18 finished with value: 0.7098957135189018 and parameters: {'latent_dim': 80, 'hidden_dim_ae': 64, 'lr_ae': 0.00128885196497654, 'epochs_ae': 29, 'dropout_rate_ae': 0.2996150650166113, 'sparsity_weight': 0.01885586824672142, 'hidden_dim_mlp': 46, 'lr_mlp': 0.0019019402898158473, 'epochs_mlp': 22, 'dropout_rate_mlp': 0.15702333197852972}. Best is trial 15 with value: 0.7656813127827621.\n",
      "[I 2025-05-10 23:23:28,751] Trial 19 finished with value: 0.7482171612606395 and parameters: {'latent_dim': 50, 'hidden_dim_ae': 104, 'lr_ae': 0.00018418742627896096, 'epochs_ae': 24, 'dropout_rate_ae': 0.3284905150874634, 'sparsity_weight': 0.007626930543198489, 'hidden_dim_mlp': 54, 'lr_mlp': 0.000292926742235648, 'epochs_mlp': 32, 'dropout_rate_mlp': 0.23905045973071998}. Best is trial 15 with value: 0.7656813127827621.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7608\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7454\n",
      "ROC-AUC autoencoded: 0.7526\n",
      "ROC-AUC autoencoded: 0.7426\n",
      "ROC-AUC autoencoded: 0.7205\n",
      "ROC-AUC autoencoded: 0.7285\n",
      "ROC-AUC autoencoded: 0.7619\n",
      "ROC-AUC autoencoded: 0.7546\n",
      "ROC-AUC autoencoded: 0.7447\n",
      "ROC-AUC autoencoded: 0.7493\n",
      "ROC-AUC autoencoded: 0.7498\n",
      "ROC-AUC autoencoded: 0.7032\n",
      "ROC-AUC autoencoded: 0.7394\n",
      "ROC-AUC autoencoded: 0.7160\n",
      "ROC-AUC autoencoded: 0.7119\n",
      "ROC-AUC autoencoded: 0.7104\n",
      "ROC-AUC autoencoded: 0.7120\n",
      "ROC-AUC autoencoded: 0.6804\n",
      "ROC-AUC autoencoded: 0.6664\n",
      "ROC-AUC autoencoded: 0.7199\n",
      "ROC-AUC autoencoded: 0.7087\n",
      "ROC-AUC autoencoded: 0.7523\n",
      "ROC-AUC autoencoded: 0.7495\n",
      "ROC-AUC autoencoded: 0.7510\n",
      "ROC-AUC autoencoded: 0.7283\n",
      "ROC-AUC autoencoded: 0.7603\n",
      "среднее 0.7303867485098837\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь блок с sparse автоэнкодером с классифицирующей головой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 23:24:39,640] A new study created in memory with name: no-name-287d9212-e000-45f1-bbb8-21094037c7ca\n",
      "[I 2025-05-10 23:24:48,103] Trial 0 finished with value: 0.6132390154129284 and parameters: {'latent_dim': 87, 'hidden_dim': 95, 'lr': 0.0002597725135296698, 'epochs': 26, 'dropout_rate': 0.17445431622961638, 'sparsity_weight': 0.0076835035396832325, 'classification_weight': 0.4300906142523754, 'C': 4.176997941941316, 'solver': 'liblinear'}. Best is trial 0 with value: 0.6132390154129284.\n",
      "[I 2025-05-10 23:25:04,215] Trial 1 finished with value: 0.5690131124913733 and parameters: {'latent_dim': 29, 'hidden_dim': 251, 'lr': 0.003097635834286806, 'epochs': 46, 'dropout_rate': 0.40385626626354487, 'sparsity_weight': 0.0005577221789078868, 'classification_weight': 0.44866056643364016, 'C': 0.6197177320180327, 'solver': 'liblinear'}. Best is trial 0 with value: 0.6132390154129284.\n",
      "[I 2025-05-10 23:25:08,490] Trial 2 finished with value: 0.7171804309485469 and parameters: {'latent_dim': 48, 'hidden_dim': 212, 'lr': 0.0003348544289974515, 'epochs': 12, 'dropout_rate': 0.3842623559006635, 'sparsity_weight': 0.0001815497287813517, 'classification_weight': 0.32525554263470147, 'C': 1.1441757948178517, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.7171804309485469.\n",
      "[I 2025-05-10 23:25:13,241] Trial 3 finished with value: 0.6808718656544742 and parameters: {'latent_dim': 51, 'hidden_dim': 121, 'lr': 0.0006515093521717981, 'epochs': 12, 'dropout_rate': 0.3209050321631344, 'sparsity_weight': 0.0001272031163737178, 'classification_weight': 0.5831162463738223, 'C': 29.87986946145633, 'solver': 'liblinear'}. Best is trial 2 with value: 0.7171804309485469.\n",
      "[I 2025-05-10 23:25:23,483] Trial 4 finished with value: 0.7215512614063337 and parameters: {'latent_dim': 48, 'hidden_dim': 244, 'lr': 0.00015321731906722214, 'epochs': 20, 'dropout_rate': 0.24951638939082943, 'sparsity_weight': 0.0026743033247532432, 'classification_weight': 0.2208764971968014, 'C': 20.156045906072364, 'solver': 'saga'}. Best is trial 4 with value: 0.7215512614063337.\n",
      "[I 2025-05-10 23:25:41,466] Trial 5 finished with value: 0.6384096311632543 and parameters: {'latent_dim': 62, 'hidden_dim': 229, 'lr': 0.00026388338502510476, 'epochs': 50, 'dropout_rate': 0.19061483704536367, 'sparsity_weight': 0.003997289628198685, 'classification_weight': 0.532666795408072, 'C': 0.025274009762010375, 'solver': 'liblinear'}. Best is trial 4 with value: 0.7215512614063337.\n",
      "[I 2025-05-10 23:25:58,184] Trial 6 finished with value: 0.7192508243232881 and parameters: {'latent_dim': 21, 'hidden_dim': 250, 'lr': 0.00034419430607886405, 'epochs': 30, 'dropout_rate': 0.33389100185087184, 'sparsity_weight': 0.007481891311226323, 'classification_weight': 0.11284229293034231, 'C': 2.462664322869565, 'solver': 'liblinear'}. Best is trial 4 with value: 0.7215512614063337.\n",
      "[I 2025-05-10 23:26:08,342] Trial 7 finished with value: 0.6674526493367073 and parameters: {'latent_dim': 47, 'hidden_dim': 119, 'lr': 0.00026616668107796163, 'epochs': 21, 'dropout_rate': 0.25361366948374214, 'sparsity_weight': 0.0011365098564102083, 'classification_weight': 0.5506006088623258, 'C': 72.92399533341742, 'solver': 'liblinear'}. Best is trial 4 with value: 0.7215512614063337.\n",
      "[I 2025-05-10 23:26:21,057] Trial 8 finished with value: 0.7249635764128518 and parameters: {'latent_dim': 41, 'hidden_dim': 90, 'lr': 0.0001695937454333535, 'epochs': 29, 'dropout_rate': 0.32381480112190225, 'sparsity_weight': 0.012445837589865028, 'classification_weight': 0.3490514933267691, 'C': 9.914094778804639, 'solver': 'saga'}. Best is trial 8 with value: 0.7249635764128518.\n",
      "[I 2025-05-10 23:26:29,613] Trial 9 finished with value: 0.5958515451269074 and parameters: {'latent_dim': 64, 'hidden_dim': 238, 'lr': 0.003668955236884183, 'epochs': 13, 'dropout_rate': 0.26007764631818076, 'sparsity_weight': 0.014059532704547038, 'classification_weight': 0.8172033447661026, 'C': 2.941786791958005, 'solver': 'saga'}. Best is trial 8 with value: 0.7249635764128518.\n",
      "[I 2025-05-10 23:26:43,909] Trial 10 finished with value: 0.6433939115098535 and parameters: {'latent_dim': 96, 'hidden_dim': 69, 'lr': 0.0015612743845394043, 'epochs': 39, 'dropout_rate': 0.4559479615344989, 'sparsity_weight': 0.061990798337020765, 'classification_weight': 0.7534910812435132, 'C': 0.1138697073077684, 'solver': 'saga'}. Best is trial 8 with value: 0.7249635764128518.\n",
      "[I 2025-05-10 23:26:55,188] Trial 11 finished with value: 0.6949812130971552 and parameters: {'latent_dim': 33, 'hidden_dim': 186, 'lr': 0.00011205417318124785, 'epochs': 22, 'dropout_rate': 0.11493185727960117, 'sparsity_weight': 0.02356140527203591, 'classification_weight': 0.21374615378440073, 'C': 13.91705075776325, 'solver': 'saga'}. Best is trial 8 with value: 0.7249635764128518.\n",
      "[I 2025-05-10 23:27:14,433] Trial 12 finished with value: 0.6607622114868491 and parameters: {'latent_dim': 75, 'hidden_dim': 162, 'lr': 0.00015507258286435592, 'epochs': 37, 'dropout_rate': 0.2502887400300466, 'sparsity_weight': 0.0014817934235417374, 'classification_weight': 0.27991598220698444, 'C': 13.165900397321302, 'solver': 'saga'}. Best is trial 8 with value: 0.7249635764128518.\n",
      "[I 2025-05-10 23:27:22,989] Trial 13 finished with value: 0.7570163331032895 and parameters: {'latent_dim': 11, 'hidden_dim': 149, 'lr': 0.0008132317451029847, 'epochs': 19, 'dropout_rate': 0.4930311342748474, 'sparsity_weight': 0.08078053088451095, 'classification_weight': 0.1253661983062151, 'C': 70.85448686693802, 'solver': 'saga'}. Best is trial 13 with value: 0.7570163331032895.\n",
      "[I 2025-05-10 23:27:35,011] Trial 14 finished with value: 0.727839122766659 and parameters: {'latent_dim': 13, 'hidden_dim': 137, 'lr': 0.0009572345796143826, 'epochs': 34, 'dropout_rate': 0.47023948578110614, 'sparsity_weight': 0.05742806541679972, 'classification_weight': 0.12287661159354725, 'C': 59.20921725985479, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.7570163331032895.\n",
      "[I 2025-05-10 23:27:47,806] Trial 15 finished with value: 0.711755233494364 and parameters: {'latent_dim': 14, 'hidden_dim': 150, 'lr': 0.009959766532555528, 'epochs': 36, 'dropout_rate': 0.4996425020667466, 'sparsity_weight': 0.08756346444185213, 'classification_weight': 0.11119565476778184, 'C': 78.83324192646087, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.7570163331032895.\n",
      "[I 2025-05-10 23:27:53,901] Trial 16 finished with value: 0.6904761904761904 and parameters: {'latent_dim': 11, 'hidden_dim': 149, 'lr': 0.0008471343683959418, 'epochs': 17, 'dropout_rate': 0.48756225236332207, 'sparsity_weight': 0.027457333475027556, 'classification_weight': 0.6721737279041279, 'C': 91.73647008602623, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.7570163331032895.\n",
      "[I 2025-05-10 23:28:06,154] Trial 17 finished with value: 0.6319875776397517 and parameters: {'latent_dim': 24, 'hidden_dim': 176, 'lr': 0.0017791477190041837, 'epochs': 34, 'dropout_rate': 0.417158316556802, 'sparsity_weight': 0.041607057131134995, 'classification_weight': 0.19715682925975836, 'C': 0.48060028510164143, 'solver': 'lbfgs'}. Best is trial 13 with value: 0.7570163331032895.\n",
      "[I 2025-05-10 23:28:20,543] Trial 18 finished with value: 0.7737328425734223 and parameters: {'latent_dim': 10, 'hidden_dim': 123, 'lr': 0.0006033008716144859, 'epochs': 42, 'dropout_rate': 0.4359631627309075, 'sparsity_weight': 0.0958035500641959, 'classification_weight': 0.10144696057929459, 'C': 0.1347719268757126, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.7737328425734223.\n",
      "[I 2025-05-10 23:28:38,881] Trial 19 finished with value: 0.6734529560616517 and parameters: {'latent_dim': 35, 'hidden_dim': 198, 'lr': 0.0004302151386261936, 'epochs': 43, 'dropout_rate': 0.44033049509309613, 'sparsity_weight': 0.029522609550903186, 'classification_weight': 0.33749238026209766, 'C': 0.09887284774852595, 'solver': 'lbfgs'}. Best is trial 18 with value: 0.7737328425734223.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7705\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingSparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(ClassifyingSparseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "    \n",
    "def train_classifying_sparse_autoencoder(model, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    class_criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, latent, classification = model(batch_x)\n",
    "            \n",
    "            recon_loss = recon_criterion(reconstructed, batch_x)\n",
    "            sparsity_loss = torch.mean(torch.abs(latent))\n",
    "            class_loss = class_criterion(classification, batch_y)\n",
    "            \n",
    "            loss = (1 - classification_weight) * (recon_loss + sparsity_weight * sparsity_loss) + classification_weight * class_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent, _ = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7302\n",
      "ROC-AUC autoencoded: 0.7115\n",
      "ROC-AUC autoencoded: 0.7241\n",
      "ROC-AUC autoencoded: 0.7283\n",
      "ROC-AUC autoencoded: 0.7264\n",
      "ROC-AUC autoencoded: 0.7726\n",
      "ROC-AUC autoencoded: 0.7745\n",
      "ROC-AUC autoencoded: 0.7731\n",
      "ROC-AUC autoencoded: 0.7750\n",
      "ROC-AUC autoencoded: 0.7720\n",
      "ROC-AUC autoencoded: 0.7445\n",
      "ROC-AUC autoencoded: 0.7419\n",
      "ROC-AUC autoencoded: 0.7413\n",
      "ROC-AUC autoencoded: 0.7359\n",
      "ROC-AUC autoencoded: 0.7371\n",
      "ROC-AUC autoencoded: 0.6875\n",
      "ROC-AUC autoencoded: 0.6855\n",
      "ROC-AUC autoencoded: 0.6841\n",
      "ROC-AUC autoencoded: 0.6787\n",
      "ROC-AUC autoencoded: 0.6730\n",
      "ROC-AUC autoencoded: 0.7548\n",
      "ROC-AUC autoencoded: 0.7477\n",
      "ROC-AUC autoencoded: 0.7511\n",
      "ROC-AUC autoencoded: 0.7499\n",
      "ROC-AUC autoencoded: 0.7468\n",
      "среднее 0.7339096574359116\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 23:30:20,924] A new study created in memory with name: no-name-679de66c-a083-415a-8b32-fd308ce86be3\n",
      "[I 2025-05-10 23:31:05,661] Trial 0 finished with value: 0.639751552795031 and parameters: {'latent_dim': 44, 'hidden_dim': 98, 'lr': 0.0001515986697605629, 'epochs': 30, 'dropout_rate': 0.10648123718712915, 'sparsity_weight': 0.09779898429249859, 'classification_weight': 0.8332143125303054, 'n_estimators': 180, 'max_depth': 9, 'learning_rate': 0.06646491611984465, 'subsample': 0.6605850657689435, 'min_samples_split': 17, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.639751552795031.\n",
      "[I 2025-05-10 23:33:03,609] Trial 1 finished with value: 0.6335978835978836 and parameters: {'latent_dim': 31, 'hidden_dim': 169, 'lr': 0.0008349457937271405, 'epochs': 13, 'dropout_rate': 0.28243490475826083, 'sparsity_weight': 0.00014538510913989083, 'classification_weight': 0.89467242270219, 'n_estimators': 487, 'max_depth': 8, 'learning_rate': 0.012565844169546684, 'subsample': 0.9088598897610067, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.639751552795031.\n",
      "[I 2025-05-10 23:33:55,289] Trial 2 finished with value: 0.5820872632466835 and parameters: {'latent_dim': 61, 'hidden_dim': 194, 'lr': 0.009691776519957434, 'epochs': 16, 'dropout_rate': 0.3140986734826715, 'sparsity_weight': 0.0018711836899424265, 'classification_weight': 0.42615443646694795, 'n_estimators': 384, 'max_depth': 3, 'learning_rate': 0.24958927252646967, 'subsample': 0.8170826924925114, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.639751552795031.\n",
      "[I 2025-05-10 23:35:13,874] Trial 3 finished with value: 0.577984817115252 and parameters: {'latent_dim': 26, 'hidden_dim': 254, 'lr': 0.0052903238689615195, 'epochs': 47, 'dropout_rate': 0.2766142585847112, 'sparsity_weight': 0.00019707403013329613, 'classification_weight': 0.17254910956617603, 'n_estimators': 436, 'max_depth': 6, 'learning_rate': 0.05582757446237233, 'subsample': 0.7599003298943318, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.639751552795031.\n",
      "[I 2025-05-10 23:37:24,555] Trial 4 finished with value: 0.7087646652864045 and parameters: {'latent_dim': 12, 'hidden_dim': 201, 'lr': 0.0006077088859387386, 'epochs': 46, 'dropout_rate': 0.45474724938723676, 'sparsity_weight': 0.00017456303442020361, 'classification_weight': 0.10083794514703666, 'n_estimators': 452, 'max_depth': 10, 'learning_rate': 0.01415123626469274, 'subsample': 0.9228111258259227, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.7087646652864045.\n",
      "[I 2025-05-10 23:38:14,688] Trial 5 finished with value: 0.6739130434782609 and parameters: {'latent_dim': 24, 'hidden_dim': 76, 'lr': 0.0005716653157755578, 'epochs': 17, 'dropout_rate': 0.31252489647498405, 'sparsity_weight': 0.007007453658663331, 'classification_weight': 0.4133191357302146, 'n_estimators': 347, 'max_depth': 6, 'learning_rate': 0.25610377799751516, 'subsample': 0.828490735034001, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 4 with value: 0.7087646652864045.\n",
      "[I 2025-05-10 23:39:05,422] Trial 6 finished with value: 0.5752051223065715 and parameters: {'latent_dim': 89, 'hidden_dim': 208, 'lr': 0.007453751302683648, 'epochs': 12, 'dropout_rate': 0.2863537136242571, 'sparsity_weight': 0.0022627719140541278, 'classification_weight': 0.6824872576904396, 'n_estimators': 205, 'max_depth': 4, 'learning_rate': 0.17043731387392813, 'subsample': 0.9049280260443522, 'min_samples_split': 14, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.7087646652864045.\n",
      "[I 2025-05-10 23:40:24,681] Trial 7 finished with value: 0.6094241239168775 and parameters: {'latent_dim': 77, 'hidden_dim': 166, 'lr': 0.000523407242199268, 'epochs': 39, 'dropout_rate': 0.4093057614783734, 'sparsity_weight': 0.0003027333255385456, 'classification_weight': 0.8137287727819128, 'n_estimators': 197, 'max_depth': 10, 'learning_rate': 0.02913335714833551, 'subsample': 0.6582682994938399, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.7087646652864045.\n",
      "[I 2025-05-10 23:41:47,574] Trial 8 finished with value: 0.5903113258185722 and parameters: {'latent_dim': 63, 'hidden_dim': 231, 'lr': 0.0008731364599409194, 'epochs': 33, 'dropout_rate': 0.38166587980693467, 'sparsity_weight': 0.0017746225531334256, 'classification_weight': 0.4364763363146973, 'n_estimators': 294, 'max_depth': 6, 'learning_rate': 0.034399324271428146, 'subsample': 0.7212222461793365, 'min_samples_split': 20, 'min_samples_leaf': 6}. Best is trial 4 with value: 0.7087646652864045.\n",
      "[I 2025-05-10 23:43:15,413] Trial 9 finished with value: 0.723564143853999 and parameters: {'latent_dim': 91, 'hidden_dim': 101, 'lr': 0.00011333485884582449, 'epochs': 25, 'dropout_rate': 0.41423860874945084, 'sparsity_weight': 0.010108373552075415, 'classification_weight': 0.6827965057244185, 'n_estimators': 201, 'max_depth': 7, 'learning_rate': 0.035356206269836606, 'subsample': 0.8830744872352714, 'min_samples_split': 20, 'min_samples_leaf': 7}. Best is trial 9 with value: 0.723564143853999.\n",
      "[I 2025-05-10 23:43:54,044] Trial 10 finished with value: 0.7238133578713288 and parameters: {'latent_dim': 100, 'hidden_dim': 119, 'lr': 0.00010417620940211247, 'epochs': 24, 'dropout_rate': 0.49381860131740135, 'sparsity_weight': 0.021720025238427296, 'classification_weight': 0.5974107611603721, 'n_estimators': 56, 'max_depth': 8, 'learning_rate': 0.09960712126888904, 'subsample': 0.9726315812187858, 'min_samples_split': 20, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.7238133578713288.\n",
      "[I 2025-05-10 23:44:43,004] Trial 11 finished with value: 0.7123686833831763 and parameters: {'latent_dim': 97, 'hidden_dim': 116, 'lr': 0.00010007512272936182, 'epochs': 24, 'dropout_rate': 0.48378178748559586, 'sparsity_weight': 0.023871505766470267, 'classification_weight': 0.6250805959047462, 'n_estimators': 73, 'max_depth': 8, 'learning_rate': 0.07684446733011903, 'subsample': 0.9829973835307444, 'min_samples_split': 20, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.7238133578713288.\n",
      "[I 2025-05-10 23:45:24,347] Trial 12 finished with value: 0.7045280269917952 and parameters: {'latent_dim': 83, 'hidden_dim': 127, 'lr': 0.00023587465533471866, 'epochs': 24, 'dropout_rate': 0.4897171622062303, 'sparsity_weight': 0.012477228638487714, 'classification_weight': 0.5957175186274942, 'n_estimators': 64, 'max_depth': 8, 'learning_rate': 0.13640375449651412, 'subsample': 0.9980670028483863, 'min_samples_split': 15, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.7238133578713288.\n",
      "[I 2025-05-10 23:46:18,285] Trial 13 finished with value: 0.5947204968944099 and parameters: {'latent_dim': 100, 'hidden_dim': 64, 'lr': 0.002512406300087674, 'epochs': 23, 'dropout_rate': 0.39677716719459377, 'sparsity_weight': 0.04778164981224579, 'classification_weight': 0.7140212897673585, 'n_estimators': 110, 'max_depth': 7, 'learning_rate': 0.025071012063240247, 'subsample': 0.8669029893596732, 'min_samples_split': 17, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.7238133578713288.\n",
      "[I 2025-05-10 23:47:04,380] Trial 14 finished with value: 0.7075952764358561 and parameters: {'latent_dim': 74, 'hidden_dim': 138, 'lr': 0.0002632020098474193, 'epochs': 31, 'dropout_rate': 0.434341747019124, 'sparsity_weight': 0.006983721845911726, 'classification_weight': 0.541789150087558, 'n_estimators': 144, 'max_depth': 5, 'learning_rate': 0.10574594246527447, 'subsample': 0.9643626687591804, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.7238133578713288.\n",
      "[I 2025-05-10 23:48:56,048] Trial 15 finished with value: 0.6564105513380875 and parameters: {'latent_dim': 88, 'hidden_dim': 100, 'lr': 0.0002473787801035145, 'epochs': 38, 'dropout_rate': 0.20159386878972596, 'sparsity_weight': 0.02430344361685845, 'classification_weight': 0.32057343279695355, 'n_estimators': 269, 'max_depth': 7, 'learning_rate': 0.03778100729853597, 'subsample': 0.8711247986936346, 'min_samples_split': 17, 'min_samples_leaf': 6}. Best is trial 10 with value: 0.7238133578713288.\n",
      "[I 2025-05-10 23:50:56,638] Trial 16 finished with value: 0.5868510850394909 and parameters: {'latent_dim': 70, 'hidden_dim': 139, 'lr': 0.002075375724452915, 'epochs': 20, 'dropout_rate': 0.3575052807466069, 'sparsity_weight': 0.0005869712760892637, 'classification_weight': 0.7388512328642367, 'n_estimators': 242, 'max_depth': 9, 'learning_rate': 0.019839607719379065, 'subsample': 0.9453477823249875, 'min_samples_split': 20, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.7238133578713288.\n",
      "[I 2025-05-10 23:51:36,698] Trial 17 finished with value: 0.7200751476113796 and parameters: {'latent_dim': 53, 'hidden_dim': 94, 'lr': 0.00011207710682732204, 'epochs': 28, 'dropout_rate': 0.49852651136230336, 'sparsity_weight': 0.005324459738463319, 'classification_weight': 0.5325905234946372, 'n_estimators': 137, 'max_depth': 5, 'learning_rate': 0.08597689089564589, 'subsample': 0.8660580288502547, 'min_samples_split': 18, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.7238133578713288.\n",
      "[I 2025-05-10 23:52:17,632] Trial 18 finished with value: 0.7025534851621807 and parameters: {'latent_dim': 94, 'hidden_dim': 149, 'lr': 0.00018893909809482203, 'epochs': 38, 'dropout_rate': 0.44739621105190897, 'sparsity_weight': 0.017094752126207962, 'classification_weight': 0.6539098399442438, 'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.04524097358990281, 'subsample': 0.7741249628341423, 'min_samples_split': 13, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.7238133578713288.\n",
      "[I 2025-05-10 23:54:32,400] Trial 19 finished with value: 0.6966873706004141 and parameters: {'latent_dim': 82, 'hidden_dim': 116, 'lr': 0.00039084158905969453, 'epochs': 27, 'dropout_rate': 0.3518221824225142, 'sparsity_weight': 0.049389617130874905, 'classification_weight': 0.3048277372808972, 'n_estimators': 315, 'max_depth': 7, 'learning_rate': 0.12033594926622973, 'subsample': 0.9404263215534383, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.7238133578713288.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7146\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7249\n",
      "ROC-AUC autoencoded: 0.7070\n",
      "ROC-AUC autoencoded: 0.7117\n",
      "ROC-AUC autoencoded: 0.6903\n",
      "ROC-AUC autoencoded: 0.7191\n",
      "ROC-AUC autoencoded: 0.7238\n",
      "ROC-AUC autoencoded: 0.7080\n",
      "ROC-AUC autoencoded: 0.7098\n",
      "ROC-AUC autoencoded: 0.7051\n",
      "ROC-AUC autoencoded: 0.6939\n",
      "ROC-AUC autoencoded: 0.7443\n",
      "ROC-AUC autoencoded: 0.7035\n",
      "ROC-AUC autoencoded: 0.7183\n",
      "ROC-AUC autoencoded: 0.6877\n",
      "ROC-AUC autoencoded: 0.7429\n",
      "ROC-AUC autoencoded: 0.7085\n",
      "ROC-AUC autoencoded: 0.7017\n",
      "ROC-AUC autoencoded: 0.7004\n",
      "ROC-AUC autoencoded: 0.6905\n",
      "ROC-AUC autoencoded: 0.7054\n",
      "ROC-AUC autoencoded: 0.7334\n",
      "ROC-AUC autoencoded: 0.7311\n",
      "ROC-AUC autoencoded: 0.7516\n",
      "ROC-AUC autoencoded: 0.7309\n",
      "ROC-AUC autoencoded: 0.7651\n",
      "среднее 0.7163534865444702\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 23:57:58,409] A new study created in memory with name: no-name-ead7a59b-6290-42b9-8426-abbe628df1eb\n",
      "[I 2025-05-10 23:58:12,327] Trial 0 finished with value: 0.6499693275055595 and parameters: {'latent_dim': 10, 'hidden_dim': 150, 'lr': 0.003181444268378388, 'epochs': 41, 'dropout_rate': 0.30293301483924245, 'sparsity_weight': 0.00939408379252416, 'classification_weight': 0.42908216702915325, 'C': 0.404588340373358, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 0 with value: 0.6499693275055595.\n",
      "[I 2025-05-10 23:58:17,957] Trial 1 finished with value: 0.6811785905988804 and parameters: {'latent_dim': 42, 'hidden_dim': 117, 'lr': 0.00013081847557917228, 'epochs': 15, 'dropout_rate': 0.152885745608848, 'sparsity_weight': 0.019224790719018805, 'classification_weight': 0.729320197473523, 'C': 0.3233723985191251, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 1 with value: 0.6811785905988804.\n",
      "[I 2025-05-10 23:58:31,367] Trial 2 finished with value: 0.5537918871252204 and parameters: {'latent_dim': 22, 'hidden_dim': 158, 'lr': 0.00034639982049452877, 'epochs': 41, 'dropout_rate': 0.14252250472036174, 'sparsity_weight': 0.07829501153550437, 'classification_weight': 0.8279701630889998, 'C': 27.480727848144717, 'kernel': 'linear'}. Best is trial 1 with value: 0.6811785905988804.\n",
      "[I 2025-05-10 23:58:35,518] Trial 3 finished with value: 0.6149260026071621 and parameters: {'latent_dim': 22, 'hidden_dim': 229, 'lr': 0.009411520966097426, 'epochs': 10, 'dropout_rate': 0.22335546904415043, 'sparsity_weight': 0.018743380927352064, 'classification_weight': 0.7540150205943598, 'C': 0.13203110481356425, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 1 with value: 0.6811785905988804.\n",
      "[I 2025-05-10 23:58:49,259] Trial 4 finished with value: 0.565428264703627 and parameters: {'latent_dim': 16, 'hidden_dim': 255, 'lr': 0.005790167631866913, 'epochs': 39, 'dropout_rate': 0.32675933624218456, 'sparsity_weight': 0.02933249013424411, 'classification_weight': 0.8544331820168388, 'C': 15.037181708381695, 'kernel': 'linear'}. Best is trial 1 with value: 0.6811785905988804.\n",
      "[I 2025-05-10 23:58:59,695] Trial 5 finished with value: 0.6107948010121923 and parameters: {'latent_dim': 28, 'hidden_dim': 79, 'lr': 0.00014888532727961036, 'epochs': 31, 'dropout_rate': 0.1466705629364997, 'sparsity_weight': 0.00024454798805398364, 'classification_weight': 0.24119203321392516, 'C': 0.35676888039400606, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 1 with value: 0.6811785905988804.\n",
      "[I 2025-05-10 23:59:12,234] Trial 6 finished with value: 0.5405835442067326 and parameters: {'latent_dim': 66, 'hidden_dim': 109, 'lr': 0.0035485930632307336, 'epochs': 39, 'dropout_rate': 0.3032740537638974, 'sparsity_weight': 0.004490930196493045, 'classification_weight': 0.8609146446042696, 'C': 0.16784514688887417, 'kernel': 'linear'}. Best is trial 1 with value: 0.6811785905988804.\n",
      "[I 2025-05-10 23:59:17,671] Trial 7 finished with value: 0.6405950463921478 and parameters: {'latent_dim': 17, 'hidden_dim': 230, 'lr': 0.0009199796267715859, 'epochs': 11, 'dropout_rate': 0.2055258231139765, 'sparsity_weight': 0.0005206479311311219, 'classification_weight': 0.3348717735636131, 'C': 45.59090359786234, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.6811785905988804.\n",
      "[I 2025-05-10 23:59:30,547] Trial 8 finished with value: 0.7105283337167395 and parameters: {'latent_dim': 13, 'hidden_dim': 142, 'lr': 0.00020880194701542387, 'epochs': 34, 'dropout_rate': 0.3870938412604743, 'sparsity_weight': 0.0017539928495981531, 'classification_weight': 0.5405558611438812, 'C': 0.25221973638203365, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 8 with value: 0.7105283337167395.\n",
      "[I 2025-05-10 23:59:37,453] Trial 9 finished with value: 0.6032800398742427 and parameters: {'latent_dim': 54, 'hidden_dim': 81, 'lr': 0.0022072627291262656, 'epochs': 19, 'dropout_rate': 0.27453944125196494, 'sparsity_weight': 0.08853208005042074, 'classification_weight': 0.5669157023351764, 'C': 22.33183725140903, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 8 with value: 0.7105283337167395.\n",
      "[I 2025-05-10 23:59:55,436] Trial 10 finished with value: 0.6198719423357104 and parameters: {'latent_dim': 78, 'hidden_dim': 183, 'lr': 0.0004229584189738415, 'epochs': 49, 'dropout_rate': 0.48820104846959633, 'sparsity_weight': 0.0011761028575714442, 'classification_weight': 0.5817089465597217, 'C': 2.0358574558331752, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 8 with value: 0.7105283337167395.\n",
      "[I 2025-05-11 00:00:05,358] Trial 11 finished with value: 0.6912430028372057 and parameters: {'latent_dim': 43, 'hidden_dim': 125, 'lr': 0.00010084926505406394, 'epochs': 25, 'dropout_rate': 0.4074377611219287, 'sparsity_weight': 0.001847178149616127, 'classification_weight': 0.6753251790066758, 'C': 1.434989082285442, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 8 with value: 0.7105283337167395.\n",
      "[I 2025-05-11 00:00:14,491] Trial 12 finished with value: 0.6597557702630166 and parameters: {'latent_dim': 98, 'hidden_dim': 130, 'lr': 0.00027279505716383784, 'epochs': 25, 'dropout_rate': 0.42060500223826797, 'sparsity_weight': 0.0017022052901950009, 'classification_weight': 0.6696436926634985, 'C': 1.4006915641161195, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 8 with value: 0.7105283337167395.\n",
      "[I 2025-05-11 00:00:25,858] Trial 13 finished with value: 0.6915401426270992 and parameters: {'latent_dim': 39, 'hidden_dim': 180, 'lr': 0.00011715564281781533, 'epochs': 29, 'dropout_rate': 0.39163924102327907, 'sparsity_weight': 0.003018069642908596, 'classification_weight': 0.4660835777889648, 'C': 4.8931052164569975, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 8 with value: 0.7105283337167395.\n",
      "[I 2025-05-11 00:00:37,893] Trial 14 finished with value: 0.5825569358178053 and parameters: {'latent_dim': 37, 'hidden_dim': 188, 'lr': 0.0007392725498007358, 'epochs': 32, 'dropout_rate': 0.3782658908428279, 'sparsity_weight': 0.00012832122530749413, 'classification_weight': 0.43639861998332913, 'C': 7.346144177170144, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 8 with value: 0.7105283337167395.\n",
      "[I 2025-05-11 00:00:47,364] Trial 15 finished with value: 0.6993137029368913 and parameters: {'latent_dim': 58, 'hidden_dim': 181, 'lr': 0.00019381653105923665, 'epochs': 24, 'dropout_rate': 0.49796945839271284, 'sparsity_weight': 0.004866583927207429, 'classification_weight': 0.15455823498717414, 'C': 5.6604556247635704, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 8 with value: 0.7105283337167395.\n",
      "[I 2025-05-11 00:00:56,529] Trial 16 finished with value: 0.6990932443830995 and parameters: {'latent_dim': 68, 'hidden_dim': 207, 'lr': 0.00019909539662402265, 'epochs': 21, 'dropout_rate': 0.47542685150869113, 'sparsity_weight': 0.007302657784499058, 'classification_weight': 0.16728988757430163, 'C': 79.68246512406358, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 8 with value: 0.7105283337167395.\n",
      "[I 2025-05-11 00:01:09,049] Trial 17 finished with value: 0.7396863737443446 and parameters: {'latent_dim': 55, 'hidden_dim': 159, 'lr': 0.0005870266927245101, 'epochs': 33, 'dropout_rate': 0.4602388199593651, 'sparsity_weight': 0.0006001709986866139, 'classification_weight': 0.1320952016636449, 'C': 0.681059708812407, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 17 with value: 0.7396863737443446.\n",
      "[I 2025-05-11 00:01:21,405] Trial 18 finished with value: 0.6779004677555401 and parameters: {'latent_dim': 87, 'hidden_dim': 143, 'lr': 0.0005183866641326947, 'epochs': 35, 'dropout_rate': 0.4446377225158347, 'sparsity_weight': 0.0006198937053193631, 'classification_weight': 0.2765824282577394, 'C': 0.698997503484248, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 17 with value: 0.7396863737443446.\n",
      "[I 2025-05-11 00:01:36,598] Trial 19 finished with value: 0.6102101065869182 and parameters: {'latent_dim': 52, 'hidden_dim': 100, 'lr': 0.001371902406743033, 'epochs': 46, 'dropout_rate': 0.34080581689548567, 'sparsity_weight': 0.0005524874795390527, 'classification_weight': 0.36975939639332667, 'C': 0.7429271577169235, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 17 with value: 0.7396863737443446.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7440\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7179\n",
      "ROC-AUC autoencoded: 0.7078\n",
      "ROC-AUC autoencoded: 0.7166\n",
      "ROC-AUC autoencoded: 0.7026\n",
      "ROC-AUC autoencoded: 0.7164\n",
      "ROC-AUC autoencoded: 0.7244\n",
      "ROC-AUC autoencoded: 0.7330\n",
      "ROC-AUC autoencoded: 0.7306\n",
      "ROC-AUC autoencoded: 0.7338\n",
      "ROC-AUC autoencoded: 0.7512\n",
      "ROC-AUC autoencoded: 0.7266\n",
      "ROC-AUC autoencoded: 0.6988\n",
      "ROC-AUC autoencoded: 0.7290\n",
      "ROC-AUC autoencoded: 0.7000\n",
      "ROC-AUC autoencoded: 0.7230\n",
      "ROC-AUC autoencoded: 0.7092\n",
      "ROC-AUC autoencoded: 0.6915\n",
      "ROC-AUC autoencoded: 0.6962\n",
      "ROC-AUC autoencoded: 0.6967\n",
      "ROC-AUC autoencoded: 0.6944\n",
      "ROC-AUC autoencoded: 0.7599\n",
      "ROC-AUC autoencoded: 0.7543\n",
      "ROC-AUC autoencoded: 0.7636\n",
      "ROC-AUC autoencoded: 0.7565\n",
      "ROC-AUC autoencoded: 0.7663\n",
      "среднее 0.7240005454317098\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:03:01,151] A new study created in memory with name: no-name-957c9cfb-363f-45a8-aa04-2882ba782f78\n",
      "[I 2025-05-11 00:03:23,943] Trial 0 finished with value: 0.7486389080591979 and parameters: {'latent_dim': 12, 'hidden_dim_ae': 135, 'hidden_dim_combined': 53, 'lr_ae': 0.00038001124498365877, 'lr_combined': 0.0002619789947568248, 'epochs_ae': 47, 'epochs_freeze': 6, 'epochs_unfreeze': 18, 'dropout_rate_ae': 0.13029327245332567, 'dropout_rate_combined': 0.12058091298621215, 'sparsity_weight': 0.011840287681188794, 'classification_weight': 0.13791395931112957}. Best is trial 0 with value: 0.7486389080591979.\n",
      "[I 2025-05-11 00:03:46,028] Trial 1 finished with value: 0.5856146001073537 and parameters: {'latent_dim': 49, 'hidden_dim_ae': 155, 'hidden_dim_combined': 103, 'lr_ae': 0.005009279122342667, 'lr_combined': 0.0019115482008657005, 'epochs_ae': 41, 'epochs_freeze': 14, 'epochs_unfreeze': 14, 'dropout_rate_ae': 0.20375740690750682, 'dropout_rate_combined': 0.2482816907919868, 'sparsity_weight': 0.01431734180155056, 'classification_weight': 0.41346062363561187}. Best is trial 0 with value: 0.7486389080591979.\n",
      "[I 2025-05-11 00:04:13,214] Trial 2 finished with value: 0.6695613833294992 and parameters: {'latent_dim': 98, 'hidden_dim_ae': 215, 'hidden_dim_combined': 59, 'lr_ae': 0.00023683575144143736, 'lr_combined': 0.00010251316348322954, 'epochs_ae': 50, 'epochs_freeze': 14, 'epochs_unfreeze': 12, 'dropout_rate_ae': 0.2846672142230916, 'dropout_rate_combined': 0.21484843631146672, 'sparsity_weight': 0.00036795891215910144, 'classification_weight': 0.7896046733005319}. Best is trial 0 with value: 0.7486389080591979.\n",
      "[I 2025-05-11 00:04:42,596] Trial 3 finished with value: 0.6670692431561998 and parameters: {'latent_dim': 32, 'hidden_dim_ae': 74, 'hidden_dim_combined': 32, 'lr_ae': 0.00029119920886659585, 'lr_combined': 0.0007897709041380319, 'epochs_ae': 34, 'epochs_freeze': 20, 'epochs_unfreeze': 11, 'dropout_rate_ae': 0.12881956596989907, 'dropout_rate_combined': 0.35628726764354457, 'sparsity_weight': 0.017557216049746607, 'classification_weight': 0.331043981755687}. Best is trial 0 with value: 0.7486389080591979.\n",
      "[I 2025-05-11 00:04:55,970] Trial 4 finished with value: 0.7236216547810751 and parameters: {'latent_dim': 49, 'hidden_dim_ae': 241, 'hidden_dim_combined': 54, 'lr_ae': 0.000174707027571589, 'lr_combined': 0.0003204672115107138, 'epochs_ae': 18, 'epochs_freeze': 5, 'epochs_unfreeze': 5, 'dropout_rate_ae': 0.22103110910295842, 'dropout_rate_combined': 0.36779714130318053, 'sparsity_weight': 0.010701004255404217, 'classification_weight': 0.725764905629618}. Best is trial 0 with value: 0.7486389080591979.\n",
      "[I 2025-05-11 00:05:14,721] Trial 5 finished with value: 0.6528257035503412 and parameters: {'latent_dim': 29, 'hidden_dim_ae': 227, 'hidden_dim_combined': 122, 'lr_ae': 0.005580697696602433, 'lr_combined': 0.00011101789573956927, 'epochs_ae': 24, 'epochs_freeze': 17, 'epochs_unfreeze': 14, 'dropout_rate_ae': 0.24110732148573488, 'dropout_rate_combined': 0.29635727303426107, 'sparsity_weight': 0.0002676877136132009, 'classification_weight': 0.3915019506309364}. Best is trial 0 with value: 0.7486389080591979.\n",
      "[I 2025-05-11 00:05:28,717] Trial 6 finished with value: 0.6340388007054674 and parameters: {'latent_dim': 96, 'hidden_dim_ae': 178, 'hidden_dim_combined': 122, 'lr_ae': 0.007871806265492892, 'lr_combined': 0.00011027618945731648, 'epochs_ae': 22, 'epochs_freeze': 7, 'epochs_unfreeze': 11, 'dropout_rate_ae': 0.1730310039492931, 'dropout_rate_combined': 0.2771165930933367, 'sparsity_weight': 0.0007594579878536335, 'classification_weight': 0.6865124330134715}. Best is trial 0 with value: 0.7486389080591979.\n",
      "[I 2025-05-11 00:06:07,120] Trial 7 finished with value: 0.7467793880837359 and parameters: {'latent_dim': 71, 'hidden_dim_ae': 109, 'hidden_dim_combined': 84, 'lr_ae': 0.00029433332983505497, 'lr_combined': 0.000312589246541367, 'epochs_ae': 40, 'epochs_freeze': 10, 'epochs_unfreeze': 19, 'dropout_rate_ae': 0.2024222981821017, 'dropout_rate_combined': 0.27899780071183666, 'sparsity_weight': 0.006753963701377751, 'classification_weight': 0.10534514940802087}. Best is trial 0 with value: 0.7486389080591979.\n",
      "[I 2025-05-11 00:06:26,490] Trial 8 finished with value: 0.5799018480177901 and parameters: {'latent_dim': 95, 'hidden_dim_ae': 159, 'hidden_dim_combined': 50, 'lr_ae': 0.003482414279476834, 'lr_combined': 0.00040575729983919045, 'epochs_ae': 23, 'epochs_freeze': 8, 'epochs_unfreeze': 13, 'dropout_rate_ae': 0.20798448164510616, 'dropout_rate_combined': 0.4902542925837676, 'sparsity_weight': 0.06541706258673083, 'classification_weight': 0.6250424578585775}. Best is trial 0 with value: 0.7486389080591979.\n",
      "[I 2025-05-11 00:06:41,912] Trial 9 finished with value: 0.6356107660455487 and parameters: {'latent_dim': 93, 'hidden_dim_ae': 112, 'hidden_dim_combined': 66, 'lr_ae': 0.0028479286094476607, 'lr_combined': 0.002440990657973959, 'epochs_ae': 29, 'epochs_freeze': 9, 'epochs_unfreeze': 8, 'dropout_rate_ae': 0.3581224589469374, 'dropout_rate_combined': 0.1520895571282846, 'sparsity_weight': 0.00012225594421944183, 'classification_weight': 0.8269804080830826}. Best is trial 0 with value: 0.7486389080591979.\n",
      "[I 2025-05-11 00:07:07,148] Trial 10 finished with value: 0.7139981596503334 and parameters: {'latent_dim': 11, 'hidden_dim_ae': 118, 'hidden_dim_combined': 32, 'lr_ae': 0.000850771422426064, 'lr_combined': 0.004897875346910475, 'epochs_ae': 49, 'epochs_freeze': 5, 'epochs_unfreeze': 20, 'dropout_rate_ae': 0.4630038546759395, 'dropout_rate_combined': 0.10045055811990528, 'sparsity_weight': 0.001877318855445147, 'classification_weight': 0.10186340158034426}. Best is trial 0 with value: 0.7486389080591979.\n",
      "[I 2025-05-11 00:07:31,701] Trial 11 finished with value: 0.6509661835748792 and parameters: {'latent_dim': 70, 'hidden_dim_ae': 110, 'hidden_dim_combined': 86, 'lr_ae': 0.0006502520031928154, 'lr_combined': 0.0002934482463957036, 'epochs_ae': 40, 'epochs_freeze': 11, 'epochs_unfreeze': 20, 'dropout_rate_ae': 0.1082058584052685, 'dropout_rate_combined': 0.17461168555002507, 'sparsity_weight': 0.004243071574062546, 'classification_weight': 0.14746294196495607}. Best is trial 0 with value: 0.7486389080591979.\n",
      "[I 2025-05-11 00:07:44,406] Trial 12 finished with value: 0.7624223602484473 and parameters: {'latent_dim': 72, 'hidden_dim_ae': 77, 'hidden_dim_combined': 87, 'lr_ae': 0.00010224577921000653, 'lr_combined': 0.0007091506613908423, 'epochs_ae': 10, 'epochs_freeze': 11, 'epochs_unfreeze': 17, 'dropout_rate_ae': 0.3403681112441152, 'dropout_rate_combined': 0.43274732642533476, 'sparsity_weight': 0.058812967987514855, 'classification_weight': 0.23574903855099255}. Best is trial 12 with value: 0.7624223602484473.\n",
      "[I 2025-05-11 00:07:58,278] Trial 13 finished with value: 0.763668430335097 and parameters: {'latent_dim': 72, 'hidden_dim_ae': 78, 'hidden_dim_combined': 97, 'lr_ae': 0.000133735737956354, 'lr_combined': 0.0008433470467034351, 'epochs_ae': 13, 'epochs_freeze': 12, 'epochs_unfreeze': 17, 'dropout_rate_ae': 0.36814994004423124, 'dropout_rate_combined': 0.4958344578705763, 'sparsity_weight': 0.07328520760344827, 'classification_weight': 0.2645303987690746}. Best is trial 13 with value: 0.763668430335097.\n",
      "[I 2025-05-11 00:08:10,875] Trial 14 finished with value: 0.759853538839046 and parameters: {'latent_dim': 71, 'hidden_dim_ae': 64, 'hidden_dim_combined': 100, 'lr_ae': 0.00011547332889391746, 'lr_combined': 0.0008971243585595639, 'epochs_ae': 10, 'epochs_freeze': 12, 'epochs_unfreeze': 16, 'dropout_rate_ae': 0.38407546330168496, 'dropout_rate_combined': 0.49944458562780314, 'sparsity_weight': 0.08956597631829127, 'classification_weight': 0.269733253035133}. Best is trial 13 with value: 0.763668430335097.\n",
      "[I 2025-05-11 00:08:26,113] Trial 15 finished with value: 0.7451499118165784 and parameters: {'latent_dim': 81, 'hidden_dim_ae': 77, 'hidden_dim_combined': 99, 'lr_ae': 0.00013689720744014766, 'lr_combined': 0.0016780123793748605, 'epochs_ae': 10, 'epochs_freeze': 14, 'epochs_unfreeze': 17, 'dropout_rate_ae': 0.34016623554508724, 'dropout_rate_combined': 0.43989099852604047, 'sparsity_weight': 0.037138894812173404, 'classification_weight': 0.5101912981354282}. Best is trial 13 with value: 0.763668430335097.\n",
      "[I 2025-05-11 00:08:41,351] Trial 16 finished with value: 0.7426386013342534 and parameters: {'latent_dim': 62, 'hidden_dim_ae': 90, 'hidden_dim_combined': 74, 'lr_ae': 0.001458720816885187, 'lr_combined': 0.0006233319286434511, 'epochs_ae': 15, 'epochs_freeze': 16, 'epochs_unfreeze': 16, 'dropout_rate_ae': 0.4258400350938136, 'dropout_rate_combined': 0.42369359035212434, 'sparsity_weight': 0.03453896662285449, 'classification_weight': 0.25527009554516245}. Best is trial 13 with value: 0.763668430335097.\n",
      "[I 2025-05-11 00:08:56,403] Trial 17 finished with value: 0.6475538685683614 and parameters: {'latent_dim': 83, 'hidden_dim_ae': 198, 'hidden_dim_combined': 110, 'lr_ae': 0.0005022594441479267, 'lr_combined': 0.00892004590258383, 'epochs_ae': 15, 'epochs_freeze': 11, 'epochs_unfreeze': 15, 'dropout_rate_ae': 0.2956019754053856, 'dropout_rate_combined': 0.43344175601564816, 'sparsity_weight': 0.037791203109513165, 'classification_weight': 0.5089825833576138}. Best is trial 13 with value: 0.763668430335097.\n",
      "[I 2025-05-11 00:09:18,217] Trial 18 finished with value: 0.7435779464764972 and parameters: {'latent_dim': 60, 'hidden_dim_ae': 89, 'hidden_dim_combined': 90, 'lr_ae': 0.00010493387334599965, 'lr_combined': 0.0013681964780658641, 'epochs_ae': 15, 'epochs_freeze': 17, 'epochs_unfreeze': 18, 'dropout_rate_ae': 0.4133474504596643, 'dropout_rate_combined': 0.3687458235487447, 'sparsity_weight': 0.09329249505741073, 'classification_weight': 0.2319263054576423}. Best is trial 13 with value: 0.763668430335097.\n",
      "[I 2025-05-11 00:09:43,587] Trial 19 finished with value: 0.6384671420903305 and parameters: {'latent_dim': 82, 'hidden_dim_ae': 137, 'hidden_dim_combined': 74, 'lr_ae': 0.0012477992525751424, 'lr_combined': 0.0030792937236918316, 'epochs_ae': 29, 'epochs_freeze': 13, 'epochs_unfreeze': 8, 'dropout_rate_ae': 0.33149213901867564, 'dropout_rate_combined': 0.40317743489432073, 'sparsity_weight': 0.002237624871514002, 'classification_weight': 0.4177042959001268}. Best is trial 13 with value: 0.763668430335097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7694\n"
     ]
    }
   ],
   "source": [
    "class CombinedClassifier(nn.Module):\n",
    "    def __init__(self, autoencoder, pgs_input_dim, hidden_dim=64, dropout_rate=0.2):\n",
    "        super(CombinedClassifier, self).__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "        self.pgs_branch = nn.Sequential(\n",
    "            nn.Linear(pgs_input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        latent_dim = list(autoencoder.classifier[0].parameters())[0].shape[1]\n",
    "        self.combined_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim // 2 + latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_snp, x_pgs):\n",
    "        _, latent, _ = self.autoencoder(x_snp)\n",
    "        pgs_features = self.pgs_branch(x_pgs)\n",
    "        combined = torch.cat([latent, pgs_features], dim=1)\n",
    "        output = self.combined_classifier(combined)\n",
    "        return output\n",
    "\n",
    "def train_combined_classifier(model, X_train_snp, X_train_pgs, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_snp_tensor = torch.FloatTensor(X_train_snp).to(device)\n",
    "    X_train_pgs_tensor = torch.FloatTensor(X_train_pgs).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_snp_tensor, X_train_pgs_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    for param in model.autoencoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs_freeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    for param in model.autoencoder.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr/10)\n",
    "    \n",
    "    for epoch in range(epochs_unfreeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_combined(model, X_snp, X_pgs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_snp_tensor = torch.FloatTensor(X_snp).to(device)\n",
    "    X_pgs_tensor = torch.FloatTensor(X_pgs).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_snp_tensor, X_pgs_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    hidden_dim_combined = trial.suggest_int('hidden_dim_combined', 32, 128)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    lr_combined = trial.suggest_float('lr_combined', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    epochs_freeze = trial.suggest_int('epochs_freeze', 5, 20)\n",
    "    epochs_unfreeze = trial.suggest_int('epochs_unfreeze', 5, 20)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    dropout_rate_combined = trial.suggest_float('dropout_rate_combined', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs_ae, batch_size, lr_ae, sparsity_weight, classification_weight)\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, X_pgs_train.shape[1], hidden_dim_combined, dropout_rate_combined)\n",
    "        combined_model = train_combined_classifier(combined_model, X_train, X_pgs_train, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr_combined)\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, X_pgs_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs_ae'], 32, \n",
    "    best_params['lr_ae'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "combined_model = CombinedClassifier(autoencoder, X_train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "combined_model = train_combined_classifier(\n",
    "    combined_model, X_train_all, X_train_pgs, y_all_train, \n",
    "    best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    ")\n",
    "\n",
    "y_pred_proba = predict_combined(combined_model, X_val_all, X_val_pgs)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7254\n",
      "ROC-AUC autoencoded: 0.7293\n",
      "ROC-AUC autoencoded: 0.7268\n",
      "ROC-AUC autoencoded: 0.7105\n",
      "ROC-AUC autoencoded: 0.7271\n",
      "ROC-AUC autoencoded: 0.7738\n",
      "ROC-AUC autoencoded: 0.7677\n",
      "ROC-AUC autoencoded: 0.7621\n",
      "ROC-AUC autoencoded: 0.7459\n",
      "ROC-AUC autoencoded: 0.7707\n",
      "ROC-AUC autoencoded: 0.7297\n",
      "ROC-AUC autoencoded: 0.7188\n",
      "ROC-AUC autoencoded: 0.7151\n",
      "ROC-AUC autoencoded: 0.7454\n",
      "ROC-AUC autoencoded: 0.7164\n",
      "ROC-AUC autoencoded: 0.6762\n",
      "ROC-AUC autoencoded: 0.6787\n",
      "ROC-AUC autoencoded: 0.6770\n",
      "ROC-AUC autoencoded: 0.6831\n",
      "ROC-AUC autoencoded: 0.6817\n",
      "ROC-AUC autoencoded: 0.7690\n",
      "ROC-AUC autoencoded: 0.7577\n",
      "ROC-AUC autoencoded: 0.7567\n",
      "ROC-AUC autoencoded: 0.7537\n",
      "ROC-AUC autoencoded: 0.7568\n",
      "среднее 0.7302164715951672\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs_ae'], 32, \n",
    "            best_params['lr_ae'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "        combined_model = train_combined_classifier(\n",
    "            combined_model, X_train, train_pgs, y_train, \n",
    "            best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, test_pgs)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше идет блок со stacked автоэнкодером"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:11:51,620] A new study created in memory with name: no-name-56608c85-5108-4f59-8e50-0deca92c48c4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:12:00,148] Trial 0 finished with value: 0.7814201364926002 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 17, 'lr': 0.005329257156731006, 'epochs': 23, 'dropout_rate': 0.2535867785704592, 'C': 0.01559747270245342, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:12:06,364] Trial 1 finished with value: 0.767732535848478 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 20, 'lr': 0.00025312136214161116, 'epochs': 18, 'dropout_rate': 0.4474397704329506, 'C': 4.743829355895827, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:12:13,746] Trial 2 finished with value: 0.7628249367379801 and parameters: {'num_layers': 2, 'latent_dim_0': 21, 'latent_dim_1': 15, 'lr': 0.00035283705704663564, 'epochs': 21, 'dropout_rate': 0.2663056161917232, 'C': 10.531525618098268, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:12:27,063] Trial 3 finished with value: 0.7657004830917874 and parameters: {'num_layers': 2, 'latent_dim_0': 21, 'latent_dim_1': 12, 'lr': 0.005324656401920179, 'epochs': 37, 'dropout_rate': 0.4703768917944392, 'C': 4.477031518412286, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:12:40,566] Trial 4 finished with value: 0.7803274288781535 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 11, 'lr': 0.0026071283937147216, 'epochs': 33, 'dropout_rate': 0.40180164406022323, 'C': 0.04489207540383941, 'solver': 'saga'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:12:50,763] Trial 5 finished with value: 0.7648378191856452 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 18, 'lr': 0.0003915028926920865, 'epochs': 23, 'dropout_rate': 0.45243799902888704, 'C': 6.724437463410322, 'solver': 'saga'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:12:58,109] Trial 6 finished with value: 0.762460700866498 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 20, 'lr': 0.0002817595680913613, 'epochs': 15, 'dropout_rate': 0.16581424353137514, 'C': 96.84223401634078, 'solver': 'saga'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:13:01,661] Trial 7 finished with value: 0.7716432788896556 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 10, 'lr': 0.0024936621375233176, 'epochs': 12, 'dropout_rate': 0.3050190417536458, 'C': 0.3859439299931163, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:13:20,659] Trial 8 finished with value: 0.7636684303350969 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 16, 'lr': 0.0003286051937438708, 'epochs': 42, 'dropout_rate': 0.3122028169657945, 'C': 27.16389856188141, 'solver': 'saga'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:13:26,951] Trial 9 finished with value: 0.7681734529560617 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 11, 'lr': 0.002638887141979103, 'epochs': 21, 'dropout_rate': 0.358965448453073, 'C': 1.189735431610214, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:13:43,976] Trial 10 finished with value: 0.775228126677402 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 14, 'lr': 0.006353151135904023, 'epochs': 49, 'dropout_rate': 0.18373287576562095, 'C': 0.01303904240399234, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:14:00,499] Trial 11 finished with value: 0.7805383022774327 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 13, 'lr': 0.001218019466421797, 'epochs': 31, 'dropout_rate': 0.38755454892121705, 'C': 0.01175885039309645, 'solver': 'saga'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:14:08,504] Trial 12 finished with value: 0.7669465531784372 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 17, 'lr': 0.00089736026087601, 'epochs': 28, 'dropout_rate': 0.23424942151688413, 'C': 0.07861597508007179, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:14:22,022] Trial 13 finished with value: 0.775937428111341 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 13, 'lr': 0.001003633691122775, 'epochs': 28, 'dropout_rate': 0.3652970422831831, 'C': 0.010183173829019048, 'solver': 'saga'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:14:34,010] Trial 14 finished with value: 0.7733686067019399 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 18, 'lr': 0.009380913790590853, 'epochs': 35, 'dropout_rate': 0.11038311459798084, 'C': 0.10822105103765475, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:14:42,801] Trial 15 finished with value: 0.7766275592362549 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 14, 'lr': 0.00013821291634016572, 'epochs': 26, 'dropout_rate': 0.22060824844443608, 'C': 0.029906704656961047, 'solver': 'saga'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:14:53,166] Trial 16 finished with value: 0.7639751552795032 and parameters: {'num_layers': 2, 'latent_dim_0': 39, 'latent_dim_1': 16, 'lr': 0.0012533079993736161, 'epochs': 40, 'dropout_rate': 0.35121133100325097, 'C': 0.41893646523319933, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:15:01,636] Trial 17 finished with value: 0.7724292615596964 and parameters: {'num_layers': 2, 'latent_dim_0': 25, 'latent_dim_1': 13, 'lr': 0.000641138064705311, 'epochs': 31, 'dropout_rate': 0.2709182953353707, 'C': 0.3542872681294973, 'solver': 'saga'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:15:04,257] Trial 18 finished with value: 0.7777010965416763 and parameters: {'num_layers': 2, 'latent_dim_0': 37, 'latent_dim_1': 18, 'lr': 0.0017587902751428535, 'epochs': 10, 'dropout_rate': 0.3975879395503068, 'C': 0.023493764075224792, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:15:16,349] Trial 19 finished with value: 0.7756498734759605 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 16, 'lr': 0.004613709705449361, 'epochs': 48, 'dropout_rate': 0.40589093231491846, 'C': 0.12811734670255281, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7814201364926002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7743\n"
     ]
    }
   ],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(SimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "        \n",
    "        return reconstructions, latents\n",
    "    \n",
    "def train_stacked_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    \n",
    "    # Обучаем каждый автоэнкодер последовательно\n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, latent)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, _ in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent = ae(batch_x)\n",
    "                loss = criterion(reconstructed, batch_x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры логистической регрессии\n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7634\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7571\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7598\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7598\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7576\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7782\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7776\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7770\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7774\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7766\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7389\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7336\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7367\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7405\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7373\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7106\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7068\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7095\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7031\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7070\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7586\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7563\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7553\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7572\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7587\n",
      "среднее 0.747787189896557\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:15:58,672] A new study created in memory with name: no-name-038fdd6d-8d51-431b-bce6-ba284dced6b9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:16:27,683] Trial 0 finished with value: 0.7328234031132581 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 10, 'lr': 0.002164756621326948, 'epochs': 32, 'dropout_rate': 0.335826338092858, 'n_estimators': 118, 'max_depth': 7, 'learning_rate': 0.08088477775842576, 'subsample': 0.8818427244102958, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7328234031132581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:17:28,089] Trial 1 finished with value: 0.7099532244459782 and parameters: {'num_layers': 2, 'latent_dim_0': 30, 'latent_dim_1': 16, 'lr': 0.00013134112585320128, 'epochs': 36, 'dropout_rate': 0.3540723012026047, 'n_estimators': 257, 'max_depth': 8, 'learning_rate': 0.097121597505875, 'subsample': 0.9267351158341312, 'min_samples_split': 16, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7328234031132581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:19:03,768] Trial 2 finished with value: 0.7208611302814202 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 12, 'lr': 0.006708568924969578, 'epochs': 37, 'dropout_rate': 0.4361523364129867, 'n_estimators': 419, 'max_depth': 9, 'learning_rate': 0.012379097451852044, 'subsample': 0.91388355379669, 'min_samples_split': 12, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7328234031132581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:19:15,710] Trial 3 finished with value: 0.7229315236561614 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 14, 'lr': 0.00720950275081813, 'epochs': 22, 'dropout_rate': 0.16651712572302124, 'n_estimators': 63, 'max_depth': 5, 'learning_rate': 0.09990361247633196, 'subsample': 0.7357756494073375, 'min_samples_split': 17, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7328234031132581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:19:29,472] Trial 4 finished with value: 0.7513610919408021 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 15, 'lr': 0.0064879965808705975, 'epochs': 27, 'dropout_rate': 0.42468265718107423, 'n_estimators': 91, 'max_depth': 3, 'learning_rate': 0.0335338602098797, 'subsample': 0.8672641483842287, 'min_samples_split': 20, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.7513610919408021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:20:26,665] Trial 5 finished with value: 0.7407215704317154 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 20, 'lr': 0.00027565543753301446, 'epochs': 29, 'dropout_rate': 0.3336594508936307, 'n_estimators': 248, 'max_depth': 8, 'learning_rate': 0.14384872302358026, 'subsample': 0.8088694619410025, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.7513610919408021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:21:03,402] Trial 6 finished with value: 0.7408365922858676 and parameters: {'num_layers': 2, 'latent_dim_0': 38, 'latent_dim_1': 19, 'lr': 0.003036114723681893, 'epochs': 41, 'dropout_rate': 0.10923632882687717, 'n_estimators': 417, 'max_depth': 3, 'learning_rate': 0.0123806075276208, 'subsample': 0.6605760037495375, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.7513610919408021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:22:01,901] Trial 7 finished with value: 0.7109117398972472 and parameters: {'num_layers': 2, 'latent_dim_0': 37, 'latent_dim_1': 16, 'lr': 0.00019822238447145683, 'epochs': 26, 'dropout_rate': 0.19070722451529623, 'n_estimators': 438, 'max_depth': 5, 'learning_rate': 0.2850512194248488, 'subsample': 0.7969336639855866, 'min_samples_split': 13, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.7513610919408021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:22:12,978] Trial 8 finished with value: 0.722567287784679 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 16, 'lr': 0.0002513001752866914, 'epochs': 16, 'dropout_rate': 0.11042662915314545, 'n_estimators': 127, 'max_depth': 3, 'learning_rate': 0.09779652768885753, 'subsample': 0.6117413866416401, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.7513610919408021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:23:42,508] Trial 9 finished with value: 0.72160877233341 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 17, 'lr': 0.0046620691130371825, 'epochs': 42, 'dropout_rate': 0.4598422298492971, 'n_estimators': 355, 'max_depth': 9, 'learning_rate': 0.11404146497879106, 'subsample': 0.8821807319098077, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.7513610919408021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:24:13,854] Trial 10 finished with value: 0.7291043631623341 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 13, 'lr': 0.0008742571057490188, 'epochs': 15, 'dropout_rate': 0.40852135070690265, 'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.02905575324440112, 'subsample': 0.9690656652219283, 'min_samples_split': 20, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.7513610919408021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:24:55,184] Trial 11 finished with value: 0.7421593436086189 and parameters: {'num_layers': 2, 'latent_dim_0': 25, 'latent_dim_1': 19, 'lr': 0.002390970336982204, 'epochs': 48, 'dropout_rate': 0.24276539310683573, 'n_estimators': 492, 'max_depth': 3, 'learning_rate': 0.01091455491486761, 'subsample': 0.6376509513732477, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.7513610919408021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:25:49,843] Trial 12 finished with value: 0.7272256728778469 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 18, 'lr': 0.0012622869439231537, 'epochs': 50, 'dropout_rate': 0.2570332686365793, 'n_estimators': 495, 'max_depth': 4, 'learning_rate': 0.028297273263690758, 'subsample': 0.7027859211489322, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.7513610919408021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:26:26,104] Trial 13 finished with value: 0.7412391687754006 and parameters: {'num_layers': 2, 'latent_dim_0': 25, 'latent_dim_1': 14, 'lr': 0.009532474480707953, 'epochs': 50, 'dropout_rate': 0.2686892594679086, 'n_estimators': 328, 'max_depth': 3, 'learning_rate': 0.025169369214423372, 'subsample': 0.8078280137187662, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 4 with value: 0.7513610919408021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:26:51,208] Trial 14 finished with value: 0.7325166781688521 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 20, 'lr': 0.0007632817180174521, 'epochs': 22, 'dropout_rate': 0.4918383179898858, 'n_estimators': 183, 'max_depth': 6, 'learning_rate': 0.0461046710992744, 'subsample': 0.6036814423371691, 'min_samples_split': 20, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.7513610919408021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:27:24,215] Trial 15 finished with value: 0.7410474656851468 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 18, 'lr': 0.0025606070305204793, 'epochs': 10, 'dropout_rate': 0.21815541851771986, 'n_estimators': 326, 'max_depth': 4, 'learning_rate': 0.01857583976671195, 'subsample': 0.7529051082833368, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.7513610919408021.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:27:41,483] Trial 16 finished with value: 0.7530864197530865 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 11, 'lr': 0.0015163415124426652, 'epochs': 44, 'dropout_rate': 0.3808691993691253, 'n_estimators': 68, 'max_depth': 4, 'learning_rate': 0.043579036276837735, 'subsample': 0.8558039982946914, 'min_samples_split': 15, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.7530864197530865.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:27:58,569] Trial 17 finished with value: 0.7479296066252589 and parameters: {'num_layers': 2, 'latent_dim_0': 21, 'latent_dim_1': 10, 'lr': 0.0005520983332583111, 'epochs': 34, 'dropout_rate': 0.3933645940911185, 'n_estimators': 86, 'max_depth': 4, 'learning_rate': 0.049912062421143724, 'subsample': 0.8598963543319954, 'min_samples_split': 16, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.7530864197530865.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:28:35,186] Trial 18 finished with value: 0.7123495130741507 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 12, 'lr': 0.0014776212164553575, 'epochs': 43, 'dropout_rate': 0.3811444169630075, 'n_estimators': 161, 'max_depth': 6, 'learning_rate': 0.04161735439533219, 'subsample': 0.9754009550904214, 'min_samples_split': 18, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.7530864197530865.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:28:51,945] Trial 19 finished with value: 0.7242926155969635 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 11, 'lr': 0.0004990374642630911, 'epochs': 27, 'dropout_rate': 0.3022678680009744, 'n_estimators': 54, 'max_depth': 10, 'learning_rate': 0.06811482181564152, 'subsample': 0.8321407020397452, 'min_samples_split': 14, 'min_samples_leaf': 8}. Best is trial 16 with value: 0.7530864197530865.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7443\n"
     ]
    }
   ],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(SimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "        \n",
    "        return reconstructions, latents\n",
    "    \n",
    "def train_stacked_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    \n",
    "    # Обучаем каждый автоэнкодер последовательно\n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, latent)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, _ in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent = ae(batch_x)\n",
    "                loss = criterion(reconstructed, batch_x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры градиентного бустинга\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7290\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7263\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7300\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7337\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7057\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7490\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7433\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7472\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7391\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7392\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7483\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7355\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7385\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7162\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7426\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7179\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7107\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6966\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7085\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7085\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7441\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7551\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7320\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7627\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7437\n",
      "среднее 0.7321375588390308\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:30:58,105] A new study created in memory with name: no-name-aee16232-1f01-4a2c-b4fc-4ca5a80b229b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:31:08,200] Trial 0 finished with value: 0.6926424353960586 and parameters: {'num_layers': 2, 'latent_dim_0': 36, 'latent_dim_1': 16, 'lr': 0.0006897194401221571, 'epochs': 32, 'dropout_rate': 0.16562295825527273, 'C': 59.92422001440525, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.6926424353960586.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:31:12,600] Trial 1 finished with value: 0.7737903535004983 and parameters: {'num_layers': 2, 'latent_dim_0': 39, 'latent_dim_1': 13, 'lr': 0.0013202091268969913, 'epochs': 10, 'dropout_rate': 0.3189780436187853, 'C': 0.2798790272568221, 'kernel': 'linear'}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:31:25,175] Trial 2 finished with value: 0.6853193773483629 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 19, 'lr': 0.00013292989922349956, 'epochs': 40, 'dropout_rate': 0.4176861338507891, 'C': 29.726390933621506, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:31:40,076] Trial 3 finished with value: 0.5714094011195461 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 18, 'lr': 0.006102616459103607, 'epochs': 47, 'dropout_rate': 0.3687772545075104, 'C': 27.46009158857906, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:33:25,061] Trial 4 finished with value: 0.7655183651560463 and parameters: {'num_layers': 2, 'latent_dim_0': 30, 'latent_dim_1': 13, 'lr': 0.0010453398824763352, 'epochs': 30, 'dropout_rate': 0.48356938801437055, 'C': 21.45730214735527, 'kernel': 'linear'}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:33:37,621] Trial 5 finished with value: 0.5775247296986428 and parameters: {'num_layers': 2, 'latent_dim_0': 36, 'latent_dim_1': 19, 'lr': 0.002079255764973959, 'epochs': 45, 'dropout_rate': 0.4099706128217031, 'C': 9.900801756138243, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:33:42,589] Trial 6 finished with value: 0.7020167165094701 and parameters: {'num_layers': 2, 'latent_dim_0': 30, 'latent_dim_1': 20, 'lr': 0.0006666617031204668, 'epochs': 15, 'dropout_rate': 0.4525025316365886, 'C': 5.5826875891057135, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:36:55,726] Trial 7 finished with value: 0.7675408327582242 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 11, 'lr': 0.00012746651124949133, 'epochs': 20, 'dropout_rate': 0.3009317958325386, 'C': 35.176780810004516, 'kernel': 'linear'}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:37:06,888] Trial 8 finished with value: 0.6710566674334791 and parameters: {'num_layers': 2, 'latent_dim_0': 38, 'latent_dim_1': 10, 'lr': 0.0002091788545859442, 'epochs': 26, 'dropout_rate': 0.14003817834674315, 'C': 0.32590738427969385, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:37:15,410] Trial 9 finished with value: 0.5534084809447127 and parameters: {'num_layers': 2, 'latent_dim_0': 25, 'latent_dim_1': 18, 'lr': 0.007972271908881615, 'epochs': 31, 'dropout_rate': 0.47469058478845494, 'C': 0.16316319939525564, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:37:22,626] Trial 10 finished with value: 0.7664864657618281 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 13, 'lr': 0.0032725241025497527, 'epochs': 12, 'dropout_rate': 0.23398808048692468, 'C': 1.0450766428698524, 'kernel': 'linear'}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:37:33,290] Trial 11 finished with value: 0.7709531477647421 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 10, 'lr': 0.00032735716453122866, 'epochs': 21, 'dropout_rate': 0.30309723000437144, 'C': 1.6174137282590182, 'kernel': 'linear'}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:37:41,690] Trial 12 finished with value: 0.7707422743654627 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 12, 'lr': 0.0003182194643468708, 'epochs': 10, 'dropout_rate': 0.3097442883920374, 'C': 1.3196822589167347, 'kernel': 'linear'}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:37:49,136] Trial 13 finished with value: 0.7726497201134883 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 15, 'lr': 0.00033766991091970194, 'epochs': 19, 'dropout_rate': 0.23672469641753793, 'C': 0.6604575075601085, 'kernel': 'linear'}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:37:53,861] Trial 14 finished with value: 0.7266122229890346 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 15, 'lr': 0.0014256835235520091, 'epochs': 17, 'dropout_rate': 0.22853803746223927, 'C': 0.4149012128130977, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:37:57,226] Trial 15 finished with value: 0.7706272525113104 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 16, 'lr': 0.00048662278403127624, 'epochs': 10, 'dropout_rate': 0.22919926147707081, 'C': 0.1525227655756384, 'kernel': 'linear'}. Best is trial 1 with value: 0.7737903535004983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:38:04,654] Trial 16 finished with value: 0.7751131048232498 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 14, 'lr': 0.0025642034827472026, 'epochs': 23, 'dropout_rate': 0.3580543869674622, 'C': 0.4246365858153455, 'kernel': 'linear'}. Best is trial 16 with value: 0.7751131048232498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:38:21,128] Trial 17 finished with value: 0.765652557319224 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 14, 'lr': 0.0035639433659169794, 'epochs': 24, 'dropout_rate': 0.35603495664344087, 'C': 2.7780942177292918, 'kernel': 'linear'}. Best is trial 16 with value: 0.7751131048232498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:38:31,108] Trial 18 finished with value: 0.7020167165094701 and parameters: {'num_layers': 2, 'latent_dim_0': 38, 'latent_dim_1': 12, 'lr': 0.0020282651046096755, 'epochs': 38, 'dropout_rate': 0.3490496330536294, 'C': 0.117949685447959, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 16 with value: 0.7751131048232498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:38:38,942] Trial 19 finished with value: 0.7300053676865271 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 14, 'lr': 0.003983097514509745, 'epochs': 26, 'dropout_rate': 0.3939545727856523, 'C': 0.26971509248381637, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 16 with value: 0.7751131048232498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7778\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры SVC\n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7129\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7217\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6983\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7183\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7024\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7673\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7440\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7712\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7497\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7700\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7440\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7474\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7489\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7356\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7428\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6612\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6678\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6668\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6686\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6744\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7389\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7372\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7056\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7464\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7173\n",
      "среднее 0.7223575401122099\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:39:34,662] A new study created in memory with name: no-name-810d3bcf-4230-476b-996e-d81093e95ca0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:39:48,185] Trial 0 finished with value: 0.7481213097155125 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 19, 'lr_ae': 0.0021499959490194113, 'epochs_ae': 26, 'dropout_rate_ae': 0.23781680715923384, 'hidden_dim_mlp': 46, 'lr_mlp': 0.005827828589207834, 'epochs_mlp': 49, 'dropout_rate_mlp': 0.4904703894620587}. Best is trial 0 with value: 0.7481213097155125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:40:00,443] Trial 1 finished with value: 0.7588758530787515 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 19, 'lr_ae': 0.0002416464612175408, 'epochs_ae': 32, 'dropout_rate_ae': 0.21142815732056675, 'hidden_dim_mlp': 69, 'lr_mlp': 0.0010010658405874815, 'epochs_mlp': 27, 'dropout_rate_mlp': 0.43612362904253976}. Best is trial 1 with value: 0.7588758530787515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:40:12,139] Trial 2 finished with value: 0.7318457173529637 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 20, 'lr_ae': 0.0077600466976338505, 'epochs_ae': 19, 'dropout_rate_ae': 0.2353997506645417, 'hidden_dim_mlp': 37, 'lr_mlp': 0.002587882502762645, 'epochs_mlp': 48, 'dropout_rate_mlp': 0.29448560822486747}. Best is trial 1 with value: 0.7588758530787515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:40:23,229] Trial 3 finished with value: 0.7565754159957058 and parameters: {'num_layers': 2, 'latent_dim_0': 30, 'latent_dim_1': 13, 'lr_ae': 0.009258552789964939, 'epochs_ae': 36, 'dropout_rate_ae': 0.15113074615315095, 'hidden_dim_mlp': 97, 'lr_mlp': 0.002288193901065771, 'epochs_mlp': 12, 'dropout_rate_mlp': 0.4204917459543934}. Best is trial 1 with value: 0.7588758530787515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:40:39,731] Trial 4 finished with value: 0.7586074687523962 and parameters: {'num_layers': 2, 'latent_dim_0': 21, 'latent_dim_1': 12, 'lr_ae': 0.00010339108194133754, 'epochs_ae': 47, 'dropout_rate_ae': 0.1794940108182841, 'hidden_dim_mlp': 100, 'lr_mlp': 0.0001210030406489195, 'epochs_mlp': 29, 'dropout_rate_mlp': 0.21983423844668676}. Best is trial 1 with value: 0.7588758530787515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:40:50,970] Trial 5 finished with value: 0.7586266390614217 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 12, 'lr_ae': 0.0009220224134366183, 'epochs_ae': 32, 'dropout_rate_ae': 0.32071857757902916, 'hidden_dim_mlp': 59, 'lr_mlp': 0.00044591609931492394, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.13963269358861385}. Best is trial 1 with value: 0.7588758530787515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:40:57,814] Trial 6 finished with value: 0.7565945863047313 and parameters: {'num_layers': 2, 'latent_dim_0': 38, 'latent_dim_1': 12, 'lr_ae': 0.00014742942535863867, 'epochs_ae': 20, 'dropout_rate_ae': 0.21734107249486767, 'hidden_dim_mlp': 110, 'lr_mlp': 0.00014016550048000998, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.27881143230104943}. Best is trial 1 with value: 0.7588758530787515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:41:04,719] Trial 7 finished with value: 0.7422935357717965 and parameters: {'num_layers': 2, 'latent_dim_0': 36, 'latent_dim_1': 20, 'lr_ae': 0.0015999294194498192, 'epochs_ae': 13, 'dropout_rate_ae': 0.19868167087670294, 'hidden_dim_mlp': 57, 'lr_mlp': 0.0031657233664571316, 'epochs_mlp': 24, 'dropout_rate_mlp': 0.19741298885991296}. Best is trial 1 with value: 0.7588758530787515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:41:13,606] Trial 8 finished with value: 0.748044628479411 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 15, 'lr_ae': 0.0014417030977450906, 'epochs_ae': 13, 'dropout_rate_ae': 0.258336637263664, 'hidden_dim_mlp': 90, 'lr_mlp': 0.0009631500364559091, 'epochs_mlp': 36, 'dropout_rate_mlp': 0.36405719342200893}. Best is trial 1 with value: 0.7588758530787515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:41:28,453] Trial 9 finished with value: 0.7005789433325665 and parameters: {'num_layers': 2, 'latent_dim_0': 37, 'latent_dim_1': 16, 'lr_ae': 0.005990095041577345, 'epochs_ae': 29, 'dropout_rate_ae': 0.1361740109427934, 'hidden_dim_mlp': 107, 'lr_mlp': 0.008445738351538428, 'epochs_mlp': 46, 'dropout_rate_mlp': 0.21479074889127842}. Best is trial 1 with value: 0.7588758530787515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:41:44,940] Trial 10 finished with value: 0.7548309178743962 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 17, 'lr_ae': 0.000334372326552803, 'epochs_ae': 42, 'dropout_rate_ae': 0.4513382677945473, 'hidden_dim_mlp': 127, 'lr_mlp': 0.00045179430101532876, 'epochs_mlp': 37, 'dropout_rate_mlp': 0.49529085630468855}. Best is trial 1 with value: 0.7588758530787515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:41:57,456] Trial 11 finished with value: 0.7580131891726095 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 11, 'lr_ae': 0.0004699650839625038, 'epochs_ae': 36, 'dropout_rate_ae': 0.36099481326822064, 'hidden_dim_mlp': 73, 'lr_mlp': 0.00044218270842949026, 'epochs_mlp': 20, 'dropout_rate_mlp': 0.12427332195032817}. Best is trial 1 with value: 0.7588758530787515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:42:10,206] Trial 12 finished with value: 0.7611187792347214 and parameters: {'num_layers': 2, 'latent_dim_0': 30, 'latent_dim_1': 10, 'lr_ae': 0.0005037259764249715, 'epochs_ae': 36, 'dropout_rate_ae': 0.3315995697236363, 'hidden_dim_mlp': 69, 'lr_mlp': 0.000672009671375941, 'epochs_mlp': 21, 'dropout_rate_mlp': 0.36739992806623867}. Best is trial 12 with value: 0.7611187792347214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:42:28,325] Trial 13 finished with value: 0.7364465915190553 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 10, 'lr_ae': 0.00025408521591748927, 'epochs_ae': 41, 'dropout_rate_ae': 0.38336581804373715, 'hidden_dim_mlp': 74, 'lr_mlp': 0.0010485916849916589, 'epochs_mlp': 26, 'dropout_rate_mlp': 0.37769984535938}. Best is trial 12 with value: 0.7611187792347214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:42:48,416] Trial 14 finished with value: 0.752511310482325 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 18, 'lr_ae': 0.0006128725799533125, 'epochs_ae': 49, 'dropout_rate_ae': 0.30053868892270824, 'hidden_dim_mlp': 63, 'lr_mlp': 0.0009834270728235996, 'epochs_mlp': 35, 'dropout_rate_mlp': 0.42900735451012495}. Best is trial 12 with value: 0.7611187792347214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:42:57,935] Trial 15 finished with value: 0.7560578176520205 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 14, 'lr_ae': 0.00021119905187012118, 'epochs_ae': 24, 'dropout_rate_ae': 0.4233825369506361, 'hidden_dim_mlp': 82, 'lr_mlp': 0.0002490439614658631, 'epochs_mlp': 19, 'dropout_rate_mlp': 0.35192057172318814}. Best is trial 12 with value: 0.7611187792347214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:43:11,602] Trial 16 finished with value: 0.7504984280346599 and parameters: {'num_layers': 2, 'latent_dim_0': 30, 'latent_dim_1': 17, 'lr_ae': 0.00064799138108739, 'epochs_ae': 35, 'dropout_rate_ae': 0.4931369598905856, 'hidden_dim_mlp': 49, 'lr_mlp': 0.00146926071729459, 'epochs_mlp': 31, 'dropout_rate_mlp': 0.4331046968230419}. Best is trial 12 with value: 0.7611187792347214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:43:26,369] Trial 17 finished with value: 0.7485622268230964 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 15, 'lr_ae': 0.0031765268486390556, 'epochs_ae': 42, 'dropout_rate_ae': 0.34174959064082633, 'hidden_dim_mlp': 71, 'lr_mlp': 0.0007046865101736018, 'epochs_mlp': 23, 'dropout_rate_mlp': 0.3344803825998567}. Best is trial 12 with value: 0.7611187792347214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:43:40,797] Trial 18 finished with value: 0.7604286481098076 and parameters: {'num_layers': 2, 'latent_dim_0': 30, 'latent_dim_1': 10, 'lr_ae': 0.0003615725074739476, 'epochs_ae': 31, 'dropout_rate_ae': 0.10092080370547221, 'hidden_dim_mlp': 86, 'lr_mlp': 0.00023620029265491763, 'epochs_mlp': 42, 'dropout_rate_mlp': 0.401035215668736}. Best is trial 12 with value: 0.7611187792347214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:43:54,852] Trial 19 finished with value: 0.7593742811134115 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 10, 'lr_ae': 0.00039410369765826143, 'epochs_ae': 28, 'dropout_rate_ae': 0.10511118266582005, 'hidden_dim_mlp': 83, 'lr_mlp': 0.0002213996990645173, 'epochs_mlp': 42, 'dropout_rate_mlp': 0.38911413250237137}. Best is trial 12 with value: 0.7611187792347214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7506\n"
     ]
    }
   ],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(SimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "        \n",
    "        return reconstructions, latents\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "def train_stacked_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    \n",
    "    # Обучаем каждый автоэнкодер последовательно\n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, latent)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, _ in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent = ae(batch_x)\n",
    "                loss = criterion(reconstructed, batch_x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры MLP\n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate_ae)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate_ae'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7428\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7182\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7054\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7268\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7327\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7637\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7565\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7695\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7605\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7564\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7120\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7356\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7296\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7177\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7327\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6757\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6789\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6705\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6801\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6849\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7492\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7471\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7562\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7403\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7598\n",
      "среднее 0.7281129920888085\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь блок с stacked автоэнкодером. Но у каждого из автоэнкодеров была дополнительная классифицирующая голова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "логистическая рергрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:45:26,180] A new study created in memory with name: no-name-8ed0496c-cab1-4b1c-b171-62ac391f12c7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:45:33,969] Trial 0 finished with value: 0.7299670270684763 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 15, 'lr': 0.0006523153058226761, 'epochs': 19, 'dropout_rate': 0.30262475655683296, 'class_weight_0': 0.5633388112542617, 'class_weight_1': 0.4531569672483491, 'C': 1.9450844155540579, 'solver': 'saga'}. Best is trial 0 with value: 0.7299670270684763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:45:41,355] Trial 1 finished with value: 0.676079288398129 and parameters: {'num_layers': 2, 'latent_dim_0': 39, 'latent_dim_1': 17, 'lr': 0.007678859889961798, 'epochs': 24, 'dropout_rate': 0.4704783932267125, 'class_weight_0': 0.3721250046948229, 'class_weight_1': 0.7816931432912494, 'C': 0.010292474540923809, 'solver': 'saga'}. Best is trial 0 with value: 0.7299670270684763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:45:51,050] Trial 2 finished with value: 0.6136032512844106 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 10, 'lr': 0.002703573024524803, 'epochs': 31, 'dropout_rate': 0.4077594693852228, 'class_weight_0': 0.5387278981702937, 'class_weight_1': 0.47287031848294603, 'C': 18.60933018832384, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7299670270684763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:46:01,078] Trial 3 finished with value: 0.6138524653017406 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 14, 'lr': 0.006570203883412905, 'epochs': 32, 'dropout_rate': 0.3917664929010838, 'class_weight_0': 0.4604142594828131, 'class_weight_1': 0.6666914668932752, 'C': 71.77091572531508, 'solver': 'liblinear'}. Best is trial 0 with value: 0.7299670270684763.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:46:14,498] Trial 4 finished with value: 0.769802929223219 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 11, 'lr': 0.0002210465448871811, 'epochs': 39, 'dropout_rate': 0.441036598818634, 'class_weight_0': 0.21157773644422173, 'class_weight_1': 0.31579360863407047, 'C': 13.163933030837695, 'solver': 'saga'}. Best is trial 4 with value: 0.769802929223219.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:46:24,249] Trial 5 finished with value: 0.7110459320604248 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 12, 'lr': 0.0016207574912276371, 'epochs': 32, 'dropout_rate': 0.3926585218153097, 'class_weight_0': 0.34437772555343493, 'class_weight_1': 0.3903931392641963, 'C': 8.35355111830804, 'solver': 'liblinear'}. Best is trial 4 with value: 0.769802929223219.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:46:34,381] Trial 6 finished with value: 0.5954297983283491 and parameters: {'num_layers': 2, 'latent_dim_0': 38, 'latent_dim_1': 18, 'lr': 0.006091493896456637, 'epochs': 32, 'dropout_rate': 0.19356360845036763, 'class_weight_0': 0.41730605046608993, 'class_weight_1': 0.38460738916156634, 'C': 0.03043845811821404, 'solver': 'saga'}. Best is trial 4 with value: 0.769802929223219.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:46:46,379] Trial 7 finished with value: 0.6258147381335787 and parameters: {'num_layers': 2, 'latent_dim_0': 21, 'latent_dim_1': 14, 'lr': 0.002103861904398666, 'epochs': 40, 'dropout_rate': 0.2518658101686466, 'class_weight_0': 0.705700272188149, 'class_weight_1': 0.2810584868820961, 'C': 0.4020456592409034, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.769802929223219.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:47:02,218] Trial 8 finished with value: 0.6268499348209492 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 14, 'lr': 0.0011656061028108321, 'epochs': 45, 'dropout_rate': 0.3507701731491585, 'class_weight_0': 0.6502677419331607, 'class_weight_1': 0.3478118366229016, 'C': 29.569524240886693, 'solver': 'saga'}. Best is trial 4 with value: 0.769802929223219.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:47:16,291] Trial 9 finished with value: 0.6828847481021395 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 13, 'lr': 0.0007224313457915749, 'epochs': 46, 'dropout_rate': 0.2029798310065989, 'class_weight_0': 0.4195340217404768, 'class_weight_1': 0.8284051388007849, 'C': 2.837059476522342, 'solver': 'liblinear'}. Best is trial 4 with value: 0.769802929223219.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:47:19,459] Trial 10 finished with value: 0.7730235411394831 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 20, 'lr': 0.0001625879417107586, 'epochs': 10, 'dropout_rate': 0.10515797225036619, 'class_weight_0': 0.10788442439622492, 'class_weight_1': 0.12684872968926963, 'C': 0.2911675895318355, 'solver': 'lbfgs'}. Best is trial 10 with value: 0.7730235411394831.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:47:22,912] Trial 11 finished with value: 0.7657963346369142 and parameters: {'num_layers': 2, 'latent_dim_0': 25, 'latent_dim_1': 20, 'lr': 0.00013273836316946808, 'epochs': 11, 'dropout_rate': 0.11702397714062295, 'class_weight_0': 0.10161084258808871, 'class_weight_1': 0.10760484478457202, 'C': 0.26470350015948163, 'solver': 'lbfgs'}. Best is trial 10 with value: 0.7730235411394831.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:47:26,104] Trial 12 finished with value: 0.7746913580246914 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 10, 'lr': 0.00014234233400790375, 'epochs': 10, 'dropout_rate': 0.4947930953018905, 'class_weight_0': 0.10091454143305541, 'class_weight_1': 0.12704606190754225, 'C': 0.14627844775732463, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.7746913580246914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:47:29,194] Trial 13 finished with value: 0.7718924929069857 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 20, 'lr': 0.0003008105214385428, 'epochs': 10, 'dropout_rate': 0.4956037735396833, 'class_weight_0': 0.13093317919544073, 'class_weight_1': 0.10514030538460116, 'C': 0.09048678498519122, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.7746913580246914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:47:34,374] Trial 14 finished with value: 0.7772985200521433 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 17, 'lr': 0.00014075717936997176, 'epochs': 17, 'dropout_rate': 0.10193553116410034, 'class_weight_0': 0.8840965885954422, 'class_weight_1': 0.1988304523249892, 'C': 0.14648153498282573, 'solver': 'lbfgs'}. Best is trial 14 with value: 0.7772985200521433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:47:39,903] Trial 15 finished with value: 0.77814201364926 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 17, 'lr': 0.00010411144728583507, 'epochs': 18, 'dropout_rate': 0.17082262295780246, 'class_weight_0': 0.7968504836731869, 'class_weight_1': 0.21607786684669011, 'C': 0.07008695833415494, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.77814201364926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:47:45,540] Trial 16 finished with value: 0.7629399585921325 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 17, 'lr': 0.00036756237010779363, 'epochs': 18, 'dropout_rate': 0.17408358615706684, 'class_weight_0': 0.8563395321857147, 'class_weight_1': 0.2362552796363576, 'C': 0.04656763668565883, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.77814201364926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:47:52,851] Trial 17 finished with value: 0.7281650180200905 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 18, 'lr': 0.0004242468992461024, 'epochs': 24, 'dropout_rate': 0.15643141489889795, 'class_weight_0': 0.8869394609117467, 'class_weight_1': 0.577603065479943, 'C': 0.7364753391923827, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.77814201364926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:47:58,249] Trial 18 finished with value: 0.7706464228203358 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 16, 'lr': 0.00023337414004473802, 'epochs': 17, 'dropout_rate': 0.2244139924626768, 'class_weight_0': 0.7797448427878704, 'class_weight_1': 0.2481569253436561, 'C': 0.015815239854791975, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.77814201364926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:48:06,247] Trial 19 finished with value: 0.7688635840809753 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 18, 'lr': 0.00010691061008957106, 'epochs': 25, 'dropout_rate': 0.14368414615851102, 'class_weight_0': 0.7914855618498869, 'class_weight_1': 0.18118427962074746, 'C': 0.08492999131955682, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.77814201364926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7738\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingSimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(ClassifyingSimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(output_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "\n",
    "class ClassifyingStackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(ClassifyingStackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(ClassifyingSimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        classifications = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent, classification = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "            classifications.append(classification)\n",
    "        \n",
    "        return reconstructions, latents, classifications\n",
    "    \n",
    "def train_classifying_stacked_autoencoder(model, X_train, y_train, epochs, batch_size, lr, classification_weights):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        recon_criterion = nn.MSELoss()\n",
    "        class_criterion = nn.BCELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent, classification = ae(batch_x)\n",
    "                \n",
    "                recon_loss = recon_criterion(reconstructed, batch_x)\n",
    "                class_loss = class_criterion(classification, batch_y)\n",
    "                \n",
    "                recon_weight = 1.0 - classification_weights[i]\n",
    "                class_weight = classification_weights[i]\n",
    "                loss = recon_weight * recon_loss + class_weight * class_loss\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent, _ = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent, _ = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "# Восстанавливаем список весов классификации\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7467\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7275\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7352\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7226\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7316\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7872\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7583\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7705\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7718\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7605\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7402\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7446\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7373\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7441\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7512\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7009\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7108\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6848\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7038\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6859\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7311\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7573\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7632\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7393\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7406\n",
      "среднее 0.7378725150008014\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        # Восстанавливаем список весов классификации\n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:48:46,281] A new study created in memory with name: no-name-7af06ea8-cfac-4d8e-81ca-0878835105b1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:49:30,311] Trial 0 finished with value: 0.7336093857832989 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 14, 'lr': 0.00011246692121613617, 'epochs': 25, 'dropout_rate': 0.26032401347053313, 'class_weight_0': 0.33317474642954437, 'class_weight_1': 0.2893251203389363, 'n_estimators': 287, 'max_depth': 4, 'learning_rate': 0.017736337519917773, 'subsample': 0.9211055515550481, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7336093857832989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:50:10,560] Trial 1 finished with value: 0.6147534698259336 and parameters: {'num_layers': 2, 'latent_dim_0': 36, 'latent_dim_1': 19, 'lr': 0.003151727987146931, 'epochs': 16, 'dropout_rate': 0.16975277869015298, 'class_weight_0': 0.8281726011706995, 'class_weight_1': 0.5317200102990268, 'n_estimators': 456, 'max_depth': 4, 'learning_rate': 0.012889774612485427, 'subsample': 0.6175008862486147, 'min_samples_split': 15, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7336093857832989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:50:52,837] Trial 2 finished with value: 0.5631086573115559 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 19, 'lr': 0.009122015894755888, 'epochs': 33, 'dropout_rate': 0.33675566911846655, 'class_weight_0': 0.4690174496257059, 'class_weight_1': 0.6052677725435108, 'n_estimators': 136, 'max_depth': 10, 'learning_rate': 0.026285427562082343, 'subsample': 0.8445295123043033, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.7336093857832989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:51:47,186] Trial 3 finished with value: 0.7161260639521508 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 18, 'lr': 0.0005973632978239416, 'epochs': 26, 'dropout_rate': 0.3591713526846836, 'class_weight_0': 0.3875504822858489, 'class_weight_1': 0.66471426409829, 'n_estimators': 233, 'max_depth': 10, 'learning_rate': 0.03112100988549508, 'subsample': 0.7938985139080967, 'min_samples_split': 20, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7336093857832989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:52:14,051] Trial 4 finished with value: 0.6792807300053676 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 18, 'lr': 0.001332678886145217, 'epochs': 15, 'dropout_rate': 0.16789272373731257, 'class_weight_0': 0.8611383202263706, 'class_weight_1': 0.31056232528991545, 'n_estimators': 102, 'max_depth': 8, 'learning_rate': 0.13671207591127663, 'subsample': 0.9799980696264239, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7336093857832989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:52:52,699] Trial 5 finished with value: 0.7333026608388927 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 13, 'lr': 0.00027147115004164314, 'epochs': 15, 'dropout_rate': 0.27866548768663857, 'class_weight_0': 0.3310616718756717, 'class_weight_1': 0.5481989351350651, 'n_estimators': 362, 'max_depth': 4, 'learning_rate': 0.02379508054606877, 'subsample': 0.7720059801759298, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7336093857832989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:53:34,318] Trial 6 finished with value: 0.6873514301050533 and parameters: {'num_layers': 2, 'latent_dim_0': 37, 'latent_dim_1': 16, 'lr': 0.0015991816715540284, 'epochs': 32, 'dropout_rate': 0.42899671920206406, 'class_weight_0': 0.19064767898019408, 'class_weight_1': 0.6019410603489648, 'n_estimators': 302, 'max_depth': 5, 'learning_rate': 0.03296103507472371, 'subsample': 0.7094549917212106, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7336093857832989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:54:15,030] Trial 7 finished with value: 0.7166628326048615 and parameters: {'num_layers': 2, 'latent_dim_0': 36, 'latent_dim_1': 19, 'lr': 0.0006487503056516135, 'epochs': 19, 'dropout_rate': 0.48655611702017676, 'class_weight_0': 0.35179106717951736, 'class_weight_1': 0.8177616232982283, 'n_estimators': 182, 'max_depth': 7, 'learning_rate': 0.03959192989435607, 'subsample': 0.8833631869764937, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7336093857832989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:54:40,253] Trial 8 finished with value: 0.6769994632313473 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 19, 'lr': 0.00399304863450794, 'epochs': 44, 'dropout_rate': 0.40039959282630255, 'class_weight_0': 0.16526185791139875, 'class_weight_1': 0.17986306620056053, 'n_estimators': 54, 'max_depth': 9, 'learning_rate': 0.03293902483141454, 'subsample': 0.8907939767289573, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.7336093857832989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:55:11,738] Trial 9 finished with value: 0.719902614830151 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 13, 'lr': 0.00018995172272829314, 'epochs': 18, 'dropout_rate': 0.22031585805080522, 'class_weight_0': 0.865301087595099, 'class_weight_1': 0.3994239277323518, 'n_estimators': 204, 'max_depth': 8, 'learning_rate': 0.16056360601191985, 'subsample': 0.6107845556077092, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.7336093857832989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:55:59,689] Trial 10 finished with value: 0.7332068092937658 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 11, 'lr': 0.00012305011287222105, 'epochs': 43, 'dropout_rate': 0.11091727545898086, 'class_weight_0': 0.6370376243224765, 'class_weight_1': 0.13129437399436783, 'n_estimators': 399, 'max_depth': 3, 'learning_rate': 0.01099467120374878, 'subsample': 0.9835512323875653, 'min_samples_split': 15, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7336093857832989.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:56:43,308] Trial 11 finished with value: 0.7411241469212483 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 14, 'lr': 0.0002564576290063379, 'epochs': 25, 'dropout_rate': 0.26076991324194654, 'class_weight_0': 0.29020697715774124, 'class_weight_1': 0.3630299095932231, 'n_estimators': 323, 'max_depth': 5, 'learning_rate': 0.017307993512859356, 'subsample': 0.7430235670514855, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.7411241469212483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:57:27,698] Trial 12 finished with value: 0.7056590752242925 and parameters: {'num_layers': 2, 'latent_dim_0': 21, 'latent_dim_1': 15, 'lr': 0.0003405240211933009, 'epochs': 26, 'dropout_rate': 0.271157817390508, 'class_weight_0': 0.23296253960606747, 'class_weight_1': 0.30358564628228835, 'n_estimators': 293, 'max_depth': 6, 'learning_rate': 0.07782739817726694, 'subsample': 0.7279705371556527, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.7411241469212483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:58:14,976] Trial 13 finished with value: 0.7483705237328425 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 14, 'lr': 0.00010042777026926685, 'epochs': 37, 'dropout_rate': 0.22758141374258625, 'class_weight_0': 0.604385448925236, 'class_weight_1': 0.36189150501867234, 'n_estimators': 351, 'max_depth': 5, 'learning_rate': 0.016089608763823128, 'subsample': 0.6903870747501748, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.7483705237328425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 00:59:05,404] Trial 14 finished with value: 0.7148416532474503 and parameters: {'num_layers': 2, 'latent_dim_0': 25, 'latent_dim_1': 10, 'lr': 0.00022578943616481502, 'epochs': 37, 'dropout_rate': 0.21572132198736238, 'class_weight_0': 0.6353838921044654, 'class_weight_1': 0.42501832537877265, 'n_estimators': 392, 'max_depth': 6, 'learning_rate': 0.29516526583224545, 'subsample': 0.6882687396700329, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.7483705237328425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:00:04,913] Trial 15 finished with value: 0.7108542289701708 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 16, 'lr': 0.00010099769326692356, 'epochs': 38, 'dropout_rate': 0.31858670228535246, 'class_weight_0': 0.6044365497770703, 'class_weight_1': 0.4212509804234007, 'n_estimators': 462, 'max_depth': 5, 'learning_rate': 0.05640610463581162, 'subsample': 0.6728503029935227, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 13 with value: 0.7483705237328425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:00:56,707] Trial 16 finished with value: 0.7112951460777547 and parameters: {'num_layers': 2, 'latent_dim_0': 30, 'latent_dim_1': 12, 'lr': 0.0004714533224827735, 'epochs': 50, 'dropout_rate': 0.2018536027478083, 'class_weight_0': 0.5167688094912212, 'class_weight_1': 0.21446996501181836, 'n_estimators': 339, 'max_depth': 5, 'learning_rate': 0.016419264332932025, 'subsample': 0.748403833037447, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.7483705237328425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:01:30,083] Trial 17 finished with value: 0.7336860670194003 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 15, 'lr': 0.00017735925661881426, 'epochs': 10, 'dropout_rate': 0.10611152201916163, 'class_weight_0': 0.695481354191886, 'class_weight_1': 0.7168200155294003, 'n_estimators': 491, 'max_depth': 3, 'learning_rate': 0.01878910998642145, 'subsample': 0.6591438498236155, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.7483705237328425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:02:22,821] Trial 18 finished with value: 0.6853768882754391 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 13, 'lr': 0.0003753907055104422, 'epochs': 37, 'dropout_rate': 0.2460604844894025, 'class_weight_0': 0.7604092976265198, 'class_weight_1': 0.3833828299915191, 'n_estimators': 247, 'max_depth': 7, 'learning_rate': 0.05856850692943994, 'subsample': 0.828049535793467, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.7483705237328425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:03:08,793] Trial 19 finished with value: 0.7365999539912583 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 17, 'lr': 0.00014082937965349574, 'epochs': 21, 'dropout_rate': 0.1506648576412569, 'class_weight_0': 0.11004460195159863, 'class_weight_1': 0.4699372387276056, 'n_estimators': 344, 'max_depth': 6, 'learning_rate': 0.010089644767557615, 'subsample': 0.6537860902148742, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.7483705237328425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7400\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7190\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6730\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7046\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7251\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7076\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7366\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7360\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7284\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7192\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7111\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7390\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7419\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7303\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7356\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7322\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7044\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7043\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7001\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6939\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7459\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7459\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7196\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7414\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7442\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7378\n",
      "среднее 0.7230878976807398\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:08:43,937] A new study created in memory with name: no-name-e7cbfb01-98f6-4936-9cf5-11271dd7435e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:08:48,917] Trial 0 finished with value: 0.7304846254121617 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 11, 'lr': 0.003942319289944774, 'epochs': 12, 'dropout_rate': 0.4769714232170974, 'class_weight_0': 0.48618961483629486, 'class_weight_1': 0.31226014152578896, 'C': 0.3744913014182304, 'kernel': 'linear'}. Best is trial 0 with value: 0.7304846254121617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:09:02,876] Trial 1 finished with value: 0.7551088873552642 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 13, 'lr': 0.0012411891643998997, 'epochs': 36, 'dropout_rate': 0.12238603336386761, 'class_weight_0': 0.10254174079483924, 'class_weight_1': 0.18666188627964297, 'C': 0.6790191707763609, 'kernel': 'linear'}. Best is trial 1 with value: 0.7551088873552642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:09:16,131] Trial 2 finished with value: 0.6228625105436699 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 20, 'lr': 0.000380187144710769, 'epochs': 39, 'dropout_rate': 0.3077381696792512, 'class_weight_0': 0.7269681874718936, 'class_weight_1': 0.8177215733142787, 'C': 10.958334656229392, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 1 with value: 0.7551088873552642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:09:21,315] Trial 3 finished with value: 0.6557395905221993 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 17, 'lr': 0.003897122332942949, 'epochs': 12, 'dropout_rate': 0.11554904986257264, 'class_weight_0': 0.4745583097434043, 'class_weight_1': 0.5705368454178784, 'C': 13.70347229695473, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.7551088873552642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:09:34,293] Trial 4 finished with value: 0.6868530020703932 and parameters: {'num_layers': 2, 'latent_dim_0': 30, 'latent_dim_1': 18, 'lr': 0.003671313286757788, 'epochs': 36, 'dropout_rate': 0.12951178418654827, 'class_weight_0': 0.294853750110983, 'class_weight_1': 0.8549266841997983, 'C': 0.16524782604101407, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.7551088873552642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:09:46,833] Trial 5 finished with value: 0.6925274135419062 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 17, 'lr': 0.0004921166552449907, 'epochs': 22, 'dropout_rate': 0.30883441325829875, 'class_weight_0': 0.23027324853594708, 'class_weight_1': 0.17168763171015114, 'C': 39.85557225236743, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 1 with value: 0.7551088873552642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:09:55,856] Trial 6 finished with value: 0.7245322444597807 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 16, 'lr': 0.0004056541336390304, 'epochs': 13, 'dropout_rate': 0.27383026639206115, 'class_weight_0': 0.12501907521139588, 'class_weight_1': 0.19463534081465658, 'C': 2.4104413374362723, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.7551088873552642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:10:07,022] Trial 7 finished with value: 0.6723410781381797 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 17, 'lr': 0.0008453181048451152, 'epochs': 28, 'dropout_rate': 0.4674111758725339, 'class_weight_0': 0.40258845102362406, 'class_weight_1': 0.3523338678120942, 'C': 0.8868773371268405, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.7551088873552642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:10:22,383] Trial 8 finished with value: 0.690303657694962 and parameters: {'num_layers': 2, 'latent_dim_0': 36, 'latent_dim_1': 20, 'lr': 0.006975442208705431, 'epochs': 48, 'dropout_rate': 0.45662068921413257, 'class_weight_0': 0.34189277927283834, 'class_weight_1': 0.257439546460301, 'C': 0.19204631549364365, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.7551088873552642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:10:31,917] Trial 9 finished with value: 0.6010275285637604 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 11, 'lr': 0.006415113028897973, 'epochs': 28, 'dropout_rate': 0.39980607702228255, 'class_weight_0': 0.6090680601122488, 'class_weight_1': 0.708716843772293, 'C': 4.670189220745731, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.7551088873552642.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:10:49,111] Trial 10 finished with value: 0.7673107890499195 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 13, 'lr': 0.00010465249747862122, 'epochs': 46, 'dropout_rate': 0.19691371368140553, 'class_weight_0': 0.11852252273510072, 'class_weight_1': 0.4715435531385003, 'C': 0.9149709936695425, 'kernel': 'linear'}. Best is trial 10 with value: 0.7673107890499195.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:11:07,335] Trial 11 finished with value: 0.7657388237098383 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 13, 'lr': 0.00010693988709403659, 'epochs': 50, 'dropout_rate': 0.19921840940941682, 'class_weight_0': 0.1054447902252708, 'class_weight_1': 0.4531148777329373, 'C': 0.8250741198334688, 'kernel': 'linear'}. Best is trial 10 with value: 0.7673107890499195.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:11:29,615] Trial 12 finished with value: 0.7719883444521126 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 14, 'lr': 0.00011015263238746214, 'epochs': 50, 'dropout_rate': 0.21373740679971445, 'class_weight_0': 0.21344865876188163, 'class_weight_1': 0.4684165148658138, 'C': 1.8715252201263217, 'kernel': 'linear'}. Best is trial 12 with value: 0.7719883444521126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:11:53,900] Trial 13 finished with value: 0.7538053063415383 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 14, 'lr': 0.00010798938482416709, 'epochs': 44, 'dropout_rate': 0.21552884083722784, 'class_weight_0': 0.8935442197471879, 'class_weight_1': 0.5716234951960448, 'C': 2.6280794075112395, 'kernel': 'linear'}. Best is trial 12 with value: 0.7719883444521126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:12:14,302] Trial 14 finished with value: 0.7544475116938886 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 14, 'lr': 0.00018464438923749402, 'epochs': 44, 'dropout_rate': 0.20123576262825515, 'class_weight_0': 0.2271834338534644, 'class_weight_1': 0.41857426683049065, 'C': 1.8465649666611181, 'kernel': 'linear'}. Best is trial 12 with value: 0.7719883444521126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:12:27,629] Trial 15 finished with value: 0.6242427727934974 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 10, 'lr': 0.00016792789177798667, 'epochs': 43, 'dropout_rate': 0.26960824812832196, 'class_weight_0': 0.23586684404291536, 'class_weight_1': 0.5574902462121494, 'C': 9.090340954985367, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 12 with value: 0.7719883444521126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:16:35,358] Trial 16 finished with value: 0.7462138639674872 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 12, 'lr': 0.00021389156646971474, 'epochs': 50, 'dropout_rate': 0.36426928078418075, 'class_weight_0': 0.6136806828122398, 'class_weight_1': 0.6595402668783646, 'C': 61.16124956592334, 'kernel': 'linear'}. Best is trial 12 with value: 0.7719883444521126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:16:48,790] Trial 17 finished with value: 0.7106241852618664 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 15, 'lr': 0.0012487147154437305, 'epochs': 40, 'dropout_rate': 0.16885582254377446, 'class_weight_0': 0.18804063943212562, 'class_weight_1': 0.47763091443567796, 'C': 0.40623361384230566, 'kernel': 'linear'}. Best is trial 12 with value: 0.7719883444521126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:16:58,927] Trial 18 finished with value: 0.7666973391611073 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 15, 'lr': 0.00026479449525636863, 'epochs': 32, 'dropout_rate': 0.24327533018641403, 'class_weight_0': 0.3415375449915874, 'class_weight_1': 0.385662528239557, 'C': 0.10691869848195294, 'kernel': 'linear'}. Best is trial 12 with value: 0.7719883444521126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:17:06,337] Trial 19 finished with value: 0.6753124760371136 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 13, 'lr': 0.0007261349170882724, 'epochs': 22, 'dropout_rate': 0.1693462310619583, 'class_weight_0': 0.41693697300322574, 'class_weight_1': 0.6633711016936925, 'C': 5.534526343596685, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 12 with value: 0.7719883444521126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7749\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7053\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7007\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7349\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7087\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7216\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7258\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7571\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7536\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7672\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7493\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7330\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7190\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7193\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7355\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7131\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6803\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6949\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6566\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6563\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6670\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7178\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7511\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7046\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7148\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7334\n",
      "среднее 0.7168301673539023\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:19:37,871] A new study created in memory with name: no-name-4bc03b76-221c-4b48-a321-1cfea0df1778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:19:52,398] Trial 0 finished with value: 0.7548309178743962 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 20, 'lr_ae': 0.0002895712921479693, 'epochs_ae': 36, 'dropout_rate_ae': 0.14616552266634267, 'class_weight_0': 0.3121484661096837, 'class_weight_1': 0.789946859094628, 'hidden_dim_combined': 128, 'lr_combined': 0.00030239100531223, 'epochs_freeze': 8, 'epochs_unfreeze': 7, 'dropout_rate_combined': 0.2529728456312813}. Best is trial 0 with value: 0.7548309178743962.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:20:02,295] Trial 1 finished with value: 0.7491565064028833 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 14, 'lr_ae': 0.00012708116071309734, 'epochs_ae': 15, 'dropout_rate_ae': 0.12967136815027627, 'class_weight_0': 0.4706799739555979, 'class_weight_1': 0.5239939210464795, 'hidden_dim_combined': 41, 'lr_combined': 0.004274033537436669, 'epochs_freeze': 6, 'epochs_unfreeze': 15, 'dropout_rate_combined': 0.47066506610210235}. Best is trial 0 with value: 0.7548309178743962.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:20:24,860] Trial 2 finished with value: 0.7462617897400506 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 17, 'lr_ae': 0.00016918389321528746, 'epochs_ae': 48, 'dropout_rate_ae': 0.35513504196333445, 'class_weight_0': 0.43541690427515967, 'class_weight_1': 0.8279840899569582, 'hidden_dim_combined': 38, 'lr_combined': 0.0022003153969559603, 'epochs_freeze': 20, 'epochs_unfreeze': 10, 'dropout_rate_combined': 0.25725362660544043}. Best is trial 0 with value: 0.7548309178743962.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:20:39,961] Trial 3 finished with value: 0.7259220918641209 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 17, 'lr_ae': 0.005731299596043752, 'epochs_ae': 19, 'dropout_rate_ae': 0.3158750100363962, 'class_weight_0': 0.22457374296604274, 'class_weight_1': 0.7957834078830647, 'hidden_dim_combined': 58, 'lr_combined': 0.0028065793042369395, 'epochs_freeze': 16, 'epochs_unfreeze': 19, 'dropout_rate_combined': 0.40597210456379984}. Best is trial 0 with value: 0.7548309178743962.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:20:51,477] Trial 4 finished with value: 0.7607928839812897 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 18, 'lr_ae': 0.00014817872069015843, 'epochs_ae': 28, 'dropout_rate_ae': 0.17514206838934177, 'class_weight_0': 0.7387828622451079, 'class_weight_1': 0.12162808694126773, 'hidden_dim_combined': 84, 'lr_combined': 0.0008543176992022861, 'epochs_freeze': 6, 'epochs_unfreeze': 5, 'dropout_rate_combined': 0.41368738253208404}. Best is trial 4 with value: 0.7607928839812897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:21:06,014] Trial 5 finished with value: 0.751955371520589 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 16, 'lr_ae': 0.00010037643004539266, 'epochs_ae': 18, 'dropout_rate_ae': 0.4052128888291441, 'class_weight_0': 0.7574424804077767, 'class_weight_1': 0.854585638610175, 'hidden_dim_combined': 105, 'lr_combined': 0.0004553190231544377, 'epochs_freeze': 14, 'epochs_unfreeze': 19, 'dropout_rate_combined': 0.27318684085831757}. Best is trial 4 with value: 0.7607928839812897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:21:23,354] Trial 6 finished with value: 0.758089870408711 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 14, 'lr_ae': 0.0002924137324554067, 'epochs_ae': 42, 'dropout_rate_ae': 0.3337230929935455, 'class_weight_0': 0.5303029194177169, 'class_weight_1': 0.13671925942233207, 'hidden_dim_combined': 78, 'lr_combined': 0.0003518592408206467, 'epochs_freeze': 9, 'epochs_unfreeze': 7, 'dropout_rate_combined': 0.28866920036163213}. Best is trial 4 with value: 0.7607928839812897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:21:32,597] Trial 7 finished with value: 0.7295261099608926 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 18, 'lr_ae': 0.008191931299942754, 'epochs_ae': 11, 'dropout_rate_ae': 0.4798182703251658, 'class_weight_0': 0.5905727123593034, 'class_weight_1': 0.5852069973503127, 'hidden_dim_combined': 128, 'lr_combined': 0.0015410240560568714, 'epochs_freeze': 11, 'epochs_unfreeze': 11, 'dropout_rate_combined': 0.2671368060086604}. Best is trial 4 with value: 0.7607928839812897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:21:55,665] Trial 8 finished with value: 0.7619239322137873 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 15, 'lr_ae': 0.0004216871638003031, 'epochs_ae': 45, 'dropout_rate_ae': 0.2501755131476606, 'class_weight_0': 0.11575997658767437, 'class_weight_1': 0.46318551765505567, 'hidden_dim_combined': 37, 'lr_combined': 0.0008378965963542949, 'epochs_freeze': 19, 'epochs_unfreeze': 18, 'dropout_rate_combined': 0.45695317707870997}. Best is trial 8 with value: 0.7619239322137873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:22:11,968] Trial 9 finished with value: 0.7563645425964266 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 10, 'lr_ae': 0.00018707260175200352, 'epochs_ae': 32, 'dropout_rate_ae': 0.26681535592480016, 'class_weight_0': 0.1841339794793073, 'class_weight_1': 0.3010539091053842, 'hidden_dim_combined': 104, 'lr_combined': 0.0013106994250241526, 'epochs_freeze': 18, 'epochs_unfreeze': 8, 'dropout_rate_combined': 0.49610173852084694}. Best is trial 8 with value: 0.7619239322137873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:22:36,898] Trial 10 finished with value: 0.6759834368530021 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 11, 'lr_ae': 0.000986896106449883, 'epochs_ae': 49, 'dropout_rate_ae': 0.2078748612870821, 'class_weight_0': 0.8716533496282914, 'class_weight_1': 0.3642330462131652, 'hidden_dim_combined': 58, 'lr_combined': 0.00014165746737234393, 'epochs_freeze': 20, 'epochs_unfreeze': 15, 'dropout_rate_combined': 0.1157041064201623}. Best is trial 8 with value: 0.7619239322137873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:22:47,363] Trial 11 finished with value: 0.7260946246453491 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 20, 'lr_ae': 0.0006614866097525581, 'epochs_ae': 25, 'dropout_rate_ae': 0.21365570088874775, 'class_weight_0': 0.6834614490792981, 'class_weight_1': 0.11964460556939507, 'hidden_dim_combined': 84, 'lr_combined': 0.008993282848873003, 'epochs_freeze': 5, 'epochs_unfreeze': 5, 'dropout_rate_combined': 0.38260869225975197}. Best is trial 8 with value: 0.7619239322137873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:23:03,277] Trial 12 finished with value: 0.6874664519592056 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 13, 'lr_ae': 0.0028394202649646774, 'epochs_ae': 28, 'dropout_rate_ae': 0.22214480239643433, 'class_weight_0': 0.894737648500216, 'class_weight_1': 0.33303218149489566, 'hidden_dim_combined': 70, 'lr_combined': 0.0006665274366256418, 'epochs_freeze': 13, 'epochs_unfreeze': 14, 'dropout_rate_combined': 0.38964126577010055}. Best is trial 8 with value: 0.7619239322137873.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:23:24,866] Trial 13 finished with value: 0.7642627099148838 and parameters: {'num_layers': 2, 'latent_dim_0': 25, 'latent_dim_1': 18, 'lr_ae': 0.0005737844445985056, 'epochs_ae': 38, 'dropout_rate_ae': 0.18065602423191174, 'class_weight_0': 0.10714573881546571, 'class_weight_1': 0.6569377385012796, 'hidden_dim_combined': 91, 'lr_combined': 0.0008349467331344482, 'epochs_freeze': 16, 'epochs_unfreeze': 20, 'dropout_rate_combined': 0.4373276828892864}. Best is trial 13 with value: 0.7642627099148838.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:23:46,848] Trial 14 finished with value: 0.7435587761674718 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 15, 'lr_ae': 0.0006470159745539028, 'epochs_ae': 40, 'dropout_rate_ae': 0.2701357595722035, 'class_weight_0': 0.10914531086366164, 'class_weight_1': 0.6299615007539775, 'hidden_dim_combined': 99, 'lr_combined': 0.00016992669600377283, 'epochs_freeze': 16, 'epochs_unfreeze': 20, 'dropout_rate_combined': 0.4432847728549966}. Best is trial 13 with value: 0.7642627099148838.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:24:08,991] Trial 15 finished with value: 0.7146499501571966 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 12, 'lr_ae': 0.0023301346441741066, 'epochs_ae': 42, 'dropout_rate_ae': 0.10487875783972304, 'class_weight_0': 0.3090732353351171, 'class_weight_1': 0.6982938566737507, 'hidden_dim_combined': 52, 'lr_combined': 0.0006267674433868152, 'epochs_freeze': 17, 'epochs_unfreeze': 17, 'dropout_rate_combined': 0.33624766404405404}. Best is trial 13 with value: 0.7642627099148838.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:24:30,143] Trial 16 finished with value: 0.7342420059811364 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 19, 'lr_ae': 0.0004207342660294486, 'epochs_ae': 36, 'dropout_rate_ae': 0.2622193364248065, 'class_weight_0': 0.10036976067727243, 'class_weight_1': 0.42889987580050004, 'hidden_dim_combined': 95, 'lr_combined': 0.0010876169222884997, 'epochs_freeze': 18, 'epochs_unfreeze': 17, 'dropout_rate_combined': 0.3437075733469665}. Best is trial 13 with value: 0.7642627099148838.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:24:53,327] Trial 17 finished with value: 0.690207806149835 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 16, 'lr_ae': 0.0016824365947799617, 'epochs_ae': 46, 'dropout_rate_ae': 0.17409051491512167, 'class_weight_0': 0.348232664217474, 'class_weight_1': 0.4752603963801403, 'hidden_dim_combined': 115, 'lr_combined': 0.00027645125710350416, 'epochs_freeze': 15, 'epochs_unfreeze': 17, 'dropout_rate_combined': 0.18476128148137383}. Best is trial 13 with value: 0.7642627099148838.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:25:12,318] Trial 18 finished with value: 0.7426002607162028 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 15, 'lr_ae': 0.0012940547373170557, 'epochs_ae': 36, 'dropout_rate_ae': 0.40717819578098835, 'class_weight_0': 0.2134063583920529, 'class_weight_1': 0.6653445974382471, 'hidden_dim_combined': 32, 'lr_combined': 0.0037753082847481133, 'epochs_freeze': 11, 'epochs_unfreeze': 20, 'dropout_rate_combined': 0.4495725156588932}. Best is trial 13 with value: 0.7642627099148838.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:25:36,780] Trial 19 finished with value: 0.7272256728778467 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 18, 'lr_ae': 0.0005632981268866106, 'epochs_ae': 45, 'dropout_rate_ae': 0.22530186209830122, 'class_weight_0': 0.3841861300017362, 'class_weight_1': 0.24449377297465869, 'hidden_dim_combined': 70, 'lr_combined': 0.001754463750821921, 'epochs_freeze': 19, 'epochs_unfreeze': 18, 'dropout_rate_combined': 0.35157854982256975}. Best is trial 13 with value: 0.7642627099148838.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.7548\n"
     ]
    }
   ],
   "source": [
    "class CombinedClassifier(nn.Module):\n",
    "    def __init__(self, stacked_autoencoder, pgs_input_dim, hidden_dim=64, dropout_rate=0.2):\n",
    "        super(CombinedClassifier, self).__init__()\n",
    "        self.stacked_autoencoder = stacked_autoencoder\n",
    "        self.pgs_branch = nn.Sequential(\n",
    "            nn.Linear(pgs_input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.combined_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim // 2 + stacked_autoencoder.autoencoders[-1].encoder[0].out_features, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_snp, x_pgs):\n",
    "        latent = x_snp\n",
    "        for ae in self.stacked_autoencoder.autoencoders:\n",
    "            _, latent, _ = ae(latent)\n",
    "        \n",
    "        pgs_features = self.pgs_branch(x_pgs)\n",
    "        combined = torch.cat([latent, pgs_features], dim=1)\n",
    "        output = self.combined_classifier(combined)\n",
    "        return output\n",
    "\n",
    "def train_combined_classifier(model, X_train_snp, X_train_pgs, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_snp_tensor = torch.FloatTensor(X_train_snp).to(device)\n",
    "    X_train_pgs_tensor = torch.FloatTensor(X_train_pgs).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_snp_tensor, X_train_pgs_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    for param in model.stacked_autoencoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs_freeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    for param in model.stacked_autoencoder.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr/10)\n",
    "    \n",
    "    for epoch in range(epochs_unfreeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_combined(model, X_snp, X_pgs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_snp_tensor = torch.FloatTensor(X_snp).to(device)\n",
    "    X_pgs_tensor = torch.FloatTensor(X_pgs).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_snp_tensor, X_pgs_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    hidden_dim_combined = trial.suggest_int('hidden_dim_combined', 32, 128)\n",
    "    lr_combined = trial.suggest_float('lr_combined', 1e-4, 1e-2, log=True)\n",
    "    epochs_freeze = trial.suggest_int('epochs_freeze', 5, 20)\n",
    "    epochs_unfreeze = trial.suggest_int('epochs_unfreeze', 5, 20)\n",
    "    dropout_rate_combined = trial.suggest_float('dropout_rate_combined', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate_ae)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs_ae, batch_size, lr_ae, classification_weights)\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, X_pgs_train.shape[1], hidden_dim_combined, dropout_rate_combined)\n",
    "        combined_model = train_combined_classifier(combined_model, X_train, X_pgs_train, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr_combined)\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, X_pgs_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate_ae'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs_ae'], 32, best_params['lr_ae'], classification_weights)\n",
    "\n",
    "combined_model = CombinedClassifier(autoencoder, X_train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "combined_model = train_combined_classifier(\n",
    "    combined_model, X_train_all, X_train_pgs, y_all_train, \n",
    "    best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    ")\n",
    "\n",
    "y_pred_proba = predict_combined(combined_model, X_val_all, X_val_pgs)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7010\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6828\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7120\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6922\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6917\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7689\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7620\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7458\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7525\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7438\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7103\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7051\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7397\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7163\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7069\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6634\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6565\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6888\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6898\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6812\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7476\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7395\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7687\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7422\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.7426\n",
      "среднее 0.7180390342555977\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs_ae'], 32, best_params['lr_ae'], classification_weights)\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "        combined_model = train_combined_classifier(\n",
    "            combined_model, X_train, train_pgs, y_train, \n",
    "            best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, test_pgs)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше идет блок с denoising автоэнкодером"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:28:11,144] A new study created in memory with name: no-name-bc931d90-146e-4c64-be81-133ca9d49633\n",
      "[I 2025-05-11 01:28:24,018] Trial 0 finished with value: 0.755923625488843 and parameters: {'latent_dim': 53, 'hidden_dim': 85, 'lr': 0.004380643411001898, 'epochs': 45, 'dropout_rate': 0.16260611864571684, 'noise_level': 0.27437748050642763, 'C': 0.39478393315988086, 'solver': 'saga'}. Best is trial 0 with value: 0.755923625488843.\n",
      "[I 2025-05-11 01:28:35,432] Trial 1 finished with value: 0.774978912660072 and parameters: {'latent_dim': 36, 'hidden_dim': 100, 'lr': 0.0013484225419722706, 'epochs': 43, 'dropout_rate': 0.2931141660243142, 'noise_level': 0.16623064656686903, 'C': 0.03974222378246643, 'solver': 'liblinear'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:28:48,054] Trial 2 finished with value: 0.7518020090483858 and parameters: {'latent_dim': 74, 'hidden_dim': 238, 'lr': 0.0008057519346256342, 'epochs': 39, 'dropout_rate': 0.30498190183495355, 'noise_level': 0.22405193406756801, 'C': 9.520068702085924, 'solver': 'liblinear'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:28:51,499] Trial 3 finished with value: 0.7522237558469443 and parameters: {'latent_dim': 49, 'hidden_dim': 94, 'lr': 0.00876036188501682, 'epochs': 12, 'dropout_rate': 0.1412906510638537, 'noise_level': 0.2981888143495987, 'C': 1.1847240704801631, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:29:00,866] Trial 4 finished with value: 0.764876159803696 and parameters: {'latent_dim': 100, 'hidden_dim': 127, 'lr': 0.004246406352657116, 'epochs': 28, 'dropout_rate': 0.16675059063260506, 'noise_level': 0.05001196279091237, 'C': 0.06595848109376592, 'solver': 'saga'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:29:14,508] Trial 5 finished with value: 0.7710298290008435 and parameters: {'latent_dim': 98, 'hidden_dim': 150, 'lr': 0.0004885354904445756, 'epochs': 47, 'dropout_rate': 0.27400408910600654, 'noise_level': 0.29354518708168986, 'C': 0.028949822350113945, 'solver': 'liblinear'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:29:25,376] Trial 6 finished with value: 0.7591250670960816 and parameters: {'latent_dim': 19, 'hidden_dim': 243, 'lr': 0.008116213550878729, 'epochs': 30, 'dropout_rate': 0.3614019211521413, 'noise_level': 0.24922019456875694, 'C': 0.2699826642327883, 'solver': 'saga'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:29:33,320] Trial 7 finished with value: 0.7568054597040104 and parameters: {'latent_dim': 58, 'hidden_dim': 107, 'lr': 0.0022747953130421786, 'epochs': 23, 'dropout_rate': 0.3127302763827373, 'noise_level': 0.28551588092194935, 'C': 0.3053288113919987, 'solver': 'saga'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:29:47,189] Trial 8 finished with value: 0.7724292615596964 and parameters: {'latent_dim': 47, 'hidden_dim': 139, 'lr': 0.00023199090605515834, 'epochs': 46, 'dropout_rate': 0.2925378480733243, 'noise_level': 0.18019264959567122, 'C': 0.03973151931751756, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:29:55,683] Trial 9 finished with value: 0.7519937121386397 and parameters: {'latent_dim': 34, 'hidden_dim': 102, 'lr': 0.0005387610259256962, 'epochs': 31, 'dropout_rate': 0.20307648827213087, 'noise_level': 0.17609048334901883, 'C': 0.8968074584879994, 'solver': 'liblinear'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:30:07,142] Trial 10 finished with value: 0.7554827083812592 and parameters: {'latent_dim': 12, 'hidden_dim': 190, 'lr': 0.0001459309656506687, 'epochs': 38, 'dropout_rate': 0.4947263919334961, 'noise_level': 0.10107443970550775, 'C': 91.07352619164693, 'solver': 'liblinear'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:30:22,090] Trial 11 finished with value: 0.7694578636607622 and parameters: {'latent_dim': 33, 'hidden_dim': 178, 'lr': 0.00011518224639324941, 'epochs': 50, 'dropout_rate': 0.39943163780940544, 'noise_level': 0.17681288843189796, 'C': 0.01154842703254459, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:30:33,336] Trial 12 finished with value: 0.7726784755770263 and parameters: {'latent_dim': 36, 'hidden_dim': 142, 'lr': 0.00022633439331493048, 'epochs': 40, 'dropout_rate': 0.23703434833312317, 'noise_level': 0.12864349381004822, 'C': 0.06953649366817066, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:30:43,564] Trial 13 finished with value: 0.7664097845257265 and parameters: {'latent_dim': 29, 'hidden_dim': 65, 'lr': 0.0015685328843274085, 'epochs': 39, 'dropout_rate': 0.2232433890639582, 'noise_level': 0.10239009121332257, 'C': 0.10315705238924182, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:30:54,477] Trial 14 finished with value: 0.7744038033893106 and parameters: {'latent_dim': 73, 'hidden_dim': 184, 'lr': 0.00030831245953426626, 'epochs': 36, 'dropout_rate': 0.37936026645531695, 'noise_level': 0.12864197127565696, 'C': 0.015235181766440778, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.774978912660072.\n",
      "[I 2025-05-11 01:31:05,721] Trial 15 finished with value: 0.7757265547120619 and parameters: {'latent_dim': 73, 'hidden_dim': 207, 'lr': 0.0012421380916314954, 'epochs': 34, 'dropout_rate': 0.43492132261409566, 'noise_level': 0.14039793147693214, 'C': 0.01424771348080498, 'solver': 'liblinear'}. Best is trial 15 with value: 0.7757265547120619.\n",
      "[I 2025-05-11 01:31:13,232] Trial 16 finished with value: 0.7290276819262326 and parameters: {'latent_dim': 75, 'hidden_dim': 214, 'lr': 0.0012599496405362681, 'epochs': 22, 'dropout_rate': 0.4647107212817006, 'noise_level': 0.22186493711858418, 'C': 4.259713768820416, 'solver': 'liblinear'}. Best is trial 15 with value: 0.7757265547120619.\n",
      "[I 2025-05-11 01:31:24,259] Trial 17 finished with value: 0.7746146767885899 and parameters: {'latent_dim': 64, 'hidden_dim': 210, 'lr': 0.0026475670272181895, 'epochs': 34, 'dropout_rate': 0.45061011142309537, 'noise_level': 0.13939467826719965, 'C': 0.010590427786332556, 'solver': 'liblinear'}. Best is trial 15 with value: 0.7757265547120619.\n",
      "[I 2025-05-11 01:31:38,673] Trial 18 finished with value: 0.7612913120159496 and parameters: {'latent_dim': 90, 'hidden_dim': 219, 'lr': 0.0008767069214140589, 'epochs': 43, 'dropout_rate': 0.41881856795380656, 'noise_level': 0.2021482316593072, 'C': 0.12859455235115663, 'solver': 'liblinear'}. Best is trial 15 with value: 0.7757265547120619.\n",
      "[I 2025-05-11 01:31:46,708] Trial 19 finished with value: 0.7741929299900314 and parameters: {'latent_dim': 86, 'hidden_dim': 167, 'lr': 0.0019648313529781023, 'epochs': 25, 'dropout_rate': 0.33763592857767055, 'noise_level': 0.1512258986837238, 'C': 0.028998618344396696, 'solver': 'liblinear'}. Best is trial 15 with value: 0.7757265547120619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7796\n"
     ]
    }
   ],
   "source": [
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "    \n",
    "def train_denoising_autoencoder(model, X_train, epochs, batch_size, lr, noise_level=0.1):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_target in train_loader:\n",
    "            # Add noise to input data\n",
    "            noisy_batch = batch_x + noise_level * torch.randn_like(batch_x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _ = model(noisy_batch)\n",
    "            # Target is the original data (not noisy)\n",
    "            loss = criterion(reconstructed, batch_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs, batch_size, lr, noise_level)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7585\n",
      "ROC-AUC autoencoded: 0.7465\n",
      "ROC-AUC autoencoded: 0.7550\n",
      "ROC-AUC autoencoded: 0.7459\n",
      "ROC-AUC autoencoded: 0.7570\n",
      "ROC-AUC autoencoded: 0.7683\n",
      "ROC-AUC autoencoded: 0.7795\n",
      "ROC-AUC autoencoded: 0.7716\n",
      "ROC-AUC autoencoded: 0.7657\n",
      "ROC-AUC autoencoded: 0.7808\n",
      "ROC-AUC autoencoded: 0.7456\n",
      "ROC-AUC autoencoded: 0.7379\n",
      "ROC-AUC autoencoded: 0.7492\n",
      "ROC-AUC autoencoded: 0.7397\n",
      "ROC-AUC autoencoded: 0.7366\n",
      "ROC-AUC autoencoded: 0.6979\n",
      "ROC-AUC autoencoded: 0.7029\n",
      "ROC-AUC autoencoded: 0.7052\n",
      "ROC-AUC autoencoded: 0.7059\n",
      "ROC-AUC autoencoded: 0.7026\n",
      "ROC-AUC autoencoded: 0.7606\n",
      "ROC-AUC autoencoded: 0.7662\n",
      "ROC-AUC autoencoded: 0.7575\n",
      "ROC-AUC autoencoded: 0.7540\n",
      "ROC-AUC autoencoded: 0.7617\n",
      "среднее 0.7460874333307989\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:33:05,489] A new study created in memory with name: no-name-9d15a218-343d-4360-9aff-606d6f19075c\n",
      "[I 2025-05-11 01:33:23,141] Trial 0 finished with value: 0.7319607392071159 and parameters: {'latent_dim': 61, 'hidden_dim': 218, 'lr': 0.0010273136071119065, 'epochs': 22, 'dropout_rate': 0.46996071840092857, 'noise_level': 0.09998413935755333, 'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.017636274070675844, 'subsample': 0.9199193685037758, 'min_samples_split': 10, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7319607392071159.\n",
      "[I 2025-05-11 01:34:51,313] Trial 1 finished with value: 0.7217621348056132 and parameters: {'latent_dim': 31, 'hidden_dim': 179, 'lr': 0.0005255648473278012, 'epochs': 15, 'dropout_rate': 0.33065627306810846, 'noise_level': 0.23836730798653627, 'n_estimators': 482, 'max_depth': 8, 'learning_rate': 0.038385832100862896, 'subsample': 0.6530459092309695, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7319607392071159.\n",
      "[I 2025-05-11 01:36:02,688] Trial 2 finished with value: 0.7170078981673185 and parameters: {'latent_dim': 88, 'hidden_dim': 167, 'lr': 0.0001216868897054471, 'epochs': 20, 'dropout_rate': 0.2255987557660446, 'noise_level': 0.06575704194231706, 'n_estimators': 318, 'max_depth': 6, 'learning_rate': 0.21132911905891913, 'subsample': 0.6565196454870768, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.7319607392071159.\n",
      "[I 2025-05-11 01:37:41,319] Trial 3 finished with value: 0.7312706080822022 and parameters: {'latent_dim': 62, 'hidden_dim': 107, 'lr': 0.0007944822551311854, 'epochs': 25, 'dropout_rate': 0.2519553550321406, 'noise_level': 0.2974746948343821, 'n_estimators': 465, 'max_depth': 6, 'learning_rate': 0.013595697249683876, 'subsample': 0.7298858347407321, 'min_samples_split': 20, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.7319607392071159.\n",
      "[I 2025-05-11 01:38:11,147] Trial 4 finished with value: 0.7307146691204661 and parameters: {'latent_dim': 24, 'hidden_dim': 168, 'lr': 0.00020103645625019402, 'epochs': 30, 'dropout_rate': 0.47707278248984886, 'noise_level': 0.1948807441837147, 'n_estimators': 119, 'max_depth': 9, 'learning_rate': 0.015349117110939848, 'subsample': 0.732966112553721, 'min_samples_split': 14, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.7319607392071159.\n",
      "[I 2025-05-11 01:38:43,219] Trial 5 finished with value: 0.737884364695959 and parameters: {'latent_dim': 56, 'hidden_dim': 182, 'lr': 0.001115824266262065, 'epochs': 26, 'dropout_rate': 0.18358727050714535, 'noise_level': 0.09612016625330506, 'n_estimators': 118, 'max_depth': 10, 'learning_rate': 0.011045720980255986, 'subsample': 0.6559315971982678, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 5 with value: 0.737884364695959.\n",
      "[I 2025-05-11 01:40:08,776] Trial 6 finished with value: 0.711410167931907 and parameters: {'latent_dim': 59, 'hidden_dim': 70, 'lr': 0.004360218526553995, 'epochs': 36, 'dropout_rate': 0.22303139465898625, 'noise_level': 0.05834707559318779, 'n_estimators': 287, 'max_depth': 7, 'learning_rate': 0.02655877797388785, 'subsample': 0.8755196934068794, 'min_samples_split': 14, 'min_samples_leaf': 7}. Best is trial 5 with value: 0.737884364695959.\n",
      "[I 2025-05-11 01:40:41,122] Trial 7 finished with value: 0.7340503028908826 and parameters: {'latent_dim': 10, 'hidden_dim': 141, 'lr': 0.001045881953677086, 'epochs': 27, 'dropout_rate': 0.42847316172108496, 'noise_level': 0.22245777265914984, 'n_estimators': 185, 'max_depth': 7, 'learning_rate': 0.04206699577300127, 'subsample': 0.7663561182136218, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 5 with value: 0.737884364695959.\n",
      "[I 2025-05-11 01:41:20,400] Trial 8 finished with value: 0.7026493367073078 and parameters: {'latent_dim': 42, 'hidden_dim': 136, 'lr': 0.001311308066840434, 'epochs': 31, 'dropout_rate': 0.16407146792162675, 'noise_level': 0.25490697066082446, 'n_estimators': 217, 'max_depth': 5, 'learning_rate': 0.10480500137895427, 'subsample': 0.7479500303226494, 'min_samples_split': 18, 'min_samples_leaf': 9}. Best is trial 5 with value: 0.737884364695959.\n",
      "[I 2025-05-11 01:42:12,607] Trial 9 finished with value: 0.7266697339161107 and parameters: {'latent_dim': 58, 'hidden_dim': 133, 'lr': 0.007854542346689275, 'epochs': 50, 'dropout_rate': 0.15287762284725204, 'noise_level': 0.19604276704456874, 'n_estimators': 144, 'max_depth': 10, 'learning_rate': 0.04493697180350359, 'subsample': 0.7151945473270036, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 5 with value: 0.737884364695959.\n",
      "[I 2025-05-11 01:44:23,014] Trial 10 finished with value: 0.7253469825933595 and parameters: {'latent_dim': 90, 'hidden_dim': 250, 'lr': 0.0028734546559515592, 'epochs': 42, 'dropout_rate': 0.11454889794757611, 'noise_level': 0.14047818918538066, 'n_estimators': 382, 'max_depth': 10, 'learning_rate': 0.07928193645800474, 'subsample': 0.6048351175821393, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.737884364695959.\n",
      "[I 2025-05-11 01:44:40,890] Trial 11 finished with value: 0.748543056514071 and parameters: {'latent_dim': 10, 'hidden_dim': 202, 'lr': 0.0003747286354293067, 'epochs': 11, 'dropout_rate': 0.3838975934274107, 'noise_level': 0.14438791068882834, 'n_estimators': 187, 'max_depth': 3, 'learning_rate': 0.010098677574671278, 'subsample': 0.8245234433828901, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.748543056514071.\n",
      "[I 2025-05-11 01:44:50,707] Trial 12 finished with value: 0.7489935587761675 and parameters: {'latent_dim': 78, 'hidden_dim': 211, 'lr': 0.0003475701478377393, 'epochs': 10, 'dropout_rate': 0.351080987566404, 'noise_level': 0.13809609541695134, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.011392984233936096, 'subsample': 0.8320055400001033, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.7489935587761675.\n",
      "[I 2025-05-11 01:45:02,192] Trial 13 finished with value: 0.7499424890729238 and parameters: {'latent_dim': 96, 'hidden_dim': 217, 'lr': 0.0003314192194999804, 'epochs': 11, 'dropout_rate': 0.3452426382496171, 'noise_level': 0.14968925375490424, 'n_estimators': 52, 'max_depth': 3, 'learning_rate': 0.02388349209212987, 'subsample': 0.8570721790622832, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.7499424890729238.\n",
      "[I 2025-05-11 01:45:14,256] Trial 14 finished with value: 0.7463959819032283 and parameters: {'latent_dim': 77, 'hidden_dim': 254, 'lr': 0.00027742707068679795, 'epochs': 11, 'dropout_rate': 0.32671181753820455, 'noise_level': 0.14496738012283558, 'n_estimators': 54, 'max_depth': 3, 'learning_rate': 0.023907174698166354, 'subsample': 0.9836261064990696, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.7499424890729238.\n",
      "[I 2025-05-11 01:45:38,190] Trial 15 finished with value: 0.7510351966873706 and parameters: {'latent_dim': 100, 'hidden_dim': 230, 'lr': 0.00011073650951012275, 'epochs': 17, 'dropout_rate': 0.37494428612792696, 'noise_level': 0.11501369039733919, 'n_estimators': 90, 'max_depth': 4, 'learning_rate': 0.022825977104423884, 'subsample': 0.8557181783330317, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 15 with value: 0.7510351966873706.\n",
      "[I 2025-05-11 01:46:38,652] Trial 16 finished with value: 0.7480637987884364 and parameters: {'latent_dim': 99, 'hidden_dim': 231, 'lr': 0.00012883967174909665, 'epochs': 17, 'dropout_rate': 0.40348228396453223, 'noise_level': 0.11181636122919884, 'n_estimators': 249, 'max_depth': 4, 'learning_rate': 0.02561910171950555, 'subsample': 0.9121894078874928, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 15 with value: 0.7510351966873706.\n",
      "[I 2025-05-11 01:47:07,198] Trial 17 finished with value: 0.7207652787362933 and parameters: {'latent_dim': 100, 'hidden_dim': 230, 'lr': 0.0001051942796041934, 'epochs': 17, 'dropout_rate': 0.30552639273342863, 'noise_level': 0.169803609807878, 'n_estimators': 106, 'max_depth': 4, 'learning_rate': 0.06351003796982793, 'subsample': 0.871422051684055, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 15 with value: 0.7510351966873706.\n",
      "[I 2025-05-11 01:48:21,598] Trial 18 finished with value: 0.7291810443984357 and parameters: {'latent_dim': 74, 'hidden_dim': 196, 'lr': 0.00019020894145467575, 'epochs': 16, 'dropout_rate': 0.27795473921266245, 'noise_level': 0.17727816268541885, 'n_estimators': 336, 'max_depth': 4, 'learning_rate': 0.020210814121414667, 'subsample': 0.9979479025708621, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 15 with value: 0.7510351966873706.\n",
      "[I 2025-05-11 01:49:05,529] Trial 19 finished with value: 0.7401848017790047 and parameters: {'latent_dim': 88, 'hidden_dim': 233, 'lr': 0.00018896016721166626, 'epochs': 21, 'dropout_rate': 0.4049980562062757, 'noise_level': 0.08242106268016294, 'n_estimators': 171, 'max_depth': 5, 'learning_rate': 0.03249597383518576, 'subsample': 0.7899701174101978, 'min_samples_split': 12, 'min_samples_leaf': 2}. Best is trial 15 with value: 0.7510351966873706.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7471\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs, batch_size, lr, noise_level)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7401\n",
      "ROC-AUC autoencoded: 0.7344\n",
      "ROC-AUC autoencoded: 0.7396\n",
      "ROC-AUC autoencoded: 0.7348\n",
      "ROC-AUC autoencoded: 0.7268\n",
      "ROC-AUC autoencoded: 0.7286\n",
      "ROC-AUC autoencoded: 0.7372\n",
      "ROC-AUC autoencoded: 0.7391\n",
      "ROC-AUC autoencoded: 0.7406\n",
      "ROC-AUC autoencoded: 0.7234\n",
      "ROC-AUC autoencoded: 0.7301\n",
      "ROC-AUC autoencoded: 0.7309\n",
      "ROC-AUC autoencoded: 0.7453\n",
      "ROC-AUC autoencoded: 0.7327\n",
      "ROC-AUC autoencoded: 0.7307\n",
      "ROC-AUC autoencoded: 0.7394\n",
      "ROC-AUC autoencoded: 0.7343\n",
      "ROC-AUC autoencoded: 0.7272\n",
      "ROC-AUC autoencoded: 0.7097\n",
      "ROC-AUC autoencoded: 0.7419\n",
      "ROC-AUC autoencoded: 0.7550\n",
      "ROC-AUC autoencoded: 0.7334\n",
      "ROC-AUC autoencoded: 0.7423\n",
      "ROC-AUC autoencoded: 0.7800\n",
      "ROC-AUC autoencoded: 0.7580\n",
      "среднее 0.7374219450250097\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 01:51:53,751] A new study created in memory with name: no-name-e1705c5e-37db-4fa0-ac7d-5ba47062114e\n",
      "[I 2025-05-11 01:51:59,596] Trial 0 finished with value: 0.6706828464074842 and parameters: {'latent_dim': 88, 'hidden_dim': 156, 'lr': 0.006671444345683114, 'epochs': 18, 'dropout_rate': 0.12009061121472664, 'noise_level': 0.27502223925424213, 'C': 1.218781456763991, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 0 with value: 0.6706828464074842.\n",
      "[I 2025-05-11 01:52:08,941] Trial 1 finished with value: 0.7573326432022084 and parameters: {'latent_dim': 58, 'hidden_dim': 169, 'lr': 0.006584716060344973, 'epochs': 28, 'dropout_rate': 0.4825236613159103, 'noise_level': 0.28291183995202773, 'C': 0.23646249452041543, 'kernel': 'linear'}. Best is trial 1 with value: 0.7573326432022084.\n",
      "[I 2025-05-11 01:52:19,578] Trial 2 finished with value: 0.6113411548194158 and parameters: {'latent_dim': 95, 'hidden_dim': 130, 'lr': 0.009191694725775343, 'epochs': 34, 'dropout_rate': 0.219997310192975, 'noise_level': 0.19769546676624594, 'C': 16.47829979326873, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 1 with value: 0.7573326432022084.\n",
      "[I 2025-05-11 01:52:31,316] Trial 3 finished with value: 0.6733283490529867 and parameters: {'latent_dim': 95, 'hidden_dim': 190, 'lr': 0.0005720561025532553, 'epochs': 37, 'dropout_rate': 0.43902004022009633, 'noise_level': 0.0757941049152323, 'C': 1.156234789202612, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 1 with value: 0.7573326432022084.\n",
      "[I 2025-05-11 01:52:40,337] Trial 4 finished with value: 0.6833831761367993 and parameters: {'latent_dim': 57, 'hidden_dim': 158, 'lr': 0.0009743334754139172, 'epochs': 28, 'dropout_rate': 0.11305760902449663, 'noise_level': 0.18928824955175255, 'C': 0.16950372359709223, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 1 with value: 0.7573326432022084.\n",
      "[I 2025-05-11 01:52:54,334] Trial 5 finished with value: 0.7303887738670346 and parameters: {'latent_dim': 97, 'hidden_dim': 84, 'lr': 0.00019084027453393412, 'epochs': 47, 'dropout_rate': 0.3560000935342872, 'noise_level': 0.17005453881624638, 'C': 0.5217534384614159, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.7573326432022084.\n",
      "[I 2025-05-11 01:52:59,140] Trial 6 finished with value: 0.7246376811594203 and parameters: {'latent_dim': 68, 'hidden_dim': 85, 'lr': 0.0011643263757028883, 'epochs': 14, 'dropout_rate': 0.38278499229136653, 'noise_level': 0.19984769996684204, 'C': 0.15028853787082055, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.7573326432022084.\n",
      "[I 2025-05-11 01:53:08,727] Trial 7 finished with value: 0.6676922781995246 and parameters: {'latent_dim': 66, 'hidden_dim': 184, 'lr': 0.00098517654244257, 'epochs': 30, 'dropout_rate': 0.4323553121108695, 'noise_level': 0.13989278116342896, 'C': 2.7627502172250114, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 1 with value: 0.7573326432022084.\n",
      "[I 2025-05-11 01:53:21,704] Trial 8 finished with value: 0.7293535771796642 and parameters: {'latent_dim': 71, 'hidden_dim': 182, 'lr': 0.005908040685039251, 'epochs': 39, 'dropout_rate': 0.47023317677710963, 'noise_level': 0.0868409955249113, 'C': 0.2573774492180612, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.7573326432022084.\n",
      "[I 2025-05-11 01:53:28,954] Trial 9 finished with value: 0.7028218694885361 and parameters: {'latent_dim': 53, 'hidden_dim': 121, 'lr': 0.0006460898456479106, 'epochs': 22, 'dropout_rate': 0.11620373639534597, 'noise_level': 0.1307073316974463, 'C': 10.224595527845544, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 1 with value: 0.7573326432022084.\n",
      "[I 2025-05-11 02:00:26,962] Trial 10 finished with value: 0.7530960049075991 and parameters: {'latent_dim': 24, 'hidden_dim': 249, 'lr': 0.002734513105998638, 'epochs': 10, 'dropout_rate': 0.27345795871184253, 'noise_level': 0.29739876869877874, 'C': 76.474633589578, 'kernel': 'linear'}. Best is trial 1 with value: 0.7573326432022084.\n",
      "[I 2025-05-11 02:09:22,983] Trial 11 finished with value: 0.76332336477264 and parameters: {'latent_dim': 22, 'hidden_dim': 243, 'lr': 0.0029219725608744555, 'epochs': 10, 'dropout_rate': 0.27204688163866964, 'noise_level': 0.299969719502636, 'C': 93.9749387934142, 'kernel': 'linear'}. Best is trial 11 with value: 0.76332336477264.\n",
      "[I 2025-05-11 02:15:40,866] Trial 12 finished with value: 0.7615501111877924 and parameters: {'latent_dim': 11, 'hidden_dim': 254, 'lr': 0.0029757426689279026, 'epochs': 23, 'dropout_rate': 0.23368046928620392, 'noise_level': 0.24980103053255043, 'C': 87.74601663907369, 'kernel': 'linear'}. Best is trial 11 with value: 0.76332336477264.\n",
      "[I 2025-05-11 02:20:58,745] Trial 13 finished with value: 0.7638026224982747 and parameters: {'latent_dim': 10, 'hidden_dim': 254, 'lr': 0.0027256826897395017, 'epochs': 21, 'dropout_rate': 0.2107791114153921, 'noise_level': 0.24078999830043235, 'C': 82.18537961274309, 'kernel': 'linear'}. Best is trial 13 with value: 0.7638026224982747.\n",
      "[I 2025-05-11 02:23:58,788] Trial 14 finished with value: 0.7522045855379188 and parameters: {'latent_dim': 31, 'hidden_dim': 219, 'lr': 0.002628586648177482, 'epochs': 10, 'dropout_rate': 0.19467960172331492, 'noise_level': 0.23949071767714183, 'C': 27.101169131781063, 'kernel': 'linear'}. Best is trial 13 with value: 0.7638026224982747.\n",
      "[I 2025-05-11 02:26:35,103] Trial 15 finished with value: 0.7617418142780462 and parameters: {'latent_dim': 10, 'hidden_dim': 218, 'lr': 0.002138312008459259, 'epochs': 17, 'dropout_rate': 0.3164124900441948, 'noise_level': 0.23479378412872992, 'C': 36.782425207911466, 'kernel': 'linear'}. Best is trial 13 with value: 0.7638026224982747.\n",
      "[I 2025-05-11 02:27:21,631] Trial 16 finished with value: 0.7322195383789586 and parameters: {'latent_dim': 36, 'hidden_dim': 225, 'lr': 0.00016247668682337405, 'epochs': 19, 'dropout_rate': 0.16999898402512748, 'noise_level': 0.25965480015393755, 'C': 7.074644536237269, 'kernel': 'linear'}. Best is trial 13 with value: 0.7638026224982747.\n",
      "[I 2025-05-11 02:31:10,270] Trial 17 finished with value: 0.772505942795798 and parameters: {'latent_dim': 21, 'hidden_dim': 235, 'lr': 0.004174839112979606, 'epochs': 14, 'dropout_rate': 0.28062125308536284, 'noise_level': 0.226546691016648, 'C': 44.46165368174324, 'kernel': 'linear'}. Best is trial 17 with value: 0.772505942795798.\n",
      "[I 2025-05-11 02:35:54,345] Trial 18 finished with value: 0.7575818572195384 and parameters: {'latent_dim': 43, 'hidden_dim': 201, 'lr': 0.004470425812852407, 'epochs': 24, 'dropout_rate': 0.3351872508284218, 'noise_level': 0.23204832671374434, 'C': 41.326327629710846, 'kernel': 'linear'}. Best is trial 17 with value: 0.772505942795798.\n",
      "[I 2025-05-11 02:36:00,886] Trial 19 finished with value: 0.6621233034276514 and parameters: {'latent_dim': 20, 'hidden_dim': 231, 'lr': 0.0017080920673334958, 'epochs': 14, 'dropout_rate': 0.2725483947717446, 'noise_level': 0.21641843962435786, 'C': 6.369492847233503, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 17 with value: 0.772505942795798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7468\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs, batch_size, lr, noise_level)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7185\n",
      "ROC-AUC autoencoded: 0.7192\n",
      "ROC-AUC autoencoded: 0.7252\n",
      "ROC-AUC autoencoded: 0.7201\n",
      "ROC-AUC autoencoded: 0.6979\n",
      "ROC-AUC autoencoded: 0.7585\n",
      "ROC-AUC autoencoded: 0.7507\n",
      "ROC-AUC autoencoded: 0.7579\n",
      "ROC-AUC autoencoded: 0.7398\n",
      "ROC-AUC autoencoded: 0.7648\n",
      "ROC-AUC autoencoded: 0.7339\n",
      "ROC-AUC autoencoded: 0.7331\n",
      "ROC-AUC autoencoded: 0.7108\n",
      "ROC-AUC autoencoded: 0.7147\n",
      "ROC-AUC autoencoded: 0.7144\n",
      "ROC-AUC autoencoded: 0.6540\n",
      "ROC-AUC autoencoded: 0.6254\n",
      "ROC-AUC autoencoded: 0.6537\n",
      "ROC-AUC autoencoded: 0.6367\n",
      "ROC-AUC autoencoded: 0.6598\n",
      "ROC-AUC autoencoded: 0.7173\n",
      "ROC-AUC autoencoded: 0.7379\n",
      "ROC-AUC autoencoded: 0.7310\n",
      "ROC-AUC autoencoded: 0.7227\n",
      "ROC-AUC autoencoded: 0.7217\n",
      "среднее 0.7127905422628076\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 03:04:20,608] A new study created in memory with name: no-name-d29bbdf6-d1fc-41f8-a8e1-9dd945a21f93\n",
      "[I 2025-05-11 03:04:37,761] Trial 0 finished with value: 0.7012690744574802 and parameters: {'latent_dim': 54, 'hidden_dim_ae': 199, 'lr_ae': 0.00015102793203035353, 'epochs_ae': 39, 'dropout_rate_ae': 0.402164643059144, 'noise_level': 0.2765553742368755, 'hidden_dim_mlp': 125, 'lr_mlp': 0.008243217728860911, 'epochs_mlp': 23, 'dropout_rate_mlp': 0.2297201414242827}. Best is trial 0 with value: 0.7012690744574802.\n",
      "[I 2025-05-11 03:04:53,298] Trial 1 finished with value: 0.7130204738900391 and parameters: {'latent_dim': 39, 'hidden_dim_ae': 91, 'lr_ae': 0.0001390451840505409, 'epochs_ae': 41, 'dropout_rate_ae': 0.3147414837925032, 'noise_level': 0.2600711961795529, 'hidden_dim_mlp': 86, 'lr_mlp': 0.0006139518631047808, 'epochs_mlp': 25, 'dropout_rate_mlp': 0.20035154055958038}. Best is trial 1 with value: 0.7130204738900391.\n",
      "[I 2025-05-11 03:05:03,795] Trial 2 finished with value: 0.736331569664903 and parameters: {'latent_dim': 90, 'hidden_dim_ae': 168, 'lr_ae': 0.0023330256524592605, 'epochs_ae': 16, 'dropout_rate_ae': 0.35752802155400976, 'noise_level': 0.06416592617973267, 'hidden_dim_mlp': 97, 'lr_mlp': 0.0003277311815547891, 'epochs_mlp': 37, 'dropout_rate_mlp': 0.3533154502965927}. Best is trial 2 with value: 0.736331569664903.\n",
      "[I 2025-05-11 03:05:15,269] Trial 3 finished with value: 0.7190207806149834 and parameters: {'latent_dim': 51, 'hidden_dim_ae': 111, 'lr_ae': 0.0002877065736280702, 'epochs_ae': 19, 'dropout_rate_ae': 0.24957747682220438, 'noise_level': 0.14077418439559947, 'hidden_dim_mlp': 39, 'lr_mlp': 0.0020980305067925882, 'epochs_mlp': 40, 'dropout_rate_mlp': 0.23541745812657494}. Best is trial 2 with value: 0.736331569664903.\n",
      "[I 2025-05-11 03:05:34,094] Trial 4 finished with value: 0.7469902614830151 and parameters: {'latent_dim': 90, 'hidden_dim_ae': 112, 'lr_ae': 0.00016462814696714413, 'epochs_ae': 12, 'dropout_rate_ae': 0.34396154748422725, 'noise_level': 0.11227853545009649, 'hidden_dim_mlp': 122, 'lr_mlp': 0.00011591440954234953, 'epochs_mlp': 46, 'dropout_rate_mlp': 0.3853294202164168}. Best is trial 4 with value: 0.7469902614830151.\n",
      "[I 2025-05-11 03:05:49,473] Trial 5 finished with value: 0.7365999539912583 and parameters: {'latent_dim': 63, 'hidden_dim_ae': 169, 'lr_ae': 0.00043347674269001216, 'epochs_ae': 14, 'dropout_rate_ae': 0.21227572736989214, 'noise_level': 0.051572271407321915, 'hidden_dim_mlp': 86, 'lr_mlp': 0.00014532158804470425, 'epochs_mlp': 45, 'dropout_rate_mlp': 0.15016986689496947}. Best is trial 4 with value: 0.7469902614830151.\n",
      "[I 2025-05-11 03:06:11,653] Trial 6 finished with value: 0.7714515757994018 and parameters: {'latent_dim': 89, 'hidden_dim_ae': 109, 'lr_ae': 0.000358846062237163, 'epochs_ae': 39, 'dropout_rate_ae': 0.3542002785071199, 'noise_level': 0.058777976386501604, 'hidden_dim_mlp': 84, 'lr_mlp': 0.00010653859019991999, 'epochs_mlp': 32, 'dropout_rate_mlp': 0.3531420531368644}. Best is trial 6 with value: 0.7714515757994018.\n",
      "[I 2025-05-11 03:06:22,765] Trial 7 finished with value: 0.7296986427421212 and parameters: {'latent_dim': 58, 'hidden_dim_ae': 233, 'lr_ae': 0.004636391743490327, 'epochs_ae': 12, 'dropout_rate_ae': 0.28502077536393144, 'noise_level': 0.09800952656092064, 'hidden_dim_mlp': 97, 'lr_mlp': 0.0013354858336173715, 'epochs_mlp': 46, 'dropout_rate_mlp': 0.4416121336586687}. Best is trial 6 with value: 0.7714515757994018.\n",
      "[I 2025-05-11 03:06:34,377] Trial 8 finished with value: 0.7662564220535234 and parameters: {'latent_dim': 20, 'hidden_dim_ae': 133, 'lr_ae': 0.00040530791170959144, 'epochs_ae': 38, 'dropout_rate_ae': 0.22202528471665517, 'noise_level': 0.06585133013897786, 'hidden_dim_mlp': 121, 'lr_mlp': 0.00018589338822971687, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.43730622308765754}. Best is trial 6 with value: 0.7714515757994018.\n",
      "[I 2025-05-11 03:06:45,712] Trial 9 finished with value: 0.726478030825857 and parameters: {'latent_dim': 43, 'hidden_dim_ae': 162, 'lr_ae': 0.0017236702620111613, 'epochs_ae': 17, 'dropout_rate_ae': 0.41000133945710115, 'noise_level': 0.12765888042188533, 'hidden_dim_mlp': 51, 'lr_mlp': 0.005035766209278218, 'epochs_mlp': 48, 'dropout_rate_mlp': 0.4157695646756058}. Best is trial 6 with value: 0.7714515757994018.\n",
      "[I 2025-05-11 03:07:02,789] Trial 10 finished with value: 0.7102407790813587 and parameters: {'latent_dim': 100, 'hidden_dim_ae': 65, 'lr_ae': 0.0008269583059966397, 'epochs_ae': 49, 'dropout_rate_ae': 0.10096518069263813, 'noise_level': 0.20299676213305218, 'hidden_dim_mlp': 62, 'lr_mlp': 0.0004953054150193093, 'epochs_mlp': 32, 'dropout_rate_mlp': 0.30846650043833934}. Best is trial 6 with value: 0.7714515757994018.\n",
      "[I 2025-05-11 03:07:12,331] Trial 11 finished with value: 0.7619047619047619 and parameters: {'latent_dim': 12, 'hidden_dim_ae': 122, 'lr_ae': 0.0005625768946756084, 'epochs_ae': 31, 'dropout_rate_ae': 0.1705333532803799, 'noise_level': 0.20255649615795684, 'hidden_dim_mlp': 108, 'lr_mlp': 0.00021171034727731987, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.49278050561542663}. Best is trial 6 with value: 0.7714515757994018.\n",
      "[I 2025-05-11 03:07:22,613] Trial 12 finished with value: 0.7534123150065178 and parameters: {'latent_dim': 19, 'hidden_dim_ae': 134, 'lr_ae': 0.0003107792058883414, 'epochs_ae': 33, 'dropout_rate_ae': 0.45621086019965135, 'noise_level': 0.07898017478992683, 'hidden_dim_mlp': 72, 'lr_mlp': 0.0002081346229631428, 'epochs_mlp': 11, 'dropout_rate_mlp': 0.32036387268107597}. Best is trial 6 with value: 0.7714515757994018.\n",
      "[I 2025-05-11 03:07:36,195] Trial 13 finished with value: 0.761655547887432 and parameters: {'latent_dim': 75, 'hidden_dim_ae': 77, 'lr_ae': 0.0012802883715645416, 'epochs_ae': 42, 'dropout_rate_ae': 0.1892126543267158, 'noise_level': 0.15817659786379934, 'hidden_dim_mlp': 110, 'lr_mlp': 0.00010076498027164001, 'epochs_mlp': 18, 'dropout_rate_mlp': 0.47617250955730045}. Best is trial 6 with value: 0.7714515757994018.\n",
      "[I 2025-05-11 03:07:46,874] Trial 14 finished with value: 0.7540641055133808 and parameters: {'latent_dim': 28, 'hidden_dim_ae': 136, 'lr_ae': 0.00029214618722769745, 'epochs_ae': 24, 'dropout_rate_ae': 0.48698887381052747, 'noise_level': 0.08671493233007552, 'hidden_dim_mlp': 72, 'lr_mlp': 0.00031739391496849, 'epochs_mlp': 30, 'dropout_rate_mlp': 0.39209281447342165}. Best is trial 6 with value: 0.7714515757994018.\n",
      "[I 2025-05-11 03:08:06,940] Trial 15 finished with value: 0.7338585998006287 and parameters: {'latent_dim': 72, 'hidden_dim_ae': 202, 'lr_ae': 0.0007465030673365911, 'epochs_ae': 48, 'dropout_rate_ae': 0.25691747518486574, 'noise_level': 0.19870785669878982, 'hidden_dim_mlp': 110, 'lr_mlp': 0.0006594257553877461, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.27496754575733373}. Best is trial 6 with value: 0.7714515757994018.\n",
      "[I 2025-05-11 03:08:26,458] Trial 16 finished with value: 0.7639368146614522 and parameters: {'latent_dim': 32, 'hidden_dim_ae': 96, 'lr_ae': 0.006171198363716461, 'epochs_ae': 36, 'dropout_rate_ae': 0.10292872687480636, 'noise_level': 0.059615103708959775, 'hidden_dim_mlp': 54, 'lr_mlp': 0.0002236260172147045, 'epochs_mlp': 31, 'dropout_rate_mlp': 0.4387079409934958}. Best is trial 6 with value: 0.7714515757994018.\n",
      "[I 2025-05-11 03:08:39,756] Trial 17 finished with value: 0.7402614830151063 and parameters: {'latent_dim': 82, 'hidden_dim_ae': 146, 'lr_ae': 0.0033604641920522704, 'epochs_ae': 26, 'dropout_rate_ae': 0.38795755056896347, 'noise_level': 0.24051816959842343, 'hidden_dim_mlp': 32, 'lr_mlp': 0.00126595191613975, 'epochs_mlp': 37, 'dropout_rate_mlp': 0.3582189588296192}. Best is trial 6 with value: 0.7714515757994018.\n",
      "[I 2025-05-11 03:08:57,128] Trial 18 finished with value: 0.7395713518901923 and parameters: {'latent_dim': 66, 'hidden_dim_ae': 188, 'lr_ae': 0.000422982251596009, 'epochs_ae': 45, 'dropout_rate_ae': 0.14982562113644865, 'noise_level': 0.11196828199604342, 'hidden_dim_mlp': 98, 'lr_mlp': 0.0025689879596740637, 'epochs_mlp': 24, 'dropout_rate_mlp': 0.45488493481883663}. Best is trial 6 with value: 0.7714515757994018.\n",
      "[I 2025-05-11 03:09:11,211] Trial 19 finished with value: 0.7565179050686296 and parameters: {'latent_dim': 19, 'hidden_dim_ae': 251, 'lr_ae': 0.009040602352917653, 'epochs_ae': 36, 'dropout_rate_ae': 0.2256530268224759, 'noise_level': 0.16673609378562393, 'hidden_dim_mlp': 118, 'lr_mlp': 0.00038116163962402305, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.3445545353922521}. Best is trial 6 with value: 0.7714515757994018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7461\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae, noise_level)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7545\n",
      "ROC-AUC autoencoded: 0.7432\n",
      "ROC-AUC autoencoded: 0.7457\n",
      "ROC-AUC autoencoded: 0.7407\n",
      "ROC-AUC autoencoded: 0.7407\n",
      "ROC-AUC autoencoded: 0.7522\n",
      "ROC-AUC autoencoded: 0.7611\n",
      "ROC-AUC autoencoded: 0.7760\n",
      "ROC-AUC autoencoded: 0.7702\n",
      "ROC-AUC autoencoded: 0.7726\n",
      "ROC-AUC autoencoded: 0.7418\n",
      "ROC-AUC autoencoded: 0.7116\n",
      "ROC-AUC autoencoded: 0.7239\n",
      "ROC-AUC autoencoded: 0.7377\n",
      "ROC-AUC autoencoded: 0.7374\n",
      "ROC-AUC autoencoded: 0.7050\n",
      "ROC-AUC autoencoded: 0.6960\n",
      "ROC-AUC autoencoded: 0.6974\n",
      "ROC-AUC autoencoded: 0.7053\n",
      "ROC-AUC autoencoded: 0.6835\n",
      "ROC-AUC autoencoded: 0.7534\n",
      "ROC-AUC autoencoded: 0.7357\n",
      "ROC-AUC autoencoded: 0.7471\n",
      "ROC-AUC autoencoded: 0.7759\n",
      "ROC-AUC autoencoded: 0.7509\n",
      "среднее 0.7383818946090119\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        mlp = MLP(X_train_latent.shape[1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь блок с denoising автоэнкодером с дополнительной классифицирующей головой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 03:11:03,002] A new study created in memory with name: no-name-eea38762-2b56-4012-889f-5b9072e4ff32\n",
      "[I 2025-05-11 03:11:19,503] Trial 0 finished with value: 0.5925350816655165 and parameters: {'latent_dim': 79, 'hidden_dim': 194, 'lr': 0.0005281179250256072, 'epochs': 29, 'dropout_rate': 0.32932165622191506, 'noise_level': 0.23986132087917084, 'classification_weight': 0.7454312435149204, 'C': 0.29526264956716886, 'solver': 'liblinear'}. Best is trial 0 with value: 0.5925350816655165.\n",
      "[I 2025-05-11 03:11:27,734] Trial 1 finished with value: 0.61833831761368 and parameters: {'latent_dim': 18, 'hidden_dim': 114, 'lr': 0.0056313477951829925, 'epochs': 16, 'dropout_rate': 0.344805016149899, 'noise_level': 0.14868804705366334, 'classification_weight': 0.7417313345606125, 'C': 10.294461681365386, 'solver': 'liblinear'}. Best is trial 1 with value: 0.61833831761368.\n",
      "[I 2025-05-11 03:11:44,295] Trial 2 finished with value: 0.6919331339621196 and parameters: {'latent_dim': 19, 'hidden_dim': 111, 'lr': 0.00039731592002572246, 'epochs': 40, 'dropout_rate': 0.40432389431040217, 'noise_level': 0.1583135390023484, 'classification_weight': 0.5223544025397714, 'C': 0.25251779415765135, 'solver': 'liblinear'}. Best is trial 2 with value: 0.6919331339621196.\n",
      "[I 2025-05-11 03:12:00,732] Trial 3 finished with value: 0.7050456253354804 and parameters: {'latent_dim': 14, 'hidden_dim': 66, 'lr': 0.00216240717725399, 'epochs': 35, 'dropout_rate': 0.26648762806931914, 'noise_level': 0.19790111413305805, 'classification_weight': 0.1214844514712084, 'C': 16.81874745775079, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.7050456253354804.\n",
      "[I 2025-05-11 03:12:32,640] Trial 4 finished with value: 0.6019668737060041 and parameters: {'latent_dim': 50, 'hidden_dim': 141, 'lr': 0.0033792541847490107, 'epochs': 50, 'dropout_rate': 0.3934482755750929, 'noise_level': 0.1241634099545726, 'classification_weight': 0.7496573084386171, 'C': 0.014015500020529603, 'solver': 'liblinear'}. Best is trial 3 with value: 0.7050456253354804.\n",
      "[I 2025-05-11 03:13:04,546] Trial 5 finished with value: 0.6659765355417528 and parameters: {'latent_dim': 56, 'hidden_dim': 211, 'lr': 0.00021706584601688535, 'epochs': 49, 'dropout_rate': 0.23088511082337507, 'noise_level': 0.1294664172832179, 'classification_weight': 0.11301848271950146, 'C': 9.901689693887347, 'solver': 'saga'}. Best is trial 3 with value: 0.7050456253354804.\n",
      "[I 2025-05-11 03:13:10,930] Trial 6 finished with value: 0.7332834905298672 and parameters: {'latent_dim': 88, 'hidden_dim': 107, 'lr': 0.0010466824987115464, 'epochs': 12, 'dropout_rate': 0.2629205233269045, 'noise_level': 0.05469795873989984, 'classification_weight': 0.18304025029267149, 'C': 0.026673629589543033, 'solver': 'saga'}. Best is trial 6 with value: 0.7332834905298672.\n",
      "[I 2025-05-11 03:13:23,445] Trial 7 finished with value: 0.685932827237175 and parameters: {'latent_dim': 78, 'hidden_dim': 249, 'lr': 0.0003619503482656851, 'epochs': 17, 'dropout_rate': 0.4302835228507683, 'noise_level': 0.0705617997912885, 'classification_weight': 0.738236228611958, 'C': 14.776461035472895, 'solver': 'liblinear'}. Best is trial 6 with value: 0.7332834905298672.\n",
      "[I 2025-05-11 03:13:44,194] Trial 8 finished with value: 0.5589103596349972 and parameters: {'latent_dim': 55, 'hidden_dim': 236, 'lr': 0.00324988061253323, 'epochs': 44, 'dropout_rate': 0.3854066231065888, 'noise_level': 0.1400435679099843, 'classification_weight': 0.6128158806173158, 'C': 14.305386504158916, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.7332834905298672.\n",
      "[I 2025-05-11 03:14:07,532] Trial 9 finished with value: 0.577390537535465 and parameters: {'latent_dim': 92, 'hidden_dim': 228, 'lr': 0.0012515064379896208, 'epochs': 30, 'dropout_rate': 0.15817185146477325, 'noise_level': 0.1999974395721008, 'classification_weight': 0.5484549178074033, 'C': 39.0235531281021, 'solver': 'saga'}. Best is trial 6 with value: 0.7332834905298672.\n",
      "[I 2025-05-11 03:14:15,053] Trial 10 finished with value: 0.624722030519132 and parameters: {'latent_dim': 95, 'hidden_dim': 170, 'lr': 0.00917972350510542, 'epochs': 10, 'dropout_rate': 0.10545667411347426, 'noise_level': 0.050478592727140115, 'classification_weight': 0.3473798002714442, 'C': 0.021029614245228766, 'solver': 'saga'}. Best is trial 6 with value: 0.7332834905298672.\n",
      "[I 2025-05-11 03:14:31,253] Trial 11 finished with value: 0.7004830917874395 and parameters: {'latent_dim': 30, 'hidden_dim': 67, 'lr': 0.0015210225336986093, 'epochs': 35, 'dropout_rate': 0.25157144041842017, 'noise_level': 0.29120867929103395, 'classification_weight': 0.10303929114052471, 'C': 1.2623080562954563, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.7332834905298672.\n",
      "[I 2025-05-11 03:14:38,929] Trial 12 finished with value: 0.7432137106050151 and parameters: {'latent_dim': 40, 'hidden_dim': 69, 'lr': 0.00011465116826113446, 'epochs': 23, 'dropout_rate': 0.24949781190931886, 'noise_level': 0.210056936345314, 'classification_weight': 0.29134124062050903, 'C': 1.4258635324713709, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.7432137106050151.\n",
      "[I 2025-05-11 03:14:47,667] Trial 13 finished with value: 0.7607928839812897 and parameters: {'latent_dim': 41, 'hidden_dim': 101, 'lr': 0.00010929979403456492, 'epochs': 22, 'dropout_rate': 0.49315642940269855, 'noise_level': 0.24293622524151545, 'classification_weight': 0.36198090960007, 'C': 1.4647549675491442, 'solver': 'saga'}. Best is trial 13 with value: 0.7607928839812897.\n",
      "[I 2025-05-11 03:14:55,367] Trial 14 finished with value: 0.76307415075531 and parameters: {'latent_dim': 39, 'hidden_dim': 89, 'lr': 0.00015811629431258318, 'epochs': 23, 'dropout_rate': 0.47631877037726583, 'noise_level': 0.24984222859941216, 'classification_weight': 0.3448285059781756, 'C': 1.5414650807021106, 'solver': 'lbfgs'}. Best is trial 14 with value: 0.76307415075531.\n",
      "[I 2025-05-11 03:15:07,375] Trial 15 finished with value: 0.7700329729315237 and parameters: {'latent_dim': 36, 'hidden_dim': 94, 'lr': 0.00010371712085509845, 'epochs': 23, 'dropout_rate': 0.4944142870126038, 'noise_level': 0.27218391054348423, 'classification_weight': 0.36011556986983884, 'C': 2.44434478660842, 'solver': 'saga'}. Best is trial 15 with value: 0.7700329729315237.\n",
      "[I 2025-05-11 03:15:18,403] Trial 16 finished with value: 0.7302162410858064 and parameters: {'latent_dim': 65, 'hidden_dim': 142, 'lr': 0.00019840107611729117, 'epochs': 24, 'dropout_rate': 0.4885458337129626, 'noise_level': 0.2875006766385561, 'classification_weight': 0.43031845057503476, 'C': 3.7703763893994506, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.7700329729315237.\n",
      "[I 2025-05-11 03:15:24,321] Trial 17 finished with value: 0.7621923165401424 and parameters: {'latent_dim': 30, 'hidden_dim': 86, 'lr': 0.00019949009944658636, 'epochs': 18, 'dropout_rate': 0.4621194224311753, 'noise_level': 0.25418375351793665, 'classification_weight': 0.27115125648231153, 'C': 0.26465830173646104, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.7700329729315237.\n",
      "[I 2025-05-11 03:15:38,430] Trial 18 finished with value: 0.6989111264473582 and parameters: {'latent_dim': 31, 'hidden_dim': 147, 'lr': 0.00070945267671628, 'epochs': 28, 'dropout_rate': 0.4461333901091239, 'noise_level': 0.27066019462026913, 'classification_weight': 0.44831989654752413, 'C': 0.10417549005231469, 'solver': 'saga'}. Best is trial 15 with value: 0.7700329729315237.\n",
      "[I 2025-05-11 03:15:49,998] Trial 19 finished with value: 0.7200176366843033 and parameters: {'latent_dim': 39, 'hidden_dim': 127, 'lr': 0.00015011614329862952, 'epochs': 34, 'dropout_rate': 0.3468806389707427, 'noise_level': 0.22603549242968796, 'classification_weight': 0.6378130470612848, 'C': 97.86329311268648, 'solver': 'lbfgs'}. Best is trial 15 with value: 0.7700329729315237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7592\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingDenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(ClassifyingDenoisingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "    \n",
    "def train_classifying_denoising_autoencoder(model, X_train, y_train, epochs, batch_size, lr, noise_level=0.1, classification_weight=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    class_criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_target, batch_y in train_loader:\n",
    "            # Add noise to input data\n",
    "            noisy_batch = batch_x + noise_level * torch.randn_like(batch_x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _, classification = model(noisy_batch)\n",
    "            \n",
    "            # Reconstruction loss (target is the original data)\n",
    "            recon_loss = recon_criterion(reconstructed, batch_target)\n",
    "            \n",
    "            # Classification loss\n",
    "            class_loss = class_criterion(classification, batch_y)\n",
    "            \n",
    "            # Combined loss with weights\n",
    "            loss = (1 - classification_weight) * recon_loss + classification_weight * class_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent, _ = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def get_classification(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, _, classification = model(X_tensor)\n",
    "    return classification.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.6874\n",
      "ROC-AUC autoencoded: 0.7028\n",
      "ROC-AUC autoencoded: 0.7000\n",
      "ROC-AUC autoencoded: 0.7154\n",
      "ROC-AUC autoencoded: 0.7055\n",
      "ROC-AUC autoencoded: 0.7609\n",
      "ROC-AUC autoencoded: 0.7443\n",
      "ROC-AUC autoencoded: 0.7383\n",
      "ROC-AUC autoencoded: 0.7263\n",
      "ROC-AUC autoencoded: 0.7650\n",
      "ROC-AUC autoencoded: 0.7052\n",
      "ROC-AUC autoencoded: 0.7266\n",
      "ROC-AUC autoencoded: 0.7405\n",
      "ROC-AUC autoencoded: 0.7290\n",
      "ROC-AUC autoencoded: 0.7388\n",
      "ROC-AUC autoencoded: 0.6758\n",
      "ROC-AUC autoencoded: 0.6570\n",
      "ROC-AUC autoencoded: 0.6824\n",
      "ROC-AUC autoencoded: 0.6461\n",
      "ROC-AUC autoencoded: 0.6762\n",
      "ROC-AUC autoencoded: 0.7370\n",
      "ROC-AUC autoencoded: 0.7341\n",
      "ROC-AUC autoencoded: 0.7173\n",
      "ROC-AUC autoencoded: 0.7103\n",
      "ROC-AUC autoencoded: 0.7462\n",
      "среднее 0.7147295091771378\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 03:16:58,306] A new study created in memory with name: no-name-42d445b3-04ea-49ca-9581-afd642fafc0d\n",
      "[I 2025-05-11 03:18:17,400] Trial 0 finished with value: 0.7096656698105974 and parameters: {'latent_dim': 66, 'hidden_dim': 115, 'lr': 0.0005702531753660865, 'epochs': 10, 'dropout_rate': 0.2845153503795229, 'noise_level': 0.1855684434640053, 'classification_weight': 0.2983997300846134, 'n_estimators': 320, 'max_depth': 9, 'learning_rate': 0.05905341431051565, 'subsample': 0.6490809424048851, 'min_samples_split': 20, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7096656698105974.\n",
      "[I 2025-05-11 03:18:57,994] Trial 1 finished with value: 0.592362548884288 and parameters: {'latent_dim': 74, 'hidden_dim': 245, 'lr': 0.0008873764003811404, 'epochs': 44, 'dropout_rate': 0.3517091198621064, 'noise_level': 0.12022404482000147, 'classification_weight': 0.224784818898676, 'n_estimators': 171, 'max_depth': 3, 'learning_rate': 0.011606958151429496, 'subsample': 0.9249098109036945, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7096656698105974.\n",
      "[I 2025-05-11 03:19:55,403] Trial 2 finished with value: 0.6424545663676099 and parameters: {'latent_dim': 85, 'hidden_dim': 153, 'lr': 0.0008624913578938194, 'epochs': 32, 'dropout_rate': 0.3745373432410808, 'noise_level': 0.1437202278576627, 'classification_weight': 0.21867490084248803, 'n_estimators': 451, 'max_depth': 3, 'learning_rate': 0.11712928411346649, 'subsample': 0.6290842433772399, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7096656698105974.\n",
      "[I 2025-05-11 03:21:29,843] Trial 3 finished with value: 0.6788589832068093 and parameters: {'latent_dim': 62, 'hidden_dim': 157, 'lr': 0.0010536369123184486, 'epochs': 23, 'dropout_rate': 0.13675835256925473, 'noise_level': 0.10830685792474819, 'classification_weight': 0.10385194048375253, 'n_estimators': 313, 'max_depth': 10, 'learning_rate': 0.10063121138184566, 'subsample': 0.7326286395638381, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.7096656698105974.\n",
      "[I 2025-05-11 03:21:56,400] Trial 4 finished with value: 0.5602906218848248 and parameters: {'latent_dim': 57, 'hidden_dim': 143, 'lr': 0.004733303405434494, 'epochs': 50, 'dropout_rate': 0.2948051145247701, 'noise_level': 0.07283188056753633, 'classification_weight': 0.47314852217585013, 'n_estimators': 86, 'max_depth': 3, 'learning_rate': 0.03265101131258436, 'subsample': 0.7156057851258047, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7096656698105974.\n",
      "[I 2025-05-11 03:23:40,320] Trial 5 finished with value: 0.653017406640595 and parameters: {'latent_dim': 85, 'hidden_dim': 102, 'lr': 0.000491089437099585, 'epochs': 44, 'dropout_rate': 0.215334308362403, 'noise_level': 0.2558240909886435, 'classification_weight': 0.19263824886276684, 'n_estimators': 314, 'max_depth': 10, 'learning_rate': 0.02393256469511536, 'subsample': 0.7284290447239749, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.7096656698105974.\n",
      "[I 2025-05-11 03:25:07,871] Trial 6 finished with value: 0.7211870255348516 and parameters: {'latent_dim': 61, 'hidden_dim': 85, 'lr': 0.00013856704772505213, 'epochs': 12, 'dropout_rate': 0.2650823132102194, 'noise_level': 0.07440325910117916, 'classification_weight': 0.5422065563349489, 'n_estimators': 409, 'max_depth': 5, 'learning_rate': 0.02559846866273308, 'subsample': 0.8876378761885224, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 6 with value: 0.7211870255348516.\n",
      "[I 2025-05-11 03:27:20,422] Trial 7 finished with value: 0.5483283490529868 and parameters: {'latent_dim': 69, 'hidden_dim': 253, 'lr': 0.0010982855346220643, 'epochs': 37, 'dropout_rate': 0.14813842136573363, 'noise_level': 0.1989099994411726, 'classification_weight': 0.855098625818092, 'n_estimators': 333, 'max_depth': 6, 'learning_rate': 0.013381505649471482, 'subsample': 0.8696410668719392, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.7211870255348516.\n",
      "[I 2025-05-11 03:28:32,562] Trial 8 finished with value: 0.7419868108273905 and parameters: {'latent_dim': 98, 'hidden_dim': 138, 'lr': 0.00018207086417841665, 'epochs': 35, 'dropout_rate': 0.24495597948102238, 'noise_level': 0.20329444301815797, 'classification_weight': 0.10913012723764118, 'n_estimators': 410, 'max_depth': 3, 'learning_rate': 0.014094589383646907, 'subsample': 0.6434099688736076, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 8 with value: 0.7419868108273905.\n",
      "[I 2025-05-11 03:29:35,553] Trial 9 finished with value: 0.7137489456330036 and parameters: {'latent_dim': 70, 'hidden_dim': 87, 'lr': 0.00026089905108322124, 'epochs': 30, 'dropout_rate': 0.25750524530286645, 'noise_level': 0.19077813635992008, 'classification_weight': 0.21280603383199886, 'n_estimators': 154, 'max_depth': 7, 'learning_rate': 0.031657560152602786, 'subsample': 0.9015309338901771, 'min_samples_split': 17, 'min_samples_leaf': 1}. Best is trial 8 with value: 0.7419868108273905.\n",
      "[I 2025-05-11 03:30:47,290] Trial 10 finished with value: 0.6989302967563837 and parameters: {'latent_dim': 28, 'hidden_dim': 198, 'lr': 0.00010348288325022312, 'epochs': 22, 'dropout_rate': 0.452883197507992, 'noise_level': 0.29654238343411143, 'classification_weight': 0.4572879614250114, 'n_estimators': 494, 'max_depth': 5, 'learning_rate': 0.29701282350202296, 'subsample': 0.8003361083412922, 'min_samples_split': 15, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.7419868108273905.\n",
      "[I 2025-05-11 03:32:14,695] Trial 11 finished with value: 0.7212253661529026 and parameters: {'latent_dim': 36, 'hidden_dim': 64, 'lr': 0.00012007105966110465, 'epochs': 11, 'dropout_rate': 0.20721745090720645, 'noise_level': 0.23304729798607912, 'classification_weight': 0.6613919510071873, 'n_estimators': 417, 'max_depth': 5, 'learning_rate': 0.01922179333825269, 'subsample': 0.991015575136115, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 8 with value: 0.7419868108273905.\n",
      "[I 2025-05-11 03:33:44,455] Trial 12 finished with value: 0.6806993328732459 and parameters: {'latent_dim': 37, 'hidden_dim': 64, 'lr': 0.00022777572646152087, 'epochs': 20, 'dropout_rate': 0.2108999061758551, 'noise_level': 0.23781330188858404, 'classification_weight': 0.7320154769288598, 'n_estimators': 399, 'max_depth': 5, 'learning_rate': 0.015522771755132357, 'subsample': 0.9996051643867762, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.7419868108273905.\n",
      "[I 2025-05-11 03:34:35,593] Trial 13 finished with value: 0.5782340311325819 and parameters: {'latent_dim': 12, 'hidden_dim': 193, 'lr': 0.00023985483427480883, 'epochs': 31, 'dropout_rate': 0.18814091774261207, 'noise_level': 0.23717289551576187, 'classification_weight': 0.6424943281727218, 'n_estimators': 252, 'max_depth': 4, 'learning_rate': 0.020282088853149007, 'subsample': 0.9915445963715839, 'min_samples_split': 9, 'min_samples_leaf': 10}. Best is trial 8 with value: 0.7419868108273905.\n",
      "[I 2025-05-11 03:37:03,945] Trial 14 finished with value: 0.634172992868645 and parameters: {'latent_dim': 98, 'hidden_dim': 127, 'lr': 0.0023553800288880454, 'epochs': 16, 'dropout_rate': 0.3558085246671774, 'noise_level': 0.27386711308599426, 'classification_weight': 0.3511546060385477, 'n_estimators': 395, 'max_depth': 7, 'learning_rate': 0.04593217306927892, 'subsample': 0.8181698029845108, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.7419868108273905.\n",
      "[I 2025-05-11 03:38:26,490] Trial 15 finished with value: 0.5639329805996472 and parameters: {'latent_dim': 44, 'hidden_dim': 196, 'lr': 0.00017546532179686094, 'epochs': 36, 'dropout_rate': 0.12495066428380203, 'noise_level': 0.20878526222828608, 'classification_weight': 0.7385222700197862, 'n_estimators': 478, 'max_depth': 4, 'learning_rate': 0.011190435257411237, 'subsample': 0.6656242408082637, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.7419868108273905.\n",
      "[I 2025-05-11 03:39:39,967] Trial 16 finished with value: 0.6391189325971934 and parameters: {'latent_dim': 46, 'hidden_dim': 70, 'lr': 0.0003878504741502466, 'epochs': 26, 'dropout_rate': 0.18719932387228025, 'noise_level': 0.15689285492677396, 'classification_weight': 0.5998825156818921, 'n_estimators': 233, 'max_depth': 6, 'learning_rate': 0.016642348392859226, 'subsample': 0.9513630039832977, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 8 with value: 0.7419868108273905.\n",
      "[I 2025-05-11 03:40:47,067] Trial 17 finished with value: 0.6817345295606166 and parameters: {'latent_dim': 21, 'hidden_dim': 174, 'lr': 0.00010483140212315057, 'epochs': 39, 'dropout_rate': 0.2391942065739102, 'noise_level': 0.22376401282503655, 'classification_weight': 0.36506332220213217, 'n_estimators': 363, 'max_depth': 4, 'learning_rate': 0.04868601417743065, 'subsample': 0.8341278537512351, 'min_samples_split': 14, 'min_samples_leaf': 10}. Best is trial 8 with value: 0.7419868108273905.\n",
      "[I 2025-05-11 03:43:30,218] Trial 18 finished with value: 0.5596771719960126 and parameters: {'latent_dim': 97, 'hidden_dim': 223, 'lr': 0.002237700998664627, 'epochs': 27, 'dropout_rate': 0.3262712730636619, 'noise_level': 0.16593815055936226, 'classification_weight': 0.891514466695923, 'n_estimators': 463, 'max_depth': 8, 'learning_rate': 0.01931492539787936, 'subsample': 0.6008152417462784, 'min_samples_split': 17, 'min_samples_leaf': 6}. Best is trial 8 with value: 0.7419868108273905.\n",
      "[I 2025-05-11 03:44:37,486] Trial 19 finished with value: 0.6974733532704547 and parameters: {'latent_dim': 31, 'hidden_dim': 131, 'lr': 0.0003343272548464109, 'epochs': 17, 'dropout_rate': 0.4432662382798292, 'noise_level': 0.26919305286833245, 'classification_weight': 0.7054641327084833, 'n_estimators': 424, 'max_depth': 4, 'learning_rate': 0.08513609048339588, 'subsample': 0.7648589521710639, 'min_samples_split': 11, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.7419868108273905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7287\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7197\n",
      "ROC-AUC autoencoded: 0.7111\n",
      "ROC-AUC autoencoded: 0.7318\n",
      "ROC-AUC autoencoded: 0.7149\n",
      "ROC-AUC autoencoded: 0.6832\n",
      "ROC-AUC autoencoded: 0.7318\n",
      "ROC-AUC autoencoded: 0.7363\n",
      "ROC-AUC autoencoded: 0.7470\n",
      "ROC-AUC autoencoded: 0.7426\n",
      "ROC-AUC autoencoded: 0.7443\n",
      "ROC-AUC autoencoded: 0.7463\n",
      "ROC-AUC autoencoded: 0.7326\n",
      "ROC-AUC autoencoded: 0.7406\n",
      "ROC-AUC autoencoded: 0.7444\n",
      "ROC-AUC autoencoded: 0.7433\n",
      "ROC-AUC autoencoded: 0.6869\n",
      "ROC-AUC autoencoded: 0.7050\n",
      "ROC-AUC autoencoded: 0.6965\n",
      "ROC-AUC autoencoded: 0.7026\n",
      "ROC-AUC autoencoded: 0.7102\n",
      "ROC-AUC autoencoded: 0.7749\n",
      "ROC-AUC autoencoded: 0.7629\n",
      "ROC-AUC autoencoded: 0.7515\n",
      "ROC-AUC autoencoded: 0.7391\n",
      "ROC-AUC autoencoded: 0.7507\n",
      "среднее 0.73000423719005\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 03:53:58,133] A new study created in memory with name: no-name-87e46670-706c-46e3-90ae-8586320739c0\n",
      "[I 2025-05-11 03:54:15,549] Trial 0 finished with value: 0.5835537918871252 and parameters: {'latent_dim': 83, 'hidden_dim': 226, 'lr': 0.002634042789192513, 'epochs': 27, 'dropout_rate': 0.28213824195793613, 'noise_level': 0.09616788941691938, 'classification_weight': 0.4169829507267572, 'C': 73.92612632581356, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 0 with value: 0.5835537918871252.\n",
      "[I 2025-05-11 03:54:43,934] Trial 1 finished with value: 0.5629936354574036 and parameters: {'latent_dim': 83, 'hidden_dim': 198, 'lr': 0.005073236980957397, 'epochs': 43, 'dropout_rate': 0.16151495971222773, 'noise_level': 0.23878194672915126, 'classification_weight': 0.7949620822466578, 'C': 42.744007615228846, 'kernel': 'linear'}. Best is trial 0 with value: 0.5835537918871252.\n",
      "[I 2025-05-11 03:54:55,957] Trial 2 finished with value: 0.6674047235641439 and parameters: {'latent_dim': 35, 'hidden_dim': 154, 'lr': 0.000305192966257473, 'epochs': 13, 'dropout_rate': 0.406082141077438, 'noise_level': 0.24427626324915286, 'classification_weight': 0.6657188225431645, 'C': 28.954313463545574, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 2 with value: 0.6674047235641439.\n",
      "[I 2025-05-11 03:55:14,471] Trial 3 finished with value: 0.6001169388850548 and parameters: {'latent_dim': 96, 'hidden_dim': 94, 'lr': 0.000818814962164846, 'epochs': 31, 'dropout_rate': 0.15198983285082704, 'noise_level': 0.1560274432249229, 'classification_weight': 0.3042954036627272, 'C': 4.1025697690698895, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 2 with value: 0.6674047235641439.\n",
      "[I 2025-05-11 03:55:44,206] Trial 4 finished with value: 0.6223065715819338 and parameters: {'latent_dim': 61, 'hidden_dim': 66, 'lr': 0.0018627666933733503, 'epochs': 50, 'dropout_rate': 0.3880744741843076, 'noise_level': 0.2037190812394597, 'classification_weight': 0.358504312684924, 'C': 0.5063750903781025, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 2 with value: 0.6674047235641439.\n",
      "[I 2025-05-11 03:56:03,151] Trial 5 finished with value: 0.5575780231577333 and parameters: {'latent_dim': 86, 'hidden_dim': 108, 'lr': 0.003637853730131039, 'epochs': 33, 'dropout_rate': 0.15638854185125114, 'noise_level': 0.10890902853184271, 'classification_weight': 0.400456749871715, 'C': 16.46189170917336, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.6674047235641439.\n",
      "[I 2025-05-11 03:56:13,882] Trial 6 finished with value: 0.717180430948547 and parameters: {'latent_dim': 92, 'hidden_dim': 105, 'lr': 0.0002327830371795418, 'epochs': 17, 'dropout_rate': 0.36538768284944656, 'noise_level': 0.21159355072637337, 'classification_weight': 0.47451860692743353, 'C': 1.8696768217965194, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 6 with value: 0.717180430948547.\n",
      "[I 2025-05-11 03:56:25,022] Trial 7 finished with value: 0.7309351276742581 and parameters: {'latent_dim': 66, 'hidden_dim': 134, 'lr': 0.00014952742539485524, 'epochs': 18, 'dropout_rate': 0.33409272219524416, 'noise_level': 0.25593894677699064, 'classification_weight': 0.6851671980271047, 'C': 0.11657229002308779, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 7 with value: 0.7309351276742581.\n",
      "[I 2025-05-11 03:56:50,257] Trial 8 finished with value: 0.5638850548270838 and parameters: {'latent_dim': 91, 'hidden_dim': 220, 'lr': 0.002901290595085878, 'epochs': 43, 'dropout_rate': 0.28767156637158386, 'noise_level': 0.27589734027775886, 'classification_weight': 0.25451660308073604, 'C': 3.66497864678181, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 7 with value: 0.7309351276742581.\n",
      "[I 2025-05-11 03:57:05,234] Trial 9 finished with value: 0.609750019170309 and parameters: {'latent_dim': 39, 'hidden_dim': 139, 'lr': 0.0009356103288836458, 'epochs': 24, 'dropout_rate': 0.14390598894111084, 'noise_level': 0.26337721256274516, 'classification_weight': 0.6221697962904322, 'C': 23.016186468157997, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 7 with value: 0.7309351276742581.\n",
      "[I 2025-05-11 03:57:11,915] Trial 10 finished with value: 0.7489648033126294 and parameters: {'latent_dim': 16, 'hidden_dim': 184, 'lr': 0.00011545632018439596, 'epochs': 10, 'dropout_rate': 0.4599120641667861, 'noise_level': 0.29496352662540004, 'classification_weight': 0.1287729457887845, 'C': 0.10707280927371368, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 10 with value: 0.7489648033126294.\n",
      "[I 2025-05-11 03:57:18,491] Trial 11 finished with value: 0.7376255655241163 and parameters: {'latent_dim': 10, 'hidden_dim': 189, 'lr': 0.00011085655324578143, 'epochs': 10, 'dropout_rate': 0.49984024112980596, 'noise_level': 0.29897352479954975, 'classification_weight': 0.1228417388544592, 'C': 0.10482221121517195, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 10 with value: 0.7489648033126294.\n",
      "[I 2025-05-11 03:57:24,951] Trial 12 finished with value: 0.7387086879840502 and parameters: {'latent_dim': 13, 'hidden_dim': 182, 'lr': 0.0001281870469008106, 'epochs': 10, 'dropout_rate': 0.492596434658753, 'noise_level': 0.28875502661307106, 'classification_weight': 0.10332297606766061, 'C': 0.11489181787429806, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 10 with value: 0.7489648033126294.\n",
      "[I 2025-05-11 03:57:37,271] Trial 13 finished with value: 0.6561517521662449 and parameters: {'latent_dim': 10, 'hidden_dim': 254, 'lr': 0.00044321231073519366, 'epochs': 20, 'dropout_rate': 0.4980597168810306, 'noise_level': 0.29781053456522655, 'classification_weight': 0.11502723657953505, 'C': 0.4367005295211685, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 10 with value: 0.7489648033126294.\n",
      "[I 2025-05-11 03:57:45,319] Trial 14 finished with value: 0.7651062035120005 and parameters: {'latent_dim': 27, 'hidden_dim': 178, 'lr': 0.00010538249903876672, 'epochs': 10, 'dropout_rate': 0.4471971024585768, 'noise_level': 0.05521586540580281, 'classification_weight': 0.21155365655386862, 'C': 0.33956843897603173, 'kernel': 'linear'}. Best is trial 14 with value: 0.7651062035120005.\n",
      "[I 2025-05-11 03:57:56,150] Trial 15 finished with value: 0.7467698029292232 and parameters: {'latent_dim': 28, 'hidden_dim': 180, 'lr': 0.000499348676559156, 'epochs': 15, 'dropout_rate': 0.43957835351280156, 'noise_level': 0.061244079267222334, 'classification_weight': 0.22308621520625, 'C': 0.4180866746737403, 'kernel': 'linear'}. Best is trial 14 with value: 0.7651062035120005.\n",
      "[I 2025-05-11 03:58:09,728] Trial 16 finished with value: 0.5687830687830687 and parameters: {'latent_dim': 45, 'hidden_dim': 212, 'lr': 0.008556700522803138, 'epochs': 22, 'dropout_rate': 0.23513944743587578, 'noise_level': 0.15802892865520335, 'classification_weight': 0.2062444847099244, 'C': 1.2858244169016253, 'kernel': 'linear'}. Best is trial 14 with value: 0.7651062035120005.\n",
      "[I 2025-05-11 03:58:28,776] Trial 17 finished with value: 0.713825626869105 and parameters: {'latent_dim': 21, 'hidden_dim': 162, 'lr': 0.00020514472973405748, 'epochs': 36, 'dropout_rate': 0.44341258680217294, 'noise_level': 0.11933263817265799, 'classification_weight': 0.5635699183697519, 'C': 0.2559001531003207, 'kernel': 'linear'}. Best is trial 14 with value: 0.7651062035120005.\n",
      "[I 2025-05-11 03:58:41,118] Trial 18 finished with value: 0.6893930680162564 and parameters: {'latent_dim': 48, 'hidden_dim': 243, 'lr': 0.00044290216401211634, 'epochs': 14, 'dropout_rate': 0.44122509942180665, 'noise_level': 0.05732029406914865, 'classification_weight': 0.8768567590013046, 'C': 1.0408789573366883, 'kernel': 'linear'}. Best is trial 14 with value: 0.7651062035120005.\n",
      "[I 2025-05-11 03:58:54,377] Trial 19 finished with value: 0.7594988881220764 and parameters: {'latent_dim': 24, 'hidden_dim': 158, 'lr': 0.00018667712836435962, 'epochs': 26, 'dropout_rate': 0.3399243992956707, 'noise_level': 0.19946659565811384, 'classification_weight': 0.20761739033648535, 'C': 0.21511426372030554, 'kernel': 'linear'}. Best is trial 14 with value: 0.7651062035120005.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7677\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), X_pgs_train], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), X_pgs_val], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train_all), X_train_pgs], axis=1)\n",
    "X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val_all), X_val_pgs], axis=1)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7330\n",
      "ROC-AUC autoencoded: 0.7114\n",
      "ROC-AUC autoencoded: 0.7151\n",
      "ROC-AUC autoencoded: 0.7121\n",
      "ROC-AUC autoencoded: 0.7011\n",
      "ROC-AUC autoencoded: 0.7247\n",
      "ROC-AUC autoencoded: 0.7477\n",
      "ROC-AUC autoencoded: 0.7464\n",
      "ROC-AUC autoencoded: 0.7633\n",
      "ROC-AUC autoencoded: 0.7616\n",
      "ROC-AUC autoencoded: 0.7286\n",
      "ROC-AUC autoencoded: 0.7296\n",
      "ROC-AUC autoencoded: 0.7581\n",
      "ROC-AUC autoencoded: 0.7659\n",
      "ROC-AUC autoencoded: 0.7151\n",
      "ROC-AUC autoencoded: 0.6794\n",
      "ROC-AUC autoencoded: 0.6714\n",
      "ROC-AUC autoencoded: 0.6717\n",
      "ROC-AUC autoencoded: 0.6722\n",
      "ROC-AUC autoencoded: 0.6462\n",
      "ROC-AUC autoencoded: 0.7391\n",
      "ROC-AUC autoencoded: 0.7441\n",
      "ROC-AUC autoencoded: 0.7490\n",
      "ROC-AUC autoencoded: 0.7349\n",
      "ROC-AUC autoencoded: 0.7431\n",
      "среднее 0.7225894100378625\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = np.concatenate([get_latent_features(autoencoder, X_train), train_pgs], axis=1)\n",
    "        X_val_latent = np.concatenate([get_latent_features(autoencoder, X_val), test_pgs], axis=1)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 03:59:35,582] A new study created in memory with name: no-name-8bf3e2aa-e31c-4499-bf67-af93a96c1a53\n",
      "[I 2025-05-11 03:59:57,321] Trial 0 finished with value: 0.6283835595429799 and parameters: {'latent_dim': 77, 'hidden_dim_ae': 205, 'hidden_dim_combined': 98, 'lr_ae': 0.00602733847227019, 'lr_combined': 0.0003566386074562373, 'epochs_ae': 29, 'epochs_freeze': 12, 'epochs_unfreeze': 9, 'dropout_rate_ae': 0.36157359442578163, 'dropout_rate_combined': 0.31587361653208434, 'noise_level': 0.17488813183509305, 'classification_weight': 0.2785149283570011}. Best is trial 0 with value: 0.6283835595429799.\n",
      "[I 2025-05-11 04:00:25,545] Trial 1 finished with value: 0.6097308488612836 and parameters: {'latent_dim': 63, 'hidden_dim_ae': 97, 'hidden_dim_combined': 68, 'lr_ae': 0.002535433722614311, 'lr_combined': 0.0003699557221832689, 'epochs_ae': 39, 'epochs_freeze': 14, 'epochs_unfreeze': 16, 'dropout_rate_ae': 0.30592481959699125, 'dropout_rate_combined': 0.33787007863477686, 'noise_level': 0.07917531182786804, 'classification_weight': 0.87285237088557}. Best is trial 0 with value: 0.6283835595429799.\n",
      "[I 2025-05-11 04:00:40,585] Trial 2 finished with value: 0.7578789970094317 and parameters: {'latent_dim': 13, 'hidden_dim_ae': 92, 'hidden_dim_combined': 87, 'lr_ae': 0.00017456722513380855, 'lr_combined': 0.0002660099706763088, 'epochs_ae': 23, 'epochs_freeze': 10, 'epochs_unfreeze': 7, 'dropout_rate_ae': 0.24167349585359488, 'dropout_rate_combined': 0.19211907283502302, 'noise_level': 0.23278410239605546, 'classification_weight': 0.8557894043169502}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:01:06,167] Trial 3 finished with value: 0.5775055593896173 and parameters: {'latent_dim': 51, 'hidden_dim_ae': 231, 'hidden_dim_combined': 120, 'lr_ae': 0.0005279003703884066, 'lr_combined': 0.00040295526998588996, 'epochs_ae': 28, 'epochs_freeze': 20, 'epochs_unfreeze': 13, 'dropout_rate_ae': 0.18852557159390002, 'dropout_rate_combined': 0.37465458371118554, 'noise_level': 0.09685091657467738, 'classification_weight': 0.5377868527635532}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:01:36,669] Trial 4 finished with value: 0.7005406027145158 and parameters: {'latent_dim': 44, 'hidden_dim_ae': 190, 'hidden_dim_combined': 93, 'lr_ae': 0.0005029268919181564, 'lr_combined': 0.00010898828454660291, 'epochs_ae': 49, 'epochs_freeze': 10, 'epochs_unfreeze': 13, 'dropout_rate_ae': 0.28608626479699695, 'dropout_rate_combined': 0.1961934935058395, 'noise_level': 0.24341888321266253, 'classification_weight': 0.5258796576595116}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:01:56,096] Trial 5 finished with value: 0.5749750785982669 and parameters: {'latent_dim': 76, 'hidden_dim_ae': 168, 'hidden_dim_combined': 117, 'lr_ae': 0.004101644708587166, 'lr_combined': 0.0010346052317485536, 'epochs_ae': 24, 'epochs_freeze': 5, 'epochs_unfreeze': 17, 'dropout_rate_ae': 0.18439443877114647, 'dropout_rate_combined': 0.47663195428841343, 'noise_level': 0.2814391364779654, 'classification_weight': 0.47138029837037687}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:02:16,281] Trial 6 finished with value: 0.7384594739667203 and parameters: {'latent_dim': 62, 'hidden_dim_ae': 172, 'hidden_dim_combined': 75, 'lr_ae': 0.00013424219648398646, 'lr_combined': 0.0001971046100260551, 'epochs_ae': 18, 'epochs_freeze': 15, 'epochs_unfreeze': 16, 'dropout_rate_ae': 0.14225951692005148, 'dropout_rate_combined': 0.45892042954693113, 'noise_level': 0.061328747339553916, 'classification_weight': 0.6333962637439475}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:02:39,407] Trial 7 finished with value: 0.5935319377348364 and parameters: {'latent_dim': 71, 'hidden_dim_ae': 105, 'hidden_dim_combined': 108, 'lr_ae': 0.0007109716078284951, 'lr_combined': 0.0015988707611767823, 'epochs_ae': 40, 'epochs_freeze': 6, 'epochs_unfreeze': 12, 'dropout_rate_ae': 0.1620556087758189, 'dropout_rate_combined': 0.19019491978002004, 'noise_level': 0.17412001330252835, 'classification_weight': 0.884226830644709}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:03:00,745] Trial 8 finished with value: 0.6092132505175982 and parameters: {'latent_dim': 96, 'hidden_dim_ae': 253, 'hidden_dim_combined': 107, 'lr_ae': 0.002908506306837878, 'lr_combined': 0.0037767037224795802, 'epochs_ae': 37, 'epochs_freeze': 5, 'epochs_unfreeze': 6, 'dropout_rate_ae': 0.26760774336212834, 'dropout_rate_combined': 0.31794212638420116, 'noise_level': 0.08877322828456603, 'classification_weight': 0.12691064568681298}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:03:14,941] Trial 9 finished with value: 0.7091672417759374 and parameters: {'latent_dim': 87, 'hidden_dim_ae': 90, 'hidden_dim_combined': 106, 'lr_ae': 0.0010944180871332789, 'lr_combined': 0.0001691244005902592, 'epochs_ae': 19, 'epochs_freeze': 10, 'epochs_unfreeze': 6, 'dropout_rate_ae': 0.30297510119128146, 'dropout_rate_combined': 0.4398674226914955, 'noise_level': 0.2870847360299853, 'classification_weight': 0.7030776491800105}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:03:34,356] Trial 10 finished with value: 0.6833256652097232 and parameters: {'latent_dim': 10, 'hidden_dim_ae': 65, 'hidden_dim_combined': 43, 'lr_ae': 0.00010676199687291492, 'lr_combined': 0.009314263527526767, 'epochs_ae': 17, 'epochs_freeze': 18, 'epochs_unfreeze': 20, 'dropout_rate_ae': 0.4716183643321319, 'dropout_rate_combined': 0.1257530928191202, 'noise_level': 0.2226093117246329, 'classification_weight': 0.7687217565033782}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:03:49,930] Trial 11 finished with value: 0.7429644965876849 and parameters: {'latent_dim': 26, 'hidden_dim_ae': 138, 'hidden_dim_combined': 73, 'lr_ae': 0.00011538937616961864, 'lr_combined': 0.00020719429979411828, 'epochs_ae': 12, 'epochs_freeze': 15, 'epochs_unfreeze': 9, 'dropout_rate_ae': 0.12279665768373904, 'dropout_rate_combined': 0.23035686673070518, 'noise_level': 0.14041791473566057, 'classification_weight': 0.6897972015699045}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:04:02,553] Trial 12 finished with value: 0.7325358484778773 and parameters: {'latent_dim': 13, 'hidden_dim_ae': 130, 'hidden_dim_combined': 56, 'lr_ae': 0.00023164376377185334, 'lr_combined': 0.0005485692270483282, 'epochs_ae': 10, 'epochs_freeze': 16, 'epochs_unfreeze': 9, 'dropout_rate_ae': 0.10077027391667276, 'dropout_rate_combined': 0.2157471911452015, 'noise_level': 0.1348315182931154, 'classification_weight': 0.7511021840771832}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:04:13,855] Trial 13 finished with value: 0.7531055900621119 and parameters: {'latent_dim': 30, 'hidden_dim_ae': 136, 'hidden_dim_combined': 85, 'lr_ae': 0.0002492464603151923, 'lr_combined': 0.0001081030453668543, 'epochs_ae': 11, 'epochs_freeze': 9, 'epochs_unfreeze': 9, 'dropout_rate_ae': 0.23113565317415885, 'dropout_rate_combined': 0.25561509520590636, 'noise_level': 0.21825896852292512, 'classification_weight': 0.6400134634392153}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:04:29,034] Trial 14 finished with value: 0.741104976612223 and parameters: {'latent_dim': 26, 'hidden_dim_ae': 135, 'hidden_dim_combined': 86, 'lr_ae': 0.0002609769477080798, 'lr_combined': 0.00010680251718218656, 'epochs_ae': 23, 'epochs_freeze': 8, 'epochs_unfreeze': 5, 'dropout_rate_ae': 0.23065971835685609, 'dropout_rate_combined': 0.11819599482322882, 'noise_level': 0.22418435858799304, 'classification_weight': 0.36716166150413876}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:04:40,154] Trial 15 finished with value: 0.753719039950924 and parameters: {'latent_dim': 32, 'hidden_dim_ae': 71, 'hidden_dim_combined': 59, 'lr_ae': 0.00023883395893977541, 'lr_combined': 0.0007527699075986971, 'epochs_ae': 14, 'epochs_freeze': 9, 'epochs_unfreeze': 8, 'dropout_rate_ae': 0.37014144875194105, 'dropout_rate_combined': 0.2597379217196394, 'noise_level': 0.25223948068742974, 'classification_weight': 0.8163621892955437}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:04:55,160] Trial 16 finished with value: 0.7363890805919792 and parameters: {'latent_dim': 39, 'hidden_dim_ae': 71, 'hidden_dim_combined': 33, 'lr_ae': 0.00104130604935953, 'lr_combined': 0.00082160632256587, 'epochs_ae': 23, 'epochs_freeze': 12, 'epochs_unfreeze': 7, 'dropout_rate_ae': 0.4055891290679881, 'dropout_rate_combined': 0.15563758070358055, 'noise_level': 0.2565786702954135, 'classification_weight': 0.8127254583973386}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:05:16,076] Trial 17 finished with value: 0.7131738363622421 and parameters: {'latent_dim': 20, 'hidden_dim_ae': 110, 'hidden_dim_combined': 60, 'lr_ae': 0.0003626918153370024, 'lr_combined': 0.0020809106680674877, 'epochs_ae': 33, 'epochs_freeze': 7, 'epochs_unfreeze': 11, 'dropout_rate_ae': 0.3644098094879968, 'dropout_rate_combined': 0.26311371226094177, 'noise_level': 0.20218131241759893, 'classification_weight': 0.8964255700741899}. Best is trial 2 with value: 0.7578789970094317.\n",
      "[I 2025-05-11 04:05:27,554] Trial 18 finished with value: 0.767540832758224 and parameters: {'latent_dim': 34, 'hidden_dim_ae': 81, 'hidden_dim_combined': 52, 'lr_ae': 0.00017822325919871108, 'lr_combined': 0.0005519009402235923, 'epochs_ae': 14, 'epochs_freeze': 11, 'epochs_unfreeze': 7, 'dropout_rate_ae': 0.47782310241697323, 'dropout_rate_combined': 0.39653378424738395, 'noise_level': 0.2975318852815708, 'classification_weight': 0.8100384287138112}. Best is trial 18 with value: 0.767540832758224.\n",
      "[I 2025-05-11 04:05:46,310] Trial 19 finished with value: 0.7187715665976535 and parameters: {'latent_dim': 40, 'hidden_dim_ae': 89, 'hidden_dim_combined': 45, 'lr_ae': 0.0015081458364641447, 'lr_combined': 0.00025727494776478884, 'epochs_ae': 26, 'epochs_freeze': 11, 'epochs_unfreeze': 11, 'dropout_rate_ae': 0.47700759252587976, 'dropout_rate_combined': 0.39863759266941073, 'noise_level': 0.29887879801418826, 'classification_weight': 0.6022606238955556}. Best is trial 18 with value: 0.767540832758224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.7637\n"
     ]
    }
   ],
   "source": [
    "class CombinedClassifier(nn.Module):\n",
    "    def __init__(self, autoencoder, pgs_input_dim, hidden_dim=64, dropout_rate=0.2):\n",
    "        super(CombinedClassifier, self).__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "        self.pgs_branch = nn.Sequential(\n",
    "            nn.Linear(pgs_input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        latent_dim = list(autoencoder.classifier[0].parameters())[0].shape[1]\n",
    "        self.combined_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim // 2 + latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_snp, x_pgs):\n",
    "        _, latent, _ = self.autoencoder(x_snp)\n",
    "        pgs_features = self.pgs_branch(x_pgs)\n",
    "        combined = torch.cat([latent, pgs_features], dim=1)\n",
    "        output = self.combined_classifier(combined)\n",
    "        return output\n",
    "\n",
    "def train_combined_classifier(model, X_train_snp, X_train_pgs, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_snp_tensor = torch.FloatTensor(X_train_snp).to(device)\n",
    "    X_train_pgs_tensor = torch.FloatTensor(X_train_pgs).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_snp_tensor, X_train_pgs_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    for param in model.autoencoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs_freeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    for param in model.autoencoder.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr/10)\n",
    "    \n",
    "    for epoch in range(epochs_unfreeze):\n",
    "        for batch_snp, batch_pgs, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_snp, batch_pgs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_combined(model, X_snp, X_pgs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_snp_tensor = torch.FloatTensor(X_snp).to(device)\n",
    "    X_pgs_tensor = torch.FloatTensor(X_pgs).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_snp_tensor, X_pgs_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, X_pgs_train, X_pgs_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    hidden_dim_combined = trial.suggest_int('hidden_dim_combined', 32, 128)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    lr_combined = trial.suggest_float('lr_combined', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    epochs_freeze = trial.suggest_int('epochs_freeze', 5, 20)\n",
    "    epochs_unfreeze = trial.suggest_int('epochs_unfreeze', 5, 20)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    dropout_rate_combined = trial.suggest_float('dropout_rate_combined', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs_ae, batch_size, lr_ae, noise_level, classification_weight)\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, X_pgs_train.shape[1], hidden_dim_combined, dropout_rate_combined)\n",
    "        combined_model = train_combined_classifier(combined_model, X_train, X_pgs_train, y_train, epochs_freeze, epochs_unfreeze, batch_size, lr_combined)\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, X_pgs_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val, X_train_pgs, X_val_pgs), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs_ae'], 32, \n",
    "    best_params['lr_ae'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "combined_model = CombinedClassifier(autoencoder, X_train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "combined_model = train_combined_classifier(\n",
    "    combined_model, X_train_all, X_train_pgs, y_all_train, \n",
    "    best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    ")\n",
    "\n",
    "y_pred_proba = predict_combined(combined_model, X_val_all, X_val_pgs)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.7603\n",
      "ROC-AUC autoencoded: 0.7360\n",
      "ROC-AUC autoencoded: 0.7436\n",
      "ROC-AUC autoencoded: 0.7532\n",
      "ROC-AUC autoencoded: 0.7443\n",
      "ROC-AUC autoencoded: 0.7732\n",
      "ROC-AUC autoencoded: 0.7621\n",
      "ROC-AUC autoencoded: 0.7627\n",
      "ROC-AUC autoencoded: 0.7788\n",
      "ROC-AUC autoencoded: 0.7668\n",
      "ROC-AUC autoencoded: 0.7210\n",
      "ROC-AUC autoencoded: 0.7256\n",
      "ROC-AUC autoencoded: 0.7249\n",
      "ROC-AUC autoencoded: 0.7310\n",
      "ROC-AUC autoencoded: 0.7383\n",
      "ROC-AUC autoencoded: 0.7035\n",
      "ROC-AUC autoencoded: 0.6903\n",
      "ROC-AUC autoencoded: 0.7125\n",
      "ROC-AUC autoencoded: 0.7125\n",
      "ROC-AUC autoencoded: 0.6975\n",
      "ROC-AUC autoencoded: 0.7779\n",
      "ROC-AUC autoencoded: 0.7590\n",
      "ROC-AUC autoencoded: 0.7662\n",
      "ROC-AUC autoencoded: 0.7574\n",
      "ROC-AUC autoencoded: 0.7547\n",
      "среднее 0.7421353944635248\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = train_snps[i - 1]\n",
    "    test_snp = test_snps[i - 1]\n",
    "    train_pgs = train_pgss[i - 1]\n",
    "    test_pgs = test_pgss[i - 1]\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs_ae'], 32, \n",
    "            best_params['lr_ae'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        combined_model = CombinedClassifier(autoencoder, train_pgs.shape[1], best_params['hidden_dim_combined'], best_params['dropout_rate_combined'])\n",
    "        combined_model = train_combined_classifier(\n",
    "            combined_model, X_train, train_pgs, y_train, \n",
    "            best_params['epochs_freeze'], best_params['epochs_unfreeze'], 32, best_params['lr_combined']\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = predict_combined(combined_model, X_val, test_pgs)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_dipl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
