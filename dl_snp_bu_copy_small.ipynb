{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_snp_all = pd.read_csv(\"./csv/all_train_snp_selected.csv\")\n",
    "validation_snp_all = pd.read_csv(\"./csv/validation_snp_selected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all_ = all_train_snp_all.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "X_val_all_ = validation_snp_all.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "y_all_train = all_train_snp_all[\"target\"] - 1\n",
    "y_val = validation_snp_all[\"target\"] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регрессия на всех SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC bigset: 0.6361\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "model_gb = LogisticRegression()\n",
    "model_gb.fit(X_train_all, y_all_train)\n",
    "\n",
    "y_pred_proba = model_gb.predict_proba(X_val_all)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5603\n",
      "ROC-AUC: 0.5720\n",
      "ROC-AUC: 0.5833\n",
      "ROC-AUC: 0.5145\n",
      "ROC-AUC: 0.6296\n",
      "среднее 0.5719375440073178\n"
     ]
    }
   ],
   "source": [
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    model_gb = LogisticRegression()\n",
    "    model_gb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг на всех SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC bigset: 0.6166\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "model_gb = GradientBoostingClassifier()\n",
    "model_gb.fit(X_train_all, y_all_train)\n",
    "\n",
    "y_pred_proba = model_gb.predict_proba(X_val_all)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5391\n",
      "ROC-AUC: 0.5855\n",
      "ROC-AUC: 0.5551\n",
      "ROC-AUC: 0.5594\n",
      "ROC-AUC: 0.6170\n",
      "среднее 0.5712163866138791\n"
     ]
    }
   ],
   "source": [
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    model_gb = GradientBoostingClassifier()\n",
    "    model_gb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC на всех SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC bigset: 0.5853\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "model_gb = SVC(probability=True)\n",
    "model_gb.fit(X_train_all, y_all_train)\n",
    "\n",
    "y_pred_proba = model_gb.predict_proba(X_val_all)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.5639\n",
      "ROC-AUC: 0.5926\n",
      "ROC-AUC: 0.5945\n",
      "ROC-AUC: 0.5222\n",
      "ROC-AUC: 0.6126\n",
      "среднее 0.5771530586473814\n"
     ]
    }
   ],
   "source": [
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    model_gb = SVC(probability=True)\n",
    "    model_gb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полносвязная сеть на всех snp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6139\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train_all)\n",
    "y_train_tensor = torch.FloatTensor(y_all_train.values).reshape(-1, 1)\n",
    "\n",
    "model = Net(X_train_all.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_val_tensor = torch.FloatTensor(X_val_all)\n",
    "    y_pred_proba = model(X_val_tensor).numpy().flatten()\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5496\n",
      "ROC-AUC autoencoded: 0.5626\n",
      "ROC-AUC autoencoded: 0.6007\n",
      "ROC-AUC autoencoded: 0.5170\n",
      "ROC-AUC autoencoded: 0.6099\n",
      "среднее 0.5679849700344691\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "    \n",
    "    model = Net(X_train.shape[1])\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val_tensor = torch.FloatTensor(X_val)\n",
    "        y_pred_proba = model(X_val_tensor).numpy().flatten()\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок обучения с использованием классического автоэнкодера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С использованием логистической регрессии для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 04:30:05,269] A new study created in memory with name: no-name-9fdc40d2-4faf-4cea-bc7e-5bdfa00e06dc\n",
      "[I 2025-05-10 04:30:11,326] Trial 0 finished with value: 0.5545203588681848 and parameters: {'latent_dim': 74, 'hidden_dim': 85, 'lr': 0.00018845467574945851, 'epochs': 17, 'C': 0.0054633169349307025, 'dropout_rate': 0.42399888770766425}. Best is trial 0 with value: 0.5545203588681848.\n",
      "[I 2025-05-10 04:30:18,386] Trial 1 finished with value: 0.6176098458707153 and parameters: {'latent_dim': 40, 'hidden_dim': 185, 'lr': 0.009017393834555815, 'epochs': 17, 'C': 0.0017309971627527242, 'dropout_rate': 0.43935297652996996}. Best is trial 1 with value: 0.6176098458707153.\n",
      "[I 2025-05-10 04:30:31,363] Trial 2 finished with value: 0.5661375661375662 and parameters: {'latent_dim': 71, 'hidden_dim': 73, 'lr': 0.00044275573786069553, 'epochs': 34, 'C': 7.740894253050016, 'dropout_rate': 0.3424897635785179}. Best is trial 1 with value: 0.6176098458707153.\n",
      "[I 2025-05-10 04:30:36,664] Trial 3 finished with value: 0.6201403266620658 and parameters: {'latent_dim': 61, 'hidden_dim': 109, 'lr': 0.003975624276576774, 'epochs': 18, 'C': 0.03312990057109084, 'dropout_rate': 0.43117410901787}. Best is trial 3 with value: 0.6201403266620658.\n",
      "[I 2025-05-10 04:30:50,999] Trial 4 finished with value: 0.6279618127444214 and parameters: {'latent_dim': 41, 'hidden_dim': 188, 'lr': 0.0005662395601531486, 'epochs': 35, 'C': 0.002713455557585171, 'dropout_rate': 0.20903205494763874}. Best is trial 4 with value: 0.6279618127444214.\n",
      "[I 2025-05-10 04:31:07,575] Trial 5 finished with value: 0.58517368299977 and parameters: {'latent_dim': 99, 'hidden_dim': 227, 'lr': 0.0006887807581157098, 'epochs': 32, 'C': 0.13295908601020576, 'dropout_rate': 0.2890822496872537}. Best is trial 4 with value: 0.6279618127444214.\n",
      "[I 2025-05-10 04:31:12,571] Trial 6 finished with value: 0.5874741200828159 and parameters: {'latent_dim': 12, 'hidden_dim': 65, 'lr': 0.0015311253667769594, 'epochs': 15, 'C': 0.013866128158643779, 'dropout_rate': 0.1636453292974697}. Best is trial 4 with value: 0.6279618127444214.\n",
      "[I 2025-05-10 04:31:28,417] Trial 7 finished with value: 0.6097308488612836 and parameters: {'latent_dim': 53, 'hidden_dim': 249, 'lr': 0.00011075029938632376, 'epochs': 43, 'C': 0.0017844205761978903, 'dropout_rate': 0.4014946793515076}. Best is trial 4 with value: 0.6279618127444214.\n",
      "[I 2025-05-10 04:31:36,455] Trial 8 finished with value: 0.6287094547964113 and parameters: {'latent_dim': 60, 'hidden_dim': 85, 'lr': 0.0001822550906468245, 'epochs': 25, 'C': 0.030561354281597897, 'dropout_rate': 0.4351943928133851}. Best is trial 8 with value: 0.6287094547964113.\n",
      "[I 2025-05-10 04:31:41,577] Trial 9 finished with value: 0.5721187025534851 and parameters: {'latent_dim': 32, 'hidden_dim': 71, 'lr': 0.005332397515738644, 'epochs': 30, 'C': 0.3144302013516275, 'dropout_rate': 0.2728583863657069}. Best is trial 8 with value: 0.6287094547964113.\n",
      "[I 2025-05-10 04:31:47,900] Trial 10 finished with value: 0.5954106280193237 and parameters: {'latent_dim': 93, 'hidden_dim': 130, 'lr': 0.0002034748015887909, 'epochs': 50, 'C': 0.9209296381865457, 'dropout_rate': 0.49110201330466413}. Best is trial 8 with value: 0.6287094547964113.\n",
      "[I 2025-05-10 04:31:50,928] Trial 11 finished with value: 0.6804692891649413 and parameters: {'latent_dim': 39, 'hidden_dim': 174, 'lr': 0.0003568616582588914, 'epochs': 25, 'C': 0.029707602135020057, 'dropout_rate': 0.1851887156213405}. Best is trial 11 with value: 0.6804692891649413.\n",
      "[I 2025-05-10 04:31:53,445] Trial 12 finished with value: 0.6169772256728778 and parameters: {'latent_dim': 16, 'hidden_dim': 159, 'lr': 0.00027786679861996875, 'epochs': 24, 'C': 0.03435222371792359, 'dropout_rate': 0.1562887023245786}. Best is trial 11 with value: 0.6804692891649413.\n",
      "[I 2025-05-10 04:31:56,515] Trial 13 finished with value: 0.5953531170922475 and parameters: {'latent_dim': 29, 'hidden_dim': 144, 'lr': 0.0014197416752286204, 'epochs': 24, 'C': 0.059473051982755244, 'dropout_rate': 0.22690552619775267}. Best is trial 11 with value: 0.6804692891649413.\n",
      "[I 2025-05-10 04:31:57,717] Trial 14 finished with value: 0.5709109730848861 and parameters: {'latent_dim': 53, 'hidden_dim': 191, 'lr': 0.0001074195143659392, 'epochs': 10, 'C': 0.010426235467334621, 'dropout_rate': 0.35340105569674135}. Best is trial 11 with value: 0.6804692891649413.\n",
      "[I 2025-05-10 04:32:01,058] Trial 15 finished with value: 0.6119162640901771 and parameters: {'latent_dim': 78, 'hidden_dim': 108, 'lr': 0.0003335144685231845, 'epochs': 25, 'C': 0.20748390511505715, 'dropout_rate': 0.10795270551922906}. Best is trial 11 with value: 0.6804692891649413.\n",
      "[I 2025-05-10 04:32:06,312] Trial 16 finished with value: 0.599091327352197 and parameters: {'latent_dim': 65, 'hidden_dim': 213, 'lr': 0.0010327238382468545, 'epochs': 40, 'C': 0.9090009495807584, 'dropout_rate': 0.49945356381674305}. Best is trial 11 with value: 0.6804692891649413.\n",
      "[I 2025-05-10 04:32:10,009] Trial 17 finished with value: 0.628191856452726 and parameters: {'latent_dim': 86, 'hidden_dim': 166, 'lr': 0.0001778705540082781, 'epochs': 28, 'C': 0.018786149784711725, 'dropout_rate': 0.3382206299717452}. Best is trial 11 with value: 0.6804692891649413.\n",
      "[I 2025-05-10 04:32:12,125] Trial 18 finished with value: 0.5845410628019323 and parameters: {'latent_dim': 48, 'hidden_dim': 109, 'lr': 0.0003527457418414806, 'epochs': 20, 'C': 0.5938892129826365, 'dropout_rate': 0.23505986104818993}. Best is trial 11 with value: 0.6804692891649413.\n",
      "[I 2025-05-10 04:32:16,939] Trial 19 finished with value: 0.62738670347366 and parameters: {'latent_dim': 23, 'hidden_dim': 139, 'lr': 0.0007922250822837018, 'epochs': 38, 'C': 0.06928415376430656, 'dropout_rate': 0.11774028848133711}. Best is trial 11 with value: 0.6804692891649413.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5726\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "    \n",
    "def train_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, _ in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _ = model(batch_x)\n",
    "            loss = criterion(reconstructed, batch_x)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    C = trial.suggest_float('C', 1e-3, 10.0, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "    autoencoder = train_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "    \n",
    "    X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "    X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "    \n",
    "    logreg = LogisticRegression(C=C, max_iter=1000)\n",
    "    logreg.fit(X_train_latent, y_train)\n",
    "    \n",
    "    y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(C=best_params['C'], max_iter=1000)\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latent_dim': 39,\n",
       " 'hidden_dim': 174,\n",
       " 'lr': 0.0003568616582588914,\n",
       " 'epochs': 25,\n",
       " 'C': 0.029707602135020057,\n",
       " 'dropout_rate': 0.1851887156213405}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5781\n",
      "ROC-AUC autoencoded: 0.5647\n",
      "ROC-AUC autoencoded: 0.5502\n",
      "ROC-AUC autoencoded: 0.6144\n",
      "ROC-AUC autoencoded: 0.5765\n",
      "среднее 0.5767875472670909\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "\n",
    "    autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "    autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "    \n",
    "    X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "    X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "    \n",
    "    logreg = LogisticRegression(C=best_params['C'], max_iter=1000)\n",
    "    logreg.fit(X_train_latent, y_train)\n",
    "    \n",
    "    y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    rocs.append(roc_auc)\n",
    "    print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "с градиентным бустингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 04:32:59,620] A new study created in memory with name: no-name-0b91be86-b78d-49b7-9ab4-00b567e206de\n",
      "[I 2025-05-10 04:34:02,794] Trial 0 finished with value: 0.5695115405260333 and parameters: {'latent_dim': 38, 'hidden_dim': 182, 'lr': 0.00046174643541737833, 'epochs': 28, 'dropout_rate': 0.2640886548635418, 'n_estimators': 369, 'max_depth': 4, 'learning_rate': 0.17641153214120936, 'subsample': 0.6058809092685482, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.5695115405260333.\n",
      "[I 2025-05-10 04:34:33,361] Trial 1 finished with value: 0.5790200138026225 and parameters: {'latent_dim': 43, 'hidden_dim': 236, 'lr': 0.0007073142636440597, 'epochs': 33, 'dropout_rate': 0.15145649647122858, 'n_estimators': 161, 'max_depth': 7, 'learning_rate': 0.03305271667725329, 'subsample': 0.6961520988761672, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.5790200138026225.\n",
      "[I 2025-05-10 04:35:22,406] Trial 2 finished with value: 0.5429990031439306 and parameters: {'latent_dim': 59, 'hidden_dim': 217, 'lr': 0.0038455066001700025, 'epochs': 17, 'dropout_rate': 0.37986064304405354, 'n_estimators': 223, 'max_depth': 6, 'learning_rate': 0.07047253732701506, 'subsample': 0.8461417716717208, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.5790200138026225.\n",
      "[I 2025-05-10 04:36:40,315] Trial 3 finished with value: 0.5534851621808144 and parameters: {'latent_dim': 82, 'hidden_dim': 199, 'lr': 0.009895371740578938, 'epochs': 14, 'dropout_rate': 0.4867353051864073, 'n_estimators': 468, 'max_depth': 3, 'learning_rate': 0.07038822124226816, 'subsample': 0.6401027118061167, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.5790200138026225.\n",
      "[I 2025-05-10 04:37:08,572] Trial 4 finished with value: 0.5351583467525496 and parameters: {'latent_dim': 13, 'hidden_dim': 172, 'lr': 0.00013736250236083013, 'epochs': 25, 'dropout_rate': 0.1430711690076469, 'n_estimators': 445, 'max_depth': 7, 'learning_rate': 0.11204653973918319, 'subsample': 0.9925244056541707, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.5790200138026225.\n",
      "[I 2025-05-10 04:38:20,818] Trial 5 finished with value: 0.5535618434169159 and parameters: {'latent_dim': 56, 'hidden_dim': 125, 'lr': 0.002956050441032871, 'epochs': 15, 'dropout_rate': 0.3983614590346669, 'n_estimators': 188, 'max_depth': 8, 'learning_rate': 0.1217699840828902, 'subsample': 0.9683118340132744, 'min_samples_split': 16, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.5790200138026225.\n",
      "[I 2025-05-10 04:39:51,574] Trial 6 finished with value: 0.576432022084196 and parameters: {'latent_dim': 89, 'hidden_dim': 139, 'lr': 0.00015299747694796394, 'epochs': 24, 'dropout_rate': 0.3797892096509048, 'n_estimators': 289, 'max_depth': 7, 'learning_rate': 0.026227367841273882, 'subsample': 0.8983043118858963, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.5790200138026225.\n",
      "[I 2025-05-10 04:40:25,699] Trial 7 finished with value: 0.5732114101679319 and parameters: {'latent_dim': 53, 'hidden_dim': 177, 'lr': 0.0026763375329793924, 'epochs': 16, 'dropout_rate': 0.31714414719158335, 'n_estimators': 354, 'max_depth': 3, 'learning_rate': 0.032574372124888756, 'subsample': 0.8638084274575175, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.5790200138026225.\n",
      "[I 2025-05-10 04:41:19,812] Trial 8 finished with value: 0.597231807376735 and parameters: {'latent_dim': 66, 'hidden_dim': 153, 'lr': 0.0011510053583876135, 'epochs': 49, 'dropout_rate': 0.15484345784738462, 'n_estimators': 210, 'max_depth': 5, 'learning_rate': 0.0264019854897386, 'subsample': 0.7712835917077794, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 8 with value: 0.597231807376735.\n",
      "[I 2025-05-10 04:42:24,106] Trial 9 finished with value: 0.5418679549114331 and parameters: {'latent_dim': 53, 'hidden_dim': 148, 'lr': 0.0038851240982456948, 'epochs': 40, 'dropout_rate': 0.4001378991191161, 'n_estimators': 428, 'max_depth': 4, 'learning_rate': 0.2113540767146331, 'subsample': 0.6527639494759834, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 8 with value: 0.597231807376735.\n",
      "[I 2025-05-10 04:42:56,246] Trial 10 finished with value: 0.5822214554098611 and parameters: {'latent_dim': 100, 'hidden_dim': 94, 'lr': 0.0003696670168671145, 'epochs': 49, 'dropout_rate': 0.21699277509087778, 'n_estimators': 57, 'max_depth': 10, 'learning_rate': 0.010038700235145461, 'subsample': 0.7725411826161109, 'min_samples_split': 14, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.597231807376735.\n",
      "[I 2025-05-10 04:43:41,717] Trial 11 finished with value: 0.5788091404033433 and parameters: {'latent_dim': 100, 'hidden_dim': 65, 'lr': 0.0003409513023071417, 'epochs': 48, 'dropout_rate': 0.22740492357227338, 'n_estimators': 54, 'max_depth': 10, 'learning_rate': 0.011135859694939798, 'subsample': 0.753913341020954, 'min_samples_split': 13, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.597231807376735.\n",
      "[I 2025-05-10 04:44:18,623] Trial 12 finished with value: 0.5930718503182271 and parameters: {'latent_dim': 79, 'hidden_dim': 93, 'lr': 0.0011336462080907982, 'epochs': 50, 'dropout_rate': 0.1987594063123752, 'n_estimators': 51, 'max_depth': 10, 'learning_rate': 0.010163020058648902, 'subsample': 0.7526210102214961, 'min_samples_split': 14, 'min_samples_leaf': 10}. Best is trial 8 with value: 0.597231807376735.\n",
      "[I 2025-05-10 04:44:46,628] Trial 13 finished with value: 0.5846560846560845 and parameters: {'latent_dim': 71, 'hidden_dim': 105, 'lr': 0.0011595247658851063, 'epochs': 42, 'dropout_rate': 0.11949520341781765, 'n_estimators': 121, 'max_depth': 5, 'learning_rate': 0.01986757186002704, 'subsample': 0.7210540727397153, 'min_samples_split': 2, 'min_samples_leaf': 10}. Best is trial 8 with value: 0.597231807376735.\n",
      "[I 2025-05-10 04:46:06,038] Trial 14 finished with value: 0.5946629859673338 and parameters: {'latent_dim': 73, 'hidden_dim': 85, 'lr': 0.0013770553072999894, 'epochs': 42, 'dropout_rate': 0.18753830838830224, 'n_estimators': 248, 'max_depth': 9, 'learning_rate': 0.016884674285224246, 'subsample': 0.8103027065780951, 'min_samples_split': 17, 'min_samples_leaf': 10}. Best is trial 8 with value: 0.597231807376735.\n",
      "[I 2025-05-10 04:47:34,315] Trial 15 finished with value: 0.5997239475500346 and parameters: {'latent_dim': 68, 'hidden_dim': 255, 'lr': 0.0015547324510166737, 'epochs': 41, 'dropout_rate': 0.17416891599801676, 'n_estimators': 265, 'max_depth': 9, 'learning_rate': 0.017930568270910344, 'subsample': 0.8344286768661362, 'min_samples_split': 20, 'min_samples_leaf': 8}. Best is trial 15 with value: 0.5997239475500346.\n",
      "[I 2025-05-10 04:48:02,082] Trial 16 finished with value: 0.5612107967180431 and parameters: {'latent_dim': 27, 'hidden_dim': 230, 'lr': 0.001874582564379327, 'epochs': 36, 'dropout_rate': 0.10227117823831608, 'n_estimators': 340, 'max_depth': 5, 'learning_rate': 0.04682204887114997, 'subsample': 0.9210820795560627, 'min_samples_split': 20, 'min_samples_leaf': 8}. Best is trial 15 with value: 0.5997239475500346.\n",
      "[I 2025-05-10 04:49:35,636] Trial 17 finished with value: 0.569799095161414 and parameters: {'latent_dim': 66, 'hidden_dim': 252, 'lr': 0.0060045315301010425, 'epochs': 45, 'dropout_rate': 0.29199834529894053, 'n_estimators': 310, 'max_depth': 8, 'learning_rate': 0.018261461994666325, 'subsample': 0.8171899608560027, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 15 with value: 0.5997239475500346.\n",
      "[I 2025-05-10 04:49:58,995] Trial 18 finished with value: 0.5766428954834751 and parameters: {'latent_dim': 42, 'hidden_dim': 199, 'lr': 0.0005989964197718585, 'epochs': 39, 'dropout_rate': 0.1668813411264842, 'n_estimators': 143, 'max_depth': 6, 'learning_rate': 0.046781651115515556, 'subsample': 0.8797381685782889, 'min_samples_split': 17, 'min_samples_leaf': 7}. Best is trial 15 with value: 0.5997239475500346.\n",
      "[I 2025-05-10 04:51:33,310] Trial 19 finished with value: 0.5746491833448355 and parameters: {'latent_dim': 88, 'hidden_dim': 156, 'lr': 0.0002259998179359856, 'epochs': 45, 'dropout_rate': 0.25717240147610765, 'n_estimators': 225, 'max_depth': 8, 'learning_rate': 0.015615456205878888, 'subsample': 0.9339781688576184, 'min_samples_split': 12, 'min_samples_leaf': 4}. Best is trial 15 with value: 0.5997239475500346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5672\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры градиентного бустинга\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5734\n",
      "ROC-AUC autoencoded: 0.5818\n",
      "ROC-AUC autoencoded: 0.6047\n",
      "ROC-AUC autoencoded: 0.5220\n",
      "ROC-AUC autoencoded: 0.5742\n",
      "ROC-AUC autoencoded: 0.4865\n",
      "ROC-AUC autoencoded: 0.5624\n",
      "ROC-AUC autoencoded: 0.5397\n",
      "ROC-AUC autoencoded: 0.5045\n",
      "ROC-AUC autoencoded: 0.5327\n",
      "ROC-AUC autoencoded: 0.5993\n",
      "ROC-AUC autoencoded: 0.5435\n",
      "ROC-AUC autoencoded: 0.5163\n",
      "ROC-AUC autoencoded: 0.6046\n",
      "ROC-AUC autoencoded: 0.5745\n",
      "ROC-AUC autoencoded: 0.5488\n",
      "ROC-AUC autoencoded: 0.5347\n",
      "ROC-AUC autoencoded: 0.5559\n",
      "ROC-AUC autoencoded: 0.6135\n",
      "ROC-AUC autoencoded: 0.5148\n",
      "ROC-AUC autoencoded: 0.5925\n",
      "ROC-AUC autoencoded: 0.6303\n",
      "ROC-AUC autoencoded: 0.6141\n",
      "ROC-AUC autoencoded: 0.6716\n",
      "ROC-AUC autoencoded: 0.6198\n",
      "среднее 0.5686455212555946\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь с SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:00:24,484] A new study created in memory with name: no-name-8848f4df-5c04-4549-8a52-1279cd9677b2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:00:41,905] Trial 0 finished with value: 0.5710643355570892 and parameters: {'latent_dim': 20, 'hidden_dim': 183, 'lr': 0.0024968373070117034, 'epochs': 21, 'dropout_rate': 0.3440076828709627, 'C': 0.12905113301852825, 'kernel': 'linear'}. Best is trial 0 with value: 0.5710643355570892.\n",
      "[I 2025-05-10 05:03:31,085] Trial 1 finished with value: 0.593263553408481 and parameters: {'latent_dim': 14, 'hidden_dim': 130, 'lr': 0.00034159266988052816, 'epochs': 32, 'dropout_rate': 0.10947963260796377, 'C': 89.63505416166461, 'kernel': 'linear'}. Best is trial 1 with value: 0.593263553408481.\n",
      "[I 2025-05-10 05:03:59,116] Trial 2 finished with value: 0.5733456023311095 and parameters: {'latent_dim': 82, 'hidden_dim': 138, 'lr': 0.0015948482981548667, 'epochs': 49, 'dropout_rate': 0.15603859148738952, 'C': 45.680374674161534, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.593263553408481.\n",
      "[I 2025-05-10 05:04:24,871] Trial 3 finished with value: 0.5312859443294226 and parameters: {'latent_dim': 86, 'hidden_dim': 127, 'lr': 0.00040166159025577784, 'epochs': 25, 'dropout_rate': 0.39834991512904694, 'C': 17.777037102369427, 'kernel': 'linear'}. Best is trial 1 with value: 0.593263553408481.\n",
      "[I 2025-05-10 05:04:41,900] Trial 4 finished with value: 0.6112069626562381 and parameters: {'latent_dim': 93, 'hidden_dim': 228, 'lr': 0.001629411747328842, 'epochs': 48, 'dropout_rate': 0.14520738244542508, 'C': 2.0827036757606123, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:05:13,662] Trial 5 finished with value: 0.5041216164404569 and parameters: {'latent_dim': 90, 'hidden_dim': 141, 'lr': 0.0012496518293077703, 'epochs': 36, 'dropout_rate': 0.3560449003257883, 'C': 25.295083209198836, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:05:41,291] Trial 6 finished with value: 0.5249597423510467 and parameters: {'latent_dim': 74, 'hidden_dim': 213, 'lr': 0.0017018132060464932, 'epochs': 25, 'dropout_rate': 0.4031846159671446, 'C': 96.69533241718021, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:06:18,876] Trial 7 finished with value: 0.519246990261483 and parameters: {'latent_dim': 62, 'hidden_dim': 85, 'lr': 0.001925205876569998, 'epochs': 44, 'dropout_rate': 0.2937963953492926, 'C': 9.282200654664333, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:06:37,337] Trial 8 finished with value: 0.5484050302890883 and parameters: {'latent_dim': 82, 'hidden_dim': 168, 'lr': 0.0005188795121981978, 'epochs': 31, 'dropout_rate': 0.1403950248532116, 'C': 0.4537705828891801, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:06:48,516] Trial 9 finished with value: 0.5554021930833525 and parameters: {'latent_dim': 46, 'hidden_dim': 174, 'lr': 0.00010669486927714575, 'epochs': 33, 'dropout_rate': 0.24822310457668775, 'C': 1.3152525281780998, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:06:53,916] Trial 10 finished with value: 0.5290430181734529 and parameters: {'latent_dim': 100, 'hidden_dim': 250, 'lr': 0.005382164014389309, 'epochs': 13, 'dropout_rate': 0.47571777132478715, 'C': 3.437039159728885, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:07:06,691] Trial 11 finished with value: 0.5157963346369143 and parameters: {'latent_dim': 14, 'hidden_dim': 89, 'lr': 0.0002345615212811163, 'epochs': 41, 'dropout_rate': 0.10284551998388407, 'C': 3.353833519667708, 'kernel': 'linear'}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:07:26,043] Trial 12 finished with value: 0.5492101832681543 and parameters: {'latent_dim': 39, 'hidden_dim': 256, 'lr': 0.0006345872322539823, 'epochs': 49, 'dropout_rate': 0.21139432706626854, 'C': 0.7952308653981053, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:08:08,530] Trial 13 finished with value: 0.5032972931523655 and parameters: {'latent_dim': 25, 'hidden_dim': 213, 'lr': 0.009436993568032008, 'epochs': 39, 'dropout_rate': 0.17846112315637047, 'C': 6.477230732699061, 'kernel': 'linear'}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:08:23,462] Trial 14 finished with value: 0.5109270761444674 and parameters: {'latent_dim': 62, 'hidden_dim': 113, 'lr': 0.00015077646324309184, 'epochs': 15, 'dropout_rate': 0.11215749439927289, 'C': 0.28585481861029427, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:09:04,369] Trial 15 finished with value: 0.5413695268767732 and parameters: {'latent_dim': 33, 'hidden_dim': 205, 'lr': 0.0002563865068365566, 'epochs': 45, 'dropout_rate': 0.2288244668336184, 'C': 1.6390048611452321, 'kernel': 'linear'}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:09:19,200] Trial 16 finished with value: 0.5125182117935742 and parameters: {'latent_dim': 51, 'hidden_dim': 110, 'lr': 0.0007936486295510001, 'epochs': 25, 'dropout_rate': 0.18174591208909674, 'C': 87.25585910010442, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:09:33,397] Trial 17 finished with value: 0.5322828003987424 and parameters: {'latent_dim': 65, 'hidden_dim': 232, 'lr': 0.0038850588894950478, 'epochs': 37, 'dropout_rate': 0.2671061074107074, 'C': 8.044818440130141, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:09:40,388] Trial 18 finished with value: 0.5449543746645196 and parameters: {'latent_dim': 99, 'hidden_dim': 68, 'lr': 0.00033131524167238067, 'epochs': 19, 'dropout_rate': 0.1309388979566748, 'C': 1.5455081973137548, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.6112069626562381.\n",
      "[I 2025-05-10 05:09:52,393] Trial 19 finished with value: 0.5161605705083966 and parameters: {'latent_dim': 11, 'hidden_dim': 158, 'lr': 0.0009759918450579839, 'epochs': 29, 'dropout_rate': 0.20433394744993977, 'C': 16.258283465783872, 'kernel': 'linear'}. Best is trial 4 with value: 0.6112069626562381.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6218\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры SVC\n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if best_params['kernel'] in ['rbf', 'poly', 'sigmoid'] else 'scale',\n",
    "    degree=best_params['degree'] if best_params['kernel'] == 'poly' else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5506\n",
      "ROC-AUC autoencoded: 0.5688\n",
      "ROC-AUC autoencoded: 0.5392\n",
      "ROC-AUC autoencoded: 0.5244\n",
      "ROC-AUC autoencoded: 0.5200\n",
      "ROC-AUC autoencoded: 0.5681\n",
      "ROC-AUC autoencoded: 0.5109\n",
      "ROC-AUC autoencoded: 0.5708\n",
      "ROC-AUC autoencoded: 0.5513\n",
      "ROC-AUC autoencoded: 0.5069\n",
      "ROC-AUC autoencoded: 0.5681\n",
      "ROC-AUC autoencoded: 0.5755\n",
      "ROC-AUC autoencoded: 0.5517\n",
      "ROC-AUC autoencoded: 0.5878\n",
      "ROC-AUC autoencoded: 0.5465\n",
      "ROC-AUC autoencoded: 0.5031\n",
      "ROC-AUC autoencoded: 0.4940\n",
      "ROC-AUC autoencoded: 0.5473\n",
      "ROC-AUC autoencoded: 0.5125\n",
      "ROC-AUC autoencoded: 0.5425\n",
      "ROC-AUC autoencoded: 0.6039\n",
      "ROC-AUC autoencoded: 0.5577\n",
      "ROC-AUC autoencoded: 0.5915\n",
      "ROC-AUC autoencoded: 0.5559\n",
      "ROC-AUC autoencoded: 0.5953\n",
      "среднее 0.5497791858420515\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if best_params['kernel'] in ['rbf', 'poly', 'sigmoid'] else 'scale',\n",
    "            degree=best_params['degree'] if best_params['kernel'] == 'poly' else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:12:46,545] A new study created in memory with name: no-name-0d897d41-ee07-4f44-8531-9f6d36dc85df\n",
      "[I 2025-05-10 05:12:58,549] Trial 0 finished with value: 0.6215780998389694 and parameters: {'latent_dim': 31, 'hidden_dim_ae': 155, 'lr_ae': 0.0013808730135573778, 'epochs_ae': 16, 'dropout_rate_ae': 0.49665118937428476, 'hidden_dim_mlp': 103, 'lr_mlp': 0.0003051841225968509, 'batch_size_mlp': 16, 'epochs_mlp': 18, 'dropout_rate_mlp': 0.11585669793210195}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:13:10,107] Trial 1 finished with value: 0.5826240318993942 and parameters: {'latent_dim': 73, 'hidden_dim_ae': 187, 'lr_ae': 0.0034965504840391193, 'epochs_ae': 25, 'dropout_rate_ae': 0.4399627182615702, 'hidden_dim_mlp': 112, 'lr_mlp': 0.0005568791968886238, 'batch_size_mlp': 64, 'epochs_mlp': 24, 'dropout_rate_mlp': 0.3449765983645124}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:13:30,012] Trial 2 finished with value: 0.5899279196380646 and parameters: {'latent_dim': 53, 'hidden_dim_ae': 186, 'lr_ae': 0.000996865942398747, 'epochs_ae': 43, 'dropout_rate_ae': 0.36269568000777563, 'hidden_dim_mlp': 44, 'lr_mlp': 0.00549507056372584, 'batch_size_mlp': 64, 'epochs_mlp': 42, 'dropout_rate_mlp': 0.3447947784062624}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:13:45,591] Trial 3 finished with value: 0.5536576949620429 and parameters: {'latent_dim': 28, 'hidden_dim_ae': 229, 'lr_ae': 0.00047890722564855056, 'epochs_ae': 32, 'dropout_rate_ae': 0.3260268604443324, 'hidden_dim_mlp': 86, 'lr_mlp': 0.005641806401783465, 'batch_size_mlp': 32, 'epochs_mlp': 20, 'dropout_rate_mlp': 0.12950955571212808}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:14:27,981] Trial 4 finished with value: 0.5967525496511004 and parameters: {'latent_dim': 23, 'hidden_dim_ae': 151, 'lr_ae': 0.00024439064247027477, 'epochs_ae': 39, 'dropout_rate_ae': 0.20574511422168534, 'hidden_dim_mlp': 40, 'lr_mlp': 0.0010100714578262912, 'batch_size_mlp': 64, 'epochs_mlp': 23, 'dropout_rate_mlp': 0.18566850537959712}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:14:50,676] Trial 5 finished with value: 0.5991296679702477 and parameters: {'latent_dim': 11, 'hidden_dim_ae': 108, 'lr_ae': 0.009209716745752036, 'epochs_ae': 23, 'dropout_rate_ae': 0.14337541174222468, 'hidden_dim_mlp': 110, 'lr_mlp': 0.00021974214624642183, 'batch_size_mlp': 32, 'epochs_mlp': 13, 'dropout_rate_mlp': 0.35836565163606615}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:15:02,864] Trial 6 finished with value: 0.5889885744958209 and parameters: {'latent_dim': 77, 'hidden_dim_ae': 221, 'lr_ae': 0.00019217381541135206, 'epochs_ae': 27, 'dropout_rate_ae': 0.27105463733159463, 'hidden_dim_mlp': 50, 'lr_mlp': 0.00017627129327385407, 'batch_size_mlp': 64, 'epochs_mlp': 26, 'dropout_rate_mlp': 0.42278612475122024}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:15:09,020] Trial 7 finished with value: 0.59372364082509 and parameters: {'latent_dim': 58, 'hidden_dim_ae': 127, 'lr_ae': 0.0004633899356110931, 'epochs_ae': 13, 'dropout_rate_ae': 0.31308424651380495, 'hidden_dim_mlp': 98, 'lr_mlp': 0.00011108968189518418, 'batch_size_mlp': 64, 'epochs_mlp': 19, 'dropout_rate_mlp': 0.4840281042201945}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:15:31,960] Trial 8 finished with value: 0.5967717199601257 and parameters: {'latent_dim': 27, 'hidden_dim_ae': 115, 'lr_ae': 0.0024633293350485056, 'epochs_ae': 28, 'dropout_rate_ae': 0.33634939387178986, 'hidden_dim_mlp': 52, 'lr_mlp': 0.00010922995445881017, 'batch_size_mlp': 16, 'epochs_mlp': 43, 'dropout_rate_mlp': 0.2639778204121104}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:15:43,370] Trial 9 finished with value: 0.6144467448815275 and parameters: {'latent_dim': 60, 'hidden_dim_ae': 106, 'lr_ae': 0.0022807369971966827, 'epochs_ae': 24, 'dropout_rate_ae': 0.24771371908717388, 'hidden_dim_mlp': 125, 'lr_mlp': 0.002504323290776315, 'batch_size_mlp': 16, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.4699557173581581}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:15:58,100] Trial 10 finished with value: 0.5677670424047235 and parameters: {'latent_dim': 42, 'hidden_dim_ae': 83, 'lr_ae': 0.00935823228580669, 'epochs_ae': 10, 'dropout_rate_ae': 0.4744636011005817, 'hidden_dim_mlp': 71, 'lr_mlp': 0.0005175590252762433, 'batch_size_mlp': 16, 'epochs_mlp': 35, 'dropout_rate_mlp': 0.10157116810703756}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:16:09,055] Trial 11 finished with value: 0.5437274748868952 and parameters: {'latent_dim': 87, 'hidden_dim_ae': 65, 'lr_ae': 0.001931965239624863, 'epochs_ae': 18, 'dropout_rate_ae': 0.2083379930405792, 'hidden_dim_mlp': 127, 'lr_mlp': 0.0020461065412749288, 'batch_size_mlp': 16, 'epochs_mlp': 15, 'dropout_rate_mlp': 0.23666676212319704}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:16:18,555] Trial 12 finished with value: 0.5748983973621654 and parameters: {'latent_dim': 48, 'hidden_dim_ae': 154, 'lr_ae': 0.0012278708469627116, 'epochs_ae': 18, 'dropout_rate_ae': 0.40273141367096177, 'hidden_dim_mlp': 128, 'lr_mlp': 0.002162126539107665, 'batch_size_mlp': 16, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.4839013920223886}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:16:41,208] Trial 13 finished with value: 0.5403726708074533 and parameters: {'latent_dim': 65, 'hidden_dim_ae': 185, 'lr_ae': 0.004869146090789021, 'epochs_ae': 33, 'dropout_rate_ae': 0.25519436136339374, 'hidden_dim_mlp': 109, 'lr_mlp': 0.0020675905501678247, 'batch_size_mlp': 16, 'epochs_mlp': 32, 'dropout_rate_mlp': 0.18124883455844448}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:17:16,913] Trial 14 finished with value: 0.5840809753853232 and parameters: {'latent_dim': 38, 'hidden_dim_ae': 255, 'lr_ae': 0.0010380810604166174, 'epochs_ae': 50, 'dropout_rate_ae': 0.13354687551334707, 'hidden_dim_mlp': 91, 'lr_mlp': 0.0004118204862950571, 'batch_size_mlp': 16, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.407965276332349}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:17:41,823] Trial 15 finished with value: 0.5930526800092016 and parameters: {'latent_dim': 99, 'hidden_dim_ae': 140, 'lr_ae': 0.0006221186694019134, 'epochs_ae': 19, 'dropout_rate_ae': 0.4808098761503427, 'hidden_dim_mlp': 70, 'lr_mlp': 0.009710822621952192, 'batch_size_mlp': 16, 'epochs_mlp': 11, 'dropout_rate_mlp': 0.28151738875742177}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:18:12,674] Trial 16 finished with value: 0.5900621118012421 and parameters: {'latent_dim': 12, 'hidden_dim_ae': 93, 'lr_ae': 0.0019388391903728786, 'epochs_ae': 15, 'dropout_rate_ae': 0.38064229503907476, 'hidden_dim_mlp': 101, 'lr_mlp': 0.0008811130377157307, 'batch_size_mlp': 16, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.2054132381428167}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:18:29,687] Trial 17 finished with value: 0.5974043401579633 and parameters: {'latent_dim': 36, 'hidden_dim_ae': 168, 'lr_ae': 0.00010241527608055702, 'epochs_ae': 22, 'dropout_rate_ae': 0.19582959753246337, 'hidden_dim_mlp': 119, 'lr_mlp': 0.0011621194680341309, 'batch_size_mlp': 32, 'epochs_mlp': 29, 'dropout_rate_mlp': 0.4415875163775219}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:18:46,596] Trial 18 finished with value: 0.5987079211716893 and parameters: {'latent_dim': 67, 'hidden_dim_ae': 125, 'lr_ae': 0.005056596517419198, 'epochs_ae': 38, 'dropout_rate_ae': 0.2754375751573208, 'hidden_dim_mlp': 75, 'lr_mlp': 0.0003343066596504473, 'batch_size_mlp': 16, 'epochs_mlp': 15, 'dropout_rate_mlp': 0.30456999679181757}. Best is trial 0 with value: 0.6215780998389694.\n",
      "[I 2025-05-10 05:18:56,440] Trial 19 finished with value: 0.5485583927612913 and parameters: {'latent_dim': 57, 'hidden_dim_ae': 97, 'lr_ae': 0.0014659865936336664, 'epochs_ae': 10, 'dropout_rate_ae': 0.10105288302991774, 'hidden_dim_mlp': 118, 'lr_mlp': 0.0034521083062341745, 'batch_size_mlp': 16, 'epochs_mlp': 20, 'dropout_rate_mlp': 0.15202506170058047}. Best is trial 0 with value: 0.6215780998389694.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5964\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры MLP\n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    batch_size_mlp = trial.suggest_categorical('batch_size_mlp', [16, 32, 64])\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(latent_dim, hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size_mlp, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = Autoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "mlp = MLP(best_params['latent_dim'], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], best_params['batch_size_mlp'], best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.4681\n",
      "ROC-AUC autoencoded: 0.5806\n",
      "ROC-AUC autoencoded: 0.5196\n",
      "ROC-AUC autoencoded: 0.4929\n",
      "ROC-AUC autoencoded: 0.5898\n",
      "ROC-AUC autoencoded: 0.5393\n",
      "ROC-AUC autoencoded: 0.5985\n",
      "ROC-AUC autoencoded: 0.5179\n",
      "ROC-AUC autoencoded: 0.5473\n",
      "ROC-AUC autoencoded: 0.5705\n",
      "ROC-AUC autoencoded: 0.5926\n",
      "ROC-AUC autoencoded: 0.6074\n",
      "ROC-AUC autoencoded: 0.5394\n",
      "ROC-AUC autoencoded: 0.5695\n",
      "ROC-AUC autoencoded: 0.5722\n",
      "ROC-AUC autoencoded: 0.5057\n",
      "ROC-AUC autoencoded: 0.4972\n",
      "ROC-AUC autoencoded: 0.4878\n",
      "ROC-AUC autoencoded: 0.5177\n",
      "ROC-AUC autoencoded: 0.5329\n",
      "ROC-AUC autoencoded: 0.6414\n",
      "ROC-AUC autoencoded: 0.5761\n",
      "ROC-AUC autoencoded: 0.5995\n",
      "ROC-AUC autoencoded: 0.5918\n",
      "ROC-AUC autoencoded: 0.5942\n",
      "среднее 0.5539932954036424\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = Autoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(best_params['latent_dim'], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], best_params['batch_size_mlp'], best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок с классическим автоэнкодером с второй классифицирующей головой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "логситическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:20:16,927] A new study created in memory with name: no-name-1d8a54e7-8e4a-420b-b5e1-9127d652ee28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:20:31,180] Trial 0 finished with value: 0.5421363392377885 and parameters: {'latent_dim': 99, 'hidden_dim': 248, 'lr': 0.0024783472537291723, 'epochs': 30, 'dropout_rate': 0.4437409284742527, 'recon_weight': 0.16192678826127846, 'C': 3.0093000062298896}. Best is trial 0 with value: 0.5421363392377885.\n",
      "[I 2025-05-10 05:20:42,043] Trial 1 finished with value: 0.5867073077218005 and parameters: {'latent_dim': 33, 'hidden_dim': 181, 'lr': 0.0009712389272543196, 'epochs': 25, 'dropout_rate': 0.12980890558191438, 'recon_weight': 0.8576220948231904, 'C': 0.3799049958986532}. Best is trial 1 with value: 0.5867073077218005.\n",
      "[I 2025-05-10 05:20:55,834] Trial 2 finished with value: 0.568648876619891 and parameters: {'latent_dim': 47, 'hidden_dim': 82, 'lr': 0.0019562019537894687, 'epochs': 27, 'dropout_rate': 0.4081055621537355, 'recon_weight': 0.5769296636093099, 'C': 0.23304548088443364}. Best is trial 1 with value: 0.5867073077218005.\n",
      "[I 2025-05-10 05:21:44,711] Trial 3 finished with value: 0.5542328042328042 and parameters: {'latent_dim': 90, 'hidden_dim': 177, 'lr': 0.0004895345508233282, 'epochs': 43, 'dropout_rate': 0.31136755758516776, 'recon_weight': 0.14511775997931872, 'C': 2.194732518133997}. Best is trial 1 with value: 0.5867073077218005.\n",
      "[I 2025-05-10 05:21:51,900] Trial 4 finished with value: 0.5620734606241853 and parameters: {'latent_dim': 62, 'hidden_dim': 158, 'lr': 0.0014836876127616613, 'epochs': 17, 'dropout_rate': 0.32744193943957267, 'recon_weight': 0.32349635946034794, 'C': 2.7440592454781063}. Best is trial 1 with value: 0.5867073077218005.\n",
      "[I 2025-05-10 05:22:07,089] Trial 5 finished with value: 0.5521815811670884 and parameters: {'latent_dim': 10, 'hidden_dim': 212, 'lr': 0.002672889086731538, 'epochs': 37, 'dropout_rate': 0.3556451280149785, 'recon_weight': 0.7488328823585244, 'C': 0.48559851876622656}. Best is trial 1 with value: 0.5867073077218005.\n",
      "[I 2025-05-10 05:22:12,991] Trial 6 finished with value: 0.5890460854228969 and parameters: {'latent_dim': 78, 'hidden_dim': 168, 'lr': 0.0023685768919929928, 'epochs': 14, 'dropout_rate': 0.3832945630459026, 'recon_weight': 0.8083393706886763, 'C': 0.048136467120503505}. Best is trial 6 with value: 0.5890460854228969.\n",
      "[I 2025-05-10 05:22:18,996] Trial 7 finished with value: 0.6180315926692739 and parameters: {'latent_dim': 18, 'hidden_dim': 121, 'lr': 0.00010814364205765986, 'epochs': 15, 'dropout_rate': 0.11475828701668621, 'recon_weight': 0.20245052896031837, 'C': 0.9113078976627508}. Best is trial 7 with value: 0.6180315926692739.\n",
      "[I 2025-05-10 05:22:27,413] Trial 8 finished with value: 0.5558431101909362 and parameters: {'latent_dim': 70, 'hidden_dim': 223, 'lr': 0.001127681941500415, 'epochs': 18, 'dropout_rate': 0.16993632862404717, 'recon_weight': 0.7784705429704568, 'C': 0.012383222485765896}. Best is trial 7 with value: 0.6180315926692739.\n",
      "[I 2025-05-10 05:22:37,449] Trial 9 finished with value: 0.5446093091020628 and parameters: {'latent_dim': 12, 'hidden_dim': 166, 'lr': 0.0015542896494184757, 'epochs': 24, 'dropout_rate': 0.2911242622647586, 'recon_weight': 0.1985097052391665, 'C': 21.249565274416156}. Best is trial 7 with value: 0.6180315926692739.\n",
      "[I 2025-05-10 05:22:41,946] Trial 10 finished with value: 0.5625335480407944 and parameters: {'latent_dim': 31, 'hidden_dim': 98, 'lr': 0.0001057952241967031, 'epochs': 10, 'dropout_rate': 0.21034918647499426, 'recon_weight': 0.46452101073322455, 'C': 84.00283392576911}. Best is trial 7 with value: 0.6180315926692739.\n",
      "[I 2025-05-10 05:22:46,692] Trial 11 finished with value: 0.5622843340234644 and parameters: {'latent_dim': 77, 'hidden_dim': 120, 'lr': 0.005980214086764732, 'epochs': 11, 'dropout_rate': 0.23464651596610564, 'recon_weight': 0.5578002758526709, 'C': 0.02507008600804905}. Best is trial 7 with value: 0.6180315926692739.\n",
      "[I 2025-05-10 05:22:54,071] Trial 12 finished with value: 0.5738632006747948 and parameters: {'latent_dim': 50, 'hidden_dim': 133, 'lr': 0.00010915424143078996, 'epochs': 17, 'dropout_rate': 0.4932013949397701, 'recon_weight': 0.34025294624870533, 'C': 0.1076011858738852}. Best is trial 7 with value: 0.6180315926692739.\n",
      "[I 2025-05-10 05:23:09,170] Trial 13 finished with value: 0.5619776090790585 and parameters: {'latent_dim': 82, 'hidden_dim': 135, 'lr': 0.000345111337678496, 'epochs': 36, 'dropout_rate': 0.10445828653237862, 'recon_weight': 0.6763460475171239, 'C': 0.05445841808994637}. Best is trial 7 with value: 0.6180315926692739.\n",
      "[I 2025-05-10 05:23:16,883] Trial 14 finished with value: 0.5739782225289471 and parameters: {'latent_dim': 31, 'hidden_dim': 64, 'lr': 0.006127834122770403, 'epochs': 20, 'dropout_rate': 0.4083609414107521, 'recon_weight': 0.3499544868881642, 'C': 10.310274564820991}. Best is trial 7 with value: 0.6180315926692739.\n",
      "[I 2025-05-10 05:23:22,447] Trial 15 finished with value: 0.6340004600874166 and parameters: {'latent_dim': 63, 'hidden_dim': 107, 'lr': 0.0003031453093980313, 'epochs': 13, 'dropout_rate': 0.267681171247705, 'recon_weight': 0.4552099643479729, 'C': 0.07501164489057759}. Best is trial 15 with value: 0.6340004600874166.\n",
      "[I 2025-05-10 05:23:41,877] Trial 16 finished with value: 0.5725021087339927 and parameters: {'latent_dim': 60, 'hidden_dim': 105, 'lr': 0.0002186844676229189, 'epochs': 47, 'dropout_rate': 0.245388591667333, 'recon_weight': 0.4361190589453519, 'C': 0.8709237713283543}. Best is trial 15 with value: 0.6340004600874166.\n",
      "[I 2025-05-10 05:23:51,134] Trial 17 finished with value: 0.6001073537305421 and parameters: {'latent_dim': 40, 'hidden_dim': 142, 'lr': 0.00021734512506129224, 'epochs': 22, 'dropout_rate': 0.1754245595268593, 'recon_weight': 0.2664282558450266, 'C': 0.1430719060372439}. Best is trial 15 with value: 0.6340004600874166.\n",
      "[I 2025-05-10 05:23:56,883] Trial 18 finished with value: 0.6279809830534469 and parameters: {'latent_dim': 21, 'hidden_dim': 106, 'lr': 0.00053553585639777, 'epochs': 14, 'dropout_rate': 0.257985130351325, 'recon_weight': 0.6270858608218646, 'C': 0.706733346604022}. Best is trial 15 with value: 0.6340004600874166.\n",
      "[I 2025-05-10 05:24:01,692] Trial 19 finished with value: 0.6035963499731616 and parameters: {'latent_dim': 24, 'hidden_dim': 80, 'lr': 0.000611655722657006, 'epochs': 12, 'dropout_rate': 0.28838033191506507, 'recon_weight': 0.6539408386154713, 'C': 0.08130163114552656}. Best is trial 15 with value: 0.6340004600874166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6105\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(ClassifyingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "\n",
    "def train_classifying_autoencoder(model, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    class_criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _, classification = model(batch_x)\n",
    "            \n",
    "            recon_loss = recon_criterion(reconstructed, batch_x)\n",
    "            class_loss = class_criterion(classification, batch_y)\n",
    "            \n",
    "            loss = recon_weight * recon_loss + class_weight * class_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent, _ = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Веса для объединенной функции потерь\n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    # Параметры логистической регрессии\n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(C=C, max_iter=1000, random_state=42)\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(C=best_params['C'], max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5458\n",
      "ROC-AUC autoencoded: 0.5559\n",
      "ROC-AUC autoencoded: 0.5614\n",
      "ROC-AUC autoencoded: 0.5584\n",
      "ROC-AUC autoencoded: 0.5511\n",
      "ROC-AUC autoencoded: 0.5863\n",
      "ROC-AUC autoencoded: 0.5748\n",
      "ROC-AUC autoencoded: 0.5776\n",
      "ROC-AUC autoencoded: 0.5456\n",
      "ROC-AUC autoencoded: 0.5590\n",
      "ROC-AUC autoencoded: 0.5669\n",
      "ROC-AUC autoencoded: 0.5761\n",
      "ROC-AUC autoencoded: 0.5826\n",
      "ROC-AUC autoencoded: 0.5346\n",
      "ROC-AUC autoencoded: 0.5973\n",
      "ROC-AUC autoencoded: 0.5005\n",
      "ROC-AUC autoencoded: 0.5043\n",
      "ROC-AUC autoencoded: 0.5409\n",
      "ROC-AUC autoencoded: 0.5545\n",
      "ROC-AUC autoencoded: 0.4764\n",
      "ROC-AUC autoencoded: 0.5830\n",
      "ROC-AUC autoencoded: 0.6114\n",
      "ROC-AUC autoencoded: 0.5989\n",
      "ROC-AUC autoencoded: 0.6006\n",
      "ROC-AUC autoencoded: 0.6314\n",
      "среднее 0.5630171546783257\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(C=best_params['C'], max_iter=1000, random_state=42)\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:24:40,351] A new study created in memory with name: no-name-c6a6706b-a49b-40b5-82ac-89945faab6ed\n",
      "[I 2025-05-10 05:25:15,890] Trial 0 finished with value: 0.5341039797561536 and parameters: {'latent_dim': 61, 'hidden_dim': 119, 'lr': 0.003654338259718915, 'epochs': 47, 'dropout_rate': 0.34299285203109614, 'recon_weight': 0.2361807970967944, 'n_estimators': 301, 'max_depth': 7, 'learning_rate': 0.21540767464499924, 'subsample': 0.838414856453522, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.5341039797561536.\n",
      "[I 2025-05-10 05:26:14,346] Trial 1 finished with value: 0.5913848631239935 and parameters: {'latent_dim': 89, 'hidden_dim': 175, 'lr': 0.00011197310952973854, 'epochs': 49, 'dropout_rate': 0.1641335767379894, 'recon_weight': 0.7492632055185102, 'n_estimators': 148, 'max_depth': 4, 'learning_rate': 0.09080135655408744, 'subsample': 0.774890483235354, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.5913848631239935.\n",
      "[I 2025-05-10 05:27:06,727] Trial 2 finished with value: 0.5897362165478107 and parameters: {'latent_dim': 79, 'hidden_dim': 82, 'lr': 0.0007600339051316355, 'epochs': 24, 'dropout_rate': 0.49065334272847994, 'recon_weight': 0.2471396922098995, 'n_estimators': 365, 'max_depth': 4, 'learning_rate': 0.0724898020487585, 'subsample': 0.8442295764867921, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.5913848631239935.\n",
      "[I 2025-05-10 05:27:41,772] Trial 3 finished with value: 0.5609424123916877 and parameters: {'latent_dim': 47, 'hidden_dim': 117, 'lr': 0.00018041399219523185, 'epochs': 31, 'dropout_rate': 0.14735582157913477, 'recon_weight': 0.1983504892520463, 'n_estimators': 380, 'max_depth': 5, 'learning_rate': 0.029491918670830203, 'subsample': 0.7118577689519662, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.5913848631239935.\n",
      "[I 2025-05-10 05:28:04,317] Trial 4 finished with value: 0.6099608925695882 and parameters: {'latent_dim': 38, 'hidden_dim': 90, 'lr': 0.0003665011219242417, 'epochs': 27, 'dropout_rate': 0.2379647823388954, 'recon_weight': 0.5492788090388404, 'n_estimators': 180, 'max_depth': 9, 'learning_rate': 0.011956407010902287, 'subsample': 0.6465708928825146, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 4 with value: 0.6099608925695882.\n",
      "[I 2025-05-10 05:29:14,419] Trial 5 finished with value: 0.5259565984203665 and parameters: {'latent_dim': 100, 'hidden_dim': 155, 'lr': 0.001171003480526984, 'epochs': 33, 'dropout_rate': 0.2881088775671188, 'recon_weight': 0.7848157659234856, 'n_estimators': 409, 'max_depth': 4, 'learning_rate': 0.027165589493081545, 'subsample': 0.9704814783435866, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.6099608925695882.\n",
      "[I 2025-05-10 05:30:47,435] Trial 6 finished with value: 0.557089180277586 and parameters: {'latent_dim': 80, 'hidden_dim': 229, 'lr': 0.0003409417798496902, 'epochs': 46, 'dropout_rate': 0.13414269140459767, 'recon_weight': 0.6833720165243482, 'n_estimators': 443, 'max_depth': 6, 'learning_rate': 0.02485505829077557, 'subsample': 0.6238118697513622, 'min_samples_split': 14, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.6099608925695882.\n",
      "[I 2025-05-10 05:31:06,612] Trial 7 finished with value: 0.557185031822713 and parameters: {'latent_dim': 80, 'hidden_dim': 157, 'lr': 0.00778175070298187, 'epochs': 21, 'dropout_rate': 0.2701433205715856, 'recon_weight': 0.7655261685701011, 'n_estimators': 189, 'max_depth': 3, 'learning_rate': 0.15388000084559322, 'subsample': 0.6550460307666766, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 4 with value: 0.6099608925695882.\n",
      "[I 2025-05-10 05:32:52,883] Trial 8 finished with value: 0.5581435472739821 and parameters: {'latent_dim': 94, 'hidden_dim': 254, 'lr': 0.009650759795988778, 'epochs': 45, 'dropout_rate': 0.2909791848363075, 'recon_weight': 0.7690862173855807, 'n_estimators': 456, 'max_depth': 8, 'learning_rate': 0.030359509639728617, 'subsample': 0.8187183333709269, 'min_samples_split': 17, 'min_samples_leaf': 9}. Best is trial 4 with value: 0.6099608925695882.\n",
      "[I 2025-05-10 05:33:51,216] Trial 9 finished with value: 0.6131048232497508 and parameters: {'latent_dim': 96, 'hidden_dim': 239, 'lr': 0.0002103485993287784, 'epochs': 19, 'dropout_rate': 0.47565258060276927, 'recon_weight': 0.1664640812361139, 'n_estimators': 390, 'max_depth': 5, 'learning_rate': 0.014709883974054679, 'subsample': 0.7793725865104933, 'min_samples_split': 18, 'min_samples_leaf': 9}. Best is trial 9 with value: 0.6131048232497508.\n",
      "[I 2025-05-10 05:33:59,119] Trial 10 finished with value: 0.589573268921095 and parameters: {'latent_dim': 11, 'hidden_dim': 208, 'lr': 0.001598062255403245, 'epochs': 11, 'dropout_rate': 0.49877803268401, 'recon_weight': 0.44516688537458904, 'n_estimators': 76, 'max_depth': 10, 'learning_rate': 0.011803751846305407, 'subsample': 0.958594033394209, 'min_samples_split': 20, 'min_samples_leaf': 1}. Best is trial 9 with value: 0.6131048232497508.\n",
      "[I 2025-05-10 05:34:51,345] Trial 11 finished with value: 0.5984395368453339 and parameters: {'latent_dim': 34, 'hidden_dim': 64, 'lr': 0.00038351579661398627, 'epochs': 16, 'dropout_rate': 0.39535968688382367, 'recon_weight': 0.49188076100285005, 'n_estimators': 257, 'max_depth': 10, 'learning_rate': 0.010088247822157358, 'subsample': 0.7085746002203439, 'min_samples_split': 12, 'min_samples_leaf': 8}. Best is trial 9 with value: 0.6131048232497508.\n",
      "[I 2025-05-10 05:35:27,346] Trial 12 finished with value: 0.5562265163714439 and parameters: {'latent_dim': 31, 'hidden_dim': 201, 'lr': 0.0003288121786915584, 'epochs': 27, 'dropout_rate': 0.22932960777655131, 'recon_weight': 0.38055615253267616, 'n_estimators': 266, 'max_depth': 8, 'learning_rate': 0.017503061073065828, 'subsample': 0.7427799762777674, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 9 with value: 0.6131048232497508.\n",
      "[I 2025-05-10 05:36:38,173] Trial 13 finished with value: 0.5958323748178821 and parameters: {'latent_dim': 59, 'hidden_dim': 119, 'lr': 0.00010114650321415529, 'epochs': 37, 'dropout_rate': 0.402927597271878, 'recon_weight': 0.61848158322662, 'n_estimators': 171, 'max_depth': 8, 'learning_rate': 0.04891697075378409, 'subsample': 0.8964609869233292, 'min_samples_split': 14, 'min_samples_leaf': 10}. Best is trial 9 with value: 0.6131048232497508.\n",
      "[I 2025-05-10 05:37:06,403] Trial 14 finished with value: 0.5609807530097385 and parameters: {'latent_dim': 43, 'hidden_dim': 252, 'lr': 0.0006386291673102236, 'epochs': 19, 'dropout_rate': 0.20744379577062533, 'recon_weight': 0.349885203163468, 'n_estimators': 335, 'max_depth': 6, 'learning_rate': 0.013823180104299957, 'subsample': 0.6013908496440012, 'min_samples_split': 20, 'min_samples_leaf': 5}. Best is trial 9 with value: 0.6131048232497508.\n",
      "[I 2025-05-10 05:37:13,091] Trial 15 finished with value: 0.58944866191243 and parameters: {'latent_dim': 12, 'hidden_dim': 95, 'lr': 0.00020331008972146426, 'epochs': 12, 'dropout_rate': 0.35562955576030786, 'recon_weight': 0.11138248181900934, 'n_estimators': 76, 'max_depth': 9, 'learning_rate': 0.01763904476872087, 'subsample': 0.6688183936425853, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 9 with value: 0.6131048232497508.\n",
      "[I 2025-05-10 05:38:29,959] Trial 16 finished with value: 0.5602714515757994 and parameters: {'latent_dim': 68, 'hidden_dim': 186, 'lr': 0.00197900222431288, 'epochs': 26, 'dropout_rate': 0.419365517797144, 'recon_weight': 0.577923399421472, 'n_estimators': 216, 'max_depth': 7, 'learning_rate': 0.04561306946764815, 'subsample': 0.9036662032674845, 'min_samples_split': 17, 'min_samples_leaf': 7}. Best is trial 9 with value: 0.6131048232497508.\n",
      "[I 2025-05-10 05:38:49,941] Trial 17 finished with value: 0.5878191856452725 and parameters: {'latent_dim': 25, 'hidden_dim': 146, 'lr': 0.0004778329613047896, 'epochs': 38, 'dropout_rate': 0.21689772395987572, 'recon_weight': 0.8943279090956412, 'n_estimators': 126, 'max_depth': 5, 'learning_rate': 0.017698897441480704, 'subsample': 0.7840898163067677, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 9 with value: 0.6131048232497508.\n",
      "[I 2025-05-10 05:40:22,716] Trial 18 finished with value: 0.5882217621348055 and parameters: {'latent_dim': 46, 'hidden_dim': 218, 'lr': 0.00017117383408644425, 'epochs': 17, 'dropout_rate': 0.4472092914474608, 'recon_weight': 0.3439356866102534, 'n_estimators': 494, 'max_depth': 9, 'learning_rate': 0.036314731819397865, 'subsample': 0.6842674507146355, 'min_samples_split': 12, 'min_samples_leaf': 9}. Best is trial 9 with value: 0.6131048232497508.\n",
      "[I 2025-05-10 05:40:52,218] Trial 19 finished with value: 0.5734414538762365 and parameters: {'latent_dim': 69, 'hidden_dim': 138, 'lr': 0.00022422732729570556, 'epochs': 22, 'dropout_rate': 0.10319994316087094, 'recon_weight': 0.5686524802242104, 'n_estimators': 223, 'max_depth': 5, 'learning_rate': 0.020161467942298682, 'subsample': 0.7462813077259092, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 9 with value: 0.6131048232497508.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6519\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Веса для объединенной функции потерь\n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    # Параметры градиентного бустинга\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5188\n",
      "ROC-AUC autoencoded: 0.5318\n",
      "ROC-AUC autoencoded: 0.5274\n",
      "ROC-AUC autoencoded: 0.5243\n",
      "ROC-AUC autoencoded: 0.5582\n",
      "ROC-AUC autoencoded: 0.5740\n",
      "ROC-AUC autoencoded: 0.5193\n",
      "ROC-AUC autoencoded: 0.6054\n",
      "ROC-AUC autoencoded: 0.5723\n",
      "ROC-AUC autoencoded: 0.5570\n",
      "ROC-AUC autoencoded: 0.5768\n",
      "ROC-AUC autoencoded: 0.5790\n",
      "ROC-AUC autoencoded: 0.5542\n",
      "ROC-AUC autoencoded: 0.6221\n",
      "ROC-AUC autoencoded: 0.6059\n",
      "ROC-AUC autoencoded: 0.4867\n",
      "ROC-AUC autoencoded: 0.5469\n",
      "ROC-AUC autoencoded: 0.5362\n",
      "ROC-AUC autoencoded: 0.5363\n",
      "ROC-AUC autoencoded: 0.5239\n",
      "ROC-AUC autoencoded: 0.5611\n",
      "ROC-AUC autoencoded: 0.5923\n",
      "ROC-AUC autoencoded: 0.6301\n",
      "ROC-AUC autoencoded: 0.5855\n",
      "ROC-AUC autoencoded: 0.6056\n",
      "среднее 0.5612410437403015\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:49:27,619] A new study created in memory with name: no-name-760c75bd-1726-4191-a7d0-aa56c2c718ed\n",
      "[I 2025-05-10 05:49:45,019] Trial 0 finished with value: 0.5681121079671804 and parameters: {'latent_dim': 56, 'hidden_dim': 73, 'lr': 0.00047974457564613703, 'epochs': 44, 'dropout_rate': 0.21595217489505714, 'recon_weight': 0.8921900439922368, 'C': 3.2282958624929936, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 0 with value: 0.5681121079671804.\n",
      "[I 2025-05-10 05:49:51,348] Trial 1 finished with value: 0.5611724560999923 and parameters: {'latent_dim': 28, 'hidden_dim': 227, 'lr': 0.002326108533681792, 'epochs': 14, 'dropout_rate': 0.398411912772509, 'recon_weight': 0.5099587406414563, 'C': 1.1447383175573178, 'kernel': 'linear'}. Best is trial 0 with value: 0.5681121079671804.\n",
      "[I 2025-05-10 05:49:57,147] Trial 2 finished with value: 0.5655432865577792 and parameters: {'latent_dim': 38, 'hidden_dim': 108, 'lr': 0.0001442802275414858, 'epochs': 13, 'dropout_rate': 0.3069689118611084, 'recon_weight': 0.3775655688532835, 'C': 0.8948185016691907, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 0 with value: 0.5681121079671804.\n",
      "[I 2025-05-10 05:50:06,402] Trial 3 finished with value: 0.558047695728855 and parameters: {'latent_dim': 42, 'hidden_dim': 224, 'lr': 0.0009790414557780223, 'epochs': 17, 'dropout_rate': 0.35666815016234443, 'recon_weight': 0.23019994573239277, 'C': 35.3001904242561, 'kernel': 'linear'}. Best is trial 0 with value: 0.5681121079671804.\n",
      "[I 2025-05-10 05:50:13,509] Trial 4 finished with value: 0.5496798558392761 and parameters: {'latent_dim': 26, 'hidden_dim': 209, 'lr': 0.0008001503808388908, 'epochs': 16, 'dropout_rate': 0.11474829762635644, 'recon_weight': 0.6142441699866954, 'C': 11.155621034104678, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.5681121079671804.\n",
      "[I 2025-05-10 05:50:25,896] Trial 5 finished with value: 0.5506383712905452 and parameters: {'latent_dim': 54, 'hidden_dim': 186, 'lr': 0.0005276978260503176, 'epochs': 27, 'dropout_rate': 0.15962687749817325, 'recon_weight': 0.7761077468670833, 'C': 1.3047982059810075, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 0 with value: 0.5681121079671804.\n",
      "[I 2025-05-10 05:50:37,870] Trial 6 finished with value: 0.5324169925619201 and parameters: {'latent_dim': 23, 'hidden_dim': 214, 'lr': 0.0004172006352698537, 'epochs': 26, 'dropout_rate': 0.18754123175988235, 'recon_weight': 0.5039956949005708, 'C': 4.147658284262847, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.5681121079671804.\n",
      "[I 2025-05-10 05:50:43,647] Trial 7 finished with value: 0.5337397438846715 and parameters: {'latent_dim': 26, 'hidden_dim': 226, 'lr': 0.008938982949513981, 'epochs': 12, 'dropout_rate': 0.44368351209004875, 'recon_weight': 0.18627524721684818, 'C': 2.165372015612392, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 0 with value: 0.5681121079671804.\n",
      "[I 2025-05-10 05:50:53,717] Trial 8 finished with value: 0.5881834215167548 and parameters: {'latent_dim': 15, 'hidden_dim': 135, 'lr': 0.00017995819878544343, 'epochs': 23, 'dropout_rate': 0.16951511374461203, 'recon_weight': 0.42648339464369556, 'C': 0.13991867510311348, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 8 with value: 0.5881834215167548.\n",
      "[I 2025-05-10 05:51:17,133] Trial 9 finished with value: 0.521077754773407 and parameters: {'latent_dim': 11, 'hidden_dim': 231, 'lr': 0.0057454745227193, 'epochs': 18, 'dropout_rate': 0.17309159404327623, 'recon_weight': 0.6504640463764587, 'C': 46.17038132891853, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 8 with value: 0.5881834215167548.\n",
      "[I 2025-05-10 05:51:34,556] Trial 10 finished with value: 0.6194597806916647 and parameters: {'latent_dim': 91, 'hidden_dim': 136, 'lr': 0.00013488269608118855, 'epochs': 40, 'dropout_rate': 0.2533325371277231, 'recon_weight': 0.3112727326957498, 'C': 0.12820341845424466, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 10 with value: 0.6194597806916647.\n",
      "[I 2025-05-10 05:51:52,959] Trial 11 finished with value: 0.6089544513457558 and parameters: {'latent_dim': 94, 'hidden_dim': 143, 'lr': 0.00010463542772557702, 'epochs': 40, 'dropout_rate': 0.2592122195002162, 'recon_weight': 0.34922531244700383, 'C': 0.1320887068795656, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 10 with value: 0.6194597806916647.\n",
      "[I 2025-05-10 05:52:10,611] Trial 12 finished with value: 0.6464419906448892 and parameters: {'latent_dim': 99, 'hidden_dim': 149, 'lr': 0.0001063686243104253, 'epochs': 39, 'dropout_rate': 0.2851118039498023, 'recon_weight': 0.30884679531444503, 'C': 0.11106778766868425, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 12 with value: 0.6464419906448892.\n",
      "[I 2025-05-10 05:52:27,075] Trial 13 finished with value: 0.5858638141246836 and parameters: {'latent_dim': 100, 'hidden_dim': 176, 'lr': 0.0002279402421984198, 'epochs': 36, 'dropout_rate': 0.29441001056362637, 'recon_weight': 0.1206479626565099, 'C': 0.3747066115101212, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 12 with value: 0.6464419906448892.\n",
      "[I 2025-05-10 05:52:47,936] Trial 14 finished with value: 0.5919983130128058 and parameters: {'latent_dim': 82, 'hidden_dim': 114, 'lr': 0.00027379927241780026, 'epochs': 50, 'dropout_rate': 0.2449266444868876, 'recon_weight': 0.2816738150966085, 'C': 0.309067992830577, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 12 with value: 0.6464419906448892.\n",
      "[I 2025-05-10 05:53:02,449] Trial 15 finished with value: 0.5514818648876619 and parameters: {'latent_dim': 80, 'hidden_dim': 151, 'lr': 0.0018992952113924065, 'epochs': 34, 'dropout_rate': 0.3178537747097769, 'recon_weight': 0.3072192126818745, 'C': 0.10017763659801425, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 12 with value: 0.6464419906448892.\n",
      "[I 2025-05-10 05:53:34,903] Trial 16 finished with value: 0.6195652173913043 and parameters: {'latent_dim': 80, 'hidden_dim': 109, 'lr': 0.00011013538445705406, 'epochs': 45, 'dropout_rate': 0.4921930377423835, 'recon_weight': 0.13185055732509166, 'C': 0.379001366427646, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 12 with value: 0.6464419906448892.\n",
      "[I 2025-05-10 05:54:28,176] Trial 17 finished with value: 0.582815734989648 and parameters: {'latent_dim': 72, 'hidden_dim': 65, 'lr': 0.0003172717645009328, 'epochs': 48, 'dropout_rate': 0.4950109287081787, 'recon_weight': 0.11306449408471514, 'C': 0.41101475242433777, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 12 with value: 0.6464419906448892.\n",
      "[I 2025-05-10 05:54:56,984] Trial 18 finished with value: 0.6163254351660149 and parameters: {'latent_dim': 67, 'hidden_dim': 90, 'lr': 0.00010182690298564115, 'epochs': 44, 'dropout_rate': 0.3830195044944505, 'recon_weight': 0.19328492419159257, 'C': 0.588165085491048, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 12 with value: 0.6464419906448892.\n",
      "[I 2025-05-10 05:55:11,749] Trial 19 finished with value: 0.546181274442144 and parameters: {'latent_dim': 84, 'hidden_dim': 256, 'lr': 0.002166496635658767, 'epochs': 33, 'dropout_rate': 0.47388825976217547, 'recon_weight': 0.4352572381595481, 'C': 0.25158751237460114, 'kernel': 'linear'}. Best is trial 12 with value: 0.6464419906448892.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6241\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5716\n",
      "ROC-AUC autoencoded: 0.5497\n",
      "ROC-AUC autoencoded: 0.5924\n",
      "ROC-AUC autoencoded: 0.5640\n",
      "ROC-AUC autoencoded: 0.5303\n",
      "ROC-AUC autoencoded: 0.5849\n",
      "ROC-AUC autoencoded: 0.5845\n",
      "ROC-AUC autoencoded: 0.5701\n",
      "ROC-AUC autoencoded: 0.5785\n",
      "ROC-AUC autoencoded: 0.5525\n",
      "ROC-AUC autoencoded: 0.5762\n",
      "ROC-AUC autoencoded: 0.5708\n",
      "ROC-AUC autoencoded: 0.5985\n",
      "ROC-AUC autoencoded: 0.5904\n",
      "ROC-AUC autoencoded: 0.5769\n",
      "ROC-AUC autoencoded: 0.5372\n",
      "ROC-AUC autoencoded: 0.5400\n",
      "ROC-AUC autoencoded: 0.5075\n",
      "ROC-AUC autoencoded: 0.5111\n",
      "ROC-AUC autoencoded: 0.5185\n",
      "ROC-AUC autoencoded: 0.6109\n",
      "ROC-AUC autoencoded: 0.6111\n",
      "ROC-AUC autoencoded: 0.6360\n",
      "ROC-AUC autoencoded: 0.6278\n",
      "ROC-AUC autoencoded: 0.6339\n",
      "среднее 0.5730146912399792\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:58:29,252] A new study created in memory with name: no-name-cfd3d2e5-6ff9-44eb-8d1a-2a5f6fb0efe9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 05:58:45,230] Trial 0 finished with value: 0.5269151138716356 and parameters: {'latent_dim': 67, 'hidden_dim': 98, 'lr': 0.00734198502197382, 'epochs': 15, 'dropout_rate': 0.22772502745690157, 'recon_weight': 0.6247249534354754}. Best is trial 0 with value: 0.5269151138716356.\n",
      "[I 2025-05-10 05:59:08,425] Trial 1 finished with value: 0.5619392684610075 and parameters: {'latent_dim': 72, 'hidden_dim': 113, 'lr': 0.00019523241909981097, 'epochs': 34, 'dropout_rate': 0.12569018127256315, 'recon_weight': 0.20379540206085356}. Best is trial 1 with value: 0.5619392684610075.\n",
      "[I 2025-05-10 05:59:27,047] Trial 2 finished with value: 0.6145617667356799 and parameters: {'latent_dim': 54, 'hidden_dim': 174, 'lr': 0.00024141022063822796, 'epochs': 46, 'dropout_rate': 0.4105535653264636, 'recon_weight': 0.7967931026575875}. Best is trial 2 with value: 0.6145617667356799.\n",
      "[I 2025-05-10 05:59:37,350] Trial 3 finished with value: 0.5650640288321448 and parameters: {'latent_dim': 48, 'hidden_dim': 174, 'lr': 0.0004301457887444728, 'epochs': 25, 'dropout_rate': 0.27258871773074766, 'recon_weight': 0.303068669176158}. Best is trial 2 with value: 0.6145617667356799.\n",
      "[I 2025-05-10 05:59:43,827] Trial 4 finished with value: 0.5658116708841346 and parameters: {'latent_dim': 23, 'hidden_dim': 205, 'lr': 0.0006327890354921857, 'epochs': 15, 'dropout_rate': 0.14957381234795344, 'recon_weight': 0.5265330611042324}. Best is trial 2 with value: 0.6145617667356799.\n",
      "[I 2025-05-10 06:00:17,961] Trial 5 finished with value: 0.5946054750402575 and parameters: {'latent_dim': 31, 'hidden_dim': 152, 'lr': 0.0005202276835596036, 'epochs': 31, 'dropout_rate': 0.282995511277255, 'recon_weight': 0.8717786605888186}. Best is trial 2 with value: 0.6145617667356799.\n",
      "[I 2025-05-10 06:00:39,117] Trial 6 finished with value: 0.5548654244306418 and parameters: {'latent_dim': 91, 'hidden_dim': 116, 'lr': 0.006914881841573923, 'epochs': 19, 'dropout_rate': 0.26679276310700867, 'recon_weight': 0.5786960288677576}. Best is trial 2 with value: 0.6145617667356799.\n",
      "[I 2025-05-10 06:01:08,867] Trial 7 finished with value: 0.6287094547964113 and parameters: {'latent_dim': 73, 'hidden_dim': 191, 'lr': 0.000105496088060103, 'epochs': 38, 'dropout_rate': 0.38152999350619654, 'recon_weight': 0.4217723183670091}. Best is trial 7 with value: 0.6287094547964113.\n",
      "[I 2025-05-10 06:01:24,414] Trial 8 finished with value: 0.55200904838586 and parameters: {'latent_dim': 39, 'hidden_dim': 180, 'lr': 0.009981486875855579, 'epochs': 38, 'dropout_rate': 0.45245525289478905, 'recon_weight': 0.4170154514327863}. Best is trial 7 with value: 0.6287094547964113.\n",
      "[I 2025-05-10 06:01:33,940] Trial 9 finished with value: 0.5652940725404494 and parameters: {'latent_dim': 83, 'hidden_dim': 176, 'lr': 0.00024207488661288372, 'epochs': 23, 'dropout_rate': 0.16104722344001146, 'recon_weight': 0.3482327940813412}. Best is trial 7 with value: 0.6287094547964113.\n",
      "[I 2025-05-10 06:02:17,743] Trial 10 finished with value: 0.5315734989648032 and parameters: {'latent_dim': 96, 'hidden_dim': 255, 'lr': 0.0023721169909662557, 'epochs': 49, 'dropout_rate': 0.37301842804558033, 'recon_weight': 0.14609738768908337}. Best is trial 7 with value: 0.6287094547964113.\n",
      "[I 2025-05-10 06:03:09,390] Trial 11 finished with value: 0.6139866574649183 and parameters: {'latent_dim': 61, 'hidden_dim': 224, 'lr': 0.000102371131187385, 'epochs': 45, 'dropout_rate': 0.39266915102029154, 'recon_weight': 0.7620973232110213}. Best is trial 7 with value: 0.6287094547964113.\n",
      "[I 2025-05-10 06:03:25,320] Trial 12 finished with value: 0.617935741124147 and parameters: {'latent_dim': 52, 'hidden_dim': 146, 'lr': 0.00010060831172412597, 'epochs': 40, 'dropout_rate': 0.49532900034621813, 'recon_weight': 0.6971786567959848}. Best is trial 7 with value: 0.6287094547964113.\n",
      "[I 2025-05-10 06:03:41,006] Trial 13 finished with value: 0.6212138639674871 and parameters: {'latent_dim': 77, 'hidden_dim': 144, 'lr': 0.00010557628631229896, 'epochs': 38, 'dropout_rate': 0.4875776704866222, 'recon_weight': 0.6824953443528622}. Best is trial 7 with value: 0.6287094547964113.\n",
      "[I 2025-05-10 06:04:04,095] Trial 14 finished with value: 0.5892952994402268 and parameters: {'latent_dim': 77, 'hidden_dim': 80, 'lr': 0.001409674768211406, 'epochs': 38, 'dropout_rate': 0.494482663197408, 'recon_weight': 0.4547647065592831}. Best is trial 7 with value: 0.6287094547964113.\n",
      "[I 2025-05-10 06:04:38,604] Trial 15 finished with value: 0.6368951767502492 and parameters: {'latent_dim': 83, 'hidden_dim': 135, 'lr': 0.0001477423627250759, 'epochs': 28, 'dropout_rate': 0.32672164766106826, 'recon_weight': 0.67307114903676}. Best is trial 15 with value: 0.6368951767502492.\n",
      "[I 2025-05-10 06:05:08,292] Trial 16 finished with value: 0.6250670960815888 and parameters: {'latent_dim': 87, 'hidden_dim': 207, 'lr': 0.0002078059793219478, 'epochs': 28, 'dropout_rate': 0.33678801170705663, 'recon_weight': 0.5073856825927658}. Best is trial 15 with value: 0.6368951767502492.\n",
      "[I 2025-05-10 06:05:21,975] Trial 17 finished with value: 0.5495552488306111 and parameters: {'latent_dim': 100, 'hidden_dim': 134, 'lr': 0.0011111174018797953, 'epochs': 34, 'dropout_rate': 0.3242595239523163, 'recon_weight': 0.2916518521608841}. Best is trial 15 with value: 0.6368951767502492.\n",
      "[I 2025-05-10 06:05:25,672] Trial 18 finished with value: 0.5673261252971398 and parameters: {'latent_dim': 65, 'hidden_dim': 68, 'lr': 0.002999314824378865, 'epochs': 10, 'dropout_rate': 0.21257832368120216, 'recon_weight': 0.41999604745703356}. Best is trial 15 with value: 0.6368951767502492.\n",
      "[I 2025-05-10 06:05:38,509] Trial 19 finished with value: 0.5836592285867649 and parameters: {'latent_dim': 84, 'hidden_dim': 199, 'lr': 0.0003697500891185422, 'epochs': 30, 'dropout_rate': 0.3418632160703925, 'recon_weight': 0.6035056127270068}. Best is trial 15 with value: 0.6368951767502492.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6274\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры автоэнкодера\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Веса для объединенной функции потерь\n",
    "    recon_weight = trial.suggest_float('recon_weight', 0.1, 0.9)\n",
    "    class_weight = 1.0 - recon_weight\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, recon_weight, class_weight)\n",
    "        \n",
    "        # Используем голову классификатора для получения предсказаний\n",
    "        y_pred_proba = predict_with_classifier_head(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "def predict_with_classifier_head(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, _, classification = model(X_tensor)\n",
    "    return classification.cpu().numpy().flatten()\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    ")\n",
    "\n",
    "# Используем голову классификатора для получения предсказаний\n",
    "y_pred_proba = predict_with_classifier_head(autoencoder, X_val_all)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5261\n",
      "ROC-AUC autoencoded: 0.6081\n",
      "ROC-AUC autoencoded: 0.5570\n",
      "ROC-AUC autoencoded: 0.5005\n",
      "ROC-AUC autoencoded: 0.5625\n",
      "ROC-AUC autoencoded: 0.5726\n",
      "ROC-AUC autoencoded: 0.5905\n",
      "ROC-AUC autoencoded: 0.5795\n",
      "ROC-AUC autoencoded: 0.5616\n",
      "ROC-AUC autoencoded: 0.5715\n",
      "ROC-AUC autoencoded: 0.6194\n",
      "ROC-AUC autoencoded: 0.5781\n",
      "ROC-AUC autoencoded: 0.5411\n",
      "ROC-AUC autoencoded: 0.5976\n",
      "ROC-AUC autoencoded: 0.5849\n",
      "ROC-AUC autoencoded: 0.5222\n",
      "ROC-AUC autoencoded: 0.5460\n",
      "ROC-AUC autoencoded: 0.5604\n",
      "ROC-AUC autoencoded: 0.6128\n",
      "ROC-AUC autoencoded: 0.5180\n",
      "ROC-AUC autoencoded: 0.5983\n",
      "ROC-AUC autoencoded: 0.6599\n",
      "ROC-AUC autoencoded: 0.6541\n",
      "ROC-AUC autoencoded: 0.6327\n",
      "ROC-AUC autoencoded: 0.6247\n",
      "среднее 0.579202063441065\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['recon_weight'], 1.0 - best_params['recon_weight']\n",
    "        )\n",
    "        \n",
    "        # Используем голову классификатора для получения предсказаний\n",
    "        y_pred_proba = predict_with_classifier_head(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше идет блок со sparse автоэнкодером без классифицирующей головы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 06:07:49,620] A new study created in memory with name: no-name-0f7f5a7f-04f4-4467-8d35-ee42debc2933\n",
      "[I 2025-05-10 06:08:25,098] Trial 0 finished with value: 0.6016409784525726 and parameters: {'latent_dim': 66, 'hidden_dim': 200, 'lr': 0.00032879586500134724, 'epochs': 38, 'dropout_rate': 0.1869359705094968, 'sparsity_weight': 0.019422574155018142, 'C': 0.18950395517933946, 'solver': 'liblinear'}. Best is trial 0 with value: 0.6016409784525726.\n",
      "[I 2025-05-10 06:08:59,759] Trial 1 finished with value: 0.602618664212867 and parameters: {'latent_dim': 98, 'hidden_dim': 127, 'lr': 0.00018096366943501873, 'epochs': 34, 'dropout_rate': 0.4925606680613889, 'sparsity_weight': 0.00018850171156886358, 'C': 0.01994311181469919, 'solver': 'saga'}. Best is trial 1 with value: 0.602618664212867.\n",
      "[I 2025-05-10 06:09:11,219] Trial 2 finished with value: 0.610248447204969 and parameters: {'latent_dim': 85, 'hidden_dim': 189, 'lr': 0.00012497734648260215, 'epochs': 12, 'dropout_rate': 0.1121922096078603, 'sparsity_weight': 0.0015852516623763345, 'C': 8.963110955374669, 'solver': 'liblinear'}. Best is trial 2 with value: 0.610248447204969.\n",
      "[I 2025-05-10 06:09:22,872] Trial 3 finished with value: 0.5955639904915269 and parameters: {'latent_dim': 92, 'hidden_dim': 178, 'lr': 0.00016607281155030132, 'epochs': 29, 'dropout_rate': 0.26442896541217564, 'sparsity_weight': 0.00020725565109140038, 'C': 1.2247714768310018, 'solver': 'liblinear'}. Best is trial 2 with value: 0.610248447204969.\n",
      "[I 2025-05-10 06:09:38,306] Trial 4 finished with value: 0.6167280116555479 and parameters: {'latent_dim': 23, 'hidden_dim': 145, 'lr': 0.0009989972162771936, 'epochs': 44, 'dropout_rate': 0.3873614668289923, 'sparsity_weight': 0.058778025013026765, 'C': 0.22033725890293418, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.6167280116555479.\n",
      "[I 2025-05-10 06:09:52,723] Trial 5 finished with value: 0.6034429875009585 and parameters: {'latent_dim': 52, 'hidden_dim': 110, 'lr': 0.008590986607936533, 'epochs': 43, 'dropout_rate': 0.18255900999389124, 'sparsity_weight': 0.07437744813059691, 'C': 1.7215477359959321, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.6167280116555479.\n",
      "[I 2025-05-10 06:10:30,129] Trial 6 finished with value: 0.6225557855992639 and parameters: {'latent_dim': 74, 'hidden_dim': 113, 'lr': 0.000430654111256817, 'epochs': 45, 'dropout_rate': 0.15991433718956652, 'sparsity_weight': 0.008306156847755741, 'C': 0.030725527977385467, 'solver': 'saga'}. Best is trial 6 with value: 0.6225557855992639.\n",
      "[I 2025-05-10 06:10:53,722] Trial 7 finished with value: 0.5903688367456483 and parameters: {'latent_dim': 62, 'hidden_dim': 108, 'lr': 0.0066550405272345495, 'epochs': 24, 'dropout_rate': 0.1017180469015428, 'sparsity_weight': 0.06601631778567404, 'C': 52.430518204121405, 'solver': 'saga'}. Best is trial 6 with value: 0.6225557855992639.\n",
      "[I 2025-05-10 06:11:16,636] Trial 8 finished with value: 0.5787132888582165 and parameters: {'latent_dim': 81, 'hidden_dim': 65, 'lr': 0.00027103975856704917, 'epochs': 39, 'dropout_rate': 0.33482988729613594, 'sparsity_weight': 0.03910792229689008, 'C': 14.643030459131646, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.6225557855992639.\n",
      "[I 2025-05-10 06:11:32,421] Trial 9 finished with value: 0.6155202821869489 and parameters: {'latent_dim': 57, 'hidden_dim': 219, 'lr': 0.0032836675896410323, 'epochs': 43, 'dropout_rate': 0.34172705714556983, 'sparsity_weight': 0.0001964342110308156, 'C': 0.05881762947631899, 'solver': 'saga'}. Best is trial 6 with value: 0.6225557855992639.\n",
      "[I 2025-05-10 06:11:50,387] Trial 10 finished with value: 0.6246070086649796 and parameters: {'latent_dim': 30, 'hidden_dim': 243, 'lr': 0.0006783780415223509, 'epochs': 49, 'dropout_rate': 0.23789593430517852, 'sparsity_weight': 0.005445772702491213, 'C': 0.010417152558849285, 'solver': 'saga'}. Best is trial 10 with value: 0.6246070086649796.\n",
      "[I 2025-05-10 06:12:33,392] Trial 11 finished with value: 0.6245111571198528 and parameters: {'latent_dim': 30, 'hidden_dim': 235, 'lr': 0.0007633910519058303, 'epochs': 50, 'dropout_rate': 0.2271352338487891, 'sparsity_weight': 0.0071846377906678765, 'C': 0.011379546435584526, 'solver': 'saga'}. Best is trial 10 with value: 0.6246070086649796.\n",
      "[I 2025-05-10 06:13:18,432] Trial 12 finished with value: 0.6195077064642283 and parameters: {'latent_dim': 26, 'hidden_dim': 250, 'lr': 0.0008566936417809854, 'epochs': 50, 'dropout_rate': 0.24114403178831992, 'sparsity_weight': 0.002201368456741783, 'C': 0.01430076007648128, 'solver': 'saga'}. Best is trial 10 with value: 0.6246070086649796.\n",
      "[I 2025-05-10 06:13:36,676] Trial 13 finished with value: 0.6215589295299441 and parameters: {'latent_dim': 38, 'hidden_dim': 256, 'lr': 0.0015778910241518766, 'epochs': 50, 'dropout_rate': 0.24752758415663345, 'sparsity_weight': 0.006371562079337792, 'C': 0.12525649771224712, 'solver': 'saga'}. Best is trial 10 with value: 0.6246070086649796.\n",
      "[I 2025-05-10 06:13:44,552] Trial 14 finished with value: 0.6192009815198221 and parameters: {'latent_dim': 14, 'hidden_dim': 238, 'lr': 0.0005781316157203391, 'epochs': 21, 'dropout_rate': 0.2884669734474821, 'sparsity_weight': 0.0013382136139343677, 'C': 0.013079923153387452, 'solver': 'saga'}. Best is trial 10 with value: 0.6246070086649796.\n",
      "[I 2025-05-10 06:14:11,156] Trial 15 finished with value: 0.5955831608005521 and parameters: {'latent_dim': 42, 'hidden_dim': 210, 'lr': 0.001816424069975053, 'epochs': 50, 'dropout_rate': 0.21194844300000068, 'sparsity_weight': 0.005981741986005478, 'C': 0.522544292291156, 'solver': 'saga'}. Best is trial 10 with value: 0.6246070086649796.\n",
      "[I 2025-05-10 06:14:51,488] Trial 16 finished with value: 0.6309140403343302 and parameters: {'latent_dim': 37, 'hidden_dim': 226, 'lr': 0.0006394522960987922, 'epochs': 34, 'dropout_rate': 0.38983177853982653, 'sparsity_weight': 0.0005628053123459525, 'C': 0.07821745375133632, 'solver': 'saga'}. Best is trial 16 with value: 0.6309140403343302.\n",
      "[I 2025-05-10 06:15:18,444] Trial 17 finished with value: 0.6158845180584311 and parameters: {'latent_dim': 10, 'hidden_dim': 169, 'lr': 0.0018521001051942845, 'epochs': 29, 'dropout_rate': 0.4309115727532451, 'sparsity_weight': 0.0006052344953106844, 'C': 0.06008111700001712, 'solver': 'saga'}. Best is trial 16 with value: 0.6309140403343302.\n",
      "[I 2025-05-10 06:15:23,746] Trial 18 finished with value: 0.6247987117552335 and parameters: {'latent_dim': 44, 'hidden_dim': 223, 'lr': 0.000510896255558822, 'epochs': 13, 'dropout_rate': 0.4109718669074062, 'sparsity_weight': 0.0005950663500587176, 'C': 0.06026025595592223, 'solver': 'lbfgs'}. Best is trial 16 with value: 0.6309140403343302.\n",
      "[I 2025-05-10 06:15:27,396] Trial 19 finished with value: 0.5714477417375968 and parameters: {'latent_dim': 44, 'hidden_dim': 220, 'lr': 0.00040195658279703787, 'epochs': 10, 'dropout_rate': 0.441712002323879, 'sparsity_weight': 0.0005285521102795247, 'C': 0.4610216414244244, 'solver': 'lbfgs'}. Best is trial 16 with value: 0.6309140403343302.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6092\n"
     ]
    }
   ],
   "source": [
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "    \n",
    "def train_sparse_autoencoder(model, X_train, epochs, batch_size, lr, sparsity_weight):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, _ in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, latent = model(batch_x)\n",
    "            \n",
    "            recon_loss = criterion(reconstructed, batch_x)\n",
    "            \n",
    "            sparsity_loss = torch.mean(torch.abs(latent))\n",
    "            \n",
    "            loss = recon_loss + sparsity_weight * sparsity_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs, batch_size, lr, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5638\n",
      "ROC-AUC autoencoded: 0.5814\n",
      "ROC-AUC autoencoded: 0.5364\n",
      "ROC-AUC autoencoded: 0.5628\n",
      "ROC-AUC autoencoded: 0.5525\n",
      "ROC-AUC autoencoded: 0.5707\n",
      "ROC-AUC autoencoded: 0.5561\n",
      "ROC-AUC autoencoded: 0.5417\n",
      "ROC-AUC autoencoded: 0.5612\n",
      "ROC-AUC autoencoded: 0.5731\n",
      "ROC-AUC autoencoded: 0.5634\n",
      "ROC-AUC autoencoded: 0.5870\n",
      "ROC-AUC autoencoded: 0.5443\n",
      "ROC-AUC autoencoded: 0.5353\n",
      "ROC-AUC autoencoded: 0.5377\n",
      "ROC-AUC autoencoded: 0.5357\n",
      "ROC-AUC autoencoded: 0.5664\n",
      "ROC-AUC autoencoded: 0.5287\n",
      "ROC-AUC autoencoded: 0.5225\n",
      "ROC-AUC autoencoded: 0.5236\n",
      "ROC-AUC autoencoded: 0.5961\n",
      "ROC-AUC autoencoded: 0.6176\n",
      "ROC-AUC autoencoded: 0.6182\n",
      "ROC-AUC autoencoded: 0.6284\n",
      "ROC-AUC autoencoded: 0.6044\n",
      "среднее 0.5643469057440909\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 06:17:46,076] A new study created in memory with name: no-name-24e317de-b6ca-469d-bf89-221cfe33288d\n",
      "[I 2025-05-10 06:18:41,779] Trial 0 finished with value: 0.5166398282340311 and parameters: {'latent_dim': 49, 'hidden_dim': 158, 'lr': 0.00011412726921265401, 'epochs': 25, 'dropout_rate': 0.364293486010539, 'sparsity_weight': 0.0015424374449212344, 'n_estimators': 343, 'max_depth': 10, 'learning_rate': 0.2819694645241251, 'subsample': 0.6192154634230002, 'min_samples_split': 10, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.5166398282340311.\n",
      "[I 2025-05-10 06:19:29,234] Trial 1 finished with value: 0.5247296986427421 and parameters: {'latent_dim': 30, 'hidden_dim': 207, 'lr': 0.003158075232747882, 'epochs': 18, 'dropout_rate': 0.4516832187399874, 'sparsity_weight': 0.01582257035721075, 'n_estimators': 436, 'max_depth': 7, 'learning_rate': 0.2744097526296593, 'subsample': 0.8269602116312261, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.5247296986427421.\n",
      "[I 2025-05-10 06:20:08,158] Trial 2 finished with value: 0.5950463921478414 and parameters: {'latent_dim': 59, 'hidden_dim': 225, 'lr': 0.005567248214445647, 'epochs': 33, 'dropout_rate': 0.199015100868016, 'sparsity_weight': 0.00016473954170174342, 'n_estimators': 228, 'max_depth': 8, 'learning_rate': 0.08706155313799295, 'subsample': 0.6414777170928326, 'min_samples_split': 16, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.5950463921478414.\n",
      "[I 2025-05-10 06:21:21,328] Trial 3 finished with value: 0.5761444674488153 and parameters: {'latent_dim': 57, 'hidden_dim': 133, 'lr': 0.0007240526822435851, 'epochs': 27, 'dropout_rate': 0.4096762249929806, 'sparsity_weight': 0.027323601231404107, 'n_estimators': 161, 'max_depth': 10, 'learning_rate': 0.026195113031223967, 'subsample': 0.9537519971680806, 'min_samples_split': 11, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.5950463921478414.\n",
      "[I 2025-05-10 06:22:35,446] Trial 4 finished with value: 0.565926692738287 and parameters: {'latent_dim': 79, 'hidden_dim': 181, 'lr': 0.000651566942566258, 'epochs': 35, 'dropout_rate': 0.16673084849575273, 'sparsity_weight': 0.001001455869450861, 'n_estimators': 269, 'max_depth': 9, 'learning_rate': 0.013602295451036356, 'subsample': 0.6315361316236687, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.5950463921478414.\n",
      "[I 2025-05-10 06:23:31,628] Trial 5 finished with value: 0.6076412851775169 and parameters: {'latent_dim': 25, 'hidden_dim': 183, 'lr': 0.00023481291684961726, 'epochs': 22, 'dropout_rate': 0.3667739634303817, 'sparsity_weight': 0.07963298211494299, 'n_estimators': 360, 'max_depth': 10, 'learning_rate': 0.02685129733643716, 'subsample': 0.9716124480225945, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:25:19,210] Trial 6 finished with value: 0.5562456866804694 and parameters: {'latent_dim': 71, 'hidden_dim': 136, 'lr': 0.0013102600224251324, 'epochs': 33, 'dropout_rate': 0.3787976772843573, 'sparsity_weight': 0.00310751228686666, 'n_estimators': 384, 'max_depth': 9, 'learning_rate': 0.1662056693399103, 'subsample': 0.7791468353257662, 'min_samples_split': 13, 'min_samples_leaf': 10}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:26:07,880] Trial 7 finished with value: 0.5398742427727935 and parameters: {'latent_dim': 49, 'hidden_dim': 177, 'lr': 0.007557929851241242, 'epochs': 15, 'dropout_rate': 0.3851635462167575, 'sparsity_weight': 0.0035266908297282074, 'n_estimators': 197, 'max_depth': 9, 'learning_rate': 0.015019153495178947, 'subsample': 0.9419175326928416, 'min_samples_split': 16, 'min_samples_leaf': 7}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:26:44,666] Trial 8 finished with value: 0.5749367379802162 and parameters: {'latent_dim': 23, 'hidden_dim': 255, 'lr': 0.0034440097559306224, 'epochs': 29, 'dropout_rate': 0.10288821723426876, 'sparsity_weight': 0.04732208844952056, 'n_estimators': 55, 'max_depth': 4, 'learning_rate': 0.02526669120327585, 'subsample': 0.9504563443783032, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:27:21,258] Trial 9 finished with value: 0.5415037190399509 and parameters: {'latent_dim': 44, 'hidden_dim': 202, 'lr': 0.00013998925444616195, 'epochs': 22, 'dropout_rate': 0.3885432781791036, 'sparsity_weight': 0.0451372852989481, 'n_estimators': 363, 'max_depth': 6, 'learning_rate': 0.20379273508415666, 'subsample': 0.6746735277554965, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:27:54,834] Trial 10 finished with value: 0.5423855532551185 and parameters: {'latent_dim': 10, 'hidden_dim': 65, 'lr': 0.00028069376416389513, 'epochs': 47, 'dropout_rate': 0.2590863008459432, 'sparsity_weight': 0.010969947366932976, 'n_estimators': 487, 'max_depth': 3, 'learning_rate': 0.043733048063242665, 'subsample': 0.8700461767779145, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:29:09,465] Trial 11 finished with value: 0.573019707077678 and parameters: {'latent_dim': 98, 'hidden_dim': 244, 'lr': 0.00990568353576483, 'epochs': 10, 'dropout_rate': 0.2647217177300337, 'sparsity_weight': 0.00025792927473485466, 'n_estimators': 255, 'max_depth': 7, 'learning_rate': 0.08813045324045998, 'subsample': 0.7355652420385307, 'min_samples_split': 20, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:30:03,402] Trial 12 finished with value: 0.5541369526876773 and parameters: {'latent_dim': 66, 'hidden_dim': 226, 'lr': 0.00032151755864348613, 'epochs': 42, 'dropout_rate': 0.16977752190888687, 'sparsity_weight': 0.00010317645523893973, 'n_estimators': 157, 'max_depth': 8, 'learning_rate': 0.07855345672370015, 'subsample': 0.7144586128911418, 'min_samples_split': 17, 'min_samples_leaf': 9}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:31:00,872] Trial 13 finished with value: 0.572712982133272 and parameters: {'latent_dim': 35, 'hidden_dim': 216, 'lr': 0.001827338162698769, 'epochs': 39, 'dropout_rate': 0.30674524115285257, 'sparsity_weight': 0.0004457297391215028, 'n_estimators': 320, 'max_depth': 5, 'learning_rate': 0.04601571540083354, 'subsample': 0.8572106264365548, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:31:16,067] Trial 14 finished with value: 0.5204355494210566 and parameters: {'latent_dim': 12, 'hidden_dim': 87, 'lr': 0.000316531901066733, 'epochs': 21, 'dropout_rate': 0.49995934949128845, 'sparsity_weight': 0.08899669025430247, 'n_estimators': 230, 'max_depth': 8, 'learning_rate': 0.09794905053957652, 'subsample': 0.8979264017457939, 'min_samples_split': 15, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:32:17,585] Trial 15 finished with value: 0.5941837282416992 and parameters: {'latent_dim': 78, 'hidden_dim': 186, 'lr': 0.004448932902318607, 'epochs': 35, 'dropout_rate': 0.31054252779460045, 'sparsity_weight': 0.006809818174356173, 'n_estimators': 76, 'max_depth': 10, 'learning_rate': 0.026998297021519384, 'subsample': 0.9919727940157983, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:33:31,559] Trial 16 finished with value: 0.5551721493750479 and parameters: {'latent_dim': 61, 'hidden_dim': 152, 'lr': 0.0005679958997544103, 'epochs': 50, 'dropout_rate': 0.22057912477323158, 'sparsity_weight': 0.00011054750919055541, 'n_estimators': 305, 'max_depth': 8, 'learning_rate': 0.06002252915739598, 'subsample': 0.7655825959631968, 'min_samples_split': 20, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:34:42,341] Trial 17 finished with value: 0.588240932443831 and parameters: {'latent_dim': 37, 'hidden_dim': 228, 'lr': 0.002305676577661132, 'epochs': 31, 'dropout_rate': 0.19664115500310175, 'sparsity_weight': 0.0005936037946502951, 'n_estimators': 422, 'max_depth': 6, 'learning_rate': 0.13190621553644852, 'subsample': 0.6808512786337444, 'min_samples_split': 14, 'min_samples_leaf': 6}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:35:22,328] Trial 18 finished with value: 0.5528525419829767 and parameters: {'latent_dim': 95, 'hidden_dim': 114, 'lr': 0.0011500439076697854, 'epochs': 13, 'dropout_rate': 0.331494091475773, 'sparsity_weight': 0.09843537074159656, 'n_estimators': 151, 'max_depth': 9, 'learning_rate': 0.0329461801690732, 'subsample': 0.8120842431954337, 'min_samples_split': 18, 'min_samples_leaf': 10}. Best is trial 5 with value: 0.6076412851775169.\n",
      "[I 2025-05-10 06:36:27,639] Trial 19 finished with value: 0.5785790966950387 and parameters: {'latent_dim': 23, 'hidden_dim': 193, 'lr': 0.005669989515710648, 'epochs': 41, 'dropout_rate': 0.11820824140877861, 'sparsity_weight': 0.0027802459093427515, 'n_estimators': 299, 'max_depth': 8, 'learning_rate': 0.01694603454648411, 'subsample': 0.6001063481213356, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 5 with value: 0.6076412851775169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5670\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs, batch_size, lr, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5406\n",
      "ROC-AUC autoencoded: 0.5144\n",
      "ROC-AUC autoencoded: 0.5003\n",
      "ROC-AUC autoencoded: 0.5158\n",
      "ROC-AUC autoencoded: 0.5347\n",
      "ROC-AUC autoencoded: 0.4932\n",
      "ROC-AUC autoencoded: 0.5010\n",
      "ROC-AUC autoencoded: 0.5665\n",
      "ROC-AUC autoencoded: 0.5238\n",
      "ROC-AUC autoencoded: 0.5037\n",
      "ROC-AUC autoencoded: 0.5193\n",
      "ROC-AUC autoencoded: 0.6208\n",
      "ROC-AUC autoencoded: 0.5520\n",
      "ROC-AUC autoencoded: 0.5282\n",
      "ROC-AUC autoencoded: 0.4924\n",
      "ROC-AUC autoencoded: 0.5021\n",
      "ROC-AUC autoencoded: 0.4558\n",
      "ROC-AUC autoencoded: 0.4866\n",
      "ROC-AUC autoencoded: 0.5417\n",
      "ROC-AUC autoencoded: 0.3946\n",
      "ROC-AUC autoencoded: 0.5252\n",
      "ROC-AUC autoencoded: 0.5885\n",
      "ROC-AUC autoencoded: 0.5752\n",
      "ROC-AUC autoencoded: 0.5611\n",
      "ROC-AUC autoencoded: 0.5999\n",
      "среднее 0.5255031218271319\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 06:43:32,477] A new study created in memory with name: no-name-88def352-a2af-4ac3-bb1d-53d587020ade\n",
      "[I 2025-05-10 06:44:00,761] Trial 0 finished with value: 0.5298673414615443 and parameters: {'latent_dim': 20, 'hidden_dim': 134, 'lr': 0.0025270276859954287, 'epochs': 28, 'dropout_rate': 0.1597209292638968, 'sparsity_weight': 0.00017154348594363849, 'C': 24.531017872812274, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.5298673414615443.\n",
      "[I 2025-05-10 06:44:08,760] Trial 1 finished with value: 0.46110344298750094 and parameters: {'latent_dim': 16, 'hidden_dim': 116, 'lr': 0.002314582881371654, 'epochs': 23, 'dropout_rate': 0.2820080056321037, 'sparsity_weight': 0.05310285780328834, 'C': 0.1361971170108466, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.5298673414615443.\n",
      "[I 2025-05-10 06:44:21,972] Trial 2 finished with value: 0.5449160340464689 and parameters: {'latent_dim': 99, 'hidden_dim': 132, 'lr': 0.0006473821943278555, 'epochs': 35, 'dropout_rate': 0.3541292040011558, 'sparsity_weight': 0.0007694707123778332, 'C': 2.4585882170886033, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 2 with value: 0.5449160340464689.\n",
      "[I 2025-05-10 06:44:41,161] Trial 3 finished with value: 0.5508204892262863 and parameters: {'latent_dim': 72, 'hidden_dim': 138, 'lr': 0.00048543450757950564, 'epochs': 50, 'dropout_rate': 0.18656149122055835, 'sparsity_weight': 0.0019832500488510055, 'C': 73.75271681235857, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.5508204892262863.\n",
      "[I 2025-05-10 06:45:24,168] Trial 4 finished with value: 0.5957940341998312 and parameters: {'latent_dim': 96, 'hidden_dim': 192, 'lr': 0.00018869621624936122, 'epochs': 24, 'dropout_rate': 0.4163075145424123, 'sparsity_weight': 0.008189354590031067, 'C': 7.273524292576821, 'kernel': 'linear'}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:46:09,772] Trial 5 finished with value: 0.4443677632083429 and parameters: {'latent_dim': 24, 'hidden_dim': 134, 'lr': 0.00012200329256243614, 'epochs': 47, 'dropout_rate': 0.3682652959351229, 'sparsity_weight': 0.002025696103459467, 'C': 24.092653448824166, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:46:52,215] Trial 6 finished with value: 0.52814201364926 and parameters: {'latent_dim': 64, 'hidden_dim': 127, 'lr': 0.00012196870703416095, 'epochs': 39, 'dropout_rate': 0.1543570562244533, 'sparsity_weight': 0.005746508926500953, 'C': 1.2529240950948706, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:47:31,707] Trial 7 finished with value: 0.525784065639138 and parameters: {'latent_dim': 91, 'hidden_dim': 92, 'lr': 0.00015493150468463477, 'epochs': 42, 'dropout_rate': 0.3307553108193751, 'sparsity_weight': 0.0010142207215418934, 'C': 82.12189308831552, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:47:44,242] Trial 8 finished with value: 0.5115980369603558 and parameters: {'latent_dim': 62, 'hidden_dim': 104, 'lr': 0.004308525856098783, 'epochs': 11, 'dropout_rate': 0.26382977198311086, 'sparsity_weight': 0.0009344660777872722, 'C': 97.35160771389111, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:48:09,438] Trial 9 finished with value: 0.52361782071927 and parameters: {'latent_dim': 12, 'hidden_dim': 159, 'lr': 0.00019212150083445872, 'epochs': 25, 'dropout_rate': 0.41194276964944343, 'sparsity_weight': 0.0033209009687913027, 'C': 1.1973614998558062, 'kernel': 'linear'}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:48:27,680] Trial 10 finished with value: 0.5815313242849475 and parameters: {'latent_dim': 41, 'hidden_dim': 227, 'lr': 0.009470540690561078, 'epochs': 16, 'dropout_rate': 0.49124746770165956, 'sparsity_weight': 0.02405438762975911, 'C': 8.477706664812265, 'kernel': 'linear'}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:48:50,345] Trial 11 finished with value: 0.548845947396672 and parameters: {'latent_dim': 39, 'hidden_dim': 232, 'lr': 0.0012539946285362905, 'epochs': 15, 'dropout_rate': 0.48459882817003275, 'sparsity_weight': 0.025968272158437337, 'C': 10.158089350686561, 'kernel': 'linear'}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:49:13,798] Trial 12 finished with value: 0.5763361705390692 and parameters: {'latent_dim': 44, 'hidden_dim': 224, 'lr': 0.007423496508376516, 'epochs': 20, 'dropout_rate': 0.4923377834039224, 'sparsity_weight': 0.013618095403720267, 'C': 6.5495695757692625, 'kernel': 'linear'}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:49:44,619] Trial 13 finished with value: 0.5727513227513228 and parameters: {'latent_dim': 82, 'hidden_dim': 196, 'lr': 0.000347831223368104, 'epochs': 17, 'dropout_rate': 0.4222765506333015, 'sparsity_weight': 0.07982117630616957, 'C': 5.588595476917158, 'kernel': 'linear'}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:50:20,601] Trial 14 finished with value: 0.522314239705544 and parameters: {'latent_dim': 45, 'hidden_dim': 196, 'lr': 0.008924807277894157, 'epochs': 32, 'dropout_rate': 0.4533740029696277, 'sparsity_weight': 0.011377531096404742, 'C': 0.385114433563823, 'kernel': 'linear'}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:50:37,999] Trial 15 finished with value: 0.5263783452189249 and parameters: {'latent_dim': 30, 'hidden_dim': 253, 'lr': 0.0010967532217822681, 'epochs': 11, 'dropout_rate': 0.4056396004665776, 'sparsity_weight': 0.031642989934526834, 'C': 20.239200233680293, 'kernel': 'linear'}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:51:02,682] Trial 16 finished with value: 0.43972854842420056 and parameters: {'latent_dim': 53, 'hidden_dim': 189, 'lr': 0.00024257214883265357, 'epochs': 19, 'dropout_rate': 0.4495935104566369, 'sparsity_weight': 0.010050800883045809, 'C': 2.3678190533857433, 'kernel': 'linear'}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:51:57,650] Trial 17 finished with value: 0.591001456943486 and parameters: {'latent_dim': 79, 'hidden_dim': 220, 'lr': 0.0017657997882809776, 'epochs': 27, 'dropout_rate': 0.49770511740052537, 'sparsity_weight': 0.018129003696340858, 'C': 10.353354316629758, 'kernel': 'linear'}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:52:31,103] Trial 18 finished with value: 0.4862932290468522 and parameters: {'latent_dim': 81, 'hidden_dim': 170, 'lr': 0.0018564604991861493, 'epochs': 29, 'dropout_rate': 0.2517638078133976, 'sparsity_weight': 0.005943309532267566, 'C': 16.857680743906656, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 4 with value: 0.5957940341998312.\n",
      "[I 2025-05-10 06:56:21,406] Trial 19 finished with value: 0.5650256882140939 and parameters: {'latent_dim': 99, 'hidden_dim': 208, 'lr': 0.0005828377306810919, 'epochs': 34, 'dropout_rate': 0.3885715689719419, 'sparsity_weight': 0.004425596970957639, 'C': 43.15566660643019, 'kernel': 'linear'}. Best is trial 4 with value: 0.5957940341998312.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5144\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs, batch_size, lr, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5481\n",
      "ROC-AUC autoencoded: 0.5459\n",
      "ROC-AUC autoencoded: 0.5298\n",
      "ROC-AUC autoencoded: 0.5454\n",
      "ROC-AUC autoencoded: 0.6000\n",
      "ROC-AUC autoencoded: 0.5450\n",
      "ROC-AUC autoencoded: 0.5285\n",
      "ROC-AUC autoencoded: 0.5587\n",
      "ROC-AUC autoencoded: 0.5514\n",
      "ROC-AUC autoencoded: 0.4982\n",
      "ROC-AUC autoencoded: 0.5818\n",
      "ROC-AUC autoencoded: 0.5010\n",
      "ROC-AUC autoencoded: 0.5500\n",
      "ROC-AUC autoencoded: 0.5615\n",
      "ROC-AUC autoencoded: 0.5898\n",
      "ROC-AUC autoencoded: 0.5334\n",
      "ROC-AUC autoencoded: 0.4832\n",
      "ROC-AUC autoencoded: 0.5474\n",
      "ROC-AUC autoencoded: 0.4638\n",
      "ROC-AUC autoencoded: 0.5287\n",
      "ROC-AUC autoencoded: 0.6086\n",
      "ROC-AUC autoencoded: 0.5529\n",
      "ROC-AUC autoencoded: 0.6233\n",
      "ROC-AUC autoencoded: 0.5502\n",
      "ROC-AUC autoencoded: 0.5885\n",
      "среднее 0.5485926704445935\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:01:16,446] A new study created in memory with name: no-name-ca6cda36-4aa8-485b-ac78-5e5cb7508b8f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:02:06,028] Trial 0 finished with value: 0.5526800092017483 and parameters: {'latent_dim': 86, 'hidden_dim_ae': 111, 'lr_ae': 0.00016231560272730592, 'epochs_ae': 41, 'dropout_rate_ae': 0.10633102905610184, 'sparsity_weight': 0.03445322639531544, 'hidden_dim_mlp': 88, 'lr_mlp': 0.003258597926326242, 'epochs_mlp': 22, 'dropout_rate_mlp': 0.30450471253968037}. Best is trial 0 with value: 0.5526800092017483.\n",
      "[I 2025-05-10 07:02:49,837] Trial 1 finished with value: 0.594778007821486 and parameters: {'latent_dim': 52, 'hidden_dim_ae': 97, 'lr_ae': 0.0009255299680799127, 'epochs_ae': 24, 'dropout_rate_ae': 0.31738787687723763, 'sparsity_weight': 0.0001864768324740467, 'hidden_dim_mlp': 122, 'lr_mlp': 0.00020443417670750128, 'epochs_mlp': 39, 'dropout_rate_mlp': 0.35096583412720483}. Best is trial 1 with value: 0.594778007821486.\n",
      "[I 2025-05-10 07:03:18,971] Trial 2 finished with value: 0.6072195383789586 and parameters: {'latent_dim': 10, 'hidden_dim_ae': 79, 'lr_ae': 0.0019539151254902346, 'epochs_ae': 25, 'dropout_rate_ae': 0.3107975106087898, 'sparsity_weight': 0.000916614336284883, 'hidden_dim_mlp': 87, 'lr_mlp': 0.00028435202085277115, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.23222205556107178}. Best is trial 2 with value: 0.6072195383789586.\n",
      "[I 2025-05-10 07:04:12,565] Trial 3 finished with value: 0.5413311862587225 and parameters: {'latent_dim': 85, 'hidden_dim_ae': 104, 'lr_ae': 0.0002818138638121216, 'epochs_ae': 33, 'dropout_rate_ae': 0.432073514008224, 'sparsity_weight': 0.0004325203670257067, 'hidden_dim_mlp': 103, 'lr_mlp': 0.0003232004321975974, 'epochs_mlp': 47, 'dropout_rate_mlp': 0.322553290316729}. Best is trial 2 with value: 0.6072195383789586.\n",
      "[I 2025-05-10 07:04:42,495] Trial 4 finished with value: 0.6049957825320144 and parameters: {'latent_dim': 37, 'hidden_dim_ae': 233, 'lr_ae': 0.004854096282301853, 'epochs_ae': 21, 'dropout_rate_ae': 0.29262640640839505, 'sparsity_weight': 0.03139201133917761, 'hidden_dim_mlp': 84, 'lr_mlp': 0.0007212442187202426, 'epochs_mlp': 12, 'dropout_rate_mlp': 0.41426087234555786}. Best is trial 2 with value: 0.6072195383789586.\n",
      "[I 2025-05-10 07:05:24,813] Trial 5 finished with value: 0.6004524192929989 and parameters: {'latent_dim': 18, 'hidden_dim_ae': 229, 'lr_ae': 0.001699612838604245, 'epochs_ae': 31, 'dropout_rate_ae': 0.4864603177728216, 'sparsity_weight': 0.0060727669381203655, 'hidden_dim_mlp': 103, 'lr_mlp': 0.0013172667100846778, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.45929404859724143}. Best is trial 2 with value: 0.6072195383789586.\n",
      "[I 2025-05-10 07:06:16,038] Trial 6 finished with value: 0.5708151215397592 and parameters: {'latent_dim': 60, 'hidden_dim_ae': 99, 'lr_ae': 0.004651507538132404, 'epochs_ae': 32, 'dropout_rate_ae': 0.2843738661900992, 'sparsity_weight': 0.004590320189924355, 'hidden_dim_mlp': 58, 'lr_mlp': 0.0007350191754501176, 'epochs_mlp': 49, 'dropout_rate_mlp': 0.2175763680010303}. Best is trial 2 with value: 0.6072195383789586.\n",
      "[I 2025-05-10 07:06:50,417] Trial 7 finished with value: 0.6037113718273138 and parameters: {'latent_dim': 73, 'hidden_dim_ae': 164, 'lr_ae': 0.005196971313347822, 'epochs_ae': 19, 'dropout_rate_ae': 0.23407843837964984, 'sparsity_weight': 0.001146672081354515, 'hidden_dim_mlp': 43, 'lr_mlp': 0.007336532866724738, 'epochs_mlp': 30, 'dropout_rate_mlp': 0.4748551478188471}. Best is trial 2 with value: 0.6072195383789586.\n",
      "[I 2025-05-10 07:07:20,789] Trial 8 finished with value: 0.5824898397362164 and parameters: {'latent_dim': 15, 'hidden_dim_ae': 86, 'lr_ae': 0.00014121543445995714, 'epochs_ae': 15, 'dropout_rate_ae': 0.34599487139182505, 'sparsity_weight': 0.000586621996256067, 'hidden_dim_mlp': 69, 'lr_mlp': 0.00039065514653980607, 'epochs_mlp': 37, 'dropout_rate_mlp': 0.4696665859893365}. Best is trial 2 with value: 0.6072195383789586.\n",
      "[I 2025-05-10 07:08:16,747] Trial 9 finished with value: 0.5658691818112108 and parameters: {'latent_dim': 70, 'hidden_dim_ae': 81, 'lr_ae': 0.00033133943257696594, 'epochs_ae': 39, 'dropout_rate_ae': 0.17683827145806685, 'sparsity_weight': 0.054550965786050266, 'hidden_dim_mlp': 88, 'lr_mlp': 0.00010567211851132197, 'epochs_mlp': 42, 'dropout_rate_mlp': 0.19485708731635676}. Best is trial 2 with value: 0.6072195383789586.\n",
      "[I 2025-05-10 07:09:19,416] Trial 10 finished with value: 0.5533701403266621 and parameters: {'latent_dim': 34, 'hidden_dim_ae': 164, 'lr_ae': 0.0011664525816799485, 'epochs_ae': 47, 'dropout_rate_ae': 0.40020929157561624, 'sparsity_weight': 0.0001327179177112924, 'hidden_dim_mlp': 125, 'lr_mlp': 0.002081647474689131, 'epochs_mlp': 26, 'dropout_rate_mlp': 0.11168447890006974}. Best is trial 2 with value: 0.6072195383789586.\n",
      "[I 2025-05-10 07:09:34,914] Trial 11 finished with value: 0.5981711525189787 and parameters: {'latent_dim': 36, 'hidden_dim_ae': 255, 'lr_ae': 0.00922772232990989, 'epochs_ae': 10, 'dropout_rate_ae': 0.259809013919932, 'sparsity_weight': 0.018597018340318485, 'hidden_dim_mlp': 78, 'lr_mlp': 0.0006735701183495667, 'epochs_mlp': 10, 'dropout_rate_mlp': 0.3836865896546262}. Best is trial 2 with value: 0.6072195383789586.\n",
      "[I 2025-05-10 07:10:05,736] Trial 12 finished with value: 0.6317191933133962 and parameters: {'latent_dim': 32, 'hidden_dim_ae': 195, 'lr_ae': 0.0022114978125760123, 'epochs_ae': 24, 'dropout_rate_ae': 0.35325309611533673, 'sparsity_weight': 0.0020357686893790776, 'hidden_dim_mlp': 102, 'lr_mlp': 0.00018063307313876144, 'epochs_mlp': 11, 'dropout_rate_mlp': 0.23139549487862937}. Best is trial 12 with value: 0.6317191933133962.\n",
      "[I 2025-05-10 07:10:38,771] Trial 13 finished with value: 0.5957940341998312 and parameters: {'latent_dim': 13, 'hidden_dim_ae': 191, 'lr_ae': 0.002356667235493919, 'epochs_ae': 25, 'dropout_rate_ae': 0.37176317550728527, 'sparsity_weight': 0.0016611429808989903, 'hidden_dim_mlp': 105, 'lr_mlp': 0.00010682741103871967, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.22225837812857255}. Best is trial 12 with value: 0.6317191933133962.\n",
      "[I 2025-05-10 07:11:14,232] Trial 14 finished with value: 0.6242427727934974 and parameters: {'latent_dim': 26, 'hidden_dim_ae': 129, 'lr_ae': 0.0006518341178702131, 'epochs_ae': 26, 'dropout_rate_ae': 0.20496719733027258, 'sparsity_weight': 0.008737377764648271, 'hidden_dim_mlp': 112, 'lr_mlp': 0.00023710109307875063, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.2595297015219603}. Best is trial 12 with value: 0.6317191933133962.\n",
      "[I 2025-05-10 07:11:33,374] Trial 15 finished with value: 0.5875508013189172 and parameters: {'latent_dim': 30, 'hidden_dim_ae': 130, 'lr_ae': 0.0006750122410136263, 'epochs_ae': 12, 'dropout_rate_ae': 0.19494249513660108, 'sparsity_weight': 0.011897244324949732, 'hidden_dim_mlp': 114, 'lr_mlp': 0.00018073271921226276, 'epochs_mlp': 19, 'dropout_rate_mlp': 0.14204521853728785}. Best is trial 12 with value: 0.6317191933133962.\n",
      "[I 2025-05-10 07:12:24,088] Trial 16 finished with value: 0.610708534621578 and parameters: {'latent_dim': 47, 'hidden_dim_ae': 195, 'lr_ae': 0.0005012046442240749, 'epochs_ae': 37, 'dropout_rate_ae': 0.1275129752463649, 'sparsity_weight': 0.002846586509330617, 'hidden_dim_mlp': 113, 'lr_mlp': 0.00047355136543610315, 'epochs_mlp': 26, 'dropout_rate_mlp': 0.2663214036205502}. Best is trial 12 with value: 0.6317191933133962.\n",
      "[I 2025-05-10 07:12:50,331] Trial 17 finished with value: 0.5889885744958209 and parameters: {'latent_dim': 26, 'hidden_dim_ae': 143, 'lr_ae': 0.0029516943065758965, 'epochs_ae': 18, 'dropout_rate_ae': 0.2130250233062388, 'sparsity_weight': 0.09852557245464227, 'hidden_dim_mlp': 98, 'lr_mlp': 0.00018768752010960387, 'epochs_mlp': 15, 'dropout_rate_mlp': 0.16446359308081465}. Best is trial 12 with value: 0.6317191933133962.\n",
      "[I 2025-05-10 07:13:34,981] Trial 18 finished with value: 0.5632045088566827 and parameters: {'latent_dim': 45, 'hidden_dim_ae': 189, 'lr_ae': 0.001094178689620441, 'epochs_ae': 28, 'dropout_rate_ae': 0.1675416449039123, 'sparsity_weight': 0.010318527536888944, 'hidden_dim_mlp': 115, 'lr_mlp': 0.0015052807995263435, 'epochs_mlp': 22, 'dropout_rate_mlp': 0.2620127962898302}. Best is trial 12 with value: 0.6317191933133962.\n",
      "[I 2025-05-10 07:14:19,756] Trial 19 finished with value: 0.5916340771413235 and parameters: {'latent_dim': 23, 'hidden_dim_ae': 145, 'lr_ae': 0.0004681441225753272, 'epochs_ae': 28, 'dropout_rate_ae': 0.2525826409498098, 'sparsity_weight': 0.0028721342730920847, 'hidden_dim_mlp': 35, 'lr_mlp': 0.00015157626832771562, 'epochs_mlp': 31, 'dropout_rate_mlp': 0.2697251053812639}. Best is trial 12 with value: 0.6317191933133962.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6079\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    \n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae, sparsity_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(latent_dim, hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = SparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_sparse_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['sparsity_weight'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "mlp = MLP(best_params['latent_dim'], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5787\n",
      "ROC-AUC autoencoded: 0.4998\n",
      "ROC-AUC autoencoded: 0.5405\n",
      "ROC-AUC autoencoded: 0.5746\n",
      "ROC-AUC autoencoded: 0.5805\n",
      "ROC-AUC autoencoded: 0.6111\n",
      "ROC-AUC autoencoded: 0.5400\n",
      "ROC-AUC autoencoded: 0.5548\n",
      "ROC-AUC autoencoded: 0.5909\n",
      "ROC-AUC autoencoded: 0.6030\n",
      "ROC-AUC autoencoded: 0.5706\n",
      "ROC-AUC autoencoded: 0.6469\n",
      "ROC-AUC autoencoded: 0.5554\n",
      "ROC-AUC autoencoded: 0.5587\n",
      "ROC-AUC autoencoded: 0.6118\n",
      "ROC-AUC autoencoded: 0.5335\n",
      "ROC-AUC autoencoded: 0.5312\n",
      "ROC-AUC autoencoded: 0.5570\n",
      "ROC-AUC autoencoded: 0.5502\n",
      "ROC-AUC autoencoded: 0.5078\n",
      "ROC-AUC autoencoded: 0.6014\n",
      "ROC-AUC autoencoded: 0.5974\n",
      "ROC-AUC autoencoded: 0.6441\n",
      "ROC-AUC autoencoded: 0.6150\n",
      "ROC-AUC autoencoded: 0.5931\n",
      "среднее 0.5739112875834018\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = SparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_sparse_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['sparsity_weight'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(best_params['latent_dim'], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь блок с sparse автоэнкодером с классифицирующей головой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:18:11,144] A new study created in memory with name: no-name-6d2fa509-e9e0-4ad4-bff0-6f310fb5c657\n",
      "[I 2025-05-10 07:18:29,521] Trial 0 finished with value: 0.5992830304424507 and parameters: {'latent_dim': 72, 'hidden_dim': 227, 'lr': 0.00011598577609605722, 'epochs': 13, 'dropout_rate': 0.11660132291296464, 'sparsity_weight': 0.0029701014533152865, 'classification_weight': 0.6412932516121752, 'C': 41.08103467100559, 'solver': 'liblinear'}. Best is trial 0 with value: 0.5992830304424507.\n",
      "[I 2025-05-10 07:18:47,468] Trial 1 finished with value: 0.6152902384786443 and parameters: {'latent_dim': 66, 'hidden_dim': 80, 'lr': 0.00015219954697445328, 'epochs': 16, 'dropout_rate': 0.14580810942124522, 'sparsity_weight': 0.0007246574031786744, 'classification_weight': 0.6718371031302441, 'C': 0.023736379107831548, 'solver': 'liblinear'}. Best is trial 1 with value: 0.6152902384786443.\n",
      "[I 2025-05-10 07:19:16,491] Trial 2 finished with value: 0.5946438156583085 and parameters: {'latent_dim': 35, 'hidden_dim': 129, 'lr': 0.0005139306014698194, 'epochs': 24, 'dropout_rate': 0.3964211274732802, 'sparsity_weight': 0.00017610277329209337, 'classification_weight': 0.8836293736303603, 'C': 0.9829050382129598, 'solver': 'saga'}. Best is trial 1 with value: 0.6152902384786443.\n",
      "[I 2025-05-10 07:19:47,123] Trial 3 finished with value: 0.5632620197837589 and parameters: {'latent_dim': 44, 'hidden_dim': 88, 'lr': 0.001680444912479706, 'epochs': 28, 'dropout_rate': 0.15040182080262926, 'sparsity_weight': 0.02736304614360854, 'classification_weight': 0.8929410944107313, 'C': 0.03597698360288837, 'solver': 'liblinear'}. Best is trial 1 with value: 0.6152902384786443.\n",
      "[I 2025-05-10 07:20:28,668] Trial 4 finished with value: 0.540200138026225 and parameters: {'latent_dim': 43, 'hidden_dim': 147, 'lr': 0.008060071397223562, 'epochs': 37, 'dropout_rate': 0.15947339654575862, 'sparsity_weight': 0.015359430349034892, 'classification_weight': 0.3154396410460073, 'C': 47.38258738855027, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.6152902384786443.\n",
      "[I 2025-05-10 07:20:52,422] Trial 5 finished with value: 0.546181274442144 and parameters: {'latent_dim': 43, 'hidden_dim': 213, 'lr': 0.0034451394178370595, 'epochs': 18, 'dropout_rate': 0.30732750110326307, 'sparsity_weight': 0.00011031407026914284, 'classification_weight': 0.6943490026169269, 'C': 1.8500321806139668, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.6152902384786443.\n",
      "[I 2025-05-10 07:21:23,220] Trial 6 finished with value: 0.5764032666206579 and parameters: {'latent_dim': 39, 'hidden_dim': 66, 'lr': 0.006555349205763671, 'epochs': 26, 'dropout_rate': 0.307816296695989, 'sparsity_weight': 0.0013099128483137462, 'classification_weight': 0.8915159657693239, 'C': 0.4081257230293033, 'solver': 'saga'}. Best is trial 1 with value: 0.6152902384786443.\n",
      "[I 2025-05-10 07:21:49,830] Trial 7 finished with value: 0.5466221915497278 and parameters: {'latent_dim': 87, 'hidden_dim': 150, 'lr': 0.0037626475243191875, 'epochs': 21, 'dropout_rate': 0.22453882210538825, 'sparsity_weight': 0.01309157224875804, 'classification_weight': 0.7824420281751412, 'C': 0.021270580902694586, 'solver': 'liblinear'}. Best is trial 1 with value: 0.6152902384786443.\n",
      "[I 2025-05-10 07:22:34,927] Trial 8 finished with value: 0.5161989111264474 and parameters: {'latent_dim': 95, 'hidden_dim': 185, 'lr': 0.003620834002753029, 'epochs': 35, 'dropout_rate': 0.18165511364985557, 'sparsity_weight': 0.023816285339658846, 'classification_weight': 0.7042612297599631, 'C': 0.6691689385703148, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.6152902384786443.\n",
      "[I 2025-05-10 07:23:39,401] Trial 9 finished with value: 0.5540027605244996 and parameters: {'latent_dim': 83, 'hidden_dim': 235, 'lr': 0.006590782244624465, 'epochs': 48, 'dropout_rate': 0.40014594100421086, 'sparsity_weight': 0.0010314571799675443, 'classification_weight': 0.12079143874140925, 'C': 0.02782193062257343, 'solver': 'saga'}. Best is trial 1 with value: 0.6152902384786443.\n",
      "[I 2025-05-10 07:23:52,272] Trial 10 finished with value: 0.5620351200061345 and parameters: {'latent_dim': 15, 'hidden_dim': 104, 'lr': 0.00010057912269641173, 'epochs': 11, 'dropout_rate': 0.4665964192810674, 'sparsity_weight': 0.08577529958002855, 'classification_weight': 0.5021096920957666, 'C': 0.14113199583509853, 'solver': 'liblinear'}. Best is trial 1 with value: 0.6152902384786443.\n",
      "[I 2025-05-10 07:24:07,395] Trial 11 finished with value: 0.6164596273291926 and parameters: {'latent_dim': 68, 'hidden_dim': 247, 'lr': 0.00010222144701123414, 'epochs': 10, 'dropout_rate': 0.10737444620055991, 'sparsity_weight': 0.0032725991965267096, 'classification_weight': 0.5506385265788977, 'C': 95.57810261184683, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6164596273291926.\n",
      "[I 2025-05-10 07:24:25,414] Trial 12 finished with value: 0.5907522429261559 and parameters: {'latent_dim': 65, 'hidden_dim': 194, 'lr': 0.00026557968369914667, 'epochs': 16, 'dropout_rate': 0.2326393726600851, 'sparsity_weight': 0.0004884046378383376, 'classification_weight': 0.5087474528566003, 'C': 5.469718032450461, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6164596273291926.\n",
      "[I 2025-05-10 07:24:42,000] Trial 13 finished with value: 0.5746683536538609 and parameters: {'latent_dim': 61, 'hidden_dim': 178, 'lr': 0.00025910683303899656, 'epochs': 11, 'dropout_rate': 0.10886845962483971, 'sparsity_weight': 0.003916685270025727, 'classification_weight': 0.39314874308740844, 'C': 4.437594239746462, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6164596273291926.\n",
      "[I 2025-05-10 07:25:11,581] Trial 14 finished with value: 0.5628402729852006 and parameters: {'latent_dim': 75, 'hidden_dim': 252, 'lr': 0.00022861330351413436, 'epochs': 19, 'dropout_rate': 0.22662152427314303, 'sparsity_weight': 0.003679375749439234, 'classification_weight': 0.611494075905496, 'C': 0.12142950280899811, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6164596273291926.\n",
      "[I 2025-05-10 07:25:22,276] Trial 15 finished with value: 0.6002990568207959 and parameters: {'latent_dim': 56, 'hidden_dim': 103, 'lr': 0.0008410902746629723, 'epochs': 10, 'dropout_rate': 0.19085432049319764, 'sparsity_weight': 0.0004991133350691054, 'classification_weight': 0.37831349041016293, 'C': 11.952601035406827, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6164596273291926.\n",
      "[I 2025-05-10 07:26:23,735] Trial 16 finished with value: 0.5705083965953531 and parameters: {'latent_dim': 99, 'hidden_dim': 128, 'lr': 0.00019134095685702845, 'epochs': 49, 'dropout_rate': 0.1025283792360063, 'sparsity_weight': 0.0016058830372631873, 'classification_weight': 0.5666392259565551, 'C': 0.010937652594503817, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6164596273291926.\n",
      "[I 2025-05-10 07:26:58,726] Trial 17 finished with value: 0.5613258185721954 and parameters: {'latent_dim': 73, 'hidden_dim': 68, 'lr': 0.0005347651112282875, 'epochs': 33, 'dropout_rate': 0.2666681263300597, 'sparsity_weight': 0.00036115989537473513, 'classification_weight': 0.7674841727849251, 'C': 82.3107462965833, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6164596273291926.\n",
      "[I 2025-05-10 07:27:15,773] Trial 18 finished with value: 0.5858829844337091 and parameters: {'latent_dim': 18, 'hidden_dim': 166, 'lr': 0.0001409081147493139, 'epochs': 15, 'dropout_rate': 0.13549420510327337, 'sparsity_weight': 0.009148844813509843, 'classification_weight': 0.24930676151966297, 'C': 0.13796710075237206, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.6164596273291926.\n",
      "[I 2025-05-10 07:27:45,401] Trial 19 finished with value: 0.5688214094011196 and parameters: {'latent_dim': 52, 'hidden_dim': 206, 'lr': 0.0004294212315081325, 'epochs': 22, 'dropout_rate': 0.3515016736323189, 'sparsity_weight': 0.0007640149829644306, 'classification_weight': 0.4362461443229667, 'C': 14.386745171867, 'solver': 'saga'}. Best is trial 11 with value: 0.6164596273291926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5983\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingSparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(ClassifyingSparseAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "    \n",
    "def train_classifying_sparse_autoencoder(model, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    class_criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, latent, classification = model(batch_x)\n",
    "            \n",
    "            recon_loss = recon_criterion(reconstructed, batch_x)\n",
    "            sparsity_loss = torch.mean(torch.abs(latent))\n",
    "            class_loss = class_criterion(classification, batch_y)\n",
    "            \n",
    "            loss = (1 - classification_weight) * (recon_loss + sparsity_weight * sparsity_loss) + classification_weight * class_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent, _ = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5241\n",
      "ROC-AUC autoencoded: 0.5392\n",
      "ROC-AUC autoencoded: 0.5352\n",
      "ROC-AUC autoencoded: 0.5172\n",
      "ROC-AUC autoencoded: 0.5490\n",
      "ROC-AUC autoencoded: 0.5391\n",
      "ROC-AUC autoencoded: 0.5857\n",
      "ROC-AUC autoencoded: 0.5883\n",
      "ROC-AUC autoencoded: 0.5844\n",
      "ROC-AUC autoencoded: 0.5340\n",
      "ROC-AUC autoencoded: 0.5961\n",
      "ROC-AUC autoencoded: 0.6225\n",
      "ROC-AUC autoencoded: 0.5675\n",
      "ROC-AUC autoencoded: 0.5824\n",
      "ROC-AUC autoencoded: 0.5586\n",
      "ROC-AUC autoencoded: 0.5509\n",
      "ROC-AUC autoencoded: 0.5574\n",
      "ROC-AUC autoencoded: 0.5651\n",
      "ROC-AUC autoencoded: 0.5426\n",
      "ROC-AUC autoencoded: 0.5717\n",
      "ROC-AUC autoencoded: 0.6272\n",
      "ROC-AUC autoencoded: 0.5470\n",
      "ROC-AUC autoencoded: 0.5923\n",
      "ROC-AUC autoencoded: 0.5822\n",
      "ROC-AUC autoencoded: 0.6224\n",
      "среднее 0.5673005941427401\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 07:29:21,793] A new study created in memory with name: no-name-bd1914da-ef69-4fc0-b038-034b4f10b68f\n",
      "[I 2025-05-10 07:30:09,274] Trial 0 finished with value: 0.5704700559773024 and parameters: {'latent_dim': 67, 'hidden_dim': 161, 'lr': 0.00011508667349360952, 'epochs': 11, 'dropout_rate': 0.4150920574516014, 'sparsity_weight': 0.002236309484565216, 'classification_weight': 0.5618181973247383, 'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.012292714297860927, 'subsample': 0.6014077501122179, 'min_samples_split': 11, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.5704700559773024.\n",
      "[I 2025-05-10 07:32:57,709] Trial 1 finished with value: 0.5998389694041867 and parameters: {'latent_dim': 75, 'hidden_dim': 133, 'lr': 0.000281242069768043, 'epochs': 40, 'dropout_rate': 0.39757363093734155, 'sparsity_weight': 0.0027636410683754427, 'classification_weight': 0.29560575772098896, 'n_estimators': 384, 'max_depth': 8, 'learning_rate': 0.026105002595662587, 'subsample': 0.8454069657103208, 'min_samples_split': 13, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.5998389694041867.\n",
      "[I 2025-05-10 07:34:05,242] Trial 2 finished with value: 0.5470822789663369 and parameters: {'latent_dim': 79, 'hidden_dim': 80, 'lr': 0.007821803446307021, 'epochs': 19, 'dropout_rate': 0.25241477958455905, 'sparsity_weight': 0.03865760772239445, 'classification_weight': 0.5908776357956486, 'n_estimators': 141, 'max_depth': 7, 'learning_rate': 0.1721747917879591, 'subsample': 0.8317153675711714, 'min_samples_split': 12, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.5998389694041867.\n",
      "[I 2025-05-10 07:34:45,196] Trial 3 finished with value: 0.5583160800552105 and parameters: {'latent_dim': 22, 'hidden_dim': 197, 'lr': 0.0005607498871393919, 'epochs': 14, 'dropout_rate': 0.14815073390409497, 'sparsity_weight': 0.02744276474987624, 'classification_weight': 0.43586017149802936, 'n_estimators': 329, 'max_depth': 4, 'learning_rate': 0.058357349480191514, 'subsample': 0.8193215391223506, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.5998389694041867.\n",
      "[I 2025-05-10 07:35:46,732] Trial 4 finished with value: 0.5493252051223066 and parameters: {'latent_dim': 42, 'hidden_dim': 174, 'lr': 0.0023820562778437337, 'epochs': 49, 'dropout_rate': 0.1799056293183086, 'sparsity_weight': 0.004551704131315852, 'classification_weight': 0.2898449505406291, 'n_estimators': 58, 'max_depth': 4, 'learning_rate': 0.2812366034885341, 'subsample': 0.6248540392249801, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.5998389694041867.\n",
      "[I 2025-05-10 07:36:37,200] Trial 5 finished with value: 0.5767770876466529 and parameters: {'latent_dim': 33, 'hidden_dim': 113, 'lr': 0.00032589742245138595, 'epochs': 20, 'dropout_rate': 0.3120836902911094, 'sparsity_weight': 0.007422854675213137, 'classification_weight': 0.13190887115599345, 'n_estimators': 287, 'max_depth': 6, 'learning_rate': 0.2818463377466603, 'subsample': 0.6297611293871846, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.5998389694041867.\n",
      "[I 2025-05-10 07:37:11,294] Trial 6 finished with value: 0.6128939498504716 and parameters: {'latent_dim': 89, 'hidden_dim': 194, 'lr': 0.0005349804026497892, 'epochs': 13, 'dropout_rate': 0.4545263242568832, 'sparsity_weight': 0.00023354302519984404, 'classification_weight': 0.5064652943765835, 'n_estimators': 135, 'max_depth': 3, 'learning_rate': 0.03578645992560437, 'subsample': 0.6364547347001089, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.6128939498504716.\n",
      "[I 2025-05-10 07:39:04,831] Trial 7 finished with value: 0.5771029829000843 and parameters: {'latent_dim': 46, 'hidden_dim': 164, 'lr': 0.00019404964392027266, 'epochs': 27, 'dropout_rate': 0.48977904496440217, 'sparsity_weight': 0.02169000992806362, 'classification_weight': 0.12378827347154511, 'n_estimators': 438, 'max_depth': 10, 'learning_rate': 0.14675321619458287, 'subsample': 0.6551521681356596, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 6 with value: 0.6128939498504716.\n",
      "[I 2025-05-10 07:40:07,741] Trial 8 finished with value: 0.5216241085806302 and parameters: {'latent_dim': 14, 'hidden_dim': 183, 'lr': 0.004077206475638672, 'epochs': 44, 'dropout_rate': 0.10366286590752614, 'sparsity_weight': 0.00023462830017930726, 'classification_weight': 0.12185177964557355, 'n_estimators': 292, 'max_depth': 3, 'learning_rate': 0.010316557118914169, 'subsample': 0.6601593803156459, 'min_samples_split': 17, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.6128939498504716.\n",
      "[I 2025-05-10 07:42:19,729] Trial 9 finished with value: 0.603366306264857 and parameters: {'latent_dim': 73, 'hidden_dim': 156, 'lr': 0.0002316949916450983, 'epochs': 24, 'dropout_rate': 0.3311500163882427, 'sparsity_weight': 0.0691185066532313, 'classification_weight': 0.1387055776007852, 'n_estimators': 248, 'max_depth': 10, 'learning_rate': 0.012669768504018736, 'subsample': 0.9636836142282953, 'min_samples_split': 20, 'min_samples_leaf': 6}. Best is trial 6 with value: 0.6128939498504716.\n",
      "[I 2025-05-10 07:43:57,314] Trial 10 finished with value: 0.5424814048002453 and parameters: {'latent_dim': 100, 'hidden_dim': 253, 'lr': 0.001185065357409632, 'epochs': 34, 'dropout_rate': 0.4945353075213616, 'sparsity_weight': 0.00012044478595612165, 'classification_weight': 0.8502757931662439, 'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.04875801634036059, 'subsample': 0.7329297171805411, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 6 with value: 0.6128939498504716.\n",
      "[I 2025-05-10 07:46:32,341] Trial 11 finished with value: 0.5522390920941647 and parameters: {'latent_dim': 95, 'hidden_dim': 224, 'lr': 0.0007460493527506178, 'epochs': 26, 'dropout_rate': 0.3451866359954644, 'sparsity_weight': 0.0006146807233791299, 'classification_weight': 0.6907770972698997, 'n_estimators': 210, 'max_depth': 10, 'learning_rate': 0.02372350349250813, 'subsample': 0.987535869917807, 'min_samples_split': 19, 'min_samples_leaf': 7}. Best is trial 6 with value: 0.6128939498504716.\n",
      "[I 2025-05-10 07:47:18,904] Trial 12 finished with value: 0.6206770953147763 and parameters: {'latent_dim': 63, 'hidden_dim': 209, 'lr': 0.00011140796143083252, 'epochs': 20, 'dropout_rate': 0.42309225722961824, 'sparsity_weight': 0.0006985473984462095, 'classification_weight': 0.4256607196435214, 'n_estimators': 67, 'max_depth': 7, 'learning_rate': 0.022851606755348253, 'subsample': 0.9953093966887951, 'min_samples_split': 20, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.6206770953147763.\n",
      "[I 2025-05-10 07:47:54,268] Trial 13 finished with value: 0.5575492676941952 and parameters: {'latent_dim': 60, 'hidden_dim': 210, 'lr': 0.00010310403784215993, 'epochs': 16, 'dropout_rate': 0.4239401990518877, 'sparsity_weight': 0.0007391257250758944, 'classification_weight': 0.4056183097890931, 'n_estimators': 54, 'max_depth': 7, 'learning_rate': 0.043665150190959054, 'subsample': 0.8902838713472382, 'min_samples_split': 15, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.6206770953147763.\n",
      "[I 2025-05-10 07:48:38,467] Trial 14 finished with value: 0.5895253431485316 and parameters: {'latent_dim': 86, 'hidden_dim': 226, 'lr': 0.0016572753634650447, 'epochs': 10, 'dropout_rate': 0.45190936238299995, 'sparsity_weight': 0.0006183543719466589, 'classification_weight': 0.7106853767889512, 'n_estimators': 118, 'max_depth': 6, 'learning_rate': 0.027977314209481127, 'subsample': 0.7418241920738824, 'min_samples_split': 18, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.6206770953147763.\n",
      "[I 2025-05-10 07:49:32,203] Trial 15 finished with value: 0.5590637221072003 and parameters: {'latent_dim': 54, 'hidden_dim': 239, 'lr': 0.0005115106796240084, 'epochs': 21, 'dropout_rate': 0.2417108034129923, 'sparsity_weight': 0.00022957131702922107, 'classification_weight': 0.391838614490236, 'n_estimators': 91, 'max_depth': 8, 'learning_rate': 0.0800799224266441, 'subsample': 0.9094292214171724, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.6206770953147763.\n",
      "[I 2025-05-10 07:51:26,691] Trial 16 finished with value: 0.573920711601871 and parameters: {'latent_dim': 88, 'hidden_dim': 201, 'lr': 0.00015575342901184074, 'epochs': 32, 'dropout_rate': 0.3736835202215207, 'sparsity_weight': 0.0012542731181385302, 'classification_weight': 0.5205119451817867, 'n_estimators': 495, 'max_depth': 3, 'learning_rate': 0.021193380239160585, 'subsample': 0.7041845575034542, 'min_samples_split': 14, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.6206770953147763.\n",
      "[I 2025-05-10 07:52:19,330] Trial 17 finished with value: 0.63166168238632 and parameters: {'latent_dim': 64, 'hidden_dim': 139, 'lr': 0.00041481089542442124, 'epochs': 16, 'dropout_rate': 0.4553983603845069, 'sparsity_weight': 0.0002428924937439843, 'classification_weight': 0.6543759700061351, 'n_estimators': 182, 'max_depth': 5, 'learning_rate': 0.016953411330564182, 'subsample': 0.7632253452976929, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.63166168238632.\n",
      "[I 2025-05-10 07:53:34,918] Trial 18 finished with value: 0.5373821025994939 and parameters: {'latent_dim': 61, 'hidden_dim': 128, 'lr': 0.00040891360016728887, 'epochs': 37, 'dropout_rate': 0.27199849992060704, 'sparsity_weight': 0.00010241311963913285, 'classification_weight': 0.6888397215830093, 'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.01706779100268283, 'subsample': 0.7760049362619255, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 17 with value: 0.63166168238632.\n",
      "[I 2025-05-10 07:54:31,549] Trial 19 finished with value: 0.5976918947933441 and parameters: {'latent_dim': 48, 'hidden_dim': 87, 'lr': 0.0010231742940463252, 'epochs': 17, 'dropout_rate': 0.3755297007893846, 'sparsity_weight': 0.0012076270037246037, 'classification_weight': 0.7499845387319524, 'n_estimators': 237, 'max_depth': 5, 'learning_rate': 0.015907521621912574, 'subsample': 0.889111077232174, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 17 with value: 0.63166168238632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6553\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5174\n",
      "ROC-AUC autoencoded: 0.5489\n",
      "ROC-AUC autoencoded: 0.4970\n",
      "ROC-AUC autoencoded: 0.5667\n",
      "ROC-AUC autoencoded: 0.5323\n",
      "ROC-AUC autoencoded: 0.5759\n",
      "ROC-AUC autoencoded: 0.5547\n",
      "ROC-AUC autoencoded: 0.5731\n",
      "ROC-AUC autoencoded: 0.5583\n",
      "ROC-AUC autoencoded: 0.5589\n",
      "ROC-AUC autoencoded: 0.5541\n",
      "ROC-AUC autoencoded: 0.5639\n",
      "ROC-AUC autoencoded: 0.5446\n",
      "ROC-AUC autoencoded: 0.5840\n",
      "ROC-AUC autoencoded: 0.5461\n",
      "ROC-AUC autoencoded: 0.5016\n",
      "ROC-AUC autoencoded: 0.5292\n",
      "ROC-AUC autoencoded: 0.4976\n",
      "ROC-AUC autoencoded: 0.5528\n",
      "ROC-AUC autoencoded: 0.5128\n",
      "ROC-AUC autoencoded: 0.5882\n",
      "ROC-AUC autoencoded: 0.6155\n",
      "ROC-AUC autoencoded: 0.6029\n",
      "ROC-AUC autoencoded: 0.6106\n",
      "ROC-AUC autoencoded: 0.5925\n",
      "среднее 0.5551885203355088\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:00:51,507] A new study created in memory with name: no-name-78bb0a4f-5cd6-4f35-a8b1-9ff3efc2a016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:01:42,143] Trial 0 finished with value: 0.5717352963729775 and parameters: {'latent_dim': 98, 'hidden_dim': 66, 'lr': 0.008792264418013077, 'epochs': 42, 'dropout_rate': 0.29625437097125135, 'sparsity_weight': 0.03406287756968008, 'classification_weight': 0.19507566231114623, 'C': 5.850440176445904, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.5717352963729775.\n",
      "[I 2025-05-10 08:02:22,976] Trial 1 finished with value: 0.5882792730618817 and parameters: {'latent_dim': 86, 'hidden_dim': 129, 'lr': 0.0001606644136360063, 'epochs': 34, 'dropout_rate': 0.12080704341026838, 'sparsity_weight': 0.0010739979386378295, 'classification_weight': 0.34159733359699707, 'C': 0.783859063696453, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 1 with value: 0.5882792730618817.\n",
      "[I 2025-05-10 08:02:47,190] Trial 2 finished with value: 0.5375354650716969 and parameters: {'latent_dim': 81, 'hidden_dim': 126, 'lr': 0.002425384523646318, 'epochs': 19, 'dropout_rate': 0.10301601541894048, 'sparsity_weight': 0.006011771891909738, 'classification_weight': 0.22299937599992248, 'C': 0.42459853189317553, 'kernel': 'linear'}. Best is trial 1 with value: 0.5882792730618817.\n",
      "[I 2025-05-10 08:03:16,472] Trial 3 finished with value: 0.5415420596580016 and parameters: {'latent_dim': 20, 'hidden_dim': 88, 'lr': 0.0001548434589168298, 'epochs': 19, 'dropout_rate': 0.4093880372633766, 'sparsity_weight': 0.0028053997112178577, 'classification_weight': 0.8771970961377441, 'C': 54.62060841832519, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.5882792730618817.\n",
      "[I 2025-05-10 08:03:38,692] Trial 4 finished with value: 0.5686009508473276 and parameters: {'latent_dim': 96, 'hidden_dim': 82, 'lr': 0.001459233096495172, 'epochs': 16, 'dropout_rate': 0.3463599176934522, 'sparsity_weight': 0.000202235114387686, 'classification_weight': 0.1167493144912152, 'C': 1.8356667789069834, 'kernel': 'linear'}. Best is trial 1 with value: 0.5882792730618817.\n",
      "[I 2025-05-10 08:04:52,589] Trial 5 finished with value: 0.5313626255655242 and parameters: {'latent_dim': 94, 'hidden_dim': 243, 'lr': 0.00040799145218523036, 'epochs': 49, 'dropout_rate': 0.2657555943055701, 'sparsity_weight': 0.06391571087459506, 'classification_weight': 0.23397173029941343, 'C': 0.4397249759920571, 'kernel': 'linear'}. Best is trial 1 with value: 0.5882792730618817.\n",
      "[I 2025-05-10 08:05:29,636] Trial 6 finished with value: 0.5078598267004064 and parameters: {'latent_dim': 17, 'hidden_dim': 160, 'lr': 0.005026868134467837, 'epochs': 29, 'dropout_rate': 0.19867114492961263, 'sparsity_weight': 0.0008712290574816769, 'classification_weight': 0.5892231926402838, 'C': 22.900639357519193, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.5882792730618817.\n",
      "[I 2025-05-10 08:06:30,200] Trial 7 finished with value: 0.5947396672034353 and parameters: {'latent_dim': 35, 'hidden_dim': 208, 'lr': 0.0001061384617039073, 'epochs': 46, 'dropout_rate': 0.27605487754247704, 'sparsity_weight': 0.00024067205094525815, 'classification_weight': 0.5068666019600355, 'C': 22.256507137272788, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 7 with value: 0.5947396672034353.\n",
      "[I 2025-05-10 08:07:20,036] Trial 8 finished with value: 0.5670673261252971 and parameters: {'latent_dim': 57, 'hidden_dim': 223, 'lr': 0.0033724024903714457, 'epochs': 37, 'dropout_rate': 0.46188118593444794, 'sparsity_weight': 0.09287203932447276, 'classification_weight': 0.12707930082269706, 'C': 21.87622693779209, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 7 with value: 0.5947396672034353.\n",
      "[I 2025-05-10 08:07:47,081] Trial 9 finished with value: 0.5439575185951998 and parameters: {'latent_dim': 44, 'hidden_dim': 189, 'lr': 0.006467038275137847, 'epochs': 17, 'dropout_rate': 0.4889412494059394, 'sparsity_weight': 0.044551019731443965, 'classification_weight': 0.38467309360437907, 'C': 36.92855406499188, 'kernel': 'linear'}. Best is trial 7 with value: 0.5947396672034353.\n",
      "[I 2025-05-10 08:08:54,701] Trial 10 finished with value: 0.5630799018480178 and parameters: {'latent_dim': 38, 'hidden_dim': 194, 'lr': 0.0006018970023007905, 'epochs': 50, 'dropout_rate': 0.2238990434208377, 'sparsity_weight': 0.00014334763660126408, 'classification_weight': 0.6089646874431098, 'C': 7.292955815491117, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 7 with value: 0.5947396672034353.\n",
      "[I 2025-05-10 08:09:35,830] Trial 11 finished with value: 0.545126907445748 and parameters: {'latent_dim': 73, 'hidden_dim': 135, 'lr': 0.00010109071839080889, 'epochs': 31, 'dropout_rate': 0.11622543270853512, 'sparsity_weight': 0.000596291339884551, 'classification_weight': 0.4376185728165496, 'C': 2.0279719649601393, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 7 with value: 0.5947396672034353.\n",
      "[I 2025-05-10 08:10:29,269] Trial 12 finished with value: 0.541379112031286 and parameters: {'latent_dim': 61, 'hidden_dim': 187, 'lr': 0.0002729310076948812, 'epochs': 41, 'dropout_rate': 0.1816994825977721, 'sparsity_weight': 0.0005523299082864289, 'classification_weight': 0.3579226164922734, 'C': 0.18098277361517, 'kernel': 'poly', 'gamma': 'auto', 'degree': 3}. Best is trial 7 with value: 0.5947396672034353.\n",
      "[I 2025-05-10 08:11:03,680] Trial 13 finished with value: 0.6434801779004677 and parameters: {'latent_dim': 31, 'hidden_dim': 113, 'lr': 0.00021378336537071637, 'epochs': 29, 'dropout_rate': 0.37052513853202323, 'sparsity_weight': 0.0019411778766688249, 'classification_weight': 0.5385538436660788, 'C': 0.7505767265789991, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 13 with value: 0.6434801779004677.\n",
      "[I 2025-05-10 08:11:36,333] Trial 14 finished with value: 0.574543746645196 and parameters: {'latent_dim': 33, 'hidden_dim': 217, 'lr': 0.0008102385876560447, 'epochs': 25, 'dropout_rate': 0.36063229940168634, 'sparsity_weight': 0.009331917297449302, 'classification_weight': 0.7163606419883094, 'C': 89.26342594991559, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 13 with value: 0.6434801779004677.\n",
      "[I 2025-05-10 08:12:03,839] Trial 15 finished with value: 0.5592937658155049 and parameters: {'latent_dim': 29, 'hidden_dim': 106, 'lr': 0.0002781907973675321, 'epochs': 26, 'dropout_rate': 0.37541582801627676, 'sparsity_weight': 0.002154647357460651, 'classification_weight': 0.5528235620878482, 'C': 6.316356955916667, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 13 with value: 0.6434801779004677.\n",
      "[I 2025-05-10 08:13:03,014] Trial 16 finished with value: 0.619852772026685 and parameters: {'latent_dim': 47, 'hidden_dim': 168, 'lr': 0.00011320023133271256, 'epochs': 44, 'dropout_rate': 0.30666391186995623, 'sparsity_weight': 0.00023668006619540223, 'classification_weight': 0.6934374028506216, 'C': 0.1386933387591591, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 13 with value: 0.6434801779004677.\n",
      "[I 2025-05-10 08:13:15,637] Trial 17 finished with value: 0.5809370447051606 and parameters: {'latent_dim': 49, 'hidden_dim': 155, 'lr': 0.00022901196474159997, 'epochs': 10, 'dropout_rate': 0.43442422062704916, 'sparsity_weight': 0.011875825827855341, 'classification_weight': 0.7328655521172921, 'C': 0.19689974177717315, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 13 with value: 0.6434801779004677.\n",
      "[I 2025-05-10 08:14:08,499] Trial 18 finished with value: 0.5747066942719118 and parameters: {'latent_dim': 67, 'hidden_dim': 161, 'lr': 0.0005103163572843911, 'epochs': 38, 'dropout_rate': 0.34561906244455054, 'sparsity_weight': 0.0003331821278853557, 'classification_weight': 0.6960021078276876, 'C': 0.11566183276162056, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 13 with value: 0.6434801779004677.\n",
      "[I 2025-05-10 08:14:34,442] Trial 19 finished with value: 0.5653515834675255 and parameters: {'latent_dim': 24, 'hidden_dim': 107, 'lr': 0.0011923381051233484, 'epochs': 23, 'dropout_rate': 0.32308190779103657, 'sparsity_weight': 0.001869454825471446, 'classification_weight': 0.8489267191586991, 'C': 0.8152992771063665, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 13 with value: 0.6434801779004677.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5995\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5469\n",
      "ROC-AUC autoencoded: 0.5579\n",
      "ROC-AUC autoencoded: 0.5705\n",
      "ROC-AUC autoencoded: 0.5739\n",
      "ROC-AUC autoencoded: 0.5713\n",
      "ROC-AUC autoencoded: 0.5564\n",
      "ROC-AUC autoencoded: 0.5750\n",
      "ROC-AUC autoencoded: 0.5831\n",
      "ROC-AUC autoencoded: 0.5706\n",
      "ROC-AUC autoencoded: 0.6069\n",
      "ROC-AUC autoencoded: 0.5538\n",
      "ROC-AUC autoencoded: 0.6158\n",
      "ROC-AUC autoencoded: 0.5601\n",
      "ROC-AUC autoencoded: 0.5546\n",
      "ROC-AUC autoencoded: 0.5758\n",
      "ROC-AUC autoencoded: 0.4814\n",
      "ROC-AUC autoencoded: 0.5532\n",
      "ROC-AUC autoencoded: 0.5575\n",
      "ROC-AUC autoencoded: 0.5460\n",
      "ROC-AUC autoencoded: 0.5213\n",
      "ROC-AUC autoencoded: 0.6060\n",
      "ROC-AUC autoencoded: 0.6277\n",
      "ROC-AUC autoencoded: 0.6199\n",
      "ROC-AUC autoencoded: 0.6068\n",
      "ROC-AUC autoencoded: 0.6505\n",
      "среднее 0.5737192557270673\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:18:39,102] A new study created in memory with name: no-name-d819529d-a993-440d-8e95-9d28b33fbb67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:19:31,268] Trial 0 finished with value: 0.5683804922935357 and parameters: {'latent_dim': 60, 'hidden_dim': 247, 'lr': 0.00016386730082072683, 'epochs': 36, 'dropout_rate': 0.2749023344981857, 'sparsity_weight': 0.027741019995136337, 'classification_weight': 0.6948732838506152}. Best is trial 0 with value: 0.5683804922935357.\n",
      "[I 2025-05-10 08:20:19,546] Trial 1 finished with value: 0.5590828924162258 and parameters: {'latent_dim': 10, 'hidden_dim': 252, 'lr': 0.000490794298540065, 'epochs': 37, 'dropout_rate': 0.27391235748201403, 'sparsity_weight': 0.03645196636026587, 'classification_weight': 0.4302684897499204}. Best is trial 0 with value: 0.5683804922935357.\n",
      "[I 2025-05-10 08:20:41,168] Trial 2 finished with value: 0.5604439843570278 and parameters: {'latent_dim': 74, 'hidden_dim': 120, 'lr': 0.003831935490396654, 'epochs': 17, 'dropout_rate': 0.10464345282316954, 'sparsity_weight': 0.0035228608253133377, 'classification_weight': 0.15914639509058084}. Best is trial 0 with value: 0.5683804922935357.\n",
      "[I 2025-05-10 08:21:22,741] Trial 3 finished with value: 0.5867264780308258 and parameters: {'latent_dim': 70, 'hidden_dim': 164, 'lr': 0.006824974218877204, 'epochs': 34, 'dropout_rate': 0.3797121243422329, 'sparsity_weight': 0.0005334790185357237, 'classification_weight': 0.17257014034832824}. Best is trial 3 with value: 0.5867264780308258.\n",
      "[I 2025-05-10 08:22:04,924] Trial 4 finished with value: 0.566233417682693 and parameters: {'latent_dim': 96, 'hidden_dim': 67, 'lr': 0.00047601773659746165, 'epochs': 38, 'dropout_rate': 0.25004999918011284, 'sparsity_weight': 0.08661247621870177, 'classification_weight': 0.6065136638270822}. Best is trial 3 with value: 0.5867264780308258.\n",
      "[I 2025-05-10 08:22:54,850] Trial 5 finished with value: 0.5899662602561153 and parameters: {'latent_dim': 67, 'hidden_dim': 243, 'lr': 0.00019917873326986732, 'epochs': 31, 'dropout_rate': 0.1506755798525756, 'sparsity_weight': 0.04923744351267722, 'classification_weight': 0.35254698705005383}. Best is trial 5 with value: 0.5899662602561153.\n",
      "[I 2025-05-10 08:23:45,753] Trial 6 finished with value: 0.616037880530634 and parameters: {'latent_dim': 30, 'hidden_dim': 137, 'lr': 0.000102734229244065, 'epochs': 43, 'dropout_rate': 0.47438430213341864, 'sparsity_weight': 0.0033078846523058657, 'classification_weight': 0.26587562717868096}. Best is trial 6 with value: 0.616037880530634.\n",
      "[I 2025-05-10 08:24:07,064] Trial 7 finished with value: 0.5897745571658616 and parameters: {'latent_dim': 84, 'hidden_dim': 236, 'lr': 0.0008816961543571869, 'epochs': 17, 'dropout_rate': 0.1818149555562444, 'sparsity_weight': 0.0020127293310206493, 'classification_weight': 0.1257988863316303}. Best is trial 6 with value: 0.616037880530634.\n",
      "[I 2025-05-10 08:24:39,362] Trial 8 finished with value: 0.533567211103443 and parameters: {'latent_dim': 95, 'hidden_dim': 255, 'lr': 0.0008618241765538012, 'epochs': 21, 'dropout_rate': 0.22369248973507494, 'sparsity_weight': 0.09834080187264775, 'classification_weight': 0.31575392117255807}. Best is trial 6 with value: 0.616037880530634.\n",
      "[I 2025-05-10 08:25:25,346] Trial 9 finished with value: 0.6103059581320451 and parameters: {'latent_dim': 30, 'hidden_dim': 120, 'lr': 0.0001884530289144543, 'epochs': 38, 'dropout_rate': 0.31107567707955674, 'sparsity_weight': 0.0002119897688726158, 'classification_weight': 0.4926994748935266}. Best is trial 6 with value: 0.616037880530634.\n",
      "[I 2025-05-10 08:26:27,089] Trial 10 finished with value: 0.5435166014876159 and parameters: {'latent_dim': 40, 'hidden_dim': 186, 'lr': 0.0024343937069011136, 'epochs': 50, 'dropout_rate': 0.48922508560898187, 'sparsity_weight': 0.007399401955858837, 'classification_weight': 0.764658237833789}. Best is trial 6 with value: 0.616037880530634.\n",
      "[I 2025-05-10 08:27:20,501] Trial 11 finished with value: 0.6030787516294763 and parameters: {'latent_dim': 33, 'hidden_dim': 118, 'lr': 0.00010738465038934293, 'epochs': 47, 'dropout_rate': 0.381871146668359, 'sparsity_weight': 0.00012204334277469286, 'classification_weight': 0.5492568106258995}. Best is trial 6 with value: 0.616037880530634.\n",
      "[I 2025-05-10 08:28:13,492] Trial 12 finished with value: 0.6392722950693965 and parameters: {'latent_dim': 23, 'hidden_dim': 116, 'lr': 0.00028362071252181667, 'epochs': 45, 'dropout_rate': 0.49252450508545165, 'sparsity_weight': 0.00045927165331090334, 'classification_weight': 0.31975673637124696}. Best is trial 12 with value: 0.6392722950693965.\n",
      "[I 2025-05-10 08:28:59,471] Trial 13 finished with value: 0.6218081435472741 and parameters: {'latent_dim': 12, 'hidden_dim': 83, 'lr': 0.0003616365948136519, 'epochs': 44, 'dropout_rate': 0.4819895263250715, 'sparsity_weight': 0.0009081673913823369, 'classification_weight': 0.2888120414381871}. Best is trial 12 with value: 0.6392722950693965.\n",
      "[I 2025-05-10 08:29:27,305] Trial 14 finished with value: 0.6289394985047159 and parameters: {'latent_dim': 10, 'hidden_dim': 69, 'lr': 0.0004055655681774782, 'epochs': 25, 'dropout_rate': 0.41137154343124926, 'sparsity_weight': 0.0006747749095086717, 'classification_weight': 0.8841620088429658}. Best is trial 12 with value: 0.6392722950693965.\n",
      "[I 2025-05-10 08:29:56,397] Trial 15 finished with value: 0.5748983973621654 and parameters: {'latent_dim': 47, 'hidden_dim': 92, 'lr': 0.0017157088101992606, 'epochs': 26, 'dropout_rate': 0.4200769095800129, 'sparsity_weight': 0.00041584601288514774, 'classification_weight': 0.8145525663181655}. Best is trial 12 with value: 0.6392722950693965.\n",
      "[I 2025-05-10 08:30:06,786] Trial 16 finished with value: 0.5604056437389772 and parameters: {'latent_dim': 19, 'hidden_dim': 64, 'lr': 0.00032704775303830593, 'epochs': 10, 'dropout_rate': 0.424503983542179, 'sparsity_weight': 0.00101355198159587, 'classification_weight': 0.6735933251239302}. Best is trial 12 with value: 0.6392722950693965.\n",
      "[I 2025-05-10 08:30:33,645] Trial 17 finished with value: 0.5939345142243693 and parameters: {'latent_dim': 20, 'hidden_dim': 97, 'lr': 0.0006623860003516757, 'epochs': 26, 'dropout_rate': 0.3338173171500044, 'sparsity_weight': 0.000314542950495244, 'classification_weight': 0.8696537720529124}. Best is trial 12 with value: 0.6392722950693965.\n",
      "[I 2025-05-10 08:31:04,641] Trial 18 finished with value: 0.5714094011195461 and parameters: {'latent_dim': 48, 'hidden_dim': 153, 'lr': 0.0012747298738959778, 'epochs': 27, 'dropout_rate': 0.4389510979079853, 'sparsity_weight': 0.00011047420894930275, 'classification_weight': 0.4315955100615846}. Best is trial 12 with value: 0.6392722950693965.\n",
      "[I 2025-05-10 08:31:31,877] Trial 19 finished with value: 0.6181657848324514 and parameters: {'latent_dim': 21, 'hidden_dim': 202, 'lr': 0.00027242218849236324, 'epochs': 21, 'dropout_rate': 0.3600533960291589, 'sparsity_weight': 0.01223795331283676, 'classification_weight': 0.5879199001432522}. Best is trial 12 with value: 0.6392722950693965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6067\n"
     ]
    }
   ],
   "source": [
    "def predict_classifier_head(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, _, classification = model(X_tensor)\n",
    "    return classification.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    sparsity_weight = trial.suggest_float('sparsity_weight', 1e-4, 1e-1, log=True)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_sparse_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, sparsity_weight, classification_weight)\n",
    "        \n",
    "        y_pred_proba = predict_classifier_head(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingSparseAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_sparse_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "y_pred_proba = predict_classifier_head(autoencoder, X_val_all)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5843\n",
      "ROC-AUC autoencoded: 0.5326\n",
      "ROC-AUC autoencoded: 0.5509\n",
      "ROC-AUC autoencoded: 0.5461\n",
      "ROC-AUC autoencoded: 0.5651\n",
      "ROC-AUC autoencoded: 0.5688\n",
      "ROC-AUC autoencoded: 0.5904\n",
      "ROC-AUC autoencoded: 0.5810\n",
      "ROC-AUC autoencoded: 0.5760\n",
      "ROC-AUC autoencoded: 0.5719\n",
      "ROC-AUC autoencoded: 0.6035\n",
      "ROC-AUC autoencoded: 0.6023\n",
      "ROC-AUC autoencoded: 0.6082\n",
      "ROC-AUC autoencoded: 0.5826\n",
      "ROC-AUC autoencoded: 0.5925\n",
      "ROC-AUC autoencoded: 0.5478\n",
      "ROC-AUC autoencoded: 0.5213\n",
      "ROC-AUC autoencoded: 0.5373\n",
      "ROC-AUC autoencoded: 0.5013\n",
      "ROC-AUC autoencoded: 0.5262\n",
      "ROC-AUC autoencoded: 0.6579\n",
      "ROC-AUC autoencoded: 0.6314\n",
      "ROC-AUC autoencoded: 0.6400\n",
      "ROC-AUC autoencoded: 0.6274\n",
      "ROC-AUC autoencoded: 0.6658\n",
      "среднее 0.5805025916966112\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingSparseAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_sparse_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['sparsity_weight'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = predict_classifier_head(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше идет блок со stacked автоэнкодером"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:37:30,038] A new study created in memory with name: no-name-60c5efc5-077a-42b7-bb20-7243655848c1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:38:04,291] Trial 0 finished with value: 0.5704125450502261 and parameters: {'num_layers': 2, 'latent_dim_0': 38, 'latent_dim_1': 18, 'lr': 0.005318275574798111, 'epochs': 40, 'dropout_rate': 0.32455597429193533, 'C': 92.71870600730225, 'solver': 'saga'}. Best is trial 0 with value: 0.5704125450502261.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:38:19,543] Trial 1 finished with value: 0.5949505406027146 and parameters: {'num_layers': 2, 'latent_dim_0': 25, 'latent_dim_1': 12, 'lr': 0.0005525208978037661, 'epochs': 18, 'dropout_rate': 0.18820030116770337, 'C': 0.29398409179921486, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.5949505406027146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:38:48,014] Trial 2 finished with value: 0.5860171765968868 and parameters: {'num_layers': 2, 'latent_dim_0': 21, 'latent_dim_1': 13, 'lr': 0.009414223370854619, 'epochs': 36, 'dropout_rate': 0.10978453688598609, 'C': 0.01725689661408734, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.5949505406027146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:39:21,370] Trial 3 finished with value: 0.5760102752856375 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 13, 'lr': 0.003262359308813166, 'epochs': 40, 'dropout_rate': 0.4174619940518227, 'C': 39.28156480452003, 'solver': 'liblinear'}. Best is trial 1 with value: 0.5949505406027146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:39:53,783] Trial 4 finished with value: 0.5587186565447435 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 17, 'lr': 0.0004613587022107844, 'epochs': 34, 'dropout_rate': 0.34726309069432576, 'C': 0.8522626435286763, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.5949505406027146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:40:22,034] Trial 5 finished with value: 0.5688597500191702 and parameters: {'num_layers': 2, 'latent_dim_0': 37, 'latent_dim_1': 10, 'lr': 0.00013471071303275105, 'epochs': 32, 'dropout_rate': 0.16102137518160153, 'C': 0.46186255037232127, 'solver': 'saga'}. Best is trial 1 with value: 0.5949505406027146.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:41:04,183] Trial 6 finished with value: 0.6155394524959742 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 17, 'lr': 0.0009671227653554779, 'epochs': 47, 'dropout_rate': 0.2666428249731402, 'C': 4.073857672022021, 'solver': 'liblinear'}. Best is trial 6 with value: 0.6155394524959742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:41:42,659] Trial 7 finished with value: 0.5478107507093015 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 16, 'lr': 0.00012890879341605733, 'epochs': 46, 'dropout_rate': 0.402211963716281, 'C': 0.13704306022574478, 'solver': 'liblinear'}. Best is trial 6 with value: 0.6155394524959742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:42:14,410] Trial 8 finished with value: 0.5993213710605015 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 18, 'lr': 0.0036307215497205637, 'epochs': 36, 'dropout_rate': 0.2618498423139042, 'C': 56.37215650216209, 'solver': 'saga'}. Best is trial 6 with value: 0.6155394524959742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:42:56,439] Trial 9 finished with value: 0.5748408864350893 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 14, 'lr': 0.0007224420002836766, 'epochs': 50, 'dropout_rate': 0.307763902189238, 'C': 1.8642174786141739, 'solver': 'saga'}. Best is trial 6 with value: 0.6155394524959742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:43:13,463] Trial 10 finished with value: 0.5985737290085115 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 20, 'lr': 0.0015056717487901168, 'epochs': 20, 'dropout_rate': 0.21484249160000127, 'C': 6.306508604855857, 'solver': 'liblinear'}. Best is trial 6 with value: 0.6155394524959742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:43:34,920] Trial 11 finished with value: 0.6600337397438847 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 19, 'lr': 0.0017589221704407002, 'epochs': 25, 'dropout_rate': 0.24101351180902197, 'C': 12.23706509453469, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6600337397438847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:43:57,994] Trial 12 finished with value: 0.5930910206272525 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 20, 'lr': 0.0015014575163147424, 'epochs': 26, 'dropout_rate': 0.2589140707719755, 'C': 9.777229166960106, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6600337397438847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:44:12,418] Trial 13 finished with value: 0.5795951230733839 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 18, 'lr': 0.0013465428529733704, 'epochs': 13, 'dropout_rate': 0.247460115692786, 'C': 5.968104636320758, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6600337397438847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:44:40,940] Trial 14 finished with value: 0.5408135879150371 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 16, 'lr': 0.00022860091903457885, 'epochs': 26, 'dropout_rate': 0.47995653684639716, 'C': 17.225565282258206, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6600337397438847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:45:09,041] Trial 15 finished with value: 0.5885668276972624 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 19, 'lr': 0.0024592960415058818, 'epochs': 27, 'dropout_rate': 0.10850784269256558, 'C': 2.3819893500345493, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6600337397438847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:45:17,609] Trial 16 finished with value: 0.5724829384249674 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 16, 'lr': 0.0003615086697101073, 'epochs': 10, 'dropout_rate': 0.3634755585238266, 'C': 20.883516286497628, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6600337397438847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:45:34,366] Trial 17 finished with value: 0.5416954221302047 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 15, 'lr': 0.0009109920112812427, 'epochs': 19, 'dropout_rate': 0.2807951632606259, 'C': 2.9463410682768427, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6600337397438847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:46:14,246] Trial 18 finished with value: 0.6262173146231117 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 20, 'lr': 0.0020627871118399544, 'epochs': 45, 'dropout_rate': 0.16294710167881418, 'C': 0.06904844572572733, 'solver': 'liblinear'}. Best is trial 11 with value: 0.6600337397438847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:46:48,412] Trial 19 finished with value: 0.6044398435702782 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 20, 'lr': 0.0021038940177061528, 'epochs': 40, 'dropout_rate': 0.14754025650873046, 'C': 0.03789611009392411, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.6600337397438847.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.6221\n"
     ]
    }
   ],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(SimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "        \n",
    "        return reconstructions, latents\n",
    "    \n",
    "def train_stacked_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    \n",
    "    # Обучаем каждый автоэнкодер последовательно\n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, latent)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, _ in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent = ae(batch_x)\n",
    "                loss = criterion(reconstructed, batch_x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры логистической регрессии\n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5619\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5617\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5720\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5517\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5704\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5320\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5608\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5470\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5315\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5730\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5022\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5966\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5352\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5140\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5627\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5110\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5171\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5352\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5766\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5026\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6119\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5182\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5554\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6011\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6132\n",
      "среднее 0.5525926610074469\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:49:19,009] A new study created in memory with name: no-name-537a2066-5866-491e-b9a4-14e016d3339e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:50:20,814] Trial 0 finished with value: 0.5152787362932291 and parameters: {'num_layers': 2, 'latent_dim_0': 39, 'latent_dim_1': 12, 'lr': 0.00013082701253353042, 'epochs': 49, 'dropout_rate': 0.24110463622931289, 'n_estimators': 320, 'max_depth': 8, 'learning_rate': 0.03323465092348356, 'subsample': 0.6645915129321791, 'min_samples_split': 16, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.5152787362932291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:51:08,705] Trial 1 finished with value: 0.567383636224216 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 15, 'lr': 0.00966362204993208, 'epochs': 46, 'dropout_rate': 0.3822971507593851, 'n_estimators': 106, 'max_depth': 6, 'learning_rate': 0.09726466586849665, 'subsample': 0.7791133816334406, 'min_samples_split': 15, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.567383636224216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:52:03,066] Trial 2 finished with value: 0.5488459473966719 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 16, 'lr': 0.004035914138407705, 'epochs': 39, 'dropout_rate': 0.1092338994706576, 'n_estimators': 484, 'max_depth': 4, 'learning_rate': 0.08188626361551274, 'subsample': 0.7220195845643985, 'min_samples_split': 18, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.567383636224216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:53:02,535] Trial 3 finished with value: 0.5371520588911892 and parameters: {'num_layers': 2, 'latent_dim_0': 39, 'latent_dim_1': 20, 'lr': 0.0005164455940777717, 'epochs': 21, 'dropout_rate': 0.4762786206814663, 'n_estimators': 429, 'max_depth': 7, 'learning_rate': 0.04524218699257284, 'subsample': 0.7977629185772183, 'min_samples_split': 12, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.567383636224216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:53:36,122] Trial 4 finished with value: 0.5051376428188022 and parameters: {'num_layers': 2, 'latent_dim_0': 25, 'latent_dim_1': 11, 'lr': 0.00012908054973727884, 'epochs': 31, 'dropout_rate': 0.43427644643713426, 'n_estimators': 131, 'max_depth': 10, 'learning_rate': 0.013202398607091865, 'subsample': 0.6852030537374686, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.567383636224216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:54:28,080] Trial 5 finished with value: 0.5232344145387623 and parameters: {'num_layers': 2, 'latent_dim_0': 37, 'latent_dim_1': 14, 'lr': 0.00037248556000594985, 'epochs': 32, 'dropout_rate': 0.16743519263705264, 'n_estimators': 458, 'max_depth': 4, 'learning_rate': 0.010845907468324223, 'subsample': 0.9592359374939059, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.567383636224216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:55:09,644] Trial 6 finished with value: 0.5440341998313013 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 13, 'lr': 0.00035747501581038794, 'epochs': 45, 'dropout_rate': 0.3285264683850758, 'n_estimators': 105, 'max_depth': 6, 'learning_rate': 0.02176206660819074, 'subsample': 0.7467839255556348, 'min_samples_split': 17, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.567383636224216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:56:19,909] Trial 7 finished with value: 0.5526991795107737 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 10, 'lr': 0.001016711093226701, 'epochs': 45, 'dropout_rate': 0.3276307347818357, 'n_estimators': 477, 'max_depth': 8, 'learning_rate': 0.10883476761479748, 'subsample': 0.7635828469296418, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.567383636224216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:56:46,851] Trial 8 finished with value: 0.5280653324131585 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 10, 'lr': 0.0067468970496836955, 'epochs': 14, 'dropout_rate': 0.44459698982266194, 'n_estimators': 255, 'max_depth': 8, 'learning_rate': 0.02716085855151051, 'subsample': 0.9465194751068978, 'min_samples_split': 19, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.567383636224216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:58:12,197] Trial 9 finished with value: 0.5253048079135035 and parameters: {'num_layers': 2, 'latent_dim_0': 37, 'latent_dim_1': 19, 'lr': 0.0003980980910934259, 'epochs': 46, 'dropout_rate': 0.399795009414758, 'n_estimators': 465, 'max_depth': 8, 'learning_rate': 0.08219415935560404, 'subsample': 0.803877035346132, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.567383636224216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:58:42,550] Trial 10 finished with value: 0.541254505022621 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 17, 'lr': 0.0024271266197354586, 'epochs': 23, 'dropout_rate': 0.2497124574496715, 'n_estimators': 208, 'max_depth': 3, 'learning_rate': 0.2613313689076234, 'subsample': 0.875275288007095, 'min_samples_split': 13, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.567383636224216.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 08:59:41,063] Trial 11 finished with value: 0.583218311479181 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 17, 'lr': 0.002009741924638159, 'epochs': 39, 'dropout_rate': 0.35854147913472667, 'n_estimators': 347, 'max_depth': 10, 'learning_rate': 0.1663351026637929, 'subsample': 0.6166775692888561, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.583218311479181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:00:42,792] Trial 12 finished with value: 0.5544628479411089 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 17, 'lr': 0.009089280822435779, 'epochs': 38, 'dropout_rate': 0.3588783754177105, 'n_estimators': 356, 'max_depth': 10, 'learning_rate': 0.22235473163573394, 'subsample': 0.603752641219117, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.583218311479181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:01:19,458] Trial 13 finished with value: 0.5471206195843877 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 15, 'lr': 0.0019212090136193764, 'epochs': 38, 'dropout_rate': 0.3922811511997836, 'n_estimators': 60, 'max_depth': 6, 'learning_rate': 0.1369648998906394, 'subsample': 0.8781286617277606, 'min_samples_split': 14, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.583218311479181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:02:04,539] Trial 14 finished with value: 0.541312015949697 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 18, 'lr': 0.0036078584240040183, 'epochs': 41, 'dropout_rate': 0.28334505854389463, 'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.1648548578049688, 'subsample': 0.6006746111642769, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.583218311479181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:03:21,596] Trial 15 finished with value: 0.5553638524653017 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 15, 'lr': 0.0011538393408921281, 'epochs': 50, 'dropout_rate': 0.3872711625740533, 'n_estimators': 384, 'max_depth': 9, 'learning_rate': 0.0663154174512459, 'subsample': 0.8579847634451312, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.583218311479181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:03:59,188] Trial 16 finished with value: 0.5250364235871482 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 16, 'lr': 0.005595098929889555, 'epochs': 25, 'dropout_rate': 0.49152362231185764, 'n_estimators': 285, 'max_depth': 7, 'learning_rate': 0.15145075798924204, 'subsample': 0.6740790407514679, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.583218311479181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:04:38,804] Trial 17 finished with value: 0.5263208342918487 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 13, 'lr': 0.0016540486560504399, 'epochs': 34, 'dropout_rate': 0.27857595581943717, 'n_estimators': 192, 'max_depth': 5, 'learning_rate': 0.29938608516431314, 'subsample': 0.6473010057959182, 'min_samples_split': 6, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.583218311479181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:06:04,849] Trial 18 finished with value: 0.5679395751859521 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 18, 'lr': 0.009240159673773016, 'epochs': 42, 'dropout_rate': 0.3437797508098239, 'n_estimators': 391, 'max_depth': 9, 'learning_rate': 0.10773152197099486, 'subsample': 0.9918467317173573, 'min_samples_split': 11, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.583218311479181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:07:23,606] Trial 19 finished with value: 0.5618817575339314 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 20, 'lr': 0.003208690768739097, 'epochs': 27, 'dropout_rate': 0.21347791272434277, 'n_estimators': 391, 'max_depth': 9, 'learning_rate': 0.05099037942854016, 'subsample': 0.9995203262199579, 'min_samples_split': 11, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.583218311479181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.5481\n"
     ]
    }
   ],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(SimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "        \n",
    "        return reconstructions, latents\n",
    "    \n",
    "def train_stacked_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    \n",
    "    # Обучаем каждый автоэнкодер последовательно\n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, latent)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, _ in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent = ae(batch_x)\n",
    "                loss = criterion(reconstructed, batch_x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры градиентного бустинга\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5668\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5411\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5357\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4483\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5406\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5595\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5645\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5325\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4958\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5287\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5011\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5450\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5217\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5516\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5199\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4773\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4973\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4532\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4996\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5107\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5481\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5614\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6013\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5454\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5377\n",
      "среднее 0.5273936839736414\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:14:34,966] A new study created in memory with name: no-name-61d2b37b-9c0e-41d2-9bea-8c92b22499c5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:15:01,400] Trial 0 finished with value: 0.5260716202745188 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 15, 'lr': 0.0010923446403356175, 'epochs': 27, 'dropout_rate': 0.41728140716152595, 'C': 1.9686822749404813, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 0 with value: 0.5260716202745188.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:15:51,738] Trial 1 finished with value: 0.5478299210183267 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 10, 'lr': 0.0006130916239096428, 'epochs': 49, 'dropout_rate': 0.36718505562054815, 'C': 2.018314971603196, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.5478299210183267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:16:05,782] Trial 2 finished with value: 0.534219001610306 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 13, 'lr': 0.0007501559274952849, 'epochs': 15, 'dropout_rate': 0.3724265478551988, 'C': 1.148131971518116, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.5478299210183267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:16:46,658] Trial 3 finished with value: 0.5107545433632391 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 11, 'lr': 0.0023481476201761098, 'epochs': 44, 'dropout_rate': 0.30431681013015327, 'C': 0.5513468176700097, 'kernel': 'poly', 'gamma': 'scale', 'degree': 3}. Best is trial 1 with value: 0.5478299210183267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:17:03,936] Trial 4 finished with value: 0.52336860670194 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 18, 'lr': 0.00012488361485075901, 'epochs': 18, 'dropout_rate': 0.4636029855814091, 'C': 49.1619180775108, 'kernel': 'poly', 'gamma': 'auto', 'degree': 2}. Best is trial 1 with value: 0.5478299210183267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:17:39,652] Trial 5 finished with value: 0.5229085192853308 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 10, 'lr': 0.002644447408653907, 'epochs': 36, 'dropout_rate': 0.2439791643880896, 'C': 83.71460348464336, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.5478299210183267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:17:52,773] Trial 6 finished with value: 0.5040065945863047 and parameters: {'num_layers': 2, 'latent_dim_0': 21, 'latent_dim_1': 14, 'lr': 0.0009207905381211476, 'epochs': 13, 'dropout_rate': 0.23478353425328935, 'C': 0.4371757599507898, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 1 with value: 0.5478299210183267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:18:26,773] Trial 7 finished with value: 0.5325415995705851 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 19, 'lr': 0.0009000983178436256, 'epochs': 42, 'dropout_rate': 0.22963485469184808, 'C': 0.45151034724727007, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4}. Best is trial 1 with value: 0.5478299210183267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:18:58,030] Trial 8 finished with value: 0.5056360708534621 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 14, 'lr': 0.0006202081601851312, 'epochs': 35, 'dropout_rate': 0.185401963922597, 'C': 0.7585140823710129, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 1 with value: 0.5478299210183267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:19:18,614] Trial 9 finished with value: 0.49277279349743114 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 19, 'lr': 0.00012833954344881957, 'epochs': 21, 'dropout_rate': 0.19084976507092954, 'C': 1.1558814595990907, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 1 with value: 0.5478299210183267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:20:02,920] Trial 10 finished with value: 0.5258415765662142 and parameters: {'num_layers': 2, 'latent_dim_0': 39, 'latent_dim_1': 12, 'lr': 0.009792782769297894, 'epochs': 50, 'dropout_rate': 0.11213701113176586, 'C': 9.303455032710705, 'kernel': 'linear'}. Best is trial 1 with value: 0.5478299210183267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:20:16,702] Trial 11 finished with value: 0.4786826163637758 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 12, 'lr': 0.0003260355212494245, 'epochs': 11, 'dropout_rate': 0.3757863682274716, 'C': 0.1261710943025026, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.5478299210183267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:20:40,966] Trial 12 finished with value: 0.4891304347826087 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 10, 'lr': 0.00035813023670430743, 'epochs': 26, 'dropout_rate': 0.3597496520046066, 'C': 7.072648868165864, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.5478299210183267.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:21:10,726] Trial 13 finished with value: 0.5749750785982669 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 17, 'lr': 0.00246041654421068, 'epochs': 33, 'dropout_rate': 0.4918853070473206, 'C': 4.125645052935031, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 13 with value: 0.5749750785982669.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:21:58,491] Trial 14 finished with value: 0.5507821486082355 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 17, 'lr': 0.0032818467142346356, 'epochs': 50, 'dropout_rate': 0.4924322502604151, 'C': 5.73251799844808, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 13 with value: 0.5749750785982669.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:22:29,602] Trial 15 finished with value: 0.5672494440610382 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 17, 'lr': 0.00536297354973038, 'epochs': 35, 'dropout_rate': 0.4917310571458895, 'C': 12.084736325527413, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 13 with value: 0.5749750785982669.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:23:05,117] Trial 16 finished with value: 0.5759144237405106 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 17, 'lr': 0.007294272867512376, 'epochs': 34, 'dropout_rate': 0.45106137038642746, 'C': 23.04357961326443, 'kernel': 'linear'}. Best is trial 16 with value: 0.5759144237405106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:23:31,210] Trial 17 finished with value: 0.5009393451422436 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 16, 'lr': 0.009752476691805498, 'epochs': 30, 'dropout_rate': 0.43227929499231477, 'C': 26.34151167538751, 'kernel': 'linear'}. Best is trial 16 with value: 0.5759144237405106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:24:11,796] Trial 18 finished with value: 0.5062495207422744 and parameters: {'num_layers': 2, 'latent_dim_0': 37, 'latent_dim_1': 20, 'lr': 0.001716513205192, 'epochs': 40, 'dropout_rate': 0.4494775916210621, 'C': 21.740981708392216, 'kernel': 'linear'}. Best is trial 16 with value: 0.5759144237405106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:24:29,943] Trial 19 finished with value: 0.5161797408174219 and parameters: {'num_layers': 2, 'latent_dim_0': 30, 'latent_dim_1': 16, 'lr': 0.004917792506091567, 'epochs': 23, 'dropout_rate': 0.3037023538139586, 'C': 4.1969755673876215, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 16 with value: 0.5759144237405106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.5626\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры SVC\n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs, batch_size, lr)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5416\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5426\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5043\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5181\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5603\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5212\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4497\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4892\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4718\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5517\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5035\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5178\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4569\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5537\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4738\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4091\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5331\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4856\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4939\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4536\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5108\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4985\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5859\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5906\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4722\n",
      "среднее 0.5075775035016836\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:28:21,262] A new study created in memory with name: no-name-0cd33a76-4baf-4051-9661-3d25ab02726d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:28:59,445] Trial 0 finished with value: 0.577582240625719 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 15, 'lr_ae': 0.007698096069764693, 'epochs_ae': 22, 'dropout_rate_ae': 0.3333390589292551, 'hidden_dim_mlp': 60, 'lr_mlp': 0.007329680017164288, 'epochs_mlp': 31, 'dropout_rate_mlp': 0.409717980428288}. Best is trial 0 with value: 0.577582240625719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:29:25,589] Trial 1 finished with value: 0.5475615366919714 and parameters: {'num_layers': 2, 'latent_dim_0': 25, 'latent_dim_1': 11, 'lr_ae': 0.00017893306437673313, 'epochs_ae': 24, 'dropout_rate_ae': 0.11609948244796559, 'hidden_dim_mlp': 74, 'lr_mlp': 0.0016639404033873641, 'epochs_mlp': 14, 'dropout_rate_mlp': 0.26769605543589947}. Best is trial 0 with value: 0.577582240625719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:30:21,875] Trial 2 finished with value: 0.5110229276895942 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 17, 'lr_ae': 0.00047023986596936795, 'epochs_ae': 46, 'dropout_rate_ae': 0.32000066364631286, 'hidden_dim_mlp': 121, 'lr_mlp': 0.00963590550776451, 'epochs_mlp': 28, 'dropout_rate_mlp': 0.38133640659353407}. Best is trial 0 with value: 0.577582240625719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:30:51,371] Trial 3 finished with value: 0.5391266007208037 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 11, 'lr_ae': 0.0001232149030042411, 'epochs_ae': 13, 'dropout_rate_ae': 0.1180186539901734, 'hidden_dim_mlp': 40, 'lr_mlp': 0.0011524688744345795, 'epochs_mlp': 43, 'dropout_rate_mlp': 0.4153879697160784}. Best is trial 0 with value: 0.577582240625719.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:31:28,157] Trial 4 finished with value: 0.5889118932597194 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 10, 'lr_ae': 0.004795506252233617, 'epochs_ae': 29, 'dropout_rate_ae': 0.19072917252504037, 'hidden_dim_mlp': 46, 'lr_mlp': 0.0024199008423043534, 'epochs_mlp': 20, 'dropout_rate_mlp': 0.227187185162293}. Best is trial 4 with value: 0.5889118932597194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:32:23,815] Trial 5 finished with value: 0.5792500575109271 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 19, 'lr_ae': 0.0036961824874977753, 'epochs_ae': 50, 'dropout_rate_ae': 0.263008594847151, 'hidden_dim_mlp': 123, 'lr_mlp': 0.0030955622244512038, 'epochs_mlp': 26, 'dropout_rate_mlp': 0.4287921090565403}. Best is trial 4 with value: 0.5889118932597194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:33:15,033] Trial 6 finished with value: 0.5660033739743885 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 16, 'lr_ae': 0.0011163508822429947, 'epochs_ae': 39, 'dropout_rate_ae': 0.31103884215015515, 'hidden_dim_mlp': 94, 'lr_mlp': 0.0005726466082327156, 'epochs_mlp': 37, 'dropout_rate_mlp': 0.2154393974750149}. Best is trial 4 with value: 0.5889118932597194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:33:59,611] Trial 7 finished with value: 0.5855570891802776 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 14, 'lr_ae': 0.00033585729093896694, 'epochs_ae': 39, 'dropout_rate_ae': 0.18107239630380026, 'hidden_dim_mlp': 58, 'lr_mlp': 0.0006310033808014397, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.19266377434570986}. Best is trial 4 with value: 0.5889118932597194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:34:45,840] Trial 8 finished with value: 0.6058392761291312 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 20, 'lr_ae': 0.006760684965161799, 'epochs_ae': 44, 'dropout_rate_ae': 0.39580673917288267, 'hidden_dim_mlp': 119, 'lr_mlp': 0.003580405852130828, 'epochs_mlp': 43, 'dropout_rate_mlp': 0.4773087545188165}. Best is trial 8 with value: 0.6058392761291312.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:35:05,492] Trial 9 finished with value: 0.5630511463844797 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 11, 'lr_ae': 0.0032330714171389207, 'epochs_ae': 12, 'dropout_rate_ae': 0.1220775136764139, 'hidden_dim_mlp': 41, 'lr_mlp': 0.000668795736798663, 'epochs_mlp': 39, 'dropout_rate_mlp': 0.14479817586807667}. Best is trial 8 with value: 0.6058392761291312.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:35:47,429] Trial 10 finished with value: 0.6073345602331109 and parameters: {'num_layers': 2, 'latent_dim_0': 39, 'latent_dim_1': 20, 'lr_ae': 0.0009451776446380985, 'epochs_ae': 39, 'dropout_rate_ae': 0.46949184541584754, 'hidden_dim_mlp': 104, 'lr_mlp': 0.00013070371194077345, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.4921645105279576}. Best is trial 10 with value: 0.6073345602331109.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:36:26,185] Trial 11 finished with value: 0.5953914577102982 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 20, 'lr_ae': 0.0013726910680362703, 'epochs_ae': 38, 'dropout_rate_ae': 0.4862481434476875, 'hidden_dim_mlp': 101, 'lr_mlp': 0.00010534457028792506, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.47847585820468413}. Best is trial 10 with value: 0.6073345602331109.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:37:02,532] Trial 12 finished with value: 0.6242619431025228 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 18, 'lr_ae': 0.001958240451207172, 'epochs_ae': 43, 'dropout_rate_ae': 0.4641039706646293, 'hidden_dim_mlp': 105, 'lr_mlp': 0.00010001641394803943, 'epochs_mlp': 48, 'dropout_rate_mlp': 0.33520034182766995}. Best is trial 12 with value: 0.6242619431025228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:37:35,451] Trial 13 finished with value: 0.5418487846024078 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 18, 'lr_ae': 0.0017431170323605712, 'epochs_ae': 33, 'dropout_rate_ae': 0.4839503240185002, 'hidden_dim_mlp': 99, 'lr_mlp': 0.00012676756329038036, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.32572972725201516}. Best is trial 12 with value: 0.6242619431025228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:38:04,861] Trial 14 finished with value: 0.6027336860670194 and parameters: {'num_layers': 2, 'latent_dim_0': 37, 'latent_dim_1': 18, 'lr_ae': 0.0007447561498431492, 'epochs_ae': 33, 'dropout_rate_ae': 0.4114771995050739, 'hidden_dim_mlp': 85, 'lr_mlp': 0.00023818955359576873, 'epochs_mlp': 45, 'dropout_rate_mlp': 0.3370251397143161}. Best is trial 12 with value: 0.6242619431025228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:38:43,739] Trial 15 finished with value: 0.5858829844337091 and parameters: {'num_layers': 2, 'latent_dim_0': 37, 'latent_dim_1': 18, 'lr_ae': 0.002350906653753224, 'epochs_ae': 43, 'dropout_rate_ae': 0.4231465997714166, 'hidden_dim_mlp': 110, 'lr_mlp': 0.0002459476765300238, 'epochs_mlp': 34, 'dropout_rate_mlp': 0.4973314537805157}. Best is trial 12 with value: 0.6242619431025228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:39:30,309] Trial 16 finished with value: 0.5694156889809063 and parameters: {'num_layers': 2, 'latent_dim_0': 37, 'latent_dim_1': 14, 'lr_ae': 0.0006233084213171147, 'epochs_ae': 50, 'dropout_rate_ae': 0.4488839699258299, 'hidden_dim_mlp': 81, 'lr_mlp': 0.00026453987272298063, 'epochs_mlp': 46, 'dropout_rate_mlp': 0.2916853327281148}. Best is trial 12 with value: 0.6242619431025228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:40:07,025] Trial 17 finished with value: 0.5699716279426424 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 20, 'lr_ae': 0.0003381460629246659, 'epochs_ae': 35, 'dropout_rate_ae': 0.3675304294361066, 'hidden_dim_mlp': 109, 'lr_mlp': 0.000165454589931029, 'epochs_mlp': 39, 'dropout_rate_mlp': 0.11424150102033456}. Best is trial 12 with value: 0.6242619431025228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:40:35,553] Trial 18 finished with value: 0.5548845947396672 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 17, 'lr_ae': 0.00187138671167093, 'epochs_ae': 29, 'dropout_rate_ae': 0.4953085925512855, 'hidden_dim_mlp': 110, 'lr_mlp': 0.0004088061163987811, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.36491230789158635}. Best is trial 12 with value: 0.6242619431025228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:41:07,124] Trial 19 finished with value: 0.6030787516294762 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 19, 'lr_ae': 0.0009382417544342134, 'epochs_ae': 42, 'dropout_rate_ae': 0.25567530941113403, 'hidden_dim_mlp': 128, 'lr_mlp': 0.00017219995754916628, 'epochs_mlp': 22, 'dropout_rate_mlp': 0.25100471485813486}. Best is trial 12 with value: 0.6242619431025228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.5629\n"
     ]
    }
   ],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(SimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "        \n",
    "        return reconstructions, latents\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "def train_stacked_autoencoder(model, X_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    \n",
    "    # Обучаем каждый автоэнкодер последовательно\n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, latent)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, _ in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent = ae(batch_x)\n",
    "                loss = criterion(reconstructed, batch_x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    # Параметры stacked автоэнкодера\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    # Определяем размерности слоев автоэнкодера\n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    \n",
    "    # Параметры MLP\n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate_ae)\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(latent_dims[-1], hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "autoencoder = StackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate_ae'])\n",
    "autoencoder = train_stacked_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "mlp = MLP(latent_dims[-1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5008\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6368\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5654\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5031\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5492\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5334\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5442\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5527\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4884\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5303\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5465\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5514\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5817\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6241\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5913\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5070\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5860\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5145\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4915\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5784\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5703\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6316\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6168\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5849\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6355\n",
      "среднее 0.5606317188623964\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "            \n",
    "        autoencoder = StackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_stacked_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(latent_dims[-1], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь блок с stacked автоэнкодером. Но у каждого из автоэнкодеров была дополнительная классифицирующая голова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "логистическая рергрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:45:58,599] A new study created in memory with name: no-name-e8863bd6-9d12-417b-84f7-07c7c732ef48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:46:17,713] Trial 0 finished with value: 0.5995130741507553 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 13, 'lr': 0.0011471954892429866, 'epochs': 28, 'dropout_rate': 0.1800397120487817, 'class_weight_0': 0.5864852424336661, 'class_weight_1': 0.8071224390207544, 'C': 5.177641358473724, 'solver': 'liblinear'}. Best is trial 0 with value: 0.5995130741507553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:46:27,395] Trial 1 finished with value: 0.5821064335557088 and parameters: {'num_layers': 2, 'latent_dim_0': 30, 'latent_dim_1': 10, 'lr': 0.00038085230712760844, 'epochs': 14, 'dropout_rate': 0.26575610820017304, 'class_weight_0': 0.4095593033669298, 'class_weight_1': 0.3208467335993751, 'C': 0.2825951837875624, 'solver': 'saga'}. Best is trial 0 with value: 0.5995130741507553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:46:42,393] Trial 2 finished with value: 0.5731730695498811 and parameters: {'num_layers': 2, 'latent_dim_0': 36, 'latent_dim_1': 14, 'lr': 0.0022720027732831016, 'epochs': 19, 'dropout_rate': 0.1146487134475962, 'class_weight_0': 0.6643514870705891, 'class_weight_1': 0.12203418034605013, 'C': 0.4815734398883442, 'solver': 'saga'}. Best is trial 0 with value: 0.5995130741507553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:47:14,228] Trial 3 finished with value: 0.5965800168698719 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 12, 'lr': 0.000256476076850045, 'epochs': 44, 'dropout_rate': 0.24370052400126152, 'class_weight_0': 0.23223312437657492, 'class_weight_1': 0.5573053458541282, 'C': 2.5518815542404174, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5995130741507553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:47:25,381] Trial 4 finished with value: 0.5984587071543593 and parameters: {'num_layers': 2, 'latent_dim_0': 37, 'latent_dim_1': 16, 'lr': 0.006162153902967531, 'epochs': 15, 'dropout_rate': 0.18420097591591178, 'class_weight_0': 0.3601802203050294, 'class_weight_1': 0.4895040689664223, 'C': 9.109472484042373, 'solver': 'liblinear'}. Best is trial 0 with value: 0.5995130741507553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:47:42,391] Trial 5 finished with value: 0.5859980062878613 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 20, 'lr': 0.003999886010699581, 'epochs': 24, 'dropout_rate': 0.3351214434627352, 'class_weight_0': 0.5182402436227884, 'class_weight_1': 0.8634682734518175, 'C': 0.13211314264467583, 'solver': 'saga'}. Best is trial 0 with value: 0.5995130741507553.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:48:15,288] Trial 6 finished with value: 0.6153477494057205 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 15, 'lr': 0.00017820151122816094, 'epochs': 48, 'dropout_rate': 0.3964966088016715, 'class_weight_0': 0.5642455077752702, 'class_weight_1': 0.2158154001492359, 'C': 0.7768187536602883, 'solver': 'liblinear'}. Best is trial 6 with value: 0.6153477494057205.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:48:37,789] Trial 7 finished with value: 0.6389655701249904 and parameters: {'num_layers': 2, 'latent_dim_0': 39, 'latent_dim_1': 10, 'lr': 0.0009683245683582885, 'epochs': 31, 'dropout_rate': 0.44997738166016343, 'class_weight_0': 0.2559988119615202, 'class_weight_1': 0.28773496621834427, 'C': 6.914110783961773, 'solver': 'saga'}. Best is trial 7 with value: 0.6389655701249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:48:57,391] Trial 8 finished with value: 0.551663982823403 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 19, 'lr': 0.003261239997907097, 'epochs': 28, 'dropout_rate': 0.12537495663704232, 'class_weight_0': 0.7996653280772726, 'class_weight_1': 0.5797289222264194, 'C': 0.65971855092756, 'solver': 'liblinear'}. Best is trial 7 with value: 0.6389655701249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:49:14,636] Trial 9 finished with value: 0.5974810213940649 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 15, 'lr': 0.00014404620368237348, 'epochs': 25, 'dropout_rate': 0.169083372304145, 'class_weight_0': 0.8011358358512434, 'class_weight_1': 0.8265707044890761, 'C': 1.1366189650077447, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.6389655701249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:49:40,637] Trial 10 finished with value: 0.5888735526416685 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 10, 'lr': 0.0007431800295714765, 'epochs': 38, 'dropout_rate': 0.4902250044697476, 'class_weight_0': 0.10459867003611811, 'class_weight_1': 0.37466139451203484, 'C': 82.14541677243855, 'solver': 'saga'}. Best is trial 7 with value: 0.6389655701249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:50:18,252] Trial 11 finished with value: 0.5444559466298596 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 17, 'lr': 0.00010330024239175912, 'epochs': 50, 'dropout_rate': 0.430962394572203, 'class_weight_0': 0.35855960990869773, 'class_weight_1': 0.1269282732076654, 'C': 0.013726845648175761, 'solver': 'liblinear'}. Best is trial 7 with value: 0.6389655701249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:50:44,045] Trial 12 finished with value: 0.6071428571428571 and parameters: {'num_layers': 2, 'latent_dim_0': 25, 'latent_dim_1': 12, 'lr': 0.0007076339180000959, 'epochs': 36, 'dropout_rate': 0.3751111092451864, 'class_weight_0': 0.226644605278084, 'class_weight_1': 0.2583366344256128, 'C': 27.533797430874912, 'solver': 'saga'}. Best is trial 7 with value: 0.6389655701249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:51:09,838] Trial 13 finished with value: 0.624971244536462 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 18, 'lr': 0.00033439819656203885, 'epochs': 36, 'dropout_rate': 0.42291822492739006, 'class_weight_0': 0.666447043266725, 'class_weight_1': 0.23548705748214122, 'C': 0.056467382716539505, 'solver': 'liblinear'}. Best is trial 7 with value: 0.6389655701249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:51:35,315] Trial 14 finished with value: 0.6079863507399739 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 18, 'lr': 0.001433957216635243, 'epochs': 36, 'dropout_rate': 0.4912739203672915, 'class_weight_0': 0.7070584375603326, 'class_weight_1': 0.4239433825263333, 'C': 0.05410806270858327, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.6389655701249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:52:04,129] Trial 15 finished with value: 0.6283452189249291 and parameters: {'num_layers': 2, 'latent_dim_0': 39, 'latent_dim_1': 17, 'lr': 0.0004190831109590173, 'epochs': 40, 'dropout_rate': 0.44835212166587607, 'class_weight_0': 0.4631560557751369, 'class_weight_1': 0.23011800212173333, 'C': 0.021017422830805706, 'solver': 'liblinear'}. Best is trial 7 with value: 0.6389655701249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:52:33,839] Trial 16 finished with value: 0.6037880530634153 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 17, 'lr': 0.0005245450064314213, 'epochs': 42, 'dropout_rate': 0.33109255150102923, 'class_weight_0': 0.24928917308780793, 'class_weight_1': 0.3242740133478636, 'C': 0.010434856059916581, 'solver': 'saga'}. Best is trial 7 with value: 0.6389655701249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:52:57,376] Trial 17 finished with value: 0.6041139483168468 and parameters: {'num_layers': 2, 'latent_dim_0': 37, 'latent_dim_1': 11, 'lr': 0.0015739455985283074, 'epochs': 32, 'dropout_rate': 0.4494984734941321, 'class_weight_0': 0.4417752050848313, 'class_weight_1': 0.666052979031014, 'C': 25.504664460043628, 'solver': 'liblinear'}. Best is trial 7 with value: 0.6389655701249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:53:26,321] Trial 18 finished with value: 0.6078329882677709 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 14, 'lr': 0.009045930222578475, 'epochs': 42, 'dropout_rate': 0.3421361047508272, 'class_weight_0': 0.12761087040508207, 'class_weight_1': 0.18167506100016123, 'C': 2.3591639324262923, 'solver': 'saga'}. Best is trial 7 with value: 0.6389655701249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:53:41,039] Trial 19 finished with value: 0.6255463538072233 and parameters: {'num_layers': 2, 'latent_dim_0': 39, 'latent_dim_1': 16, 'lr': 0.0005738080994717933, 'epochs': 21, 'dropout_rate': 0.46162117601134817, 'class_weight_0': 0.3279644183649395, 'class_weight_1': 0.4524596801790655, 'C': 12.675965057594201, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.6389655701249904.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.5950\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingSimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.2):\n",
    "        super(ClassifyingSimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(output_dim, input_dim),\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(output_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "\n",
    "class ClassifyingStackedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, layer_dims, dropout_rate=0.2):\n",
    "        super(ClassifyingStackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        \n",
    "        # Создаем последовательность автоэнкодеров\n",
    "        prev_dim = input_dim\n",
    "        for dim in layer_dims:\n",
    "            self.autoencoders.append(ClassifyingSimpleAutoencoder(prev_dim, dim, dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = x\n",
    "        reconstructions = []\n",
    "        latents = []\n",
    "        classifications = []\n",
    "        \n",
    "        # Прямой проход через все автоэнкодеры\n",
    "        for ae in self.autoencoders:\n",
    "            reconstructed, latent, classification = ae(latent)\n",
    "            reconstructions.append(reconstructed)\n",
    "            latents.append(latent)\n",
    "            classifications.append(classification)\n",
    "        \n",
    "        return reconstructions, latents, classifications\n",
    "    \n",
    "def train_classifying_stacked_autoencoder(model, X_train, y_train, epochs, batch_size, lr, classification_weights):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    latent = X_train_tensor\n",
    "    for i, ae in enumerate(model.autoencoders):\n",
    "        print(f\"Training autoencoder {i+1}/{len(model.autoencoders)}\")\n",
    "        \n",
    "        train_dataset = TensorDataset(latent, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        optimizer = optim.Adam(ae.parameters(), lr=lr)\n",
    "        recon_criterion = nn.MSELoss()\n",
    "        class_criterion = nn.BCELoss()\n",
    "        \n",
    "        ae.train()\n",
    "        for epoch in range(epochs):\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconstructed, new_latent, classification = ae(batch_x)\n",
    "                \n",
    "                recon_loss = recon_criterion(reconstructed, batch_x)\n",
    "                class_loss = class_criterion(classification, batch_y)\n",
    "                \n",
    "                recon_weight = 1.0 - classification_weights[i]\n",
    "                class_weight = classification_weights[i]\n",
    "                loss = recon_weight * recon_loss + class_weight * class_loss\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # Получаем латентное представление для следующего автоэнкодера\n",
    "        ae.eval()\n",
    "        with torch.no_grad():\n",
    "            _, latent, _ = ae(latent)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Получаем латентное представление из последнего автоэнкодера\n",
    "    latent = X_tensor\n",
    "    for ae in model.autoencoders:\n",
    "        with torch.no_grad():\n",
    "            _, latent, _ = ae(latent)\n",
    "            \n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)  # Минимальный размер 10\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Восстанавливаем список размерностей слоев из best_params\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "# Восстанавливаем список весов классификации\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5882\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5676\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5124\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5232\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5351\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5707\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5546\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5708\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5812\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5717\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5579\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5510\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5642\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6145\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5653\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5277\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5318\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5059\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5357\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5645\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5951\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5760\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5968\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5895\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6421\n",
      "среднее 0.5637411662795593\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        # Восстанавливаем список размерностей слоев из best_params\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        # Восстанавливаем список весов классификации\n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:56:17,346] A new study created in memory with name: no-name-c635ca74-f590-4f7a-8049-edf62f48348a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:56:48,368] Trial 0 finished with value: 0.5340464688290775 and parameters: {'num_layers': 2, 'latent_dim_0': 30, 'latent_dim_1': 11, 'lr': 0.0001341865805230774, 'epochs': 29, 'dropout_rate': 0.46480785055865836, 'class_weight_0': 0.13830302709070247, 'class_weight_1': 0.8641914202011804, 'n_estimators': 207, 'max_depth': 7, 'learning_rate': 0.21238879063791152, 'subsample': 0.8156937221468447, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.5340464688290775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:57:42,055] Trial 1 finished with value: 0.6146192776627558 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 16, 'lr': 0.0005415787600997951, 'epochs': 49, 'dropout_rate': 0.4319763176702335, 'class_weight_0': 0.4632687670117889, 'class_weight_1': 0.3406472726661909, 'n_estimators': 253, 'max_depth': 8, 'learning_rate': 0.013547458277397569, 'subsample': 0.9773147939981347, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.6146192776627558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:58:06,219] Trial 2 finished with value: 0.6066252587991718 and parameters: {'num_layers': 2, 'latent_dim_0': 39, 'latent_dim_1': 13, 'lr': 0.0008226288207446649, 'epochs': 20, 'dropout_rate': 0.3952423778679829, 'class_weight_0': 0.5824164154989562, 'class_weight_1': 0.1820142398466417, 'n_estimators': 172, 'max_depth': 9, 'learning_rate': 0.049810350269324066, 'subsample': 0.6122288073594542, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.6146192776627558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:58:46,604] Trial 3 finished with value: 0.5791733762748256 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 17, 'lr': 0.0012599883024873063, 'epochs': 38, 'dropout_rate': 0.27302547637359426, 'class_weight_0': 0.6852747877135325, 'class_weight_1': 0.6701777672071055, 'n_estimators': 318, 'max_depth': 5, 'learning_rate': 0.010607676973824079, 'subsample': 0.7635765039891507, 'min_samples_split': 17, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.6146192776627558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 09:59:18,414] Trial 4 finished with value: 0.5638179587454949 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 19, 'lr': 0.0017063421695071397, 'epochs': 14, 'dropout_rate': 0.4798472632079399, 'class_weight_0': 0.3291167305952206, 'class_weight_1': 0.27653729248399583, 'n_estimators': 257, 'max_depth': 9, 'learning_rate': 0.13131151225758692, 'subsample': 0.9723959026689666, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.6146192776627558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:00:00,555] Trial 5 finished with value: 0.5886051683153132 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 12, 'lr': 0.004617505459659014, 'epochs': 26, 'dropout_rate': 0.48666420912642006, 'class_weight_0': 0.5797107710670435, 'class_weight_1': 0.11856257945810694, 'n_estimators': 495, 'max_depth': 8, 'learning_rate': 0.01179227996722109, 'subsample': 0.965134664896615, 'min_samples_split': 12, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.6146192776627558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:00:37,960] Trial 6 finished with value: 0.5804194463614754 and parameters: {'num_layers': 2, 'latent_dim_0': 38, 'latent_dim_1': 16, 'lr': 0.0009167900909608362, 'epochs': 34, 'dropout_rate': 0.22859453173431873, 'class_weight_0': 0.5469733018347033, 'class_weight_1': 0.6755848862759375, 'n_estimators': 425, 'max_depth': 7, 'learning_rate': 0.01935319455146686, 'subsample': 0.8432904433028983, 'min_samples_split': 13, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.6146192776627558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:00:59,949] Trial 7 finished with value: 0.6027336860670194 and parameters: {'num_layers': 2, 'latent_dim_0': 23, 'latent_dim_1': 20, 'lr': 0.0016924769322502376, 'epochs': 21, 'dropout_rate': 0.13539318188892532, 'class_weight_0': 0.5165834246717914, 'class_weight_1': 0.23655373181408496, 'n_estimators': 309, 'max_depth': 4, 'learning_rate': 0.16487294071590833, 'subsample': 0.8170516468725663, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.6146192776627558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:01:22,616] Trial 8 finished with value: 0.6091557395905222 and parameters: {'num_layers': 2, 'latent_dim_0': 38, 'latent_dim_1': 11, 'lr': 0.0011987010679706683, 'epochs': 16, 'dropout_rate': 0.25401587554559557, 'class_weight_0': 0.6286359899731736, 'class_weight_1': 0.7855679948621818, 'n_estimators': 293, 'max_depth': 9, 'learning_rate': 0.05507685404120524, 'subsample': 0.8703084111281738, 'min_samples_split': 13, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.6146192776627558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:02:08,054] Trial 9 finished with value: 0.5649490069779924 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 20, 'lr': 0.0002547967718985515, 'epochs': 34, 'dropout_rate': 0.23025827438455654, 'class_weight_0': 0.2640955877661798, 'class_weight_1': 0.14333903762234002, 'n_estimators': 341, 'max_depth': 9, 'learning_rate': 0.0113613809227539, 'subsample': 0.8360659934141466, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.6146192776627558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:02:34,586] Trial 10 finished with value: 0.6247603711371827 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 14, 'lr': 0.00033739368251161267, 'epochs': 50, 'dropout_rate': 0.3826369470707986, 'class_weight_0': 0.7900337200015818, 'class_weight_1': 0.4020176915175252, 'n_estimators': 63, 'max_depth': 3, 'learning_rate': 0.031405119875955, 'subsample': 0.7090028588731621, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.6247603711371827.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:03:08,280] Trial 11 finished with value: 0.612357181197761 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 14, 'lr': 0.0003520125626359536, 'epochs': 50, 'dropout_rate': 0.3713048189237173, 'class_weight_0': 0.8685206984977908, 'class_weight_1': 0.4420271811867623, 'n_estimators': 55, 'max_depth': 3, 'learning_rate': 0.028379094130257517, 'subsample': 0.6902119225110588, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 10 with value: 0.6247603711371827.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:03:30,690] Trial 12 finished with value: 0.5869948623571812 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 15, 'lr': 0.0003954217607232462, 'epochs': 50, 'dropout_rate': 0.3644761336045242, 'class_weight_0': 0.8486764373005738, 'class_weight_1': 0.39186287439920386, 'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.027653404604037708, 'subsample': 0.7205988476286515, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 10 with value: 0.6247603711371827.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:03:57,346] Trial 13 finished with value: 0.6172647803082585 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 17, 'lr': 0.00010550366575599242, 'epochs': 43, 'dropout_rate': 0.41368595048998286, 'class_weight_0': 0.7466537114849168, 'class_weight_1': 0.5563343299871458, 'n_estimators': 130, 'max_depth': 6, 'learning_rate': 0.06550046601648771, 'subsample': 0.9079355152617458, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 10 with value: 0.6247603711371827.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:04:20,047] Trial 14 finished with value: 0.6060884901464612 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 18, 'lr': 0.00010818440806060507, 'epochs': 43, 'dropout_rate': 0.3204942860788709, 'class_weight_0': 0.7381123076008107, 'class_weight_1': 0.5929964273232375, 'n_estimators': 124, 'max_depth': 3, 'learning_rate': 0.08303428207416881, 'subsample': 0.8973256185995611, 'min_samples_split': 16, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.6247603711371827.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:04:40,023] Trial 15 finished with value: 0.6248562226823097 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 14, 'lr': 0.00019940868740147188, 'epochs': 42, 'dropout_rate': 0.32394215778012597, 'class_weight_0': 0.7524564399427458, 'class_weight_1': 0.5282091728643254, 'n_estimators': 129, 'max_depth': 5, 'learning_rate': 0.05013170348642395, 'subsample': 0.6164090433102254, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 15 with value: 0.6248562226823097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:04:59,110] Trial 16 finished with value: 0.6048615903688367 and parameters: {'num_layers': 2, 'latent_dim_0': 36, 'latent_dim_1': 14, 'lr': 0.00023727289021250797, 'epochs': 43, 'dropout_rate': 0.32549121580504015, 'class_weight_0': 0.8971111667873535, 'class_weight_1': 0.48623360489448725, 'n_estimators': 109, 'max_depth': 4, 'learning_rate': 0.0348099289022208, 'subsample': 0.6027286603398899, 'min_samples_split': 6, 'min_samples_leaf': 10}. Best is trial 15 with value: 0.6248562226823097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:05:18,274] Trial 17 finished with value: 0.577390537535465 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 13, 'lr': 0.0002105843172524263, 'epochs': 39, 'dropout_rate': 0.12597784690486663, 'class_weight_0': 0.77667089168197, 'class_weight_1': 0.33778318489203263, 'n_estimators': 192, 'max_depth': 4, 'learning_rate': 0.10060197324907405, 'subsample': 0.6485125728399531, 'min_samples_split': 20, 'min_samples_leaf': 9}. Best is trial 15 with value: 0.6248562226823097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:05:42,020] Trial 18 finished with value: 0.5572425427497891 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 15, 'lr': 0.00413004599893335, 'epochs': 46, 'dropout_rate': 0.3421136062785658, 'class_weight_0': 0.43699187864635725, 'class_weight_1': 0.595759756601075, 'n_estimators': 94, 'max_depth': 5, 'learning_rate': 0.04388111295762415, 'subsample': 0.6826644571165699, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 15 with value: 0.6248562226823097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:06:00,201] Trial 19 finished with value: 0.5604343992025151 and parameters: {'num_layers': 2, 'latent_dim_0': 36, 'latent_dim_1': 10, 'lr': 0.008882182335339554, 'epochs': 39, 'dropout_rate': 0.19874869160640463, 'class_weight_0': 0.8020209232663346, 'class_weight_1': 0.4919267332504881, 'n_estimators': 142, 'max_depth': 3, 'learning_rate': 0.019075537355985498, 'subsample': 0.7584328848760074, 'min_samples_split': 11, 'min_samples_leaf': 9}. Best is trial 15 with value: 0.6248562226823097.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.6085\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5506\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6033\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5687\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5529\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5667\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5687\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5742\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6098\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5497\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4995\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5221\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5230\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5228\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5746\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5737\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4783\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5145\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5054\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.4807\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5756\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6266\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6342\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6457\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5913\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6005\n",
      "среднее 0.5605206506722592\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:08:46,505] A new study created in memory with name: no-name-e2c2d433-8a01-4d79-9979-543357ad3027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:09:02,729] Trial 0 finished with value: 0.5546257955678245 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 18, 'lr': 0.0002240411918389202, 'epochs': 31, 'dropout_rate': 0.32161247884607913, 'class_weight_0': 0.6526169733491671, 'class_weight_1': 0.32504842892881786, 'C': 9.13543592088661, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.5546257955678245.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:09:15,037] Trial 1 finished with value: 0.5910206272525113 and parameters: {'num_layers': 2, 'latent_dim_0': 38, 'latent_dim_1': 17, 'lr': 0.0001948846678441702, 'epochs': 30, 'dropout_rate': 0.4573945490551191, 'class_weight_0': 0.7878345482020925, 'class_weight_1': 0.6264709939753058, 'C': 2.0482871810685297, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 1 with value: 0.5910206272525113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:09:24,851] Trial 2 finished with value: 0.5129591289011579 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 20, 'lr': 0.00010384623543067977, 'epochs': 12, 'dropout_rate': 0.24852915797917327, 'class_weight_0': 0.742010736738501, 'class_weight_1': 0.3569414954405472, 'C': 11.60281299847955, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4}. Best is trial 1 with value: 0.5910206272525113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:09:31,773] Trial 3 finished with value: 0.5364044168391994 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 14, 'lr': 0.006530502637855939, 'epochs': 18, 'dropout_rate': 0.1552794767647138, 'class_weight_0': 0.5587608727336317, 'class_weight_1': 0.7873984013765774, 'C': 4.90388019360948, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.5910206272525113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:09:51,739] Trial 4 finished with value: 0.6110344298750096 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 16, 'lr': 0.0002661124814624766, 'epochs': 41, 'dropout_rate': 0.12552908632259896, 'class_weight_0': 0.8708805633964845, 'class_weight_1': 0.40263349205705745, 'C': 2.9357867583987636, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 4 with value: 0.6110344298750096.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:10:11,217] Trial 5 finished with value: 0.6120312859443294 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 20, 'lr': 0.00022496758469441378, 'epochs': 47, 'dropout_rate': 0.3757605979852312, 'class_weight_0': 0.2868305048776634, 'class_weight_1': 0.45802313697216, 'C': 0.21148193732999318, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 5 with value: 0.6120312859443294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:10:43,048] Trial 6 finished with value: 0.5836496434322521 and parameters: {'num_layers': 2, 'latent_dim_0': 30, 'latent_dim_1': 16, 'lr': 0.0012579203337997685, 'epochs': 50, 'dropout_rate': 0.19358325900880474, 'class_weight_0': 0.5528904835501579, 'class_weight_1': 0.3953827630110711, 'C': 16.470449159668945, 'kernel': 'linear'}. Best is trial 5 with value: 0.6120312859443294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:10:59,905] Trial 7 finished with value: 0.5060003067249444 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 18, 'lr': 0.00037376892589102907, 'epochs': 28, 'dropout_rate': 0.21895473270947902, 'class_weight_0': 0.16158920888789155, 'class_weight_1': 0.7353269035140862, 'C': 93.11750088902957, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 5 with value: 0.6120312859443294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:11:26,079] Trial 8 finished with value: 0.5189210950080515 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 18, 'lr': 0.00012125498802149046, 'epochs': 40, 'dropout_rate': 0.10365319521705581, 'class_weight_0': 0.21651767381107448, 'class_weight_1': 0.47690751522100516, 'C': 0.25989892502769185, 'kernel': 'linear'}. Best is trial 5 with value: 0.6120312859443294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:11:37,936] Trial 9 finished with value: 0.5906084656084656 and parameters: {'num_layers': 2, 'latent_dim_0': 38, 'latent_dim_1': 20, 'lr': 0.0030769269714143407, 'epochs': 32, 'dropout_rate': 0.47000532386099514, 'class_weight_0': 0.26934493132982407, 'class_weight_1': 0.4290269023042933, 'C': 0.11736552639545281, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 5 with value: 0.6120312859443294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:12:06,930] Trial 10 finished with value: 0.5779273061881758 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 11, 'lr': 0.0007017656202234111, 'epochs': 49, 'dropout_rate': 0.3674053151870489, 'class_weight_0': 0.3720211242264104, 'class_weight_1': 0.12329875595503376, 'C': 0.7269065674366986, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 5 with value: 0.6120312859443294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:12:30,883] Trial 11 finished with value: 0.6028870485392225 and parameters: {'num_layers': 2, 'latent_dim_0': 32, 'latent_dim_1': 14, 'lr': 0.00048252552023839027, 'epochs': 41, 'dropout_rate': 0.388381074970154, 'class_weight_0': 0.8600329009908392, 'class_weight_1': 0.24196783384120324, 'C': 0.9272519481744239, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 5 with value: 0.6120312859443294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:12:47,553] Trial 12 finished with value: 0.5963020473890039 and parameters: {'num_layers': 2, 'latent_dim_0': 29, 'latent_dim_1': 11, 'lr': 0.001089880298454675, 'epochs': 41, 'dropout_rate': 0.29455175279775586, 'class_weight_0': 0.37933402245140674, 'class_weight_1': 0.5788602772856812, 'C': 0.35854602589734536, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 5 with value: 0.6120312859443294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:13:08,734] Trial 13 finished with value: 0.5724829384249673 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 15, 'lr': 0.0002637184842806742, 'epochs': 45, 'dropout_rate': 0.4053752933719391, 'class_weight_0': 0.4117536203131187, 'class_weight_1': 0.6001169085646832, 'C': 43.58624287585437, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 5 with value: 0.6120312859443294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:13:25,577] Trial 14 finished with value: 0.5727704930603482 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 13, 'lr': 0.002318337371450329, 'epochs': 36, 'dropout_rate': 0.3059387360378621, 'class_weight_0': 0.3047671122882322, 'class_weight_1': 0.26324384204814566, 'C': 1.909216684619511, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 5 with value: 0.6120312859443294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:13:50,144] Trial 15 finished with value: 0.6389272295069396 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 20, 'lr': 0.0005266848229227485, 'epochs': 45, 'dropout_rate': 0.11086639103560814, 'class_weight_0': 0.11865518182749835, 'class_weight_1': 0.5327337152828555, 'C': 0.1036097519047279, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 15 with value: 0.6389272295069396.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:14:02,866] Trial 16 finished with value: 0.5838221762134806 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 20, 'lr': 0.0005991697428520532, 'epochs': 23, 'dropout_rate': 0.2613374115655854, 'class_weight_0': 0.10516398945379968, 'class_weight_1': 0.8827405284642136, 'C': 0.1103647945019615, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 15 with value: 0.6389272295069396.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:14:27,443] Trial 17 finished with value: 0.6311344988881221 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 19, 'lr': 0.0014470425451773702, 'epochs': 46, 'dropout_rate': 0.34224002944020687, 'class_weight_0': 0.10314789050447692, 'class_weight_1': 0.548964118093774, 'C': 0.2781960851299887, 'kernel': 'linear'}. Best is trial 15 with value: 0.6389272295069396.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:14:43,859] Trial 18 finished with value: 0.6105935127674259 and parameters: {'num_layers': 2, 'latent_dim_0': 40, 'latent_dim_1': 19, 'lr': 0.0020151403551109956, 'epochs': 37, 'dropout_rate': 0.18383936508971227, 'class_weight_0': 0.1368573562723471, 'class_weight_1': 0.5387875412746316, 'C': 0.6123907304255685, 'kernel': 'linear'}. Best is trial 15 with value: 0.6389272295069396.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:15:10,245] Trial 19 finished with value: 0.6033854765738824 and parameters: {'num_layers': 2, 'latent_dim_0': 36, 'latent_dim_1': 19, 'lr': 0.005108014055836572, 'epochs': 44, 'dropout_rate': 0.34101390719511815, 'class_weight_0': 0.19085842142739762, 'class_weight_1': 0.7046168883600753, 'C': 0.1042424255756961, 'kernel': 'linear'}. Best is trial 15 with value: 0.6389272295069396.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.5543\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5860\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5465\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5590\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5617\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5732\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5227\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5780\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5499\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5739\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5588\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5439\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5506\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5589\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5621\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5587\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5405\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5138\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5204\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5106\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5566\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5873\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6128\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5960\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5895\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5534\n",
      "среднее 0.5585940396729852\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:17:47,873] A new study created in memory with name: no-name-1640b70a-1ace-49f1-93ed-1d20dacba23b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:17:55,417] Trial 0 finished with value: 0.6202745188252434 and parameters: {'num_layers': 2, 'latent_dim_0': 36, 'latent_dim_1': 16, 'lr': 0.0005303465566704047, 'epochs': 14, 'dropout_rate': 0.356747107292432, 'class_weight_0': 0.6502241560219879, 'class_weight_1': 0.6750716164363699}. Best is trial 0 with value: 0.6202745188252434.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:18:16,034] Trial 1 finished with value: 0.623821025994939 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 10, 'lr': 0.0016600243328055613, 'epochs': 38, 'dropout_rate': 0.31209561497460775, 'class_weight_0': 0.1734672218260144, 'class_weight_1': 0.806238609492102}. Best is trial 1 with value: 0.623821025994939.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:18:24,622] Trial 2 finished with value: 0.6114561766735679 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 17, 'lr': 0.009341625083926736, 'epochs': 17, 'dropout_rate': 0.24404755244212195, 'class_weight_0': 0.2935023588528221, 'class_weight_1': 0.35963191353776247}. Best is trial 1 with value: 0.623821025994939.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:18:45,511] Trial 3 finished with value: 0.6368184955141477 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 12, 'lr': 0.000854117846276179, 'epochs': 47, 'dropout_rate': 0.13154138917875594, 'class_weight_0': 0.14937710049973563, 'class_weight_1': 0.45528967669157006}. Best is trial 3 with value: 0.6368184955141477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:19:00,456] Trial 4 finished with value: 0.6035388390460854 and parameters: {'num_layers': 2, 'latent_dim_0': 35, 'latent_dim_1': 20, 'lr': 0.0005209723514479664, 'epochs': 30, 'dropout_rate': 0.16261145573319763, 'class_weight_0': 0.8932668983813699, 'class_weight_1': 0.6339392143199174}. Best is trial 3 with value: 0.6368184955141477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:19:22,669] Trial 5 finished with value: 0.6148876619891113 and parameters: {'num_layers': 2, 'latent_dim_0': 28, 'latent_dim_1': 14, 'lr': 0.0029032466305788252, 'epochs': 45, 'dropout_rate': 0.47867049451638466, 'class_weight_0': 0.1371856644304642, 'class_weight_1': 0.7017140769776584}. Best is trial 3 with value: 0.6368184955141477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:19:27,265] Trial 6 finished with value: 0.6409976228816809 and parameters: {'num_layers': 2, 'latent_dim_0': 25, 'latent_dim_1': 20, 'lr': 0.0010118567618263143, 'epochs': 13, 'dropout_rate': 0.38424068098449504, 'class_weight_0': 0.8571663874330441, 'class_weight_1': 0.5094117209831567}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:19:50,844] Trial 7 finished with value: 0.6178015489609693 and parameters: {'num_layers': 2, 'latent_dim_0': 33, 'latent_dim_1': 16, 'lr': 0.0002726233487830819, 'epochs': 42, 'dropout_rate': 0.45157807726863863, 'class_weight_0': 0.2822325976031185, 'class_weight_1': 0.8408342033916114}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:20:12,226] Trial 8 finished with value: 0.5811479181044399 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 14, 'lr': 0.00021268064378371238, 'epochs': 46, 'dropout_rate': 0.37417882114573964, 'class_weight_0': 0.24005412263270848, 'class_weight_1': 0.4528793603752036}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:20:29,161] Trial 9 finished with value: 0.5654474350126524 and parameters: {'num_layers': 2, 'latent_dim_0': 34, 'latent_dim_1': 13, 'lr': 0.00013302475275805354, 'epochs': 37, 'dropout_rate': 0.2771859784107754, 'class_weight_0': 0.8050368423115345, 'class_weight_1': 0.29323051029601876}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:20:42,097] Trial 10 finished with value: 0.6065485775630703 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 20, 'lr': 0.004646758248911568, 'epochs': 21, 'dropout_rate': 0.406188422736006, 'class_weight_0': 0.5025284675586991, 'class_weight_1': 0.2609653794555927}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:20:54,139] Trial 11 finished with value: 0.618491680085883 and parameters: {'num_layers': 2, 'latent_dim_0': 20, 'latent_dim_1': 11, 'lr': 0.0009461953470041173, 'epochs': 26, 'dropout_rate': 0.11114418329320794, 'class_weight_0': 0.4288958514320365, 'class_weight_1': 0.11109804570352522}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:21:16,089] Trial 12 finished with value: 0.5790391841116479 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 12, 'lr': 0.00127985975694491, 'epochs': 49, 'dropout_rate': 0.22682294755572932, 'class_weight_0': 0.6706322221211938, 'class_weight_1': 0.4928287901104217}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:21:19,680] Trial 13 finished with value: 0.6003373974388467 and parameters: {'num_layers': 2, 'latent_dim_0': 24, 'latent_dim_1': 18, 'lr': 0.0006541303512875959, 'epochs': 10, 'dropout_rate': 0.18202328851437108, 'class_weight_0': 0.4402951810157195, 'class_weight_1': 0.5693548274581759}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:21:32,257] Trial 14 finished with value: 0.5949505406027146 and parameters: {'num_layers': 2, 'latent_dim_0': 39, 'latent_dim_1': 18, 'lr': 0.0023745185559060624, 'epochs': 24, 'dropout_rate': 0.3277944707722137, 'class_weight_0': 0.6107438886312054, 'class_weight_1': 0.4563204836067467}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:21:45,963] Trial 15 finished with value: 0.6073345602331109 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 12, 'lr': 0.0002761954845356209, 'epochs': 34, 'dropout_rate': 0.4133084837604189, 'class_weight_0': 0.7541584438086208, 'class_weight_1': 0.3698948580579524}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:22:01,775] Trial 16 finished with value: 0.6212713748945633 and parameters: {'num_layers': 2, 'latent_dim_0': 27, 'latent_dim_1': 10, 'lr': 0.0009578715953496912, 'epochs': 31, 'dropout_rate': 0.11061752143113569, 'class_weight_0': 0.5208740788328405, 'class_weight_1': 0.5688129057523522}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:22:05,421] Trial 17 finished with value: 0.6076604554865425 and parameters: {'num_layers': 2, 'latent_dim_0': 26, 'latent_dim_1': 15, 'lr': 0.004106238403786154, 'epochs': 10, 'dropout_rate': 0.2800756899068109, 'class_weight_0': 0.8650159172664501, 'class_weight_1': 0.1686014257943131}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:22:13,711] Trial 18 finished with value: 0.5864964343225213 and parameters: {'num_layers': 2, 'latent_dim_0': 31, 'latent_dim_1': 19, 'lr': 0.00040205122862658067, 'epochs': 17, 'dropout_rate': 0.17511603025959185, 'class_weight_0': 0.37350217981444245, 'class_weight_1': 0.39286440058898553}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:22:33,225] Trial 19 finished with value: 0.5984778774633847 and parameters: {'num_layers': 2, 'latent_dim_0': 22, 'latent_dim_1': 13, 'lr': 0.0018234830561732543, 'epochs': 40, 'dropout_rate': 0.4137527873546515, 'class_weight_0': 0.5853957151692174, 'class_weight_1': 0.5491567278498202}. Best is trial 6 with value: 0.6409976228816809.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded bigset: 0.6300\n"
     ]
    }
   ],
   "source": [
    "def get_classifier_predictions(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    latent = X_tensor\n",
    "    with torch.no_grad():\n",
    "        for i, ae in enumerate(model.autoencoders):\n",
    "            if i == len(model.autoencoders) - 1:\n",
    "                _, _, classification = ae(latent)\n",
    "                return classification.cpu().numpy().flatten()\n",
    "            else:\n",
    "                _, latent, _ = ae(latent)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 2)\n",
    "    latent_dims = []\n",
    "    \n",
    "    dim = X_train.shape[1]\n",
    "    for i in range(num_layers):\n",
    "        dim = dim // 2\n",
    "        dim = max(10, dim)\n",
    "        latent_dim = trial.suggest_int(f'latent_dim_{i}', max(8, dim//2), dim)\n",
    "        latent_dims.append(latent_dim)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    \n",
    "    classification_weights = []\n",
    "    for i in range(num_layers):\n",
    "        class_weight = trial.suggest_float(f'class_weight_{i}', 0.1, 0.9)\n",
    "        classification_weights.append(class_weight)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, dropout_rate)\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, classification_weights)\n",
    "        \n",
    "        y_pred_proba = get_classifier_predictions(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "latent_dims = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    latent_dims.append(best_params[f'latent_dim_{i}'])\n",
    "\n",
    "classification_weights = []\n",
    "for i in range(best_params['num_layers']):\n",
    "    classification_weights.append(best_params[f'class_weight_{i}'])\n",
    "\n",
    "autoencoder = ClassifyingStackedAutoencoder(X_train_all.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "\n",
    "y_pred_proba = get_classifier_predictions(autoencoder, X_val_all)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5510\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5855\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5506\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5742\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5861\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5892\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5762\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6157\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5659\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5768\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5776\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5527\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5795\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5674\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5792\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5221\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5005\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5160\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5160\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5087\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6357\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6152\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5870\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.6212\n",
      "Training autoencoder 1/2\n",
      "Training autoencoder 2/2\n",
      "ROC-AUC autoencoded: 0.5970\n",
      "среднее 0.5698866529540064\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        latent_dims = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            latent_dims.append(best_params[f'latent_dim_{k}'])\n",
    "        \n",
    "        classification_weights = []\n",
    "        for k in range(best_params['num_layers']):\n",
    "            classification_weights.append(best_params[f'class_weight_{k}'])\n",
    "            \n",
    "        autoencoder = ClassifyingStackedAutoencoder(X_train.shape[1], latent_dims, best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_stacked_autoencoder(autoencoder, X_train, y_train, best_params['epochs'], 32, best_params['lr'], classification_weights)\n",
    "        \n",
    "        y_pred_proba = get_classifier_predictions(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше идет блок с denoising автоэнкодером"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:23:20,748] A new study created in memory with name: no-name-709caea0-c706-458d-8b2d-861ea8dd540b\n",
      "[I 2025-05-10 10:23:40,124] Trial 0 finished with value: 0.5797484855455869 and parameters: {'latent_dim': 54, 'hidden_dim': 129, 'lr': 0.00013674711185684686, 'epochs': 46, 'dropout_rate': 0.19881332997191872, 'noise_level': 0.22842500253892972, 'C': 4.595220273736951, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5797484855455869.\n",
      "[I 2025-05-10 10:23:47,608] Trial 1 finished with value: 0.5811287477954145 and parameters: {'latent_dim': 50, 'hidden_dim': 111, 'lr': 0.0003375358643252982, 'epochs': 13, 'dropout_rate': 0.15676924248800128, 'noise_level': 0.2787508791355909, 'C': 0.01681495557530516, 'solver': 'liblinear'}. Best is trial 1 with value: 0.5811287477954145.\n",
      "[I 2025-05-10 10:23:56,181] Trial 2 finished with value: 0.6168622038187256 and parameters: {'latent_dim': 79, 'hidden_dim': 200, 'lr': 0.006047342775994164, 'epochs': 20, 'dropout_rate': 0.15391170328990836, 'noise_level': 0.23847348643586103, 'C': 23.539719794776232, 'solver': 'liblinear'}. Best is trial 2 with value: 0.6168622038187256.\n",
      "[I 2025-05-10 10:24:12,439] Trial 3 finished with value: 0.5875508013189172 and parameters: {'latent_dim': 10, 'hidden_dim': 132, 'lr': 0.00037389855854268037, 'epochs': 35, 'dropout_rate': 0.48719595746438793, 'noise_level': 0.2446898989348698, 'C': 57.19549882185349, 'solver': 'liblinear'}. Best is trial 2 with value: 0.6168622038187256.\n",
      "[I 2025-05-10 10:24:33,366] Trial 4 finished with value: 0.6052833371673952 and parameters: {'latent_dim': 51, 'hidden_dim': 237, 'lr': 0.00011789184514985743, 'epochs': 39, 'dropout_rate': 0.29738869575682914, 'noise_level': 0.16423128363803335, 'C': 28.135445041979178, 'solver': 'liblinear'}. Best is trial 2 with value: 0.6168622038187256.\n",
      "[I 2025-05-10 10:24:54,750] Trial 5 finished with value: 0.6049957825320144 and parameters: {'latent_dim': 94, 'hidden_dim': 179, 'lr': 0.0007327898158598202, 'epochs': 47, 'dropout_rate': 0.2239026954000418, 'noise_level': 0.1320658838774863, 'C': 0.06267683772811417, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.6168622038187256.\n",
      "[I 2025-05-10 10:25:03,063] Trial 6 finished with value: 0.5977494057204202 and parameters: {'latent_dim': 39, 'hidden_dim': 186, 'lr': 0.00012155960885966903, 'epochs': 14, 'dropout_rate': 0.2706057875971374, 'noise_level': 0.1689008312831663, 'C': 0.014890213798386743, 'solver': 'liblinear'}. Best is trial 2 with value: 0.6168622038187256.\n",
      "[I 2025-05-10 10:25:09,933] Trial 7 finished with value: 0.5884518058431102 and parameters: {'latent_dim': 60, 'hidden_dim': 230, 'lr': 0.00035914808662499526, 'epochs': 15, 'dropout_rate': 0.49617390156746943, 'noise_level': 0.09865616954892308, 'C': 0.26536327088211864, 'solver': 'liblinear'}. Best is trial 2 with value: 0.6168622038187256.\n",
      "[I 2025-05-10 10:25:32,384] Trial 8 finished with value: 0.6217889732382486 and parameters: {'latent_dim': 22, 'hidden_dim': 183, 'lr': 0.00011806869982876846, 'epochs': 41, 'dropout_rate': 0.1928357195256677, 'noise_level': 0.16581556156893051, 'C': 0.041097019000084924, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 10:25:47,630] Trial 9 finished with value: 0.579499271528257 and parameters: {'latent_dim': 90, 'hidden_dim': 203, 'lr': 0.0014999345633497654, 'epochs': 30, 'dropout_rate': 0.18139714429398535, 'noise_level': 0.13364520439716654, 'C': 17.120215282125198, 'solver': 'liblinear'}. Best is trial 8 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 10:26:00,550] Trial 10 finished with value: 0.6014684456713443 and parameters: {'latent_dim': 11, 'hidden_dim': 81, 'lr': 0.0029022580559050185, 'epochs': 29, 'dropout_rate': 0.3797907250195084, 'noise_level': 0.05415883602280544, 'C': 0.6700819884241194, 'solver': 'saga'}. Best is trial 8 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 10:26:10,110] Trial 11 finished with value: 0.5932827237175063 and parameters: {'latent_dim': 76, 'hidden_dim': 157, 'lr': 0.005645545081903888, 'epochs': 23, 'dropout_rate': 0.10653469030379084, 'noise_level': 0.21048355146951678, 'C': 2.3036963237007777, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 10:26:21,016] Trial 12 finished with value: 0.602561153285791 and parameters: {'latent_dim': 29, 'hidden_dim': 217, 'lr': 0.009712062065588474, 'epochs': 23, 'dropout_rate': 0.10885194827957767, 'noise_level': 0.2930959884637153, 'C': 0.10715517074728899, 'solver': 'saga'}. Best is trial 8 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 10:26:43,320] Trial 13 finished with value: 0.5748217161260639 and parameters: {'latent_dim': 74, 'hidden_dim': 173, 'lr': 0.0023077558455176896, 'epochs': 42, 'dropout_rate': 0.3549357167676067, 'noise_level': 0.19602486673574318, 'C': 6.747784844366561, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 10:26:52,945] Trial 14 finished with value: 0.6164979679472433 and parameters: {'latent_dim': 74, 'hidden_dim': 203, 'lr': 0.0007602358138001158, 'epochs': 21, 'dropout_rate': 0.2422045163499682, 'noise_level': 0.2642704347498769, 'C': 1.030789724972206, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 10:27:14,224] Trial 15 finished with value: 0.6100184034966644 and parameters: {'latent_dim': 20, 'hidden_dim': 252, 'lr': 0.00468495346085067, 'epochs': 36, 'dropout_rate': 0.15040408343580855, 'noise_level': 0.19663517626269017, 'C': 0.06569044806522494, 'solver': 'saga'}. Best is trial 8 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 10:27:21,408] Trial 16 finished with value: 0.6059926386013342 and parameters: {'latent_dim': 31, 'hidden_dim': 159, 'lr': 0.0013422244291996753, 'epochs': 19, 'dropout_rate': 0.3540127173612252, 'noise_level': 0.24152291985033994, 'C': 0.3283817816553064, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 10:27:35,003] Trial 17 finished with value: 0.6136799325205122 and parameters: {'latent_dim': 85, 'hidden_dim': 205, 'lr': 0.00022212709250101425, 'epochs': 27, 'dropout_rate': 0.14585906388463027, 'noise_level': 0.1389393062986544, 'C': 14.10523031702396, 'solver': 'lbfgs'}. Best is trial 8 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 10:28:01,627] Trial 18 finished with value: 0.5742657771643279 and parameters: {'latent_dim': 99, 'hidden_dim': 140, 'lr': 0.008797668110008709, 'epochs': 50, 'dropout_rate': 0.2396845080810686, 'noise_level': 0.09737769438612881, 'C': 78.67168175560113, 'solver': 'liblinear'}. Best is trial 8 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 10:28:17,054] Trial 19 finished with value: 0.5714669120466221 and parameters: {'latent_dim': 62, 'hidden_dim': 97, 'lr': 0.0026646898054954694, 'epochs': 34, 'dropout_rate': 0.197369048351607, 'noise_level': 0.21628146144116936, 'C': 2.1673540116199104, 'solver': 'saga'}. Best is trial 8 with value: 0.6217889732382486.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6161\n"
     ]
    }
   ],
   "source": [
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "    \n",
    "def train_denoising_autoencoder(model, X_train, epochs, batch_size, lr, noise_level=0.1):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_target in train_loader:\n",
    "            # Add noise to input data\n",
    "            noisy_batch = batch_x + noise_level * torch.randn_like(batch_x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _ = model(noisy_batch)\n",
    "            # Target is the original data (not noisy)\n",
    "            loss = criterion(reconstructed, batch_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs, batch_size, lr, noise_level)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5525\n",
      "ROC-AUC autoencoded: 0.5357\n",
      "ROC-AUC autoencoded: 0.5474\n",
      "ROC-AUC autoencoded: 0.5370\n",
      "ROC-AUC autoencoded: 0.5783\n",
      "ROC-AUC autoencoded: 0.5625\n",
      "ROC-AUC autoencoded: 0.5289\n",
      "ROC-AUC autoencoded: 0.5596\n",
      "ROC-AUC autoencoded: 0.5783\n",
      "ROC-AUC autoencoded: 0.5450\n",
      "ROC-AUC autoencoded: 0.5748\n",
      "ROC-AUC autoencoded: 0.5876\n",
      "ROC-AUC autoencoded: 0.5398\n",
      "ROC-AUC autoencoded: 0.5832\n",
      "ROC-AUC autoencoded: 0.6015\n",
      "ROC-AUC autoencoded: 0.5127\n",
      "ROC-AUC autoencoded: 0.5169\n",
      "ROC-AUC autoencoded: 0.5880\n",
      "ROC-AUC autoencoded: 0.5540\n",
      "ROC-AUC autoencoded: 0.4995\n",
      "ROC-AUC autoencoded: 0.6429\n",
      "ROC-AUC autoencoded: 0.6086\n",
      "ROC-AUC autoencoded: 0.6004\n",
      "ROC-AUC autoencoded: 0.6013\n",
      "ROC-AUC autoencoded: 0.5978\n",
      "среднее 0.5653633670928665\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:30:08,803] A new study created in memory with name: no-name-f0651eab-7e30-430a-bd47-d2145e3d648f\n",
      "[I 2025-05-10 10:30:57,867] Trial 0 finished with value: 0.5491526723410781 and parameters: {'latent_dim': 97, 'hidden_dim': 116, 'lr': 0.0014269240249802815, 'epochs': 42, 'dropout_rate': 0.23225952863997043, 'noise_level': 0.24678097003012323, 'n_estimators': 269, 'max_depth': 6, 'learning_rate': 0.037651539153283904, 'subsample': 0.6441380915217304, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.5491526723410781.\n",
      "[I 2025-05-10 10:31:27,591] Trial 1 finished with value: 0.5850586611456177 and parameters: {'latent_dim': 53, 'hidden_dim': 150, 'lr': 0.00020126165851854476, 'epochs': 40, 'dropout_rate': 0.1742413840190667, 'noise_level': 0.07109338125007529, 'n_estimators': 355, 'max_depth': 3, 'learning_rate': 0.012119440609057423, 'subsample': 0.7668864636948762, 'min_samples_split': 16, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.5850586611456177.\n",
      "[I 2025-05-10 10:31:52,205] Trial 2 finished with value: 0.5754351660148761 and parameters: {'latent_dim': 63, 'hidden_dim': 205, 'lr': 0.0021314674994774093, 'epochs': 50, 'dropout_rate': 0.41481681566407624, 'noise_level': 0.29824436649173613, 'n_estimators': 59, 'max_depth': 9, 'learning_rate': 0.030470888981992173, 'subsample': 0.642752171329049, 'min_samples_split': 20, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.5850586611456177.\n",
      "[I 2025-05-10 10:32:13,969] Trial 3 finished with value: 0.5396633693735143 and parameters: {'latent_dim': 94, 'hidden_dim': 233, 'lr': 0.00010343690892891124, 'epochs': 22, 'dropout_rate': 0.36836618505175134, 'noise_level': 0.05498342520470763, 'n_estimators': 83, 'max_depth': 6, 'learning_rate': 0.17770364952055537, 'subsample': 0.8628362233982036, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.5850586611456177.\n",
      "[I 2025-05-10 10:33:20,065] Trial 4 finished with value: 0.5476573882370984 and parameters: {'latent_dim': 91, 'hidden_dim': 86, 'lr': 0.000770233649991086, 'epochs': 45, 'dropout_rate': 0.14743966942067038, 'noise_level': 0.09870186518625139, 'n_estimators': 469, 'max_depth': 5, 'learning_rate': 0.020377528242303367, 'subsample': 0.6874014793858154, 'min_samples_split': 5, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.5850586611456177.\n",
      "[I 2025-05-10 10:34:47,121] Trial 5 finished with value: 0.5549996165938195 and parameters: {'latent_dim': 94, 'hidden_dim': 65, 'lr': 0.0003500501843971817, 'epochs': 18, 'dropout_rate': 0.1703467837875966, 'noise_level': 0.20118022746956238, 'n_estimators': 287, 'max_depth': 9, 'learning_rate': 0.052790870261788365, 'subsample': 0.9697036489874324, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.5850586611456177.\n",
      "[I 2025-05-10 10:35:14,563] Trial 6 finished with value: 0.5428456406717276 and parameters: {'latent_dim': 88, 'hidden_dim': 116, 'lr': 0.00010957803841938614, 'epochs': 36, 'dropout_rate': 0.4305084596734935, 'noise_level': 0.10450917751168191, 'n_estimators': 216, 'max_depth': 3, 'learning_rate': 0.11219978299703331, 'subsample': 0.7568109949460631, 'min_samples_split': 19, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.5850586611456177.\n",
      "[I 2025-05-10 10:36:05,246] Trial 7 finished with value: 0.5880875699716279 and parameters: {'latent_dim': 55, 'hidden_dim': 175, 'lr': 0.0009939579908839044, 'epochs': 27, 'dropout_rate': 0.13960791373278536, 'noise_level': 0.1916994369691864, 'n_estimators': 323, 'max_depth': 9, 'learning_rate': 0.16617674784591202, 'subsample': 0.868495519615478, 'min_samples_split': 13, 'min_samples_leaf': 4}. Best is trial 7 with value: 0.5880875699716279.\n",
      "[I 2025-05-10 10:36:53,611] Trial 8 finished with value: 0.5824323288091403 and parameters: {'latent_dim': 65, 'hidden_dim': 124, 'lr': 0.00042856190317039626, 'epochs': 40, 'dropout_rate': 0.18977723441242944, 'noise_level': 0.10201947680090746, 'n_estimators': 437, 'max_depth': 5, 'learning_rate': 0.015900322833385605, 'subsample': 0.6936201698927541, 'min_samples_split': 13, 'min_samples_leaf': 4}. Best is trial 7 with value: 0.5880875699716279.\n",
      "[I 2025-05-10 10:37:19,301] Trial 9 finished with value: 0.5592745955064795 and parameters: {'latent_dim': 13, 'hidden_dim': 88, 'lr': 0.0012276787956647045, 'epochs': 50, 'dropout_rate': 0.22223252243719954, 'noise_level': 0.270261449911974, 'n_estimators': 337, 'max_depth': 10, 'learning_rate': 0.022287261247448356, 'subsample': 0.6374365316275411, 'min_samples_split': 14, 'min_samples_leaf': 8}. Best is trial 7 with value: 0.5880875699716279.\n",
      "[I 2025-05-10 10:37:35,391] Trial 10 finished with value: 0.5851736829997699 and parameters: {'latent_dim': 31, 'hidden_dim': 189, 'lr': 0.009361978426805584, 'epochs': 11, 'dropout_rate': 0.10262826226618642, 'noise_level': 0.16795079946391941, 'n_estimators': 147, 'max_depth': 8, 'learning_rate': 0.29227441341253413, 'subsample': 0.8893734277076182, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.5880875699716279.\n",
      "[I 2025-05-10 10:37:53,082] Trial 11 finished with value: 0.5477915804002761 and parameters: {'latent_dim': 32, 'hidden_dim': 188, 'lr': 0.007767474461523123, 'epochs': 10, 'dropout_rate': 0.1165937007451417, 'noise_level': 0.1712543590834809, 'n_estimators': 170, 'max_depth': 8, 'learning_rate': 0.26924183500661236, 'subsample': 0.8639340950456084, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.5880875699716279.\n",
      "[I 2025-05-10 10:38:20,038] Trial 12 finished with value: 0.5572808833678399 and parameters: {'latent_dim': 38, 'hidden_dim': 181, 'lr': 0.004118398175933616, 'epochs': 28, 'dropout_rate': 0.29736936887106236, 'noise_level': 0.16631399530891022, 'n_estimators': 145, 'max_depth': 8, 'learning_rate': 0.11949923077022992, 'subsample': 0.9342119797412262, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.5880875699716279.\n",
      "[I 2025-05-10 10:38:44,415] Trial 13 finished with value: 0.5608273905375355 and parameters: {'latent_dim': 33, 'hidden_dim': 219, 'lr': 0.009712541094465255, 'epochs': 10, 'dropout_rate': 0.28213903007939667, 'noise_level': 0.21194044081534674, 'n_estimators': 388, 'max_depth': 8, 'learning_rate': 0.2994297767370689, 'subsample': 0.858084296240225, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.5880875699716279.\n",
      "[I 2025-05-10 10:39:01,422] Trial 14 finished with value: 0.5329921018326815 and parameters: {'latent_dim': 12, 'hidden_dim': 164, 'lr': 0.00307110847442459, 'epochs': 18, 'dropout_rate': 0.1079784562292874, 'noise_level': 0.1439585039581959, 'n_estimators': 244, 'max_depth': 10, 'learning_rate': 0.09465400526464794, 'subsample': 0.9165248873506874, 'min_samples_split': 12, 'min_samples_leaf': 5}. Best is trial 7 with value: 0.5880875699716279.\n",
      "[I 2025-05-10 10:39:28,579] Trial 15 finished with value: 0.5860363469059121 and parameters: {'latent_dim': 47, 'hidden_dim': 253, 'lr': 0.0006830920937921384, 'epochs': 25, 'dropout_rate': 0.11443066917910202, 'noise_level': 0.22517702241316837, 'n_estimators': 148, 'max_depth': 7, 'learning_rate': 0.18366726842030365, 'subsample': 0.9983592032750522, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.5880875699716279.\n",
      "[I 2025-05-10 10:40:16,235] Trial 16 finished with value: 0.5612874779541447 and parameters: {'latent_dim': 49, 'hidden_dim': 256, 'lr': 0.0006381120412009763, 'epochs': 29, 'dropout_rate': 0.34583159592983737, 'noise_level': 0.22331382309217443, 'n_estimators': 311, 'max_depth': 7, 'learning_rate': 0.06747536741194143, 'subsample': 0.972333697226038, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 7 with value: 0.5880875699716279.\n",
      "[I 2025-05-10 10:40:54,443] Trial 17 finished with value: 0.5604248140480025 and parameters: {'latent_dim': 76, 'hidden_dim': 236, 'lr': 0.00040884601642487116, 'epochs': 24, 'dropout_rate': 0.24224841627647353, 'noise_level': 0.24374245421823232, 'n_estimators': 198, 'max_depth': 7, 'learning_rate': 0.1775279809124118, 'subsample': 0.8087123788505405, 'min_samples_split': 11, 'min_samples_leaf': 6}. Best is trial 7 with value: 0.5880875699716279.\n",
      "[I 2025-05-10 10:42:15,242] Trial 18 finished with value: 0.5646422820335865 and parameters: {'latent_dim': 44, 'hidden_dim': 255, 'lr': 0.0018552358252723023, 'epochs': 33, 'dropout_rate': 0.49234634640748504, 'noise_level': 0.13322307255951912, 'n_estimators': 399, 'max_depth': 9, 'learning_rate': 0.1724637285420292, 'subsample': 0.9999714496411994, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 7 with value: 0.5880875699716279.\n",
      "[I 2025-05-10 10:42:43,957] Trial 19 finished with value: 0.5671152518978605 and parameters: {'latent_dim': 62, 'hidden_dim': 148, 'lr': 0.0008889984233397576, 'epochs': 25, 'dropout_rate': 0.14632707204613488, 'noise_level': 0.1911187083033836, 'n_estimators': 128, 'max_depth': 5, 'learning_rate': 0.06972610914471669, 'subsample': 0.8137585371061561, 'min_samples_split': 18, 'min_samples_leaf': 5}. Best is trial 7 with value: 0.5880875699716279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5851\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs, batch_size, lr, noise_level)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5203\n",
      "ROC-AUC autoencoded: 0.5348\n",
      "ROC-AUC autoencoded: 0.5243\n",
      "ROC-AUC autoencoded: 0.5543\n",
      "ROC-AUC autoencoded: 0.5073\n",
      "ROC-AUC autoencoded: 0.5751\n",
      "ROC-AUC autoencoded: 0.4917\n",
      "ROC-AUC autoencoded: 0.4954\n",
      "ROC-AUC autoencoded: 0.5039\n",
      "ROC-AUC autoencoded: 0.5869\n",
      "ROC-AUC autoencoded: 0.4939\n",
      "ROC-AUC autoencoded: 0.5376\n",
      "ROC-AUC autoencoded: 0.5422\n",
      "ROC-AUC autoencoded: 0.4894\n",
      "ROC-AUC autoencoded: 0.5876\n",
      "ROC-AUC autoencoded: 0.5336\n",
      "ROC-AUC autoencoded: 0.5040\n",
      "ROC-AUC autoencoded: 0.5117\n",
      "ROC-AUC autoencoded: 0.4833\n",
      "ROC-AUC autoencoded: 0.5136\n",
      "ROC-AUC autoencoded: 0.5960\n",
      "ROC-AUC autoencoded: 0.6586\n",
      "ROC-AUC autoencoded: 0.5642\n",
      "ROC-AUC autoencoded: 0.6181\n",
      "ROC-AUC autoencoded: 0.6044\n",
      "среднее 0.5412958592550272\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:50:31,702] A new study created in memory with name: no-name-68f9994f-da64-432c-bf62-b553de889db7\n",
      "[I 2025-05-10 10:51:02,786] Trial 0 finished with value: 0.5700866497967947 and parameters: {'latent_dim': 93, 'hidden_dim': 212, 'lr': 0.0001275989477619311, 'epochs': 32, 'dropout_rate': 0.10084732120329734, 'noise_level': 0.1969963500969113, 'C': 7.890231893750371, 'kernel': 'linear'}. Best is trial 0 with value: 0.5700866497967947.\n",
      "[I 2025-05-10 10:51:19,733] Trial 1 finished with value: 0.5830649490069779 and parameters: {'latent_dim': 91, 'hidden_dim': 233, 'lr': 0.0019560435191848476, 'epochs': 39, 'dropout_rate': 0.3893002429543936, 'noise_level': 0.2796562350909645, 'C': 7.376130454670963, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 1 with value: 0.5830649490069779.\n",
      "[I 2025-05-10 10:51:27,528] Trial 2 finished with value: 0.49798711755233493 and parameters: {'latent_dim': 43, 'hidden_dim': 148, 'lr': 0.000269581040778079, 'epochs': 19, 'dropout_rate': 0.16014035241986457, 'noise_level': 0.19464311806941587, 'C': 0.1255135024699051, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 1 with value: 0.5830649490069779.\n",
      "[I 2025-05-10 10:51:41,360] Trial 3 finished with value: 0.5783490529867342 and parameters: {'latent_dim': 43, 'hidden_dim': 247, 'lr': 0.0002643881476562415, 'epochs': 28, 'dropout_rate': 0.42486719958869623, 'noise_level': 0.23873004160639832, 'C': 16.266405747475233, 'kernel': 'linear'}. Best is trial 1 with value: 0.5830649490069779.\n",
      "[I 2025-05-10 10:51:46,469] Trial 4 finished with value: 0.5983053446821563 and parameters: {'latent_dim': 51, 'hidden_dim': 232, 'lr': 0.0056224236503121475, 'epochs': 11, 'dropout_rate': 0.15630456369672366, 'noise_level': 0.07452744441233476, 'C': 0.16943619936796225, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 4 with value: 0.5983053446821563.\n",
      "[I 2025-05-10 10:51:59,350] Trial 5 finished with value: 0.5366919714745801 and parameters: {'latent_dim': 22, 'hidden_dim': 239, 'lr': 0.00016131962909641495, 'epochs': 32, 'dropout_rate': 0.3042223244204354, 'noise_level': 0.05555354876701356, 'C': 0.8387673076962783, 'kernel': 'poly', 'gamma': 'auto', 'degree': 5}. Best is trial 4 with value: 0.5983053446821563.\n",
      "[I 2025-05-10 10:52:04,286] Trial 6 finished with value: 0.5567632850241546 and parameters: {'latent_dim': 96, 'hidden_dim': 94, 'lr': 0.0008043525294697242, 'epochs': 10, 'dropout_rate': 0.4399508331739349, 'noise_level': 0.23323878951340143, 'C': 0.7723702007553931, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 4 with value: 0.5983053446821563.\n",
      "[I 2025-05-10 10:52:13,672] Trial 7 finished with value: 0.6160378805306341 and parameters: {'latent_dim': 22, 'hidden_dim': 179, 'lr': 0.00400226814970745, 'epochs': 24, 'dropout_rate': 0.18834329022960752, 'noise_level': 0.19808529941932712, 'C': 0.28970017106399887, 'kernel': 'linear'}. Best is trial 7 with value: 0.6160378805306341.\n",
      "[I 2025-05-10 10:52:26,605] Trial 8 finished with value: 0.5393566444291081 and parameters: {'latent_dim': 42, 'hidden_dim': 169, 'lr': 0.0010167039925006657, 'epochs': 31, 'dropout_rate': 0.12060924732575007, 'noise_level': 0.29528336616664586, 'C': 5.669102784381073, 'kernel': 'linear'}. Best is trial 7 with value: 0.6160378805306341.\n",
      "[I 2025-05-10 10:52:41,153] Trial 9 finished with value: 0.5656391381029062 and parameters: {'latent_dim': 95, 'hidden_dim': 80, 'lr': 0.004511384950700841, 'epochs': 40, 'dropout_rate': 0.13057281571800888, 'noise_level': 0.2668712416739281, 'C': 0.1485019117197561, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 7 with value: 0.6160378805306341.\n",
      "[I 2025-05-10 10:53:32,978] Trial 10 finished with value: 0.5384939805229659 and parameters: {'latent_dim': 14, 'hidden_dim': 176, 'lr': 0.008030085093312496, 'epochs': 48, 'dropout_rate': 0.24493592902958805, 'noise_level': 0.12938315394708244, 'C': 97.23454892402813, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 7 with value: 0.6160378805306341.\n",
      "[I 2025-05-10 10:53:37,499] Trial 11 finished with value: 0.5889118932597194 and parameters: {'latent_dim': 69, 'hidden_dim': 199, 'lr': 0.0036123649581752135, 'epochs': 10, 'dropout_rate': 0.22720186033635953, 'noise_level': 0.1265539640492358, 'C': 0.47666748951553023, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 7 with value: 0.6160378805306341.\n",
      "[I 2025-05-10 10:53:45,296] Trial 12 finished with value: 0.5797676558546124 and parameters: {'latent_dim': 65, 'hidden_dim': 134, 'lr': 0.006637775732544626, 'epochs': 19, 'dropout_rate': 0.2061450883256866, 'noise_level': 0.05810729325705216, 'C': 0.34553398237595406, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 7 with value: 0.6160378805306341.\n",
      "[I 2025-05-10 10:53:53,007] Trial 13 finished with value: 0.5427306188175752 and parameters: {'latent_dim': 29, 'hidden_dim': 202, 'lr': 0.0023940008843236307, 'epochs': 19, 'dropout_rate': 0.314928807154779, 'noise_level': 0.14118447770389123, 'C': 1.6019343602208385, 'kernel': 'linear'}. Best is trial 7 with value: 0.6160378805306341.\n",
      "[I 2025-05-10 10:54:01,931] Trial 14 finished with value: 0.5619392684610075 and parameters: {'latent_dim': 58, 'hidden_dim': 127, 'lr': 0.0012782712125906878, 'epochs': 24, 'dropout_rate': 0.18598181186916454, 'noise_level': 0.09993978854672816, 'C': 0.24643694405285108, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 7 with value: 0.6160378805306341.\n",
      "[I 2025-05-10 10:54:09,954] Trial 15 finished with value: 0.5498619737750173 and parameters: {'latent_dim': 78, 'hidden_dim': 183, 'lr': 0.004261078879496377, 'epochs': 14, 'dropout_rate': 0.25589428035704725, 'noise_level': 0.1653366314369557, 'C': 1.739228603386657, 'kernel': 'linear'}. Best is trial 7 with value: 0.6160378805306341.\n",
      "[I 2025-05-10 10:54:22,667] Trial 16 finished with value: 0.5348516218081435 and parameters: {'latent_dim': 32, 'hidden_dim': 256, 'lr': 0.009101388436028968, 'epochs': 26, 'dropout_rate': 0.16443134506569518, 'noise_level': 0.09413911625376578, 'C': 0.13398748746760544, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2}. Best is trial 7 with value: 0.6160378805306341.\n",
      "[I 2025-05-10 10:54:32,052] Trial 17 finished with value: 0.6002607162027452 and parameters: {'latent_dim': 16, 'hidden_dim': 213, 'lr': 0.0005770741038952318, 'epochs': 22, 'dropout_rate': 0.33112200003685044, 'noise_level': 0.16676513057016823, 'C': 0.3237874569782573, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 7 with value: 0.6160378805306341.\n",
      "[I 2025-05-10 10:54:40,856] Trial 18 finished with value: 0.5711793574112415 and parameters: {'latent_dim': 12, 'hidden_dim': 211, 'lr': 0.0005578393588811832, 'epochs': 22, 'dropout_rate': 0.3628327221876395, 'noise_level': 0.178280808294901, 'C': 2.0206917493553016, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 7 with value: 0.6160378805306341.\n",
      "[I 2025-05-10 10:54:54,039] Trial 19 finished with value: 0.5767962579556783 and parameters: {'latent_dim': 22, 'hidden_dim': 150, 'lr': 0.00047327666096537126, 'epochs': 36, 'dropout_rate': 0.4847313680905522, 'noise_level': 0.22802616680306703, 'C': 0.7057572935145138, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 7 with value: 0.6160378805306341.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5792\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs, batch_size, lr, noise_level)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5889\n",
      "ROC-AUC autoencoded: 0.5221\n",
      "ROC-AUC autoencoded: 0.5696\n",
      "ROC-AUC autoencoded: 0.5610\n",
      "ROC-AUC autoencoded: 0.5893\n",
      "ROC-AUC autoencoded: 0.5330\n",
      "ROC-AUC autoencoded: 0.4795\n",
      "ROC-AUC autoencoded: 0.5944\n",
      "ROC-AUC autoencoded: 0.5704\n",
      "ROC-AUC autoencoded: 0.4867\n",
      "ROC-AUC autoencoded: 0.5475\n",
      "ROC-AUC autoencoded: 0.5277\n",
      "ROC-AUC autoencoded: 0.5012\n",
      "ROC-AUC autoencoded: 0.5482\n",
      "ROC-AUC autoencoded: 0.5963\n",
      "ROC-AUC autoencoded: 0.5358\n",
      "ROC-AUC autoencoded: 0.5033\n",
      "ROC-AUC autoencoded: 0.5009\n",
      "ROC-AUC autoencoded: 0.5541\n",
      "ROC-AUC autoencoded: 0.5416\n",
      "ROC-AUC autoencoded: 0.4968\n",
      "ROC-AUC autoencoded: 0.5808\n",
      "ROC-AUC autoencoded: 0.4052\n",
      "ROC-AUC autoencoded: 0.4316\n",
      "ROC-AUC autoencoded: 0.5750\n",
      "среднее 0.533632717423921\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs'], 32, best_params['lr'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 10:55:59,180] A new study created in memory with name: no-name-0716c897-78ab-42b4-a095-b7467aeda1ce\n",
      "[I 2025-05-10 10:56:18,896] Trial 0 finished with value: 0.5958132045088567 and parameters: {'latent_dim': 68, 'hidden_dim_ae': 107, 'lr_ae': 0.00019396492536367436, 'epochs_ae': 49, 'dropout_rate_ae': 0.3874923781730385, 'noise_level': 0.12325098340484285, 'hidden_dim_mlp': 104, 'lr_mlp': 0.00019805889678554018, 'epochs_mlp': 14, 'dropout_rate_mlp': 0.4724847829679121}. Best is trial 0 with value: 0.5958132045088567.\n",
      "[I 2025-05-10 10:56:39,602] Trial 1 finished with value: 0.5764128517751707 and parameters: {'latent_dim': 57, 'hidden_dim_ae': 95, 'lr_ae': 0.008302857190570733, 'epochs_ae': 44, 'dropout_rate_ae': 0.13797726333603466, 'noise_level': 0.14256779941659653, 'hidden_dim_mlp': 66, 'lr_mlp': 0.009524201080760051, 'epochs_mlp': 25, 'dropout_rate_mlp': 0.4015584888404613}. Best is trial 0 with value: 0.5958132045088567.\n",
      "[I 2025-05-10 10:56:55,875] Trial 2 finished with value: 0.5856912813434553 and parameters: {'latent_dim': 99, 'hidden_dim_ae': 132, 'lr_ae': 0.004070811492071051, 'epochs_ae': 37, 'dropout_rate_ae': 0.48026522736974164, 'noise_level': 0.1405721763822501, 'hidden_dim_mlp': 57, 'lr_mlp': 0.0005580561798164179, 'epochs_mlp': 17, 'dropout_rate_mlp': 0.27634651781892294}. Best is trial 0 with value: 0.5958132045088567.\n",
      "[I 2025-05-10 10:57:10,952] Trial 3 finished with value: 0.5753009738516984 and parameters: {'latent_dim': 15, 'hidden_dim_ae': 80, 'lr_ae': 0.0005773060404619067, 'epochs_ae': 38, 'dropout_rate_ae': 0.47210522687743073, 'noise_level': 0.12353047419234063, 'hidden_dim_mlp': 107, 'lr_mlp': 0.001602803604902464, 'epochs_mlp': 18, 'dropout_rate_mlp': 0.18453776886676093}. Best is trial 0 with value: 0.5958132045088567.\n",
      "[I 2025-05-10 10:57:32,429] Trial 4 finished with value: 0.5922475270301357 and parameters: {'latent_dim': 73, 'hidden_dim_ae': 252, 'lr_ae': 0.008581432114479776, 'epochs_ae': 50, 'dropout_rate_ae': 0.37282606009158026, 'noise_level': 0.08376155289851504, 'hidden_dim_mlp': 69, 'lr_mlp': 0.00036650216072581915, 'epochs_mlp': 11, 'dropout_rate_mlp': 0.40900734995797605}. Best is trial 0 with value: 0.5958132045088567.\n",
      "[I 2025-05-10 10:57:54,029] Trial 5 finished with value: 0.5672686143700636 and parameters: {'latent_dim': 48, 'hidden_dim_ae': 222, 'lr_ae': 0.005847855677501091, 'epochs_ae': 37, 'dropout_rate_ae': 0.36917253358464275, 'noise_level': 0.2129539034753311, 'hidden_dim_mlp': 121, 'lr_mlp': 0.0005250944286841272, 'epochs_mlp': 41, 'dropout_rate_mlp': 0.3652269012333419}. Best is trial 0 with value: 0.5958132045088567.\n",
      "[I 2025-05-10 10:58:08,916] Trial 6 finished with value: 0.5477532397822252 and parameters: {'latent_dim': 20, 'hidden_dim_ae': 133, 'lr_ae': 0.005590141385636849, 'epochs_ae': 23, 'dropout_rate_ae': 0.2868823848482319, 'noise_level': 0.21088724684635823, 'hidden_dim_mlp': 106, 'lr_mlp': 0.004283045180557212, 'epochs_mlp': 39, 'dropout_rate_mlp': 0.3567433194069598}. Best is trial 0 with value: 0.5958132045088567.\n",
      "[I 2025-05-10 10:58:30,221] Trial 7 finished with value: 0.5793650793650792 and parameters: {'latent_dim': 66, 'hidden_dim_ae': 174, 'lr_ae': 0.00724088606450581, 'epochs_ae': 33, 'dropout_rate_ae': 0.4199374727098215, 'noise_level': 0.17718679701424783, 'hidden_dim_mlp': 79, 'lr_mlp': 0.0011170624293149807, 'epochs_mlp': 50, 'dropout_rate_mlp': 0.4775063909330586}. Best is trial 0 with value: 0.5958132045088567.\n",
      "[I 2025-05-10 10:58:44,369] Trial 8 finished with value: 0.5987079211716893 and parameters: {'latent_dim': 90, 'hidden_dim_ae': 67, 'lr_ae': 0.0012222525242368916, 'epochs_ae': 35, 'dropout_rate_ae': 0.15678553741323797, 'noise_level': 0.29648234301587567, 'hidden_dim_mlp': 67, 'lr_mlp': 0.00015506953162979832, 'epochs_mlp': 16, 'dropout_rate_mlp': 0.18974361381486507}. Best is trial 8 with value: 0.5987079211716893.\n",
      "[I 2025-05-10 10:58:54,550] Trial 9 finished with value: 0.559696342305038 and parameters: {'latent_dim': 59, 'hidden_dim_ae': 85, 'lr_ae': 0.0010681739984274156, 'epochs_ae': 14, 'dropout_rate_ae': 0.11862399430618585, 'noise_level': 0.05621094110245327, 'hidden_dim_mlp': 99, 'lr_mlp': 0.0038895066264336836, 'epochs_mlp': 32, 'dropout_rate_mlp': 0.18138627709700197}. Best is trial 8 with value: 0.5987079211716893.\n",
      "[I 2025-05-10 10:59:08,528] Trial 10 finished with value: 0.6074879227053139 and parameters: {'latent_dim': 98, 'hidden_dim_ae': 179, 'lr_ae': 0.001543020577775045, 'epochs_ae': 26, 'dropout_rate_ae': 0.21850629873977578, 'noise_level': 0.2849451945473798, 'hidden_dim_mlp': 36, 'lr_mlp': 0.00011963210502070307, 'epochs_mlp': 24, 'dropout_rate_mlp': 0.12324188504041396}. Best is trial 10 with value: 0.6074879227053139.\n",
      "[I 2025-05-10 10:59:21,632] Trial 11 finished with value: 0.5825090100452419 and parameters: {'latent_dim': 97, 'hidden_dim_ae': 185, 'lr_ae': 0.00154990550985896, 'epochs_ae': 25, 'dropout_rate_ae': 0.21440373152624437, 'noise_level': 0.2887559331229129, 'hidden_dim_mlp': 33, 'lr_mlp': 0.00010238540381115089, 'epochs_mlp': 24, 'dropout_rate_mlp': 0.12735550674768686}. Best is trial 10 with value: 0.6074879227053139.\n",
      "[I 2025-05-10 10:59:34,946] Trial 12 finished with value: 0.5962541216164405 and parameters: {'latent_dim': 87, 'hidden_dim_ae': 198, 'lr_ae': 0.0020149325754770316, 'epochs_ae': 26, 'dropout_rate_ae': 0.20934576354374063, 'noise_level': 0.2997288670673727, 'hidden_dim_mlp': 34, 'lr_mlp': 0.00011102129510355278, 'epochs_mlp': 22, 'dropout_rate_mlp': 0.10099671114702476}. Best is trial 10 with value: 0.6074879227053139.\n",
      "[I 2025-05-10 10:59:46,774] Trial 13 finished with value: 0.614772640134959 and parameters: {'latent_dim': 83, 'hidden_dim_ae': 148, 'lr_ae': 0.0004450895016707912, 'epochs_ae': 17, 'dropout_rate_ae': 0.2051727280251174, 'noise_level': 0.2511415604323115, 'hidden_dim_mlp': 50, 'lr_mlp': 0.00023670388647156765, 'epochs_mlp': 32, 'dropout_rate_mlp': 0.2414860589576966}. Best is trial 13 with value: 0.614772640134959.\n",
      "[I 2025-05-10 10:59:56,892] Trial 14 finished with value: 0.5889310635687447 and parameters: {'latent_dim': 37, 'hidden_dim_ae': 152, 'lr_ae': 0.0003726849611557919, 'epochs_ae': 14, 'dropout_rate_ae': 0.2709745747711175, 'noise_level': 0.2529582899879427, 'hidden_dim_mlp': 47, 'lr_mlp': 0.0002565012428302276, 'epochs_mlp': 32, 'dropout_rate_mlp': 0.2569454155432987}. Best is trial 13 with value: 0.614772640134959.\n",
      "[I 2025-05-10 11:00:10,599] Trial 15 finished with value: 0.554117782378652 and parameters: {'latent_dim': 80, 'hidden_dim_ae': 208, 'lr_ae': 0.0001296214143935058, 'epochs_ae': 20, 'dropout_rate_ae': 0.22536752564613746, 'noise_level': 0.24639879360483116, 'hidden_dim_mlp': 47, 'lr_mlp': 0.00030441697427632027, 'epochs_mlp': 37, 'dropout_rate_mlp': 0.2450367956519694}. Best is trial 13 with value: 0.614772640134959.\n",
      "[I 2025-05-10 11:00:21,897] Trial 16 finished with value: 0.534525726554712 and parameters: {'latent_dim': 79, 'hidden_dim_ae': 153, 'lr_ae': 0.0005362753218952679, 'epochs_ae': 18, 'dropout_rate_ae': 0.1657212859320558, 'noise_level': 0.2562481504737443, 'hidden_dim_mlp': 48, 'lr_mlp': 0.0006321913938528276, 'epochs_mlp': 28, 'dropout_rate_mlp': 0.14997035691145832}. Best is trial 13 with value: 0.614772640134959.\n",
      "[I 2025-05-10 11:00:39,797] Trial 17 finished with value: 0.5870140326662064 and parameters: {'latent_dim': 86, 'hidden_dim_ae': 126, 'lr_ae': 0.0030439714446028492, 'epochs_ae': 29, 'dropout_rate_ae': 0.32057299295059116, 'noise_level': 0.2064200146468318, 'hidden_dim_mlp': 89, 'lr_mlp': 0.00014155478903750225, 'epochs_mlp': 44, 'dropout_rate_mlp': 0.3171209050911429}. Best is trial 13 with value: 0.614772640134959.\n",
      "[I 2025-05-10 11:00:49,658] Trial 18 finished with value: 0.5792308872019017 and parameters: {'latent_dim': 42, 'hidden_dim_ae': 171, 'lr_ae': 0.00029005703524592313, 'epochs_ae': 10, 'dropout_rate_ae': 0.24632520348466982, 'noise_level': 0.2683370997499947, 'hidden_dim_mlp': 41, 'lr_mlp': 0.00021607800446612945, 'epochs_mlp': 35, 'dropout_rate_mlp': 0.2296222849860429}. Best is trial 13 with value: 0.614772640134959.\n",
      "[I 2025-05-10 11:01:02,461] Trial 19 finished with value: 0.5401809677171996 and parameters: {'latent_dim': 98, 'hidden_dim_ae': 230, 'lr_ae': 0.0006494080204948368, 'epochs_ae': 20, 'dropout_rate_ae': 0.1821206114961033, 'noise_level': 0.23561659317437827, 'hidden_dim_mlp': 56, 'lr_mlp': 0.002003673905079281, 'epochs_mlp': 28, 'dropout_rate_mlp': 0.3071538391237288}. Best is trial 13 with value: 0.614772640134959.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5941\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_mlp(model, X_train, y_train, epochs, batch_size, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_mlp(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_tensor)\n",
    "    \n",
    "    return predictions.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim_ae = trial.suggest_int('hidden_dim_ae', 64, 256)\n",
    "    lr_ae = trial.suggest_float('lr_ae', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs_ae = trial.suggest_int('epochs_ae', 10, 50)\n",
    "    dropout_rate_ae = trial.suggest_float('dropout_rate_ae', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    \n",
    "    hidden_dim_mlp = trial.suggest_int('hidden_dim_mlp', 32, 128)\n",
    "    lr_mlp = trial.suggest_float('lr_mlp', 1e-4, 1e-2, log=True)\n",
    "    epochs_mlp = trial.suggest_int('epochs_mlp', 10, 50)\n",
    "    dropout_rate_mlp = trial.suggest_float('dropout_rate_mlp', 0.1, 0.5)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim_ae, dropout_rate_ae)\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, epochs_ae, batch_size, lr_ae, noise_level)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(latent_dim, hidden_dim_mlp, dropout_rate_mlp)\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, epochs_mlp, batch_size, lr_mlp)\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = DenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "autoencoder = train_denoising_autoencoder(autoencoder, X_train_all, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['noise_level'])\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "mlp = MLP(best_params['latent_dim'], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "mlp = train_mlp(mlp, X_train_latent, y_all_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "\n",
    "y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5769\n",
      "ROC-AUC autoencoded: 0.5376\n",
      "ROC-AUC autoencoded: 0.5298\n",
      "ROC-AUC autoencoded: 0.5035\n",
      "ROC-AUC autoencoded: 0.5628\n",
      "ROC-AUC autoencoded: 0.5748\n",
      "ROC-AUC autoencoded: 0.5218\n",
      "ROC-AUC autoencoded: 0.5685\n",
      "ROC-AUC autoencoded: 0.5743\n",
      "ROC-AUC autoencoded: 0.5207\n",
      "ROC-AUC autoencoded: 0.5878\n",
      "ROC-AUC autoencoded: 0.5809\n",
      "ROC-AUC autoencoded: 0.5396\n",
      "ROC-AUC autoencoded: 0.5055\n",
      "ROC-AUC autoencoded: 0.5537\n",
      "ROC-AUC autoencoded: 0.5085\n",
      "ROC-AUC autoencoded: 0.5861\n",
      "ROC-AUC autoencoded: 0.5467\n",
      "ROC-AUC autoencoded: 0.5133\n",
      "ROC-AUC autoencoded: 0.4964\n",
      "ROC-AUC autoencoded: 0.6207\n",
      "ROC-AUC autoencoded: 0.6135\n",
      "ROC-AUC autoencoded: 0.6250\n",
      "ROC-AUC autoencoded: 0.5864\n",
      "ROC-AUC autoencoded: 0.6073\n",
      "среднее 0.5576756704853453\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = DenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim_ae'], best_params['dropout_rate_ae'])\n",
    "        autoencoder = train_denoising_autoencoder(autoencoder, X_train, best_params['epochs_ae'], 32, best_params['lr_ae'], best_params['noise_level'])\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        mlp = MLP(best_params['latent_dim'], best_params['hidden_dim_mlp'], best_params['dropout_rate_mlp'])\n",
    "        mlp = train_mlp(mlp, X_train_latent, y_train, best_params['epochs_mlp'], 32, best_params['lr_mlp'])\n",
    "        \n",
    "        y_pred_proba = predict_mlp(mlp, X_val_latent)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь блок с denoising автоэнкодером с дополнительной классифицирующей головой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 11:02:24,038] A new study created in memory with name: no-name-55c63169-682b-435c-8ff9-dc03935dd341\n",
      "[I 2025-05-10 11:02:39,564] Trial 0 finished with value: 0.6132006747948776 and parameters: {'latent_dim': 77, 'hidden_dim': 124, 'lr': 0.0003223835060752233, 'epochs': 36, 'dropout_rate': 0.27678640859491843, 'noise_level': 0.27989373614485535, 'classification_weight': 0.25439843351929603, 'C': 5.995824547834075, 'solver': 'liblinear'}. Best is trial 0 with value: 0.6132006747948776.\n",
      "[I 2025-05-10 11:02:47,672] Trial 1 finished with value: 0.6123955218158117 and parameters: {'latent_dim': 79, 'hidden_dim': 224, 'lr': 0.00023765863201493889, 'epochs': 17, 'dropout_rate': 0.14321760154938376, 'noise_level': 0.2600028483338492, 'classification_weight': 0.16189030090122794, 'C': 0.0314000343794539, 'solver': 'saga'}. Best is trial 0 with value: 0.6132006747948776.\n",
      "[I 2025-05-10 11:03:04,591] Trial 2 finished with value: 0.6224982746721877 and parameters: {'latent_dim': 18, 'hidden_dim': 177, 'lr': 0.0007607170708489095, 'epochs': 37, 'dropout_rate': 0.45097483641574854, 'noise_level': 0.23607593835633733, 'classification_weight': 0.14595761097706614, 'C': 0.0779654902248923, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:03:17,802] Trial 3 finished with value: 0.6056859136569281 and parameters: {'latent_dim': 15, 'hidden_dim': 161, 'lr': 0.0003387710114937995, 'epochs': 31, 'dropout_rate': 0.24263213259875013, 'noise_level': 0.26909140311245994, 'classification_weight': 0.17856699344574417, 'C': 0.17502172728501444, 'solver': 'saga'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:03:46,158] Trial 4 finished with value: 0.5543478260869565 and parameters: {'latent_dim': 32, 'hidden_dim': 143, 'lr': 0.0012128382501455446, 'epochs': 49, 'dropout_rate': 0.43318347434998106, 'noise_level': 0.05680969803216353, 'classification_weight': 0.8679171618304005, 'C': 3.8716919005360455, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:04:03,143] Trial 5 finished with value: 0.6033087953377808 and parameters: {'latent_dim': 77, 'hidden_dim': 158, 'lr': 0.005461460064224684, 'epochs': 23, 'dropout_rate': 0.47132958677543135, 'noise_level': 0.13881508031024226, 'classification_weight': 0.1041849566302056, 'C': 7.7986270799098945, 'solver': 'saga'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:04:20,322] Trial 6 finished with value: 0.5941837282416992 and parameters: {'latent_dim': 25, 'hidden_dim': 237, 'lr': 0.0012101979850856455, 'epochs': 20, 'dropout_rate': 0.49004936869218596, 'noise_level': 0.13325548951173288, 'classification_weight': 0.6209861368172476, 'C': 0.11670811288620513, 'solver': 'liblinear'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:04:42,302] Trial 7 finished with value: 0.6132390154129285 and parameters: {'latent_dim': 25, 'hidden_dim': 152, 'lr': 0.00013210565478607146, 'epochs': 28, 'dropout_rate': 0.4017565396211116, 'noise_level': 0.23130103803024998, 'classification_weight': 0.6852496550626953, 'C': 0.26579928997000707, 'solver': 'saga'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:04:49,957] Trial 8 finished with value: 0.5724829384249673 and parameters: {'latent_dim': 70, 'hidden_dim': 96, 'lr': 0.001290917206588023, 'epochs': 10, 'dropout_rate': 0.3162582900371087, 'noise_level': 0.08964562485272588, 'classification_weight': 0.4798599102261093, 'C': 29.70359280356362, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:05:08,846] Trial 9 finished with value: 0.5851065869181812 and parameters: {'latent_dim': 73, 'hidden_dim': 216, 'lr': 0.0004189509066151929, 'epochs': 22, 'dropout_rate': 0.2808064180039799, 'noise_level': 0.18013129390581922, 'classification_weight': 0.4137075534939195, 'C': 1.6463895305196685, 'solver': 'saga'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:05:44,356] Trial 10 finished with value: 0.5389157273215245 and parameters: {'latent_dim': 47, 'hidden_dim': 196, 'lr': 0.005382830391148626, 'epochs': 43, 'dropout_rate': 0.36791210666464824, 'noise_level': 0.20717390945814226, 'classification_weight': 0.3257451854614214, 'C': 0.01002848503606133, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:05:59,480] Trial 11 finished with value: 0.6185875316310098 and parameters: {'latent_dim': 10, 'hidden_dim': 183, 'lr': 0.0001268515268521831, 'epochs': 36, 'dropout_rate': 0.3897066384288584, 'noise_level': 0.2220645341856845, 'classification_weight': 0.6927563506687205, 'C': 0.37560629849322613, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:06:16,046] Trial 12 finished with value: 0.6172264396902079 and parameters: {'latent_dim': 10, 'hidden_dim': 190, 'lr': 0.00012106086375157779, 'epochs': 39, 'dropout_rate': 0.3623546469229743, 'noise_level': 0.22946172780961227, 'classification_weight': 0.6688865149297979, 'C': 0.5394668562330024, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:06:32,026] Trial 13 finished with value: 0.5396441990644889 and parameters: {'latent_dim': 46, 'hidden_dim': 256, 'lr': 0.0032366192941542184, 'epochs': 34, 'dropout_rate': 0.42749756981685705, 'noise_level': 0.2988719169695565, 'classification_weight': 0.8831186307007429, 'C': 0.026318686176703392, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:06:49,117] Trial 14 finished with value: 0.5780806686603789 and parameters: {'latent_dim': 36, 'hidden_dim': 66, 'lr': 0.0006005611124307162, 'epochs': 43, 'dropout_rate': 0.3461017441316302, 'noise_level': 0.19187782069368933, 'classification_weight': 0.5647096119663059, 'C': 0.05794794037799708, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:07:02,483] Trial 15 finished with value: 0.5288321447741737 and parameters: {'latent_dim': 97, 'hidden_dim': 181, 'lr': 0.0024368804777669204, 'epochs': 28, 'dropout_rate': 0.20264371914387996, 'noise_level': 0.14856779981224455, 'classification_weight': 0.7662304558611593, 'C': 1.0589824938878305, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:07:18,987] Trial 16 finished with value: 0.5960624185261867 and parameters: {'latent_dim': 18, 'hidden_dim': 131, 'lr': 0.0007174726073810577, 'epochs': 40, 'dropout_rate': 0.4529402343860986, 'noise_level': 0.23498962193456222, 'classification_weight': 0.3960993985481652, 'C': 81.86297054499718, 'solver': 'liblinear'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:07:41,824] Trial 17 finished with value: 0.590157963346369 and parameters: {'latent_dim': 62, 'hidden_dim': 202, 'lr': 0.000189370365599139, 'epochs': 50, 'dropout_rate': 0.3966146273901293, 'noise_level': 0.20929103308288557, 'classification_weight': 0.7788717145598383, 'C': 0.4709845043623813, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:07:57,111] Trial 18 finished with value: 0.5581243769649565 and parameters: {'latent_dim': 38, 'hidden_dim': 175, 'lr': 0.002012439600034903, 'epochs': 34, 'dropout_rate': 0.491631547479747, 'noise_level': 0.16338555376937602, 'classification_weight': 0.5244158799413398, 'C': 0.0772474966510101, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.6224982746721877.\n",
      "[I 2025-05-10 11:08:14,825] Trial 19 finished with value: 0.5563607085346215 and parameters: {'latent_dim': 24, 'hidden_dim': 112, 'lr': 0.009459095160849766, 'epochs': 43, 'dropout_rate': 0.10139604190242982, 'noise_level': 0.25184830293472293, 'classification_weight': 0.29000909135706193, 'C': 0.012872388569617099, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.6224982746721877.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6483\n"
     ]
    }
   ],
   "source": [
    "class ClassifyingDenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, dropout_rate=0.2):\n",
    "        super(ClassifyingDenoisingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        classification = self.classifier(latent)\n",
    "        return reconstructed, latent, classification\n",
    "    \n",
    "def train_classifying_denoising_autoencoder(model, X_train, y_train, epochs, batch_size, lr, noise_level=0.1, classification_weight=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    recon_criterion = nn.MSELoss()\n",
    "    class_criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_x, batch_target, batch_y in train_loader:\n",
    "            # Add noise to input data\n",
    "            noisy_batch = batch_x + noise_level * torch.randn_like(batch_x)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _, classification = model(noisy_batch)\n",
    "            \n",
    "            # Reconstruction loss (target is the original data)\n",
    "            recon_loss = recon_criterion(reconstructed, batch_target)\n",
    "            \n",
    "            # Classification loss\n",
    "            class_loss = class_criterion(classification, batch_y)\n",
    "            \n",
    "            # Combined loss with weights\n",
    "            loss = (1 - classification_weight) * recon_loss + classification_weight * class_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_latent_features(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, latent, _ = model(X_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "def get_classification(model, X):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        _, _, classification = model(X_tensor)\n",
    "    return classification.cpu().numpy().flatten()\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5611\n",
      "ROC-AUC autoencoded: 0.5588\n",
      "ROC-AUC autoencoded: 0.5580\n",
      "ROC-AUC autoencoded: 0.5632\n",
      "ROC-AUC autoencoded: 0.5553\n",
      "ROC-AUC autoencoded: 0.6060\n",
      "ROC-AUC autoencoded: 0.5728\n",
      "ROC-AUC autoencoded: 0.6179\n",
      "ROC-AUC autoencoded: 0.5835\n",
      "ROC-AUC autoencoded: 0.5619\n",
      "ROC-AUC autoencoded: 0.5741\n",
      "ROC-AUC autoencoded: 0.5451\n",
      "ROC-AUC autoencoded: 0.6006\n",
      "ROC-AUC autoencoded: 0.5750\n",
      "ROC-AUC autoencoded: 0.5764\n",
      "ROC-AUC autoencoded: 0.5360\n",
      "ROC-AUC autoencoded: 0.5161\n",
      "ROC-AUC autoencoded: 0.5214\n",
      "ROC-AUC autoencoded: 0.5478\n",
      "ROC-AUC autoencoded: 0.4934\n",
      "ROC-AUC autoencoded: 0.6430\n",
      "ROC-AUC autoencoded: 0.6357\n",
      "ROC-AUC autoencoded: 0.6090\n",
      "ROC-AUC autoencoded: 0.6353\n",
      "ROC-AUC autoencoded: 0.6057\n",
      "среднее 0.574121143259872\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        logreg = LogisticRegression(\n",
    "            C=best_params['C'],\n",
    "            solver=best_params['solver'],\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        logreg.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = logreg.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 11:10:09,457] A new study created in memory with name: no-name-e3a42574-7953-40d3-bec6-156dea9b5129\n",
      "[I 2025-05-10 11:11:02,670] Trial 0 finished with value: 0.558143547273982 and parameters: {'latent_dim': 97, 'hidden_dim': 211, 'lr': 0.0013103861902723688, 'epochs': 24, 'dropout_rate': 0.47252236265213277, 'noise_level': 0.12623174181644392, 'classification_weight': 0.8893519352281958, 'n_estimators': 482, 'max_depth': 3, 'learning_rate': 0.01560921567194944, 'subsample': 0.8208124063899469, 'min_samples_split': 13, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.558143547273982.\n",
      "[I 2025-05-10 11:11:46,726] Trial 1 finished with value: 0.5231002223755846 and parameters: {'latent_dim': 29, 'hidden_dim': 207, 'lr': 0.006649542759351199, 'epochs': 42, 'dropout_rate': 0.30078903772382926, 'noise_level': 0.2245719483723011, 'classification_weight': 0.18449611899709206, 'n_estimators': 338, 'max_depth': 5, 'learning_rate': 0.05521766955092921, 'subsample': 0.9675490858037822, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.558143547273982.\n",
      "[I 2025-05-10 11:12:55,755] Trial 2 finished with value: 0.6032321141016793 and parameters: {'latent_dim': 68, 'hidden_dim': 144, 'lr': 0.00017532306117486302, 'epochs': 31, 'dropout_rate': 0.19619563279821556, 'noise_level': 0.2987579092585044, 'classification_weight': 0.4341121887497911, 'n_estimators': 495, 'max_depth': 10, 'learning_rate': 0.11117211925444084, 'subsample': 0.9906975189678282, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:13:17,543] Trial 3 finished with value: 0.5282186948853616 and parameters: {'latent_dim': 24, 'hidden_dim': 121, 'lr': 0.0024706546353311797, 'epochs': 44, 'dropout_rate': 0.13619222257527694, 'noise_level': 0.12496911676559432, 'classification_weight': 0.23457794409055932, 'n_estimators': 61, 'max_depth': 9, 'learning_rate': 0.11905189255197263, 'subsample': 0.7448435554324779, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:13:51,765] Trial 4 finished with value: 0.5742082662372517 and parameters: {'latent_dim': 39, 'hidden_dim': 177, 'lr': 0.00035392007540418314, 'epochs': 23, 'dropout_rate': 0.12339171724269199, 'noise_level': 0.21329133207765338, 'classification_weight': 0.6118628597784097, 'n_estimators': 306, 'max_depth': 7, 'learning_rate': 0.01650770793604799, 'subsample': 0.8550088798886688, 'min_samples_split': 17, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:14:07,362] Trial 5 finished with value: 0.5500728471742964 and parameters: {'latent_dim': 27, 'hidden_dim': 126, 'lr': 0.0006808568498224647, 'epochs': 30, 'dropout_rate': 0.16830072994064504, 'noise_level': 0.27286777611070384, 'classification_weight': 0.36247994378691395, 'n_estimators': 90, 'max_depth': 3, 'learning_rate': 0.03140176448323988, 'subsample': 0.8717628540489144, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:14:35,591] Trial 6 finished with value: 0.5833333333333334 and parameters: {'latent_dim': 41, 'hidden_dim': 82, 'lr': 0.001153459621404492, 'epochs': 20, 'dropout_rate': 0.341415375115616, 'noise_level': 0.1617054457447502, 'classification_weight': 0.6038988706572693, 'n_estimators': 385, 'max_depth': 5, 'learning_rate': 0.0753429588489137, 'subsample': 0.7072201871671284, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:15:34,052] Trial 7 finished with value: 0.5320910973084886 and parameters: {'latent_dim': 69, 'hidden_dim': 206, 'lr': 0.0008657195372618482, 'epochs': 50, 'dropout_rate': 0.3339982993861544, 'noise_level': 0.29883924804827167, 'classification_weight': 0.8393001956137384, 'n_estimators': 376, 'max_depth': 4, 'learning_rate': 0.06626027567126241, 'subsample': 0.689219714623138, 'min_samples_split': 17, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:16:01,099] Trial 8 finished with value: 0.5435741124146921 and parameters: {'latent_dim': 31, 'hidden_dim': 237, 'lr': 0.0012390178910498223, 'epochs': 27, 'dropout_rate': 0.4207680139117206, 'noise_level': 0.16613100892579674, 'classification_weight': 0.4902691931012232, 'n_estimators': 423, 'max_depth': 9, 'learning_rate': 0.1590422464660984, 'subsample': 0.877539867512616, 'min_samples_split': 11, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:16:21,020] Trial 9 finished with value: 0.5578943332566522 and parameters: {'latent_dim': 73, 'hidden_dim': 228, 'lr': 0.001076939459106074, 'epochs': 31, 'dropout_rate': 0.3034544965682947, 'noise_level': 0.12253577678863618, 'classification_weight': 0.26644441568121524, 'n_estimators': 81, 'max_depth': 3, 'learning_rate': 0.08501034232156113, 'subsample': 0.7929334193400511, 'min_samples_split': 17, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:17:04,977] Trial 10 finished with value: 0.5837550801318917 and parameters: {'latent_dim': 99, 'hidden_dim': 151, 'lr': 0.0001075230280637353, 'epochs': 10, 'dropout_rate': 0.2116282879986649, 'noise_level': 0.055777404573727346, 'classification_weight': 0.41013356477437696, 'n_estimators': 198, 'max_depth': 10, 'learning_rate': 0.2574498517589291, 'subsample': 0.6137940907391393, 'min_samples_split': 11, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:17:50,080] Trial 11 finished with value: 0.5843493597116786 and parameters: {'latent_dim': 98, 'hidden_dim': 150, 'lr': 0.00012266977872343377, 'epochs': 12, 'dropout_rate': 0.21403631087973862, 'noise_level': 0.05834129984366943, 'classification_weight': 0.37236655440312083, 'n_estimators': 202, 'max_depth': 10, 'learning_rate': 0.2845932040900667, 'subsample': 0.6055658243635297, 'min_samples_split': 11, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:18:33,783] Trial 12 finished with value: 0.5490951614140019 and parameters: {'latent_dim': 81, 'hidden_dim': 158, 'lr': 0.00010135132112751505, 'epochs': 12, 'dropout_rate': 0.2276746194111124, 'noise_level': 0.06467792644881015, 'classification_weight': 0.6048246840540737, 'n_estimators': 227, 'max_depth': 8, 'learning_rate': 0.28074896152050904, 'subsample': 0.9492023176166344, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:19:27,365] Trial 13 finished with value: 0.5795376121463077 and parameters: {'latent_dim': 59, 'hidden_dim': 99, 'lr': 0.000237402295126829, 'epochs': 34, 'dropout_rate': 0.22475841900621413, 'noise_level': 0.2399654935349998, 'classification_weight': 0.11154776356342777, 'n_estimators': 187, 'max_depth': 10, 'learning_rate': 0.16257910311007986, 'subsample': 0.6184789318738352, 'min_samples_split': 14, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:20:04,213] Trial 14 finished with value: 0.5817230273752013 and parameters: {'latent_dim': 85, 'hidden_dim': 131, 'lr': 0.00020813249295320623, 'epochs': 16, 'dropout_rate': 0.18307367091919327, 'noise_level': 0.09100103250824548, 'classification_weight': 0.37673328286639685, 'n_estimators': 149, 'max_depth': 8, 'learning_rate': 0.03082476508156136, 'subsample': 0.6670653164676141, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:21:03,216] Trial 15 finished with value: 0.5525266467295452 and parameters: {'latent_dim': 53, 'hidden_dim': 173, 'lr': 0.0003922947172381544, 'epochs': 36, 'dropout_rate': 0.25266792952351186, 'noise_level': 0.18798811911647859, 'classification_weight': 0.724791314751249, 'n_estimators': 268, 'max_depth': 10, 'learning_rate': 0.1773018004901341, 'subsample': 0.9925485212584384, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:23:36,898] Trial 16 finished with value: 0.5975960432482171 and parameters: {'latent_dim': 88, 'hidden_dim': 64, 'lr': 0.00018112724229674197, 'epochs': 17, 'dropout_rate': 0.2644489015534107, 'noise_level': 0.26742198282652, 'classification_weight': 0.47442941170612196, 'n_estimators': 487, 'max_depth': 7, 'learning_rate': 0.1063756660511938, 'subsample': 0.9148826799387606, 'min_samples_split': 14, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:25:15,604] Trial 17 finished with value: 0.559542979832835 and parameters: {'latent_dim': 60, 'hidden_dim': 69, 'lr': 0.00020702001907788557, 'epochs': 18, 'dropout_rate': 0.39101756397641607, 'noise_level': 0.2629460993852681, 'classification_weight': 0.4697953604964586, 'n_estimators': 491, 'max_depth': 6, 'learning_rate': 0.09572400442208398, 'subsample': 0.9154174264244967, 'min_samples_split': 14, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:27:24,568] Trial 18 finished with value: 0.5663484395368453 and parameters: {'latent_dim': 85, 'hidden_dim': 102, 'lr': 0.00047499327112298555, 'epochs': 38, 'dropout_rate': 0.26375848902425386, 'noise_level': 0.29886531599410665, 'classification_weight': 0.5387905779161837, 'n_estimators': 444, 'max_depth': 6, 'learning_rate': 0.03789539761496772, 'subsample': 0.9452699466379753, 'min_samples_split': 19, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.6032321141016793.\n",
      "[I 2025-05-10 11:28:04,874] Trial 19 finished with value: 0.5442067326125297 and parameters: {'latent_dim': 14, 'hidden_dim': 66, 'lr': 0.0026917714313185585, 'epochs': 26, 'dropout_rate': 0.1022688916291904, 'noise_level': 0.26517425527535954, 'classification_weight': 0.7031187893831776, 'n_estimators': 449, 'max_depth': 7, 'learning_rate': 0.04312737468886335, 'subsample': 0.9046236822622681, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.6032321141016793.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.5284\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    subsample=best_params['subsample'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5532\n",
      "ROC-AUC autoencoded: 0.5085\n",
      "ROC-AUC autoencoded: 0.5542\n",
      "ROC-AUC autoencoded: 0.6134\n",
      "ROC-AUC autoencoded: 0.5562\n",
      "ROC-AUC autoencoded: 0.5699\n",
      "ROC-AUC autoencoded: 0.5096\n",
      "ROC-AUC autoencoded: 0.5483\n",
      "ROC-AUC autoencoded: 0.5949\n",
      "ROC-AUC autoencoded: 0.5511\n",
      "ROC-AUC autoencoded: 0.5921\n",
      "ROC-AUC autoencoded: 0.5609\n",
      "ROC-AUC autoencoded: 0.5874\n",
      "ROC-AUC autoencoded: 0.5754\n",
      "ROC-AUC autoencoded: 0.5731\n",
      "ROC-AUC autoencoded: 0.5229\n",
      "ROC-AUC autoencoded: 0.5288\n",
      "ROC-AUC autoencoded: 0.4731\n",
      "ROC-AUC autoencoded: 0.5162\n",
      "ROC-AUC autoencoded: 0.5221\n",
      "ROC-AUC autoencoded: 0.6385\n",
      "ROC-AUC autoencoded: 0.6090\n",
      "ROC-AUC autoencoded: 0.5795\n",
      "ROC-AUC autoencoded: 0.6499\n",
      "ROC-AUC autoencoded: 0.6320\n",
      "среднее 0.5648120727170126\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            subsample=best_params['subsample'],\n",
    "            min_samples_split=best_params['min_samples_split'],\n",
    "            min_samples_leaf=best_params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        )\n",
    "        gb.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = gb.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 11:39:47,003] A new study created in memory with name: no-name-195d0708-0c75-4681-87ad-cfcc80d02a80\n",
      "[I 2025-05-10 11:40:06,338] Trial 0 finished with value: 0.5264166858369758 and parameters: {'latent_dim': 93, 'hidden_dim': 245, 'lr': 0.0022845983021262117, 'epochs': 19, 'dropout_rate': 0.2291511849302631, 'noise_level': 0.2300256331016185, 'classification_weight': 0.8290667566096585, 'C': 20.905708812709477, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.5264166858369758.\n",
      "[I 2025-05-10 11:40:29,597] Trial 1 finished with value: 0.5540123456790123 and parameters: {'latent_dim': 50, 'hidden_dim': 133, 'lr': 0.0005522115040894249, 'epochs': 28, 'dropout_rate': 0.28974865993487986, 'noise_level': 0.2366078826440225, 'classification_weight': 0.6344121795377521, 'C': 88.37853973764302, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.5540123456790123.\n",
      "[I 2025-05-10 11:40:59,957] Trial 2 finished with value: 0.534650333563377 and parameters: {'latent_dim': 42, 'hidden_dim': 144, 'lr': 0.0037918798846520276, 'epochs': 34, 'dropout_rate': 0.1050224776893137, 'noise_level': 0.13051246529233068, 'classification_weight': 0.4287238169969426, 'C': 0.18050782486974282, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.5540123456790123.\n",
      "[I 2025-05-10 11:41:27,419] Trial 3 finished with value: 0.5461237635150678 and parameters: {'latent_dim': 51, 'hidden_dim': 93, 'lr': 0.0013955339767244169, 'epochs': 34, 'dropout_rate': 0.2515423830443412, 'noise_level': 0.18306740565030022, 'classification_weight': 0.14475438706710142, 'C': 3.6193903310092805, 'kernel': 'linear'}. Best is trial 1 with value: 0.5540123456790123.\n",
      "[I 2025-05-10 11:41:51,616] Trial 4 finished with value: 0.5947971781305115 and parameters: {'latent_dim': 52, 'hidden_dim': 176, 'lr': 0.0017816861106373693, 'epochs': 33, 'dropout_rate': 0.3225755863916767, 'noise_level': 0.274501300369001, 'classification_weight': 0.1426762524648525, 'C': 0.3672372608152738, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 4 with value: 0.5947971781305115.\n",
      "[I 2025-05-10 11:42:16,230] Trial 5 finished with value: 0.5340081282110267 and parameters: {'latent_dim': 96, 'hidden_dim': 146, 'lr': 0.001641358702167042, 'epochs': 33, 'dropout_rate': 0.10894018529362129, 'noise_level': 0.12161230705882424, 'classification_weight': 0.8768043420986581, 'C': 11.906534847835221, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 4 with value: 0.5947971781305115.\n",
      "[I 2025-05-10 11:42:51,357] Trial 6 finished with value: 0.570700099685607 and parameters: {'latent_dim': 60, 'hidden_dim': 205, 'lr': 0.0007945049726232481, 'epochs': 45, 'dropout_rate': 0.49778701273772874, 'noise_level': 0.06396837975278626, 'classification_weight': 0.46476087460636994, 'C': 0.6746922769809944, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 4 with value: 0.5947971781305115.\n",
      "[I 2025-05-10 11:43:11,988] Trial 7 finished with value: 0.6269170309025381 and parameters: {'latent_dim': 25, 'hidden_dim': 158, 'lr': 0.0002664662326451994, 'epochs': 25, 'dropout_rate': 0.3056817767762767, 'noise_level': 0.16715906908532568, 'classification_weight': 0.28434870637881604, 'C': 0.10865522298515162, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 7 with value: 0.6269170309025381.\n",
      "[I 2025-05-10 11:43:39,311] Trial 8 finished with value: 0.6122229890345833 and parameters: {'latent_dim': 36, 'hidden_dim': 179, 'lr': 0.0012091498339521656, 'epochs': 32, 'dropout_rate': 0.48791236611571664, 'noise_level': 0.08265888532328623, 'classification_weight': 0.15473853274814742, 'C': 0.12419064570151339, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 7 with value: 0.6269170309025381.\n",
      "[I 2025-05-10 11:44:05,520] Trial 9 finished with value: 0.5307587608312246 and parameters: {'latent_dim': 84, 'hidden_dim': 245, 'lr': 0.0010677730924624153, 'epochs': 28, 'dropout_rate': 0.3004799496540762, 'noise_level': 0.10830016731263024, 'classification_weight': 0.6588863556435158, 'C': 33.4889153454913, 'kernel': 'poly', 'gamma': 'scale', 'degree': 5}. Best is trial 7 with value: 0.6269170309025381.\n",
      "[I 2025-05-10 11:44:15,715] Trial 10 finished with value: 0.4585346215780998 and parameters: {'latent_dim': 12, 'hidden_dim': 67, 'lr': 0.00014344630878135846, 'epochs': 12, 'dropout_rate': 0.4095922458047047, 'noise_level': 0.18119674091176952, 'classification_weight': 0.3186679380021149, 'C': 1.4426641037254222, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 7 with value: 0.6269170309025381.\n",
      "[I 2025-05-10 11:44:34,059] Trial 11 finished with value: 0.6122421593436086 and parameters: {'latent_dim': 22, 'hidden_dim': 193, 'lr': 0.000259350032776989, 'epochs': 22, 'dropout_rate': 0.49428501387778834, 'noise_level': 0.05175232626437467, 'classification_weight': 0.2964171702070502, 'C': 0.13656842904187258, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 7 with value: 0.6269170309025381.\n",
      "[I 2025-05-10 11:44:53,129] Trial 12 finished with value: 0.6144467448815275 and parameters: {'latent_dim': 13, 'hidden_dim': 207, 'lr': 0.00023608761560445302, 'epochs': 21, 'dropout_rate': 0.40734549856915114, 'noise_level': 0.14989802340451144, 'classification_weight': 0.32000573052330294, 'C': 0.10788815052280225, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 7 with value: 0.6269170309025381.\n",
      "[I 2025-05-10 11:45:09,549] Trial 13 finished with value: 0.5850203205275669 and parameters: {'latent_dim': 26, 'hidden_dim': 206, 'lr': 0.00027482848627645857, 'epochs': 17, 'dropout_rate': 0.36055573075350605, 'noise_level': 0.1484584125255136, 'classification_weight': 0.306797482870407, 'C': 0.42174084285672286, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 7 with value: 0.6269170309025381.\n",
      "[I 2025-05-10 11:45:29,133] Trial 14 finished with value: 0.591710758377425 and parameters: {'latent_dim': 12, 'hidden_dim': 118, 'lr': 0.00010040229279592842, 'epochs': 23, 'dropout_rate': 0.40781368727842326, 'noise_level': 0.20825404890803284, 'classification_weight': 0.3774912176789943, 'C': 2.681291899759716, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 7 with value: 0.6269170309025381.\n",
      "[I 2025-05-10 11:45:40,474] Trial 15 finished with value: 0.6198815274902233 and parameters: {'latent_dim': 72, 'hidden_dim': 167, 'lr': 0.00031352070720950994, 'epochs': 11, 'dropout_rate': 0.19544603656026222, 'noise_level': 0.15944988536205207, 'classification_weight': 0.5412175385542349, 'C': 0.9536625125662305, 'kernel': 'linear'}. Best is trial 7 with value: 0.6269170309025381.\n",
      "[I 2025-05-10 11:45:50,922] Trial 16 finished with value: 0.5885668276972624 and parameters: {'latent_dim': 71, 'hidden_dim': 158, 'lr': 0.0004783912250905256, 'epochs': 10, 'dropout_rate': 0.18445765051474639, 'noise_level': 0.1642354260611971, 'classification_weight': 0.5496633313069045, 'C': 1.0874413827969973, 'kernel': 'linear'}. Best is trial 7 with value: 0.6269170309025381.\n",
      "[I 2025-05-10 11:46:23,084] Trial 17 finished with value: 0.5414845487309256 and parameters: {'latent_dim': 67, 'hidden_dim': 116, 'lr': 0.00930467260643418, 'epochs': 40, 'dropout_rate': 0.17744451625204677, 'noise_level': 0.2906463365199063, 'classification_weight': 0.5716329130090361, 'C': 6.8665555892264685, 'kernel': 'linear'}. Best is trial 7 with value: 0.6269170309025381.\n",
      "[I 2025-05-10 11:46:37,648] Trial 18 finished with value: 0.5841672417759375 and parameters: {'latent_dim': 78, 'hidden_dim': 226, 'lr': 0.00036937056303167195, 'epochs': 15, 'dropout_rate': 0.185452793825557, 'noise_level': 0.19757939194846494, 'classification_weight': 0.23079742692133484, 'C': 0.32522489512010333, 'kernel': 'linear'}. Best is trial 7 with value: 0.6269170309025381.\n",
      "[I 2025-05-10 11:47:20,339] Trial 19 finished with value: 0.5647189632696878 and parameters: {'latent_dim': 36, 'hidden_dim': 169, 'lr': 0.0001645872896801535, 'epochs': 50, 'dropout_rate': 0.2567583189124994, 'noise_level': 0.09689594604389731, 'classification_weight': 0.735983396276407, 'C': 1.8524858334912158, 'kernel': 'linear'}. Best is trial 7 with value: 0.6269170309025381.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6256\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto']) if kernel in ['rbf', 'poly', 'sigmoid'] else 'scale'\n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            degree=degree,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "X_train_latent = get_latent_features(autoencoder, X_train_all)\n",
    "X_val_latent = get_latent_features(autoencoder, X_val_all)\n",
    "\n",
    "svc = SVC(\n",
    "    C=best_params['C'],\n",
    "    kernel=best_params['kernel'],\n",
    "    gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "    degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "svc.fit(X_train_latent, y_all_train)\n",
    "\n",
    "y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5450\n",
      "ROC-AUC autoencoded: 0.5595\n",
      "ROC-AUC autoencoded: 0.5351\n",
      "ROC-AUC autoencoded: 0.5702\n",
      "ROC-AUC autoencoded: 0.5490\n",
      "ROC-AUC autoencoded: 0.6230\n",
      "ROC-AUC autoencoded: 0.5551\n",
      "ROC-AUC autoencoded: 0.5625\n",
      "ROC-AUC autoencoded: 0.5544\n",
      "ROC-AUC autoencoded: 0.5588\n",
      "ROC-AUC autoencoded: 0.6137\n",
      "ROC-AUC autoencoded: 0.5819\n",
      "ROC-AUC autoencoded: 0.5684\n",
      "ROC-AUC autoencoded: 0.5830\n",
      "ROC-AUC autoencoded: 0.5859\n",
      "ROC-AUC autoencoded: 0.5417\n",
      "ROC-AUC autoencoded: 0.5482\n",
      "ROC-AUC autoencoded: 0.5313\n",
      "ROC-AUC autoencoded: 0.5195\n",
      "ROC-AUC autoencoded: 0.4868\n",
      "ROC-AUC autoencoded: 0.6375\n",
      "ROC-AUC autoencoded: 0.6105\n",
      "ROC-AUC autoencoded: 0.5751\n",
      "ROC-AUC autoencoded: 0.6125\n",
      "ROC-AUC autoencoded: 0.6256\n",
      "среднее 0.569370595962708\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        X_train_latent = get_latent_features(autoencoder, X_train)\n",
    "        X_val_latent = get_latent_features(autoencoder, X_val)\n",
    "        \n",
    "        svc = SVC(\n",
    "            C=best_params['C'],\n",
    "            kernel=best_params['kernel'],\n",
    "            gamma=best_params['gamma'] if 'gamma' in best_params else 'scale',\n",
    "            degree=best_params['degree'] if 'degree' in best_params else 3,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        svc.fit(X_train_latent, y_train)\n",
    "        \n",
    "        y_pred_proba = svc.predict_proba(X_val_latent)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 11:49:53,115] A new study created in memory with name: no-name-a6e1364b-1a74-4fb6-bf53-83873919e10e\n",
      "[I 2025-05-10 11:50:25,542] Trial 0 finished with value: 0.575780231577333 and parameters: {'latent_dim': 19, 'hidden_dim': 117, 'lr': 0.0004168617690114259, 'epochs': 41, 'dropout_rate': 0.16855010999706688, 'noise_level': 0.14801122421296492, 'classification_weight': 0.4827756801964076}. Best is trial 0 with value: 0.575780231577333.\n",
      "[I 2025-05-10 11:50:43,466] Trial 1 finished with value: 0.5938003220611917 and parameters: {'latent_dim': 27, 'hidden_dim': 216, 'lr': 0.001065584234095018, 'epochs': 21, 'dropout_rate': 0.47504974615026097, 'noise_level': 0.10657983995878952, 'classification_weight': 0.4003613550345003}. Best is trial 1 with value: 0.5938003220611917.\n",
      "[I 2025-05-10 11:51:02,249] Trial 2 finished with value: 0.6074495820872632 and parameters: {'latent_dim': 88, 'hidden_dim': 96, 'lr': 0.0007417885664433373, 'epochs': 24, 'dropout_rate': 0.2957460683291744, 'noise_level': 0.2534032016234189, 'classification_weight': 0.38969254679061205}. Best is trial 2 with value: 0.6074495820872632.\n",
      "[I 2025-05-10 11:51:15,725] Trial 3 finished with value: 0.6217889732382486 and parameters: {'latent_dim': 67, 'hidden_dim': 226, 'lr': 0.00010160335896796192, 'epochs': 14, 'dropout_rate': 0.1957903419857271, 'noise_level': 0.10691608098691487, 'classification_weight': 0.2721808790088891}. Best is trial 3 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 11:51:38,003] Trial 4 finished with value: 0.5572808833678399 and parameters: {'latent_dim': 16, 'hidden_dim': 166, 'lr': 0.0026760205287040114, 'epochs': 26, 'dropout_rate': 0.23660886534068168, 'noise_level': 0.05204249123287068, 'classification_weight': 0.14744478358502253}. Best is trial 3 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 11:52:21,289] Trial 5 finished with value: 0.615175216624492 and parameters: {'latent_dim': 53, 'hidden_dim': 231, 'lr': 0.00016850172184542368, 'epochs': 48, 'dropout_rate': 0.3815920716484774, 'noise_level': 0.12674060055275976, 'classification_weight': 0.14434886189917934}. Best is trial 3 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 11:52:37,423] Trial 6 finished with value: 0.5896403650026838 and parameters: {'latent_dim': 41, 'hidden_dim': 146, 'lr': 0.006161831852223016, 'epochs': 20, 'dropout_rate': 0.49206172106276713, 'noise_level': 0.1945379582886494, 'classification_weight': 0.6286427711216442}. Best is trial 3 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 11:53:15,651] Trial 7 finished with value: 0.5405643738977072 and parameters: {'latent_dim': 73, 'hidden_dim': 251, 'lr': 0.0007982485699512944, 'epochs': 40, 'dropout_rate': 0.11997649531588164, 'noise_level': 0.17084722742835512, 'classification_weight': 0.20656489796127292}. Best is trial 3 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 11:53:47,300] Trial 8 finished with value: 0.5351008358254735 and parameters: {'latent_dim': 57, 'hidden_dim': 175, 'lr': 0.007919587227248913, 'epochs': 38, 'dropout_rate': 0.14181652428424307, 'noise_level': 0.19313477722119105, 'classification_weight': 0.5495480673027608}. Best is trial 3 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 11:54:05,081] Trial 9 finished with value: 0.5555555555555555 and parameters: {'latent_dim': 10, 'hidden_dim': 136, 'lr': 0.005657969217330136, 'epochs': 23, 'dropout_rate': 0.12293597981977791, 'noise_level': 0.11712799153049959, 'classification_weight': 0.8470128452001197}. Best is trial 3 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 11:54:14,725] Trial 10 finished with value: 0.6023886205045625 and parameters: {'latent_dim': 98, 'hidden_dim': 198, 'lr': 0.0001464719687931656, 'epochs': 12, 'dropout_rate': 0.23178125078596393, 'noise_level': 0.05102132491072428, 'classification_weight': 0.31138828222519843}. Best is trial 3 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 11:54:50,440] Trial 11 finished with value: 0.6115711985277202 and parameters: {'latent_dim': 60, 'hidden_dim': 254, 'lr': 0.00011800475104451945, 'epochs': 50, 'dropout_rate': 0.3878194482588467, 'noise_level': 0.11210100681467461, 'classification_weight': 0.10357864109217166}. Best is trial 3 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 11:54:58,487] Trial 12 finished with value: 0.619948623571812 and parameters: {'latent_dim': 71, 'hidden_dim': 220, 'lr': 0.00023143886180680142, 'epochs': 10, 'dropout_rate': 0.3652896478888936, 'noise_level': 0.08531640670177953, 'classification_weight': 0.2597752192321862}. Best is trial 3 with value: 0.6217889732382486.\n",
      "[I 2025-05-10 11:55:07,543] Trial 13 finished with value: 0.6250862663906142 and parameters: {'latent_dim': 75, 'hidden_dim': 194, 'lr': 0.000291421023578427, 'epochs': 11, 'dropout_rate': 0.3685349809534449, 'noise_level': 0.08323772250652811, 'classification_weight': 0.27383633066877444}. Best is trial 13 with value: 0.6250862663906142.\n",
      "[I 2025-05-10 11:55:20,750] Trial 14 finished with value: 0.6112261329652635 and parameters: {'latent_dim': 79, 'hidden_dim': 203, 'lr': 0.0003147132496680159, 'epochs': 15, 'dropout_rate': 0.3121946605011237, 'noise_level': 0.08184771576710036, 'classification_weight': 0.31873058826116774}. Best is trial 13 with value: 0.6250862663906142.\n",
      "[I 2025-05-10 11:55:34,053] Trial 15 finished with value: 0.6241085806303198 and parameters: {'latent_dim': 44, 'hidden_dim': 183, 'lr': 0.00011381293894574117, 'epochs': 16, 'dropout_rate': 0.20940516521992747, 'noise_level': 0.29811020640929486, 'classification_weight': 0.6850574519973498}. Best is trial 13 with value: 0.6250862663906142.\n",
      "[I 2025-05-10 11:55:58,820] Trial 16 finished with value: 0.5782148608235566 and parameters: {'latent_dim': 44, 'hidden_dim': 185, 'lr': 0.00043537670589948054, 'epochs': 31, 'dropout_rate': 0.30156514237041904, 'noise_level': 0.2963329205645025, 'classification_weight': 0.7547348452115417}. Best is trial 13 with value: 0.6250862663906142.\n",
      "[I 2025-05-10 11:56:12,606] Trial 17 finished with value: 0.6346330802852541 and parameters: {'latent_dim': 36, 'hidden_dim': 152, 'lr': 0.00025733819996485367, 'epochs': 17, 'dropout_rate': 0.42720170637093324, 'noise_level': 0.24498262010761748, 'classification_weight': 0.6862205049690708}. Best is trial 17 with value: 0.6346330802852541.\n",
      "[I 2025-05-10 11:56:36,593] Trial 18 finished with value: 0.5620351200061345 and parameters: {'latent_dim': 32, 'hidden_dim': 138, 'lr': 0.001955949233634413, 'epochs': 31, 'dropout_rate': 0.4377869007933928, 'noise_level': 0.24432557479822348, 'classification_weight': 0.828300485957802}. Best is trial 17 with value: 0.6346330802852541.\n",
      "[I 2025-05-10 11:56:49,915] Trial 19 finished with value: 0.6393106356874473 and parameters: {'latent_dim': 85, 'hidden_dim': 67, 'lr': 0.0002379665643763768, 'epochs': 18, 'dropout_rate': 0.41560302901831575, 'noise_level': 0.22825798785825938, 'classification_weight': 0.5597016329571369}. Best is trial 19 with value: 0.6393106356874473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded bigset: 0.6176\n"
     ]
    }
   ],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 10, 100)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = 32\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    noise_level = trial.suggest_float('noise_level', 0.05, 0.3)\n",
    "    classification_weight = trial.suggest_float('classification_weight', 0.1, 0.9)\n",
    "    \n",
    "    rocs = []\n",
    "    for i in range(3):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], latent_dim, hidden_dim, dropout_rate)\n",
    "        autoencoder = train_classifying_denoising_autoencoder(autoencoder, X_train, y_train, epochs, batch_size, lr, noise_level, classification_weight)\n",
    "        \n",
    "        y_pred_proba = get_classification(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "    return np.mean(rocs)\n",
    "\n",
    "# Блок 1: оптимизация на валидации\n",
    "ss = StandardScaler()\n",
    "X_train_all = ss.fit_transform(X_train_all_)\n",
    "X_val_all = ss.transform(X_val_all_)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_train_all, y_all_train, X_val_all, y_val), n_trials=20)\n",
    "\n",
    "best_params = study.best_params\n",
    "autoencoder = ClassifyingDenoisingAutoencoder(X_train_all.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "autoencoder = train_classifying_denoising_autoencoder(\n",
    "    autoencoder, X_train_all, y_all_train, best_params['epochs'], 32, \n",
    "    best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    ")\n",
    "\n",
    "y_pred_proba = get_classification(autoencoder, X_val_all)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "print(f'ROC-AUC autoencoded bigset: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC autoencoded: 0.5401\n",
      "ROC-AUC autoencoded: 0.5755\n",
      "ROC-AUC autoencoded: 0.5144\n",
      "ROC-AUC autoencoded: 0.5671\n",
      "ROC-AUC autoencoded: 0.5084\n",
      "ROC-AUC autoencoded: 0.5502\n",
      "ROC-AUC autoencoded: 0.5479\n",
      "ROC-AUC autoencoded: 0.5546\n",
      "ROC-AUC autoencoded: 0.5082\n",
      "ROC-AUC autoencoded: 0.5485\n",
      "ROC-AUC autoencoded: 0.5749\n",
      "ROC-AUC autoencoded: 0.5676\n",
      "ROC-AUC autoencoded: 0.6232\n",
      "ROC-AUC autoencoded: 0.5867\n",
      "ROC-AUC autoencoded: 0.5528\n",
      "ROC-AUC autoencoded: 0.4914\n",
      "ROC-AUC autoencoded: 0.5465\n",
      "ROC-AUC autoencoded: 0.5576\n",
      "ROC-AUC autoencoded: 0.5275\n",
      "ROC-AUC autoencoded: 0.5099\n",
      "ROC-AUC autoencoded: 0.6143\n",
      "ROC-AUC autoencoded: 0.6605\n",
      "ROC-AUC autoencoded: 0.6173\n",
      "ROC-AUC autoencoded: 0.6637\n",
      "ROC-AUC autoencoded: 0.6074\n",
      "среднее 0.5646470674025474\n"
     ]
    }
   ],
   "source": [
    "# Блок 2: кросс-валидация\n",
    "rocs = []\n",
    "for i in range(1, 6):\n",
    "    train_snp = pd.read_csv(f\"./csv/train_{i}_snp_selected.csv\")\n",
    "    test_snp = pd.read_csv(f\"./csv/test_{i}_snp_selected.csv\")\n",
    "\n",
    "    X_train_ = train_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    X_val_ = test_snp.drop(columns=[\"Unnamed: 0\", \"target\"]).to_numpy()\n",
    "    y_train = train_snp[\"target\"] - 1\n",
    "    y_test = test_snp[\"target\"] - 1\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train_)\n",
    "    X_val = ss.transform(X_val_)\n",
    "    \n",
    "    for j in range(5):\n",
    "        autoencoder = ClassifyingDenoisingAutoencoder(X_train.shape[1], best_params['latent_dim'], best_params['hidden_dim'], best_params['dropout_rate'])\n",
    "        autoencoder = train_classifying_denoising_autoencoder(\n",
    "            autoencoder, X_train, y_train, best_params['epochs'], 32, \n",
    "            best_params['lr'], best_params['noise_level'], best_params['classification_weight']\n",
    "        )\n",
    "        \n",
    "        y_pred_proba = get_classification(autoencoder, X_val)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        rocs.append(roc_auc)\n",
    "        print(f'ROC-AUC autoencoded: {roc_auc:.4f}')\n",
    "print(\"среднее\", np.mean(rocs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_dipl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
